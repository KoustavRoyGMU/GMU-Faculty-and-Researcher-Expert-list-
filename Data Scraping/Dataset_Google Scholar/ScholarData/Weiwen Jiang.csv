titles,authors,date,source,descriptions,citations
Accuracy vs. efficiency: Achieving both through fpga-implementation aware neural architecture search,"Weiwen Jiang, Xinyi Zhang, Edwin H-M Sha, Lei Yang, Qingfeng Zhuge, Yiyu Shi, Jingtong Hu",2019/6/2,Book (Best Paper Nomination) Proceedings of the 56th Annual Design Automation Conference 2019,"A fundamental question lies in almost every application of deep neural networks: what is the optimal neural architecture given a specific data set? Recently, several Neural Architecture Search (NAS) frameworks have been developed that use reinforcement learning and evolutionary algorithm to search for the solution. However, most of them take a long time to find the optimal architecture due to the huge search space and the lengthy training process needed to evaluate each candidate. In addition, most of them aim at accuracy only and do not take into consideration the hardware that will be used to implement the architecture. This will potentially lead to excessive latencies beyond specifications, rendering the resulting architectures useless. To address both issues, in this paper we use Field Programmable Gate Arrays (FPGAs) as a vehicle to present a novel hardware-aware NAS framework, namely FNAS, which …",130
Hardware/software co-exploration of neural architectures,"Weiwen Jiang, Lei Yang, Edwin Hsing-Mean Sha, Qingfeng Zhuge, Shouzhen Gu, Sakyasingha Dasgupta, Yiyu Shi, Jingtong Hu",2020/4/8,Journal (Best Paper Award) IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,"We propose a novel hardware and software co-exploration framework for efficient neural architecture search (NAS). Different from existing hardware-aware NAS which assumes a fixed hardware design and explores the NAS space only, our framework simultaneously explores both the architecture search space and the hardware design space to identify the best neural architecture and hardware pairs that maximize both test accuracy and hardware efficiency. Such a practice greatly opens up the design freedom and pushes forward the Pareto frontier between hardware efficiency and test accuracy for better design tradeoffs. The framework iteratively performs a two-level (fast and slow) exploration. Without lengthy training, the fast exploration can effectively fine-tune hyperparameters and prune inferior architectures in terms of hardware specifications, which significantly accelerates the NAS process. Then, the slow …",114
Co-exploration of neural architectures and heterogeneous asic accelerator designs targeting multiple tasks,"Lei Yang, Zheyu Yan, Meng Li, Hyoukjun Kwon, Liangzhen Lai, Tushar Krishna, Vikas Chandra, Weiwen Jiang, Yiyu Shi",2020/7/20,Conference 2020 57th ACM/IEEE Design Automation Conference (DAC),"Neural Architecture Search (NAS) has demonstrated its power on various AI accelerating platforms such as Field Programmable Gate Arrays (FPGAs) and Graphic Processing Units (GPUs). However, it remains an open problem how to integrate NAS with Application-Specific Integrated Circuits (ASICs), despite them being the most powerful AI accelerating platforms. The major bottleneck comes from the large design freedom associated with ASIC designs. Moreover, with the consideration that multiple DNNs will run in parallel for different workloads with diverse layer operations and sizes, integrating heterogeneous ASIC sub-accelerators for distinct DNNs in one design can significantly boost performance, and at the same time further complicate the design space. To address these challenges, in this paper we build ASIC template set based on existing successful designs, described by their unique dataflows, so that …",91
Achieving super-linear speedup across multi-fpga for real-time dnn inference,"Weiwen Jiang, Edwin H-M Sha, Xinyi Zhang, Lei Yang, Qingfeng Zhuge, Yiyu Shi, Jingtong Hu",2019/10/8,Journal (Best Paper Nomination @ CODES+ISSS'19) ACM Transactions on Embedded Computing Systems (TECS),"Real-time Deep Neural Network (DNN) inference with low-latency requirement has become increasingly important for numerous applications in both cloud computing (e.g., Apple’s Siri) and edge computing (e.g., Google/Waymo’s driverless car). FPGA-based DNN accelerators have demonstrated both superior flexibility and performance; in addition, for real-time inference with low batch size, FPGA is expected to achieve further performance improvement. However, the performance gain from the single-FPGA design is obstructed by the limited on-chip resource. In this paper, we employ multiple FPGAs to cooperatively run DNNs with the objective of achieving super-linear speed-up against single-FPGA design. In implementing such systems, we found two barriers that hinder us from achieving the design goal: (1) the lack of a clear partition scheme for each DNN layer to fully exploit parallelism, and (2) the insufficient …",68
On neural architecture search for resource-constrained hardware platforms,"Qing Lu, Weiwen Jiang, Xiaowei Xu, Yiyu Shi, Jingtong Hu",2019/10/31,Journal arXiv preprint arXiv:1911.00105,"In the recent past, the success of Neural Architecture Search (NAS) has enabled researchers to broadly explore the design space using learning-based methods. Apart from finding better neural network architectures, the idea of automation has also inspired to improve their implementations on hardware. While some practices of hardware machine-learning automation have achieved remarkable performance, the traditional design concept is still followed: a network architecture is first structured with excellent test accuracy, and then compressed and optimized to fit into a target platform. Such a design flow will easily lead to inferior local-optimal solutions. To address this problem, we propose a new framework to jointly explore the space of neural architecture, hardware implementation, and quantization. Our objective is to find a quantized architecture with the highest accuracy that is implementable on given hardware specifications. We employ FPGAs to implement and test our designs with limited loop-up tables (LUTs) and required throughput. Compared to the separate design/searching methods, our framework has demonstrated much better performance under strict specifications and generated designs of higher accuracy by 18\% to 68\% in the task of classifying CIFAR10 images. With 30,000 LUTs, a light-weight design is found to achieve 82.98\% accuracy and 1293 images/second throughput, compared to which, under the same constraints, the traditional method even fails to find a valid solution.",67
A new design of in-memory file system based on file virtual address framework,"Edwin H-M Sha, Xianzhang Chen, Qingfeng Zhuge, Liang Shi, Weiwen Jiang",2016/1/8,Journal (Editor’s pick of the year 2016) IEEE Transactions on Computers,"The emerging technologies of persistent memory, such as PCM, MRAM, provide opportunities for preserving files in memory. Traditional file system structures may need to be re-studied. Even though there are several file systems proposed for memory, most of them have limited performance without fully utilizing the hardware at the processor side. This paper presents a framework based on a new concept, “File Virtual Address Space”. A file system, Sustainable In-Memory File System (SIMFS), is designed and implemented, which fully utilizes the memory mapping hardware at the file access path. First, SIMFS embeds the address space of an open file into the process' address space. Then, file accesses are handled by the memory mapping hardware. Several optimization approaches are also presented for the proposed SIMFS. Extensive experiments are conducted. The experimental results show that the throughput …",62
Standing on the shoulders of giants: Hardware and neural architecture co-search with hot start,"Weiwen Jiang, Lei Yang, Sakyasingha Dasgupta, Jingtong Hu, Yiyu Shi",2020/10/2,Journal IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,"Hardware and neural architecture co-search that automatically generates artificial intelligence (AI) solutions from a given dataset are promising to promote AI democratization; however, the amount of time that is required by current co-search frameworks is in the order of hundreds of GPU hours for one target hardware. This inhibits the use of such frameworks on commodity hardware. The root cause of the low efficiency in existing co-search frameworks is the fact that they start from a “cold” state (i.e., search from scratch). In this article, we propose a novel framework, namely, HotNAS, that starts from a “hot” state based on a set of existing pretrained models (also known as model zoo) to avoid lengthy training time. As such, the search time can be reduced from 200 GPU hours to less than 3 GPU hours. In HotNAS, in addition to hardware design space and neural architecture search space, we further integrate a …",54
Device-circuit-architecture co-exploration for computing-in-memory neural accelerators,"Weiwen Jiang, Qiuwen Lou, Zheyu Yan, Lei Yang, Jingtong Hu, Xiaobo Sharon Hu, Yiyu Shi",2020/4/30,Journal IEEE Transactions on Computers,"Co-exploration of neural architectures and hardware design is promising due to its capability to simultaneously optimize network accuracy and hardware efficiency. However, state-of-the-art neural architecture search algorithms for the co-exploration are dedicated for the conventional von-Neumann computing architecture, whose performance is heavily limited by the well-known memory wall. In this article, we are the first to bring the computing-in-memory architecture, which can easily transcend the memory wall, to interplay with the neural architecture search, aiming to find the most efficient neural architectures with high network accuracy and maximized hardware efficiency. Such a novel combination makes opportunities to boost performance, but also brings a bunch of challenges: The optimization space spans across multiple design layers from device type and circuit topology to neural architecture; and the …",51
A Co-Design Framework of Neural Networks and Quantum Circuits Towards Quantum Advantage,"Weiwen Jiang, Jinjun Xiong, Yiyu Shi",2021/1/4,Journal Nature Communications,"Despite the pursuit of quantum advantages in various applications, the power of quantum computers in executing neural network has mostly remained unknown, primarily due to a missing tool that effectively designs a neural network suitable for quantum circuit. Here, we present a neural network and quantum circuit co-design framework, namely QuantumFlow, to address the issue. In QuantumFlow, we represent data as unitary matrices to exploit quantum power by encoding n = 2k inputs into k qubits and representing data as random variables to seamlessly connect layers without measurement. Coupled with a novel algorithm, the cost complexity of the unitary matrices-based neural computation can be reduced from O(n) in classical computing to O(polylog(n)) in quantum computing. Results show that on MNIST dataset, QuantumFlow can achieve an accuracy of 94.09% with a cost reduction of 10.85 × against …",46
Ms-nas: Multi-scale neural architecture search for medical image segmentation,"Xingang Yan, Weiwen Jiang, Yiyu Shi, Cheng Zhuo",2020,"Conference Medical Image Computing and Computer Assisted Intervention–MICCAI 2020: 23rd International Conference, Lima, Peru, October 4–8, 2020, Proceedings, Part I 23","The recent breakthroughs of Neural Architecture Search (NAS) have motivated various applications in medical image segmentation. However, most existing work either simply rely on hyper-parameter tuning or stick to a fixed network backbone, thereby limiting the underlying search space to identify more efficient architecture. This paper presents a Multi-Scale NAS (MS-NAS) framework that is featured with multi-scale search space from network backbone to cell operation, and multi-scale fusion capability to fuse features with different sizes. To mitigate the computational overhead due to the larger search space, a partial channel connection scheme and a two-step decoding method are utilized to reduce computational overhead while maintaining optimization quality. Experimental results show that on various datasets for segmentation, MS-NAS outperforms the state-of-the-art methods and achieves 0.6–5.4 …",41
Application mapping and scheduling for network-on-chip-based multiprocessor system-on-chip with fine-grain communication optimization,"Lei Yang, Weichen Liu, Weiwen Jiang, Mengquan Li, Juan Yi, Edwin Hsing-Mean Sha",2016/3/15,Journal IEEE Transactions on Very Large Scale Integration (VLSI) Systems,"Network-on-chip (NoC) is promising for the communication paradigm of the next-generation multiprocessor system-on-chip (MPSoC). As communication has become an integral part of on-chip computing, and even the performance bottleneck, researchers are paying much attention to its implementation and optimization. Traditional techniques that model communication inaccurately will lead to unexpected runtime performance, which is on average 90.8% worse than the predicted results based on observation, and are not suitable for the deep optimization of communication-intensive scenarios. In this paper, techniques are presented for the NoC-based MPSoCs that integrate optimization on interprocessor communications with the objective of minimizing the schedule length. A fine-grained integer-linear programming (ILP) model is proposed to properly address the communication latency with a network contention …",38
FoToNoC: A folded torus-like network-on-chip based many-core systems-on-chip in the dark silicon era,"Lei Yang, Weichen Liu, Weiwen Jiang, Mengquan Li, Peng Chen, Edwin Hsing-Mean Sha",2016/12/22,Journal IEEE Transactions on Parallel and Distributed Systems,"Dark silicon refers to the phenomenon that a fraction of a many-core chip has to become “dark” or “dim” in order to guarantee the system to be kept in a safe temperature range and allowable power budget. Techniques have been developed to selectively activate non-adjacent cores on many-core chip to avoid temperature hotspot, while resulting unexpected increase of communication overhead due to the longer average distance between active cores, and in turn affecting application performance and energy efficiency, when Network-on-Chip (NoC) is used as a scalable communication subsystem. To address the brand-new challenges brought by dark silicon, in this paper, we present FoToNoC, a Folded Torus-like NoC, coupled with a hierarchical management strategy for heterogeneous many-core systems. On top of it, objectives of maximizing application performance, energy efficiency and chip reliability are …",34
Accelerating transformer-based deep learning models on fpgas using column balanced block pruning,"Hongwu Peng, Shaoyi Huang, Tong Geng, Ang Li, Weiwen Jiang, Hang Liu, Shusen Wang, Caiwen Ding",2021/4/7,Conference 2021 22nd International Symposium on Quality Electronic Design (ISQED),"Although Transformer-based language representations achieve state-of-the-art accuracy on various natural language processing (NLP) tasks, the large model size has been challenging the resource constrained computing platforms. Weight pruning, as a popular and effective technique in reducing the number of weight parameters and accelerating the Transformer, has been investigated on GPUs. However, the Transformer acceleration using weight pruning on field-programmable gate array (FPGAs) remains unexplored. This paper investigates the column balanced block-wise pruning on Transformer and designs an FPGA acceleration engine to customize the balanced blockwise matrix multiplication. We implement the Transformer model with proper hardware scheduling, and the experiments show that the Transformer inference on FPGA achieves 10.35 ms latency with the batch size of 32, which is 10.96 …",32
Co-exploring neural architecture and network-on-chip design for real-time artificial intelligence,"Lei Yang, Weiwen Jiang, Weichen Liu, HM Edwin, Yiyu Shi, Jingtong Hu",2020/1/13,Conference (Best Paper Nomination) 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC),"Hardware-aware Neural Architecture Search (NAS), which automatically finds an architecture that works best on a given hardware design, has prevailed in response to the ever-growing demand for real-time Artificial Intelligence (AI). However, in many situations, the underlying hardware is not pre-determined. We argue that simply assuming an arbitrary yet fixed hardware design will lead to inferior solutions, and it is best to co-explore neural architecture space and hardware design space for the best pair of neural architecture and hardware design. To demonstrate this, we employ Network-on-Chip (NoC) as the infrastructure and propose a novel framework, namely NANDS, to co-explore NAS space and NoC Design Search (NDS) space with the objective to maximize accuracy and throughput. Since two metrics are tightly coupled, we develop a multi-phase manager to guide NANDS to gradually converge to …",32
Heterogeneous fpga-based cost-optimal design for timing-constrained cnns,"Weiwen Jiang, Edwin Hsing-Mean Sha, Qingfeng Zhuge, Lei Yang, Xianzhang Chen, Jingtong Hu",2018/7/18,Journal IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,"Field programmable gate array (FPGA) has been one of the most popular platforms to implement convolutional neural networks (CNNs) due to its high performance and cost efficiency; however, limited by the on-chip resources, the existing single-FPGA architectures cannot fully exploit the parallelism in CNNs. In this paper, we explore heterogeneous FPGA-based designs to effectively leverage both task and data parallelism, such that the resultant system can achieve the minimum cost while satisfying timing constraints. In order to maximize the task parallelism, we investigate two critical problems: 1) buffer placement, where to place buffers to partition CNNs into pipeline stages and 2) task assignment, what type of FPGA to implement different CNN layers. We first formulate the system-level optimization problem with a mixed integer linear programming model. Then, we propose an efficient dynamic programming …",29
Thermal-aware task mapping on dynamically reconfigurable network-on-chip based multiprocessor system-on-chip,"Weichen Liu, Lei Yang, Weiwen Jiang, Liang Feng, Nan Guan, Wei Zhang, Nikil Dutt",2018/6/6,Journal IEEE Transactions on Computers,"Dark silicon is the phenomenon that a fraction of many-core chip has to be turned off or run in a low-power state in order to maintain the safe chip temperature. System-level thermal management techniques normally map application on non-adjacent cores, while communication efficiency among these cores will be oppositely affected over conventional network-on-chip (NoC). Recently, SMART NoC architecture is proposed, enabling single-cycle multi-hop bypass channels to be built between distant cores at runtime, to reduce communication latency. However, communication efficiency of SMART NoC will be diminished by communication contention, which will in turn decrease system performance. In this paper, we first propose an Integer-Linear Programming (ILP) model to properly address communication problem, which generates the optimal solutions with the consideration of inter-processor communication. We …",29
Efficient data placement for improving data access performance on domain-wall memory,"Xianzhang Chen, Edwin Hsing-Mean Sha, Qingfeng Zhuge, Chun Jason Xue, Weiwen Jiang, Yuangang Wang",2016/3/31,Journal IEEE Transactions on Very Large Scale Integration (VLSI) Systems,"A domain-wall memory (DWM) is becoming an attractive candidate to replace the traditional memories for its high density, low-power leakage, and low access latency. Accessing data on DWM is accomplished by shift operations that move data located on nanowires to read/write ports. Due to this kind of construction, data accesses on DWM exhibit varying access latencies. Therefore, data placement (DP) strategy has a significant impact on the performance of data accesses on DWM. In this paper, we prove the nondeterministic polynomial time (NP)-completeness of the DP problem on DWM. For the DWMs organized in single DWM block cluster (DBC), we present integer linear programming formulations to solve the problem optimally. We also propose an efficient single DBC placement (S-DBC-P) algorithm to exploit the benefits of multiple read/write ports and data locality. Compared with the sequential DP strategy …",29
Optimizing data placement for reducing shift operations on domain wall memories,"Xianzhang Chen, Edwin H-M Sha, Qingfeng Zhuge, Penglin Dai, Weiwen Jiang",2015/6/7,Book Proceedings of the 52nd Annual Design Automation Conference,"Domain Wall Memory (DWM) using nanowire with data access port, exhibits extraordinary high density, low power leakage, and low access latency. These properties enable DWM to become an attractive candidate for replacing traditional memories. However, data accesses on DWM may require multiple shift operations before the port points to requested data, resulting in varying access latencies. Data placement, therefore, has a significant impact on the performance of data accesses on DWM. This paper studies compiler-based optimization techniques for data placement on DWM. To the authors' best knowledge, this is the first work addressing data placement problem on DWM. We present an efficient heuristic, called Grouping-Based Data Placement (GBDP), for the data placement problem of a given data access sequence on DWM. The experimental results show that GBDP has a significant performance …",26
When neural architecture search meets hardware implementation: from hardware awareness to co-design,"Xinyi Zhang, Weiwen Jiang, Yiyu Shi, Jingtong Hu",2019/7/15,Source 2019 IEEE Computer Society Annual Symposium on VLSI (ISVLSI),"Neural Architecture Search (NAS), that automatically identifies the best network architecture, is a promising technique to respond to the ever-growing demand for application-specific Artificial Intelligence (AI). On the other hand, a large number of research efforts have been put on implementing and optimizing AI applications on the hardware. Out of all leading computation platforms, Field Programmable Gate Arrays (FPGAs) stand out due to its flexibility and versatility over ASICs and its efficiency over CPUs and GPUs. To identify the best neural architecture and hardware implementation pair, a number of research works are emerging to involve the awareness of hardware efficiency in the NAS process, which is called ""hardware-aware NAS"". Unlike the conventional NAS with a mono-criteria of accuracy, hardware-aware NAS is a multi-objective optimization problem, which aims to identify the best network and …",25
Integrating memristors and CMOS for better AI,"Weiwen Jiang, Bike Xie, Chun-Chen Liu, Yiyu Shi",2019/9,Journal Nature Electronics,"By integrating memristor arrays with CMOS circuitry, a computing-in-memory architecture can be created that could provide efficient deep neural network processors.",22
Nass: Optimizing secure inference via neural architecture search,"Song Bian, Weiwen Jiang, Qing Lu, Yiyu Shi, Takashi Sato",2020/1/30,Journal arXiv preprint arXiv:2001.11854,"Due to increasing privacy concerns, neural network (NN) based secure inference (SI) schemes that simultaneously hide the client inputs and server models attract major research interests. While existing works focused on developing secure protocols for NN-based SI, in this work, we take a different approach. We propose NASS, an integrated framework to search for tailored NN architectures designed specifically for SI. In particular, we propose to model cryptographic protocols as design elements with associated reward functions. The characterized models are then adopted in a joint optimization with predicted hyperparameters in identifying the best NN architectures that balance prediction accuracy and execution efficiency. In the experiment, it is demonstrated that we can achieve the best of both worlds by using NASS, where the prediction accuracy can be improved from 81.6% to 84.6%, while the inference runtime is reduced by 2x and communication bandwidth by 1.9x on the CIFAR-10 dataset.",21
Designing an efficient persistent in-memory file system,"Edwin H-M Sha, Xianzhang Chen, Qingfeng Zhuge, Liang Shi, Weiwen Jiang",2015/8/19,Conference 2015 IEEE Non-Volatile Memory System and Applications Symposium (NVMSA),"As the emerging technologies of persistent memory, such as MRAM, PCM, etc., provide opportunities for connecting persistent memory to main memory bus directly, file system structure needs re-studying and re-designing. This paper presents a new design of persistent, in-memory file system for computers systems employing persistent memory. We introduce a novel design framework based on the concept that each file has its own “File Virtual Address Space”. Following this idea, address mapping of file data access can be efficiently handled by address translation hardware. The new design pushes the boundary of persistent, in-memory file system to such an extent that software layers in I/O stack are bypassed. File data can be read continuously without interrupt or traversing metadata structure. The proposed file system, called Sustainable In-Memory File System (SIMFS), is implemented in Linux. Extensive …",19
Variational quantum pulse learning,"Zhiding Liang, Hanrui Wang, Jinglei Cheng, Yongshan Ding, Hang Ren, Zhengqi Gao, Zhirui Hu, Duane S Boning, Xuehai Qian, Song Han, Weiwen Jiang, Yiyu Shi",2022/9/18,Conference 2022 IEEE International Conference on Quantum Computing and Engineering (QCE),"Quantum computing is among the most promising emerging techniques to solve problems that are computationally intractable on classical hardware. A large body of existing works focus on using variational quantum algorithms on the gate level for machine learning tasks, such as the variational quantum circuit (VQC). However, VQC has limited flexibility and expressibility due to limited number of parameters, e.g. only one parameter can be trained in one rotation gate. On the other hand, we observe that quantum pulses are lower than quantum gates in the stack of quantum computing and offers more control parameters. Inspired by the promising performance of VQC, in this paper we propose variational quantum pulses (VQP), a novel paradigm to directly train quantum pulses for learning tasks. The proposed method manipulates variational quantum pulses by pulling and pushing the amplitudes of pulses in an …",18
When machine learning meets quantum computers: A case study,"Weiwen Jiang, Jinjun Xiong, Yiyu Shi",2021/1/18,Book Proceedings of the 26th Asia and South Pacific Design Automation Conference,"Along with the development of AI democratization, the machine learning approach, in particular neural networks, has been applied to wide-range applications. In different application scenarios, the neural network will be accelerated on the tailored computing platform. The acceleration of neural networks on classical computing platforms, such as CPU, GPU, FPGA, ASIC, has been widely studied; however, when the scale of the application consistently grows up, the memory bottleneck becomes obvious, widely known as memory-wall. In response to such a challenge, advanced quantum computing, which can represent 2N states with N quantum bits (qubits), is regarded as a promising solution. It is imminent to know how to design the quantum circuit for accelerating neural networks. Most recently, there are initial works studying how to map neural networks to actual quantum processors. To better understand the state …",18
Efficient assignment algorithms to minimize operation cost for supply chain networks in agile manufacturing,"Weiwen Jiang, Edwin H-M Sha, Qingfeng Zhuge, Lin Wu",2017/6/1,Journal Computers & Industrial Engineering,"While the production process evolves toward modularization and decentralization, the design of supply chain networks, in particular considering the agile manufacturing scenario, becomes challenging due to the following reasons: (1) supply chains that produce a network of components become large-scale; (2) the number of possible assignments is growing exponentially as the increasing choices of plants for components. In this paper, the assignment problem considers the strategic and tactical decisions together, which involves the mapping of components to geographically distributed plants, the selection of logistics services between the mapped plants, and the allocation of inventories in each plant. The goal of this paper is to find the optimal assignment with the minimum total cost under the constraint of production rate. We first mathematically formulate the problem as a mixed integer linear program. Then, by …",16
The design of an efficient swap mechanism for hybrid DRAM-NVM systems,"Xianzhang Chen, Edwin H-M Sha, Weiwen Jiang, Qingfeng Zhuge, Junxi Chen, Jiejie Qin, Yuansong Zeng",2016/10/1,Book Proceedings of the 13th International Conference on Embedded Software,"Non-Volatile Memory (NVM) is becoming an attractive candidate to be the swap area in embedded systems for its near-DRAM speed, low energy consumption, high density, and byte-addressability. Swapping data from DRAM out to NVM, however, can cause large performance/energy penalty and deplete the lifetime of NVM. Traditional swap mechanisms may need to be re-studied. Even through there are several swap mechanisms proposed for the hybrid DRAM-NVM systems, most of them have limited performance without considering the data access features of applications.",16
FoToNoC: A hierarchical management strategy based on folded torus-like network-on-chip for dark silicon many-core systems,"Lei Yang, Weichen Liu, Weiwen Jiang, Mengquan Li, Juan Yi, Edwin Hsing-Mean Sha",2016/1/25,Conference 2016 21st Asia and South Pacific Design Automation Conference (ASP-DAC),"In this dark silicon era, techniques have been developed to selectively activate nonadjacent cores in physical locations to maintain the safe temperature and allowable power budget on a many-core chip. This will result in unexpected increase in the communication overhead due to longer average distance between active cores in a typical mesh-based Network-on-Chip (NoC), and in turn reduce the system performance and energy efficiency. In this paper, we present FoToNoC, a Folded Torus-like NoC, and a hierarchical management strategy on top of it, to address this tradeoff problem for heterogeneous many-core systems. Optimizations of chip temperature, inter-core communication, application performance, and system energy consumption are well isolated in FoToNoC, and addressed in different design phases and aspects. A cluster-based hierarchical strategy is proposed to manage the system adaptively in …",16
A unified framework for designing high performance in-memory and hybrid memory file systems,"Xianzhang Chen, Edwin H-M Sha, Qingfeng Zhuge, Weiwen Jiang, Junxi Chen, Jun Chen, Jun Xu",2016/8/1,Journal Journal of Systems Architecture,"The emerging non-volatile memory technologies provide a new choice for storing persistent data in memory. Therefore, file system structure needs re-studying and re-designing. Our goal is to design a framework that gives high-performance in-memory file accesses and allows a file whose data can be stored across memory and block device. This paper presents a novel unified framework for in-memory and hybrid memory file systems based on the concept that each file has a contiguous “File Virtual Address Space”. Within this framework, the file access for in-memory data can be efficiently handled by address translation hardware and the virtual address space of file. The file accesses for data in block devices are handled by a dedicated page fault handler for file system. A file system called Hybrid Memory File System (HMFS) is implemented based on this framework. Experimental results show that the throughput of …",14
Exploration of quantum neural architecture by mixing quantum neuron designs,"Zhepeng Wang, Zhiding Liang, Shanglin Zhou, Caiwen Ding, Yiyu Shi, Weiwen Jiang",2021/11/1,Conference 2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD),"With the constant increase of the number of quantum bits (qubits) in the actual quantum computers, implementing and accelerating the prevalent deep learning on quantum computers are becoming possible. Along with this trend, there emerge quantum neural architectures based on different designs of quantum neurons. A fundamental question in quantum deep learning arises: what is the best quantum neural architecture? Inspired by the design of neural architectures for classical computing which typically employs multiple types of neurons, this paper makes the very first attempt to mix quantum neuron designs to build quantum neural architectures. We observe that the existing quantum neuron designs may be quite different but complementary, such as neurons from variational quantum circuits (VQC) and Quantumflow. More specifically, VQC can apply real-valued weights but suffer from being extended to …",13
Can noise on qubits be learned in quantum neural network? a case study on quantumflow,"Zhiding Liang, Zhepeng Wang, Junhuan Yang, Lei Yang, Yiyu Shi, Weiwen Jiang",2021/11/1,Conference 2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD),"In the noisy intermediate-scale quantum (NISQ) era, one of the key questions is how to deal with the high noise level existing in physical quantum bits (qubits). Quantum error correction is promising but requires an extensive number (e.g., over 1,000) of physical qubits to create one ”perfect” qubit, exceeding the capacity of the existing quantum computers. This paper aims to tackle the noise issue from another angle: instead of creating perfect qubits for general quantum algorithms, we investigate the potential to mitigate the noise issue for dedicate algorithms. Specifically, this paper targets quantum neural network (QNN), and proposes to learn the errors in the training phase, so that the identified QNN model can be resilient to noise. As a result, the implementation of QNN needs no or a small number of additional physical qubits, which is more realistic for the near-term quantum computers. To achieve this goal, an …",13
Hardware design and the competency awareness of a neural network,"Yukun Ding, Weiwen Jiang, Qiuwen Lou, Jinglan Liu, Jinjun Xiong, Xiaobo Sharon Hu, Xiaowei Xu, Yiyu Shi",2020/9,Source Nature Electronics,"The ability to estimate the uncertainty of predictions made by a neural network is essential when applying neural networks to tasks such as medical diagnosis and autonomous vehicles. The approach is of particular relevance when deploying the networks on devices with limited hardware resources, but existing competency-aware neural networks largely ignore any resource constraints. Here we examine the relationship between hardware platforms and the competency awareness of a neural network. We highlight the impact of two key areas of hardware development — increasing memory size of accelerator architectures and device-to-device variation in the emerging devices typically used in in-memory computing — on uncertainty estimation quality. We also consider the challenges that developments in uncertainty estimation methods impose on hardware designs. Finally, we explore the innovations required in …",13
A length adaptive algorithm-hardware co-design of transformer on fpga through sparse attention and dynamic pipelining,"Hongwu Peng, Shaoyi Huang, Shiyang Chen, Bingbing Li, Tong Geng, Ang Li, Weiwen Jiang, Wujie Wen, Jinbo Bi, Hang Liu, Caiwen Ding",2022/7/10,Book Proceedings of the 59th ACM/IEEE Design Automation Conference,"Transformers are considered one of the most important deep learning models since 2018, in part because it establishes state-of-the-art (SOTA) records and could potentially replace existing Deep Neural Networks (DNNs). Despite the remarkable triumphs, the prolonged turnaround time of Transformer models is a widely recognized roadblock. The variety of sequence lengths imposes additional computing overhead where inputs need to be zero-padded to the maximum sentence length in the batch to accommodate the parallel computing platforms. This paper targets the field-programmable gate array (FPGA) and proposes a coherent sequence length adaptive algorithm-hardware co-design for Transformer acceleration. Particularly, we develop a hardware-friendly sparse attention operator and a length-aware hardware resource scheduling algorithm. The proposed sparse attention operator brings the complexity of …",12
One proxy device is enough for hardware-aware neural architecture search,"Bingqian Lu, Jianyi Yang, Weiwen Jiang, Yiyu Shi, Shaolei Ren",2021/12/15,Journal Proceedings of the ACM on Measurement and Analysis of Computing Systems,"Convolutional neural networks (CNNs) are used in numerous real-world applications such as vision-based autonomous driving and video content analysis. To run CNN inference on various target devices, hardware-aware neural architecture search (NAS) is crucial. A key requirement of efficient hardware-aware NAS is the fast evaluation of inference latencies in order to rank different architectures. While building a latency predictor for each target device has been commonly used in state of the art, this is a very time-consuming process, lacking scalability in the presence of extremely diverse devices. In this work, we address the scalability challenge by exploiting latency monotonicity --- the architecture latency rankings on different devices are often correlated. When strong latency monotonicity exists, we can re-use architectures searched for one proxy device on new target devices, without losing optimality. In the …",11
Xfer: A novel design to achieve super-linear performance on multiple fpgas for real-time ai,"Weiwen Jiang, Xinyi Zhang, Edwin H-M Sha, Qingfeng Zhuge, Lei Yang, Yiyu Shi, Jingtong Hu",2019/2/20,Book Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays,"Real-time inference with low latency requirement has become increasingly important for numerous applications in both cloud computing and edge computing. The FPGA-based Deep Neural Network (DNN) accelerators have demonstrated the superior performance and energy efficiency over CPUs and GPUs; in addition, for real-time AI with low batch size, FPGA is expected to achieve further performance improvement over the general purpose computing platform. However, the performance gain of the single-FPGA design is hindered by the limited on-chip resource. In this paper, we leverage a cluster of FPGAs to fully exploit the parallelism in DNNs with the objective of obtaining super-linear performance. To achieve this goal, a novel design, ""XFER"", is proposed to deploy DNNs to FPGA cluster by splitting the DNN layer to multiple FPGAs and moving traffics from memory bus to inter-FPGA links. The resultant …",11
Optimal functional-unit assignment for heterogeneous systems under timing constraint,"Weiwen Jiang, Edwin Hsing-Mean Sha, Xianzhang Chen, Lei Yang, Lei Zhou, Qingfeng Zhuge",2017/3/1,Journal IEEE Transactions on Parallel and Distributed Systems,"In high-level synthesis for real-time systems, it typically employs heterogeneous functional-unit types to achieve high-performance and low-cost designs. In the design phase, it is critical to determine which functional-unit type to be mapped for each operation in a given application such that the total cost is minimized while the deadline can be met. For a path or tree structured application, existing approaches can obtain the minimum-cost assignment, called “optimal assignment”, under which the resultant system satisfies a given timing constraint. However, it is still an open question whether there exist efficient algorithms to obtain the optimal assignment for the directed acyclic graph (DAG), or more generally, the data-flow graph with cycles (cyclic DFG). For DAGs, by analyzing the property of the problem, this paper designs an efficient algorithm to obtain the optimal assignments. For cyclic DFGs, we approach this …",11
Optimal functional-unit assignment and buffer placement for probabilistic pipelines,"Weiwen Jiang, Edwin H-M Sha, Qingfeng Zhuge, Xianzhang Chen",2016/10/1,Book Proceedings of the Eleventh IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis,"Applications, such as streaming applications, modeled by task graphs can be efficiently executed in a pipelined fashion. In synthesizing application-specific heterogeneous pipelined systems, where to place buffers (called buffer placement) and what type of functional units to execute each task (called functional assignment) are two critical problems. In reality, the execution time of each task may not be fixed, which makes the above two problems much more challenging. In this paper, we model the execution time of each task on different types of functional units as a random variable. Our objective is to obtain the optimal functional assignment and buffer placement, such that the resultant pipeline can satisfy the timing requirement with the minimum cost under the guaranteed confidence probability. This paper presents efficient algorithms to achieve the objective. Experiments show that other techniques cannot find any …",11
DNA: Differentiable network-accelerator co-search,"Yongan Zhang, Yonggan Fu, Weiwen Jiang, Chaojian Li, Haoran You, Meng Li, Vikas Chandra, Yingyan Lin",2020/10/28,Journal arXiv preprint arXiv:2010.14778,"Powerful yet complex deep neural networks (DNNs) have fueled a booming demand for efficient DNN solutions to bring DNN-powered intelligence into numerous applications. Jointly optimizing the networks and their accelerators are promising in providing optimal performance. However, the great potential of such solutions have yet to be unleashed due to the challenge of simultaneously exploring the vast and entangled, yet different design spaces of the networks and their accelerators. To this end, we propose DNA, a Differentiable Network-Accelerator co-search framework for automatically searching for matched networks and accelerators to maximize both the task accuracy and acceleration efficiency. Specifically, DNA integrates two enablers: (1) a generic design space for DNN accelerators that is applicable to both FPGA- and ASIC-based DNN accelerators and compatible with DNN frameworks such as PyTorch to enable algorithmic exploration for more efficient DNNs and their accelerators; and (2) a joint DNN network and accelerator co-search algorithm that enables simultaneously searching for optimal DNN structures and their accelerators' micro-architectures and mapping methods to maximize both the task accuracy and acceleration efficiency. Experiments and ablation studies based on FPGA measurements and ASIC synthesis show that the matched networks and accelerators generated by DNA consistently outperform state-of-the-art (SOTA) DNNs and DNN accelerators (e.g., 3.04x better FPS with a 5.46% higher accuracy on ImageNet), while requiring notably reduced search time (up to 1234.3x) over SOTA co-exploration methods …",10
Towards the design of efficient hash-based indexing scheme for growing databases on non-volatile memory,"Zhulin Ma, Edwin H-M Sha, Qingfeng Zhuge, Weiwen Jiang, Runyu Zhang, Shouzhen Gu",2020/4/1,Journal Future Generation Computer Systems,"The index is a fundamental component in data intensive systems to accelerate data retrieval operations. In the design of Non-Volatile Memory (NVM) based indexes, the hash-based structure is one of the most promising candidates since it can take full advantages of byte-addressable property of NVM to perform query operations with constant time complexity. However, we found that the basic operation, “rehash operation”, may incur a large number of write activities on NVM, which is harmful to the endurance of NVM, and will cause drastic performance degradation. Additionally, range query operations cannot be efficiently conducted on hash-based indexes. In this paper, we first investigate how to design an NVM-friendly hash-based structure with the considerations of endurance and performance issues. Then, we propose a novel indexing scheme called “Bucket Hash”, which can significantly reduce the overhead …",10
Hardware-software collaboration for dark silicon heterogeneous many-core systems,"Lei Yang, Weichen Liu, Weiwen Jiang, Chao Chen, Mengquan Li, Peng Chen, HM Edwin",2017/3/1,Journal Future Generation Computer Systems,"In dark silicon many-core systems, system-level techniques have been developed to selectively activate nonadjacent cores in physical locations to maintain the allowable power budget and eliminate thermal hotspot. However, this will unexpectedly increase communication overhead due to the longer average distance between active cores in a typical mesh-based Network-on-Chip (NoC), and in turn reduce application performance. Inspired by ARM’s big. LITTLE architecture coupled with Heterogeneous Multi-Processing (HMP) which enables energy-efficient solutions, in this paper, we propose two alternative hardware–software collaborated techniques to address the temperature/communication conflict in the dark silicon era. A Folded Torus-like NoC, FoToNoC, is presented to address the Cluster-switching based heterogeneous system, and a Quad-core-group based NoC, QcNoC, is presented to address the In …",10
Achieving full parallelism in LSTM via a unified accelerator design,"Xinyi Zhang, Weiwen Jiang, Jingtong Hu",2020/10/18,Conference 2020 IEEE 38th International Conference on Computer Design (ICCD),"Recently, Long Short-Term Memory (LSTM), a type of recurrent neural network, has been widely employed in realtime applications, such as speech recognition, word segmentation, machine translation, etc. While existing works demonstrate that LSTM can be efficiently deployed in cloud platforms, the high communication latency between cloud and edge will drastically reduce its efficiency. Therefore, efficient LSTM accelerators at the edge are highly demanded. The limited resource in edge devices and the heterogeneous operations in LSTM (e.g., LSTM gates) bring challenges for the LSTM accelerator design. It seems straightforward to implement each operation as a specific hardware kernel. However, the data dependency among gates leads to significant running stalls in the existing heterogeneous-kernel accelerator, resulting in low parallelism and low resource utilization. To overcome the above challenges …",9
Refinery swap: An efficient swap mechanism for hybrid DRAM–NVM systems,"Xianzhang Chen, Edwin H-M Sha, Weiwen Jiang, Chaoshu Yang, Ting Wu, Qingfeng Zhuge",2017/12/1,Journal Future Generation Computer Systems,"Abstract Emerging Non-Volatile Memory (NVM) technologies have shown great promise for enabling high performance swapping mechanism in embedded systems. Most of existing swap mechanisms have limited performance for lacking the knowledge of memory accesses and cause large overhead of swap operations by entirely avoiding direct writes to NVM. This paper, we find out the feature of “write count disparity”, ie, most pages are rarely written and most writes are concentrated on a few pages. With the observations in mind, this paper rethinks and re-designs the swap mechanism to reduce the number of swap operations and writes to NVM in hybrid DRAM–NVM systems by tolerating small writes to NVM. A new swap mechanism, Refinery Swap, is proposed with a (1+ ε)-competitive algorithm for swap-in operations, a multilevel priority algorithm for selecting the victim pages of swap-out operations, and a …",9
Traffic-aware application mapping for network-on-chip based multiprocessor system-on-chip,"Lei Yang, Weichen Liu, Weiwen Jiang, Wei Zhang, Mengquan Li, Juan Yi, Duo Liu, Edwin H-M Sha",2015/8/24,"Conference 2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems","Network on Chip (NoC) has become a promising solution for the communication paradigm of the next-generation multiprocessor system-on-chip (MPSoC). As communication has become an integral part of on-chip computing, researchers are paying more attention to its implementation and optimization. Traditional techniques that model inter-processor communication inaccurately will lead to unexpected runtime performance, which is on average 90.8% worse than the predicted results based on an observation. In this paper, we present an application mapping and scheduling technique for NoC-based MPSoCs that integrates fine-grain optimization on inter-processor communications with the objective of minimizing the schedule length. A communication model is proposed to address properly the latency of inter-processor communication with network contention. Performance evaluation results show that solutions …",8
An improved thermal model for static optimization of application mapping and scheduling in multiprocessor system-on-chip,"Juan Yi, Weichen Liu, Weiwen Jiang, Mingwen Qin, Lei Yang, Duo Liu, Chunming Xiao, Luelue Du, Edwin H-M Sha",2014/7/9,Conference 2014 IEEE Computer Society Annual Symposium on VLSI,"With the increasing power density and number of cores integrated into a single chip, thermal management is widely recognized as one of the essential issues in Multi-Processor Systems-on-Chip (MPSoCs). An uncontrolled temperature could significantly decrease system performance, lead to high cooling and packaging costs, and even cause serious damage. These issues have made temperature one of the major factors that must be addressed in MPSoC designs. Static scheduling of applications should take the thermal effects of task executions into consideration to keep the chip temperature under a safety threshold. However, inaccurate temperature estimation would cause processor overheating or system performance degradation. In this paper, we propose an improved thermal modeling technique that can be used to predict the chip temperature more accurately and efficiently at design time. We further …",8
On the design of minimal-cost pipeline systems satisfying hard/soft real-time constraints,"Weiwen Jiang, Edwin Hsing-Mean Sha, Qingfeng Zhuge, Lei Yang, Hailiang Dong, Xianzhang Chen",2018/1/1,Journal (Best Paper Award @ ICCD'17) IEEE Transactions on Emerging Topics in Computing,"Pipeline systems provide high throughput for applications by overlapping the executions of tasks. In the architectures with heterogeneity, two basic issues in the design of application-specific pipelines need to be studied: what type of functional unit to execute each task, and where to place buffers. Due to the increasing complexity of applications, pipeline designs face a bundle of problems. One of the most challenging problems is the uncertainty on the execution times, which makes the deterministic techniques inapplicable. In this paper, the execution times are modeled as random variables. Given an application, our objective is to construct the optimal pipeline, such that the total cost of the resultant pipeline can be minimized while satisfying the required timing constraints with the given guaranteed probability. We first prove the NP-hardness of the problem. Then, we present Mixed Integer Linear Programming (MILP …",7
Properties of self-timed ring architectures for deadlock-free and consistent configuration reaching maximum throughput,"Weiwen Jiang, Qingfeng Zhuge, Xianzhang Chen, Lei Yang, Juan Yi, Edwin H-M Sha",2016/7,Journal Journal of Signal Processing Systems,"Multiprocessor System-on-Chip with self-ti-med design becomes increasingly attractive due to its ability to exploit high parallelism of applications. Previous research efforts on self-timed techniques mostly focused on hardware layer. However, the problem of correctly synthesizing self-timed systems remains to be difficult. In particular, the problem of how to configure a self-timed ring structure to achieve the maximal throughput with no deadlock is still unsolved. Self-timed ring (STR) is composed of a ring of connected “stages”, each consisting of a processing element, communication units and its current state. The correct configuration of STR is determined by the initial state of each stage and a number of inserted buffers into the ring to maintain correct behavior of applications on an STR. This paper establishes a series of theorems based on the understanding of properties of self-timed structures. Based on the …",7
Quantum neural network compression,"Zhirui Hu, Peiyan Dong, Zhepeng Wang, Youzuo Lin, Yanzhi Wang, Weiwen Jiang",2022/10/30,Book Proceedings of the 41st IEEE/ACM International Conference on Computer-Aided Design,"Model compression, such as pruning and quantization, has been widely applied to optimize neural networks on resource-limited classical devices. Recently, there are growing interest in variational quantum circuits (VQC), that is, a type of neural network on quantum computers (a.k.a., quantum neural networks). It is well known that the near-term quantum devices have high noise and limited resources (i.e., quantum bits, qubits); yet, how to compress quantum neural networks has not been thoroughly studied. One might think it is straightforward to apply the classical compression techniques to quantum scenarios. However, this paper reveals that there exist differences between the compression of quantum and classical neural networks. Based on our observations, we claim that the compilation/traspilation has to be involved in the compression process. On top of this, we propose the very first systematical framework …",6
DIAN: Differentiable accelerator-network co-search towards maximal dnn efficiency,"Yongan Zhang, Yonggan Fu, Weiwen Jiang, Chaojian Li, Haoran You, Meng Li, Vikas Chandra, Yingyan Lin",2021/7/26,Conference 2021 IEEE/ACM International Symposium on Low Power Electronics and Design (ISLPED),"We present DIAN, a Differentiable Accelerator-Network Co-Search framework for automatically searching for matched networks and accelerators to maximize both the accuracy and efficiency. Specifically, DIAN integrates two enablers: (1) a generic design space for DNN accelerators that is applicable to both FPGA- and ASIC-based DNN accelerators; and (2) a joint DNN network and accelerator co-search algorithm that enables the simultaneous search for optimal DNN structures and their accelerators. Experiments and ablation studies based on FPGA measurements and ASIC synthesis show that the matched networks and accelerators generated by DIAN consistently outperform state-of-the-art (SOTA) DNNs and DNN accelerators (e.g., 3.04× better FPS with a 5.46% higher accuracy on ImageNet), while requiring notably reduced search time (up to  over SOTA co-exploration methods, when evaluated …",6
Dancing along Battery: Enabling Transformer with Run-time Reconfigurability on Mobile Devices,"Yuhong Song, Weiwen Jiang, Bingbing Li, Panjie Qi, Qingfeng Zhuge, Edwin Hsing-Mean Sha, Sakyasingha Dasgupta, Yiyu Shi, Caiwen Ding",2021/2/12,Journal Proceedings of the 58th Annual Design Automation Conference 2021,"A pruning-based AutoML framework for run-time reconfigurability, namely RT 3 , is proposed in this work. This enables Transformer-based large Natural Language Processing (NLP) models to be efficiently executed on resource-constrained mobile devices and reconfigured (i.e., switching models for dynamic hardware conditions) at run-time. Such reconfigurability is the key to save energy for battery-powered mobile devices, which widely use dynamic voltage and frequency scaling (DVFS) technique for hardware reconfiguration to prolong battery life. In this work, we creatively explore a hybrid block-structured pruning (BP) and pattern pruning (PP) for Transformer-based models and first attempt to combine hardware and software reconfiguration to maximally save energy for battery-powered mobile devices. Specifically, RT 3  integrates two-level optimizations: First, it utilizes an efficient BP as the first-step compression …",6
Towards cardiac intervention assistance: hardware-aware neural architecture exploration for real-time 3D cardiac cine MRI segmentation,"Dewen Zeng, Weiwen Jiang, Tianchen Wang, Xiaowei Xu, Haiyun Yuan, Meiping Huang, Jian Zhuang, Jingtong Hu, Yiyu Shi",2020/11/2,Book Proceedings of the 39th International Conference on Computer-Aided Design,"Real-time cardiac magnetic resonance imaging (MRI) plays an increasingly important role in guiding various cardiac interventions. In order to provide better visual assistance, the cine MRI frames need to be segmented on-the-fly to avoid noticeable visual lag. In addition, considering reliability and patient data privacy, the computation is preferably done on local hardware. State-of-the-art MRI segmentation methods mostly focus on accuracy only, and can hardly be adopted for real-time application or on local hardware. In this work, we present the first hardware-aware multi-scale neural architecture search (NAS) framework for real-time 3D cardiac cine MRI segmentation. The proposed framework incorporates a latency regularization term into the loss function to handle realtime constraints, with the consideration of underlying hardware. In addition, the formulation is fully differentiable with respect to the architecture …",6
"MSP: an FPGA-specific mixed-scheme, multi-precision deep neural network quantization framework","Sung-En Chang, Yanyu Li, Mengshu Sun, Weiwen Jiang, Runbin Shi, Xue Lin, Yanzhi Wang",2020/9/16,Journal arXiv preprint arXiv:2009.07460,"With the tremendous success of deep learning, there exists imminent need to deploy deep learning models onto edge devices. To tackle the limited computing and storage resources in edge devices, model compression techniques have been widely used to trim deep neural network (DNN) models for on-device inference execution. This paper targets the commonly used FPGA (field programmable gate array) devices as the hardware platforms for DNN edge computing. We focus on the DNN quantization as the main model compression technique, since DNN quantization has been of great importance for the implementations of DNN models on the hardware platforms. The novelty of this work comes in twofold: (i) We propose a mixed-scheme DNN quantization method that incorporates both the linear and non-linear number systems for quantization, with the aim to boost the utilization of the heterogeneous computing resources, i.e., LUTs (look up tables) and DSPs (digital signal processors) on an FPGA. Note that all the existing (single-scheme) quantization methods can only utilize one type of resources (either LUTs or DSPs for the MAC (multiply-accumulate) operations in deep learning computations. (ii) We use a quantization method that supports multiple precisions along the intra-layer dimension, while the existing quantization methods apply multi-precision quantization along the inter-layer dimension. The intra-layer multi-precision method can uniform the hardware configurations for different layers to reduce computation overhead and at the same time preserve the model accuracy as the inter-layer approach.",6
UMFS: An efficient user-space file system for non-volatile memory,"Xianzhang Chen, Edwin H-M Sha, Qingfeng Zhuge, Ting Wu, Weiwen Jiang, Xiaoping Zeng, Lin Wu",2018/9/1,Journal Journal of Systems Architecture,"Emerging non-volatile memory (NVM) is expected to be a mainstream storage media in embedded systems for its low-power consumption, near-DRAM speed, high density, and byte-addressability. In-memory file systems are proposed to achieve high-performance file accesses by storing files in NVM. Existing in-memory file systems, such as NOVA and EXT4-DAX, operate in kernel space and have additional overhead caused by kernel layers and mode change. In this paper, we propose a new design of User-space in-Memory File System (UMFS) to improve file access speed by minimizing the overhead of kernel. We implement UMFS in Linux system to verify the proposed design. In open operation, UMFS exposes a file into user-space in constant time independent from the file size. Then, UMFS can achieve high-performance file accesses taking advantages of user virtual address space and existing address …",6
Efficient wear leveling for inodes of file systems on persistent memories,"Xianzhang Chen, Edwin H-M Sha, Yuansong Zeng, Chaoshu Yang, Weiwen Jiang, Qingfeng Zhuge",2018/3/19,"Conference 2018 Design, Automation & Test in Europe Conference & Exhibition (DATE)","Existing persistent memory file systems achieve high-performance file accesses by exploiting advanced characteristics of persistent memories (PMs), such as PCM. However, they ignore the limited endurance of PMs. Particularly, the frequently updated inodes are stored on fixed locations throughout their lifetime, which can easily damage PM with common file operations. To address such issues, we propose a new mechanism, Virtualized Inode (VInode), for the wear leveling of inodes of persistent memory file systems. In VInode, we develop an algorithm called Pages as Communicating Vessels (PCV) to efficiently find and migrate the heavily written inodes. We implement VInode in SIMFS, a typical persistent memory file system. Experiments are conducted with well-known benchmarks. Compared with original SIMFS, experimental results show that VInode can reduce the maximum value and standard deviation of …",6
UDORN: A design framework of persistent in-memory key-value database for NVM,"Xianzhang Chen, Edwin H-M Sha, Ahmad Abdullah, Qingfeng Zhuge, Lin Wu, Chaoshu Yang, Weiwen Jiang",2017/8/16,Conference 2017 IEEE 6th Non-Volatile Memory Systems and Applications Symposium (NVMSA),"Emerging non-volatile memory (NVM) technologies provide opportunities to improve the performance of key-value databases (KVDBs) by deploying database on NVM. However, existing in-memory KVDBs cannot fully exploit the advantages of NVM. They process data on in-memory database and store an image on persistent storage via an underlying file system. The performance of database operations is degraded by the backup mechanisms and involved I/O routines. In this paper, we propose a new design framework of in-memory KVDB called Unified Database on Raw NVM (UDORN). In UDORN, a persistent database on NVM is employed to accomplish the functions of both conventional in-memory database and persistent image. During runtime, the persistent database is mapped to process address space. The operations are directly performed on NVM via the corresponding address space. We implement a …",6
Optimal functional unit assignment and voltage selection for pipelined MPSoC with guaranteed probability on time performance,"Weiwen Jiang, Edwin H-M Sha, Qingfeng Zhuge, Hailiang Dong, Xianzhang Chen",2017/6/21,Journal ACM SIGPLAN Notices," Pipelined heterogeneous multiprocessor system-on-chip (MPSoC) can provide high throughput for streaming applications. In the design of such systems, time performance and system cost are the most concerning issues. By analyzing runtime behaviors of benchmarks in real-world platforms, we find that execution times of tasks are not fixed but spread with probabilities. In terms of this feature, we model execution times of tasks as random variables. In this paper, we study how to design high-performance and low-cost MPSoC systems to execute a set of such tasks with data dependencies in a pipelined fashion. Our objective is to obtain the optimal functional unit assignment and voltage selection for the pipelined MPSoC systems, such that the system cost is minimized while timing constraints can be met with a given guaranteed probability. For each required probability, our proposed algorithm can efficiently obtain …",6
Optimizing data placement of mapreduce on ceph-based framework under load-balancing constraint,"Edwin H-M Sha, Yutong Liang, Weiwen Jiang, Xianzhang Chen, Qingfeng Zhuge",2016/12/13,Conference 2016 IEEE 22nd International Conference on Parallel and Distributed Systems (ICPADS),"Ceph has been widely used as a distributed object store and file system due to its high availability, reliability and scalability. Strategies of data placements in Ceph composed of heterogeneous clusters can greatly affect the system performance and load balancing. For a given application, it is critical to find the optimal data placement in Ceph, such that the completion time of the application can be minimized under the load-balancing constraint. This paper presents a novel Ceph-based framework that integrally considers the load balancing and the heterogeneities, including the computational capacity and the network bandwidth. The presented framework is suitable for the applications based on the principle of moving computation rather than data across clusters, such as MapReduce. According to the Ceph-based framework and the properties of MapReduce, we formulate the Mixed Integer Linear Programming …",6
Contention-aware task and communication co-scheduling for network-on-chip based multiprocessor system-on-chip,"Lei Yang, Weichen Liu, Weiwen Jiang, Juan Yi, Duo Liu, Qingfeng Zhuge",2014/8/20,Conference 2014 IEEE 20th International Conference on Embedded and Real-Time Computing Systems and Applications,"To satisfy the ever increasing performance requirement of applications, Multiprocessor System-on-Chip (MPSoC) plays an irreplaceable role in embedded system these days. It is significant to effectively optimize communication for achieving maximum parallelism on MPSoC, especially on Network-on-Chip (NoC) based architectures. The problem of how to make an arbitration of communication congestion is remained unsolved. In this paper, we propose a reasonable Unified Priority-Based Scheduling (UPS) algorithm for task and communication co-scheduling with communication contention, which is based on a novel Task Communication Graph (TCG) model of an application. The proposed method is more accurate and effective to describe the overall process of applications. The experimental results show that the performance is improved by 31.1% on average of scheduling generated by our algorithm. It verifies …",6
Effective file data-block placement for different types of page cache on hybrid main memory architectures,"Penglin Dai, Qingfeng Zhuge, Xianzhang Chen, Weiwen Jiang, Edwin H-M Sha",2013/9,Journal Design Automation for Embedded Systems,"Hybrid main memory architectures employing both DRAM and non-volatile memories (NVMs) are becoming increasingly attractive due to the opportunities for exploring benefits of various memory technologies, for example, high speed writes on DRAM and low stand-by power consumption on NVMs. File data-block placement (FDP) on different types of page cache is one of the important problems that directly impact the performance and cost of file operations on a hybrid main memory architecture. Page cache is widely used in modern operating systems to expedite file I/O by mapping disk-backed file data-blocks in main memory to process space in virtual memory. In a hybrid main memory, different types of memory with different read/write costs can be allocated as page cache by operating system. In this paper, we study the problem of file data-block placement on different types of page cache to minimize the …",6
Towards sparsification of graph neural networks,"Hongwu Peng, Deniz Gurevin, Shaoyi Huang, Tong Geng, Weiwen Jiang, Orner Khan, Caiwen Ding",2022/10/23,Conference 2022 IEEE 40th International Conference on Computer Design (ICCD),"As real-world graphs expand in size, larger GNN models with billions of parameters are deployed. High parameter count in such models makes training and inference on graphs expensive and challenging. To reduce the computational and memory costs of GNNs, optimization methods such as pruning the redundant nodes and edges in input graphs have been commonly adopted. However, model compression, which directly targets the sparsification of model layers, has been mostly limited to traditional Deep Neural Networks (DNNs) used for tasks such as image classification and object detection. In this paper, we utilize two state-of-the-art model compression methods (1) train and prune and (2) sparse training for the sparsification of weight layers in GNNs. We evaluate and compare the efficiency of both methods in terms of accuracy, training sparsity, and training FLOPs on real-world graphs. Our experimental …",5
Detecting gender bias in transformer-based models: a case study on Bert,"Bingbing Li, Hongwu Peng, Rajat Sainju, Junhuan Yang, Lei Yang, Yueying Liang, Weiwen Jiang, Binghui Wang, Hang Liu, Caiwen Ding",2021/10/15,Journal arXiv preprint arXiv:2110.15733,"In this paper, we propose a novel gender bias detection method by utilizing attention map for transformer-based models. We 1) give an intuitive gender bias judgement method by comparing the different relation degree between the genders and the occupation according to the attention scores, 2) design a gender bias detector by modifying the attention module, 3) insert the gender bias detector into different positions of the model to present the internal gender bias flow, and 4) draw the consistent gender bias conclusion by scanning the entire Wikipedia, a BERT pretraining dataset. We observe that 1) the attention matrices, Wq and Wk introduce much more gender bias than other modules (including the embedding layer) and 2) the bias degree changes periodically inside of the model (attention matrix Q, K, V, and the remaining part of the attention layer (including the fully-connected layer, the residual connection, and the layer normalization module) enhance the gender bias while the averaged attentions reduces the bias).",5
Can Quantum Computers Learn Like Classical Computers? A Co-Design Framework of Machine Learning and Quantum Circuits,"Weiwen Jiang, Jinjun Xiong, Yiyu Shi",2020/7/9,"Description Despite the pursuit of quantum supremacy in various applications, the power of quantum computers in machine learning (such as neural network models) has mostly remained unknown, primarily due to a missing link that effectively designs a neural network model suitable for quantum circuit implementation. In this article, we present the first co-design framework, namely QuantumFlow, to fixed the missing link. QuantumFlow consists of a novel quantum-friendly neural network (QF-Net) design, an automatic tool (QF-Map) to generate the quantum circuit (QF-Circ) for QF-Net, and a theoretic-based execution engine (QF-FB) to efficiently support the training of QF-Net on a classical computer. We discover that, in order to make full use of the strength of quantum representation, data in QF-Net is best modeled as random variables rather than real numbers. Moreover, instead of using the classical batch normalization (which is key to achieve high accuracy for deep neural networks), a quantum-aware batch normalization method is proposed for QF-Net. Evaluation results show that QF-Net can achieve 97.01% accuracy in distinguishing digits 3 and 6 in the widely used MNIST dataset, which is 14.55% higher than the state-of-the-art quantum-aware implementation. A case study on a binary classification application is conducted. Running on IBM Quantum processor’s “ibmq_essex” backend, a neural network designed by QuantumFlow can achieve 82% accuracy. To the best of our knowledge, QuantumFlow is the first framework that co-designs both the machine learning model and its quantum circuit.","Despite the pursuit of quantum supremacy in various applications, the power of quantum computers in machine learning (such as neural network models) has mostly remained unknown, primarily due to a missing link that effectively designs a neural network model suitable for quantum circuit implementation. In this article, we present the first co-design framework, namely QuantumFlow, to fixed the missing link. QuantumFlow consists of a novel quantum-friendly neural network (QF-Net) design, an automatic tool (QF-Map) to generate the quantum circuit (QF-Circ) for QF-Net, and a theoretic-based execution engine (QF-FB) to efficiently support the training of QF-Net on a classical computer. We discover that, in order to make full use of the strength of quantum representation, data in QF-Net is best modeled as random variables rather than real numbers. Moreover, instead of using the classical batch normalization (which is key to achieve high accuracy for deep neural networks), a quantum-aware batch normalization method is proposed for QF-Net. Evaluation results show that QF-Net can achieve 97.01% accuracy in distinguishing digits 3 and 6 in the widely used MNIST dataset, which is 14.55% higher than the state-of-the-art quantum-aware implementation. A case study on a binary classification application is conducted. Running on IBM Quantum processor’s “ibmq_essex” backend, a neural network designed by QuantumFlow can achieve 82% accuracy. To the best of our knowledge, QuantumFlow is the first framework that co-designs both the machine learning model and its quantum circuit.",5
Synthesizing distributed pipelining systems with timing constraints via optimal functional unit assignment and communication selection,"Weiwen Jiang, Edwin H-M Sha, Xianzhang Chen, Lin Wu, Qingfeng Zhuge",2018/5/1,Journal Journal of computational science,"The design of efficient optimization techniques is important to synthesize application-specific distributed systems with timing constraints. In many applications, represented by task graphs, the consecutive executions of a task graph can be overlapped in a pipelined fashion with a proper buffer placement. The performance of such a system is closely related to the behavior of pipelining. Given a timing (throughput) constraint, however, using the fastest functional units or communication protocols may incur unacceptable high cost. In the design of such distributed pipelining systems with timing constraint, several problems need to be solved: how to properly place buffers, assign functional unit types for each task, and select communication protocols for each pair of tasks. This paper presents efficient optimization algorithms by integrally considering the above problems, such that the resultant systems can satisfy the timing …",5
The design and implementation of an efficient user-space in-memory file system,"Edwin H-M Sha, Yang Jia, Xianzhang Chen, Qingfeng Zhuge, Weiwen Jiang, Jiejie Qin",2016/8/17,Conference 2016 5th Non-Volatile Memory Systems and Applications Symposium (NVMSA),"The file accesses of existing in-memory file systems have additional costs for traversing the software stacks of the kernel, such as VFS. To avoid such costs, the existing file systems generally enable user-space file accesses using the memorymapped file (mmap) techniques. The mmap approaches, however, are add-ons of the file systems in the kernel level that have large overhead for mapping the files into the user space. In this paper, we propose the design of a genuine user-space in-memory file system. A user-space in-memory file system is designed and implemented. The software routines of the file operations in the proposed file system are re-designed to enable user-space file accesses and be compatible with the POSIX interfaces. A file can be mapped into the user space in constant time regardless of the file size. The file data of the implemented file system can be accessed in the user space with …",5
Radars: memory efficient reinforcement learning aided differentiable neural architecture search,"Zheyu Yan, Weiwen Jiang, Xiaobo Sharon Hu, Yiyu Shi",2022/1/17,Conference 2022 27th Asia and South Pacific Design Automation Conference (ASP-DAC),"Differentiable neural architecture search (DNAS) is known for its capacity in the automatic generation of superior neural networks. However, DNAS based methods suffer from memory usage explosion when the search space expands, which may prevent them from running successfully on even advanced GPU platforms. On the other hand, reinforcement learning (RL) based methods, while being memory efficient, are extremely time-consuming. Combining the advantages of both types of methods, this paper presents RADARS, a scalable RL aided DNAS framework that can explore large search spaces in a fast and memory-efficient manner. RADARS iteratively applies RL to prune undesired architecture candidates and identifies a promising subspace to carry out DNAS. Experiments using a workstation with 12 GB GPU memory show that on CIFAR-10 and ImageNet datasets, RADARS can achieve up to 3.41 …",4
Optimizing fpga-based accelerator design for large-scale molecular similarity search (special session paper),"Hongwu Peng, Shiyang Chen, Zhepeng Wang, Junhuan Yang, Scott A Weitze, Tong Geng, Ang Li, Jinbo Bi, Minghu Song, Weiwen Jiang, Hang Liu, Caiwen Ding",2021/11/1,Conference 2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD),"Molecular similarity search has been widely used in drug discovery to identify structurally similar compounds from large molecular databases rapidly. With the increasing size of chemical libraries, there is growing interest in the efficient acceleration of large-scale similarity search. Existing works mainly focus on CPU and GPU to accelerate the computation of the Tanimoto coefficient in measuring the pairwise similarity between different molecular fingerprints. In this paper, we propose and optimize an FPGA-based accelerator design on exhaustive and approximate search algorithms. On exhaustive search using BitBound & folding, we analyze the similarity cutoff and folding level relationship with search speedup and accuracy, and propose a scalable on-the-fly query engine on FPGAs to reduce the resource utilization and pipeline interval. We achieve a 450 million compounds-per-second processing throughput for a …",4
Contour: A process variation aware wear-leveling mechanism for inodes of persistent memory file systems,"Xianzhang Chen, Edwin H-M Sha, Xinxin Wang, Chaoshu Yang, Weiwen Jiang, Qingfeng Zhuge",2020/6/15,Journal IEEE Transactions on Computers,"Existing persistent memory file systems exploit the fast, byte-addressable persistent memory (PM) to boost storage performance but ignore the limited endurance of PM. Particularly, the PM storing the inode section is extremely vulnerable for the inodes are most frequently updated, fixed on a location throughout lifetime, and require immediate persistency. The huge endurance variation of persistent memory domains caused by process variation makes things even worse. In this article, we propose a process variation aware wear leveling mechanism called Contour for the inode section of persistent memory file system. Contour first enables the movement of inodes by virtualizing the inodes with a deflection table. Then, Contour adopts cross-domain migration algorithm and intra-domain migration algorithm to balance the writes across and within the memory domains. We implement the proposed Contour mechanism in …",4
On the design of high-performance and energy-efficient probabilistic self-timed systems,"Edwin H-M Sha, Weiwen Jiang, Qingfeng Zhuge, Lei Yang, Xianzhang Chen",2015/8/24,"Conference 2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems","Traditional synchronous systems relied on a global clock to maintain synchronization have incurred problems in worst-case performance and power consumption. A self-timed system that does not depend on a global clock is one of the high-caliber candidates to solve such problems. In this paper, a probabilistic self-timed system model is studied, on which task execution time is represented by a random variable. This paper presents the fundamental properties on time behavior of the probabilistic self-timed system and establishes formulas to calculate its throughput. Then, using the results, efficient algorithms are designed to optimize system throughput and minimize energy consumption. Experimental results show that the throughput of self-timed systems optimized by our algorithms achieves 33.73% improvement compared with that of the optimized synchronous systems. Additionally, the proposed algorithms on …",4
On self-timed ring for consistent mapping and maximum throughput,"Weiwen Jiang, Qingfeng Zhuge, Juan Yi, Lei Yang, HM Edwin",2014/8/20,Conference 2014 IEEE 20th International Conference on Embedded and Real-Time Computing Systems and Applications,"Multiprocessor System-on-Chip employing self-timed technique becomes increasingly attractive due to its ability for exploiting high parallelism of applications. There have been many research efforts on studying self-timed techniques on hardware layer. However, these research results are unable to be applied to system synthesis; in particular, how to correctly and optimally map an application represented by a Data Flow Graph to a self-timed ring architecture remains unknown. Self-timed ring (STR) is a popular and easy to implemented architecture. This paper establishes a series of theorems about the setting of initial configuration to achieve correct mappings and the formulas of calculating corresponding throughputs of STR. Based on the understanding, we can obtain a correct initial configuration of STR. And an algorithm presented in the paper can also find the best initial configuration that achieves the …",4
QuEst: Graph Transformer for Quantum Circuit Reliability Estimation,"Hanrui Wang, Pengyu Liu, Jinglei Cheng, Zhiding Liang, Jiaqi Gu, Zirui Li, Yongshan Ding, Weiwen Jiang, Yiyu Shi, Xuehai Qian, David Z Pan, Frederic T Chong, Song Han",2022/10/30,Journal arXiv preprint arXiv:2210.16724,"Among different quantum algorithms, PQC for QML show promises on near-term devices. To facilitate the QML and PQC research, a recent python library called TorchQuantum has been released. It can construct, simulate, and train PQC for machine learning tasks with high speed and convenient debugging supports. Besides quantum for ML, we want to raise the community's attention on the reversed direction: ML for quantum. Specifically, the TorchQuantum library also supports using data-driven ML models to solve problems in quantum system research, such as predicting the impact of quantum noise on circuit fidelity and improving the quantum circuit compilation efficiency. This paper presents a case study of the ML for quantum part. Since estimating the noise impact on circuit reliability is an essential step toward understanding and mitigating noise, we propose to leverage classical ML to predict noise impact on circuit fidelity. Inspired by the natural graph representation of quantum circuits, we propose to leverage a graph transformer model to predict the noisy circuit fidelity. We firstly collect a large dataset with a variety of quantum circuits and obtain their fidelity on noisy simulators and real machines. Then we embed each circuit into a graph with gate and noise properties as node features, and adopt a graph transformer to predict the fidelity. Evaluated on 5 thousand random and algorithm circuits, the graph transformer predictor can provide accurate fidelity estimation with RMSE error 0.04 and outperform a simple neural network-based model by 0.02 on average. It can achieve 0.99 and 0.95 R scores for random and algorithm circuits …",3
FL-DISCO: Federated Generative Adversarial Network for Graph-based Molecule Drug Discovery: Special Session Paper,"Daniel Manu, Yi Sheng, Junhuan Yang, Jieren Deng, Tong Geng, Ang Li, Caiwen Ding, Weiwen Jiang, Lei Yang",2021/11/1,Conference 2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD),"The outbreak of the global COVID-19 pandemic emphasizes the importance of collaborative drug discovery for high effectiveness; however, due to the stringent data regulation, data privacy becomes an imminent issue needing to be addressed to enable collaborative drug discovery. In addition to the data privacy issue, the efficiency of drug discovery is another key objective since infectious diseases spread exponentially and effectively conducting drug discovery could save lives. Advanced Artificial Intelligence (AI) techniques are promising to solve these problems: (1) Federated Learning (FL) is born to keep data privacy while learning data from distributed clients; (2) graph neural network (GNN) can extract structural properties of molecules whose underlying architecture is the connected atoms; and (3) generative adversarial network (GAN) can generate novel molecules while retaining the properties learned from …",3
Fgnas: Fpga-aware graph neural architecture search,"Qing Lu, Weiwen Jiang, Meng Jiang, Jingtong Hu, Sakyasingha Dasgupta, Yiyu Shi",2020,"Description The success of gragh neural networks (GNNs) in the past years has aroused grow-ing interest and effort in designing best models to handle graph-structured data. Asthe neural architecture search technique has been witnessed to rival against humanexperts in discovering performant network topologies, recently, it has been appliedto the field of graphic network engineering. However, such works on graphic NASso far are purely software design and not considering hardware constraints at all.To address this problem,  we propose the first SW-HW codesign framework forautomating the deployment of GNNs.  Using FPGA as the target platform,  ourframework is able to performs the FPGA-aware graph neural architecture search(FGNAS). To evaluate our design, we experiment on benckmark datasets, namelyCora,  CiteCeer,  and PubMed,  and the results show FGNAS has better capabil-ity in optimizing the accuracy of GNNs when their hardware implementation isspecifically constrained.","The success of gragh neural networks (GNNs) in the past years has aroused grow-ing interest and effort in designing best models to handle graph-structured data. Asthe neural architecture search technique has been witnessed to rival against humanexperts in discovering performant network topologies, recently, it has been appliedto the field of graphic network engineering. However, such works on graphic NASso far are purely software design and not considering hardware constraints at all.To address this problem,  we propose the first SW-HW codesign framework forautomating the deployment of GNNs.  Using FPGA as the target platform,  ourframework is able to performs the FPGA-aware graph neural architecture search(FGNAS). To evaluate our design, we experiment on benckmark datasets, namelyCora,  CiteCeer,  and PubMed,  and the results show FGNAS has better capabil-ity in optimizing the accuracy of GNNs when their hardware implementation isspecifically constrained.",3
BUNET: blind medical image segmentation based on secure UNET,"Song Bian, Xiaowei Xu, Weiwen Jiang, Yiyu Shi, Takashi Sato",2020,"Conference Medical Image Computing and Computer Assisted Intervention–MICCAI 2020: 23rd International Conference, Lima, Peru, October 4–8, 2020, Proceedings, Part II 23","The strict security requirements placed on medical records by various privacy regulations become major obstacles in the age of big data. To ensure efficient machine learning as a service schemes while protecting data confidentiality, in this work, we propose blind UNET (BUNET), a secure protocol that implements privacy-preserving medical image segmentation based on the UNET architecture. In BUNET, we efficiently utilize cryptographic primitives such as homomorphic encryption and garbled circuits (GC) to design a complete secure protocol for the UNET neural architecture. In addition, we perform extensive architectural search in reducing the computational bottleneck of GC-based secure activation protocols with high-dimensional input data. In the experiment, we thoroughly examine the parameter space of our protocol, and show that we can achieve up to 14x inference time reduction compared to …",3
Towards the design of efficient and consistent index structure with minimal write activities for non-volatile memory,"Edwin Hsing-Mean Sha, Weiwen Jiang, Hailiang Dong, Zhulin Ma, Runyu Zhang, Xianzhang Chen, Qingfeng Zhuge",2017/9/19,Journal IEEE Transactions on Computers,"Index structures can significantly accelerate the data retrieval operations in data intensive systems, such as databases. Tree structures, such as B + -tree alike, are commonly employed as index structures; however, we found that the tree structure may not be appropriate for Non-Volatile Memory (NVM) in terms of the requirements for high-performance and high-endurance. This paper studies what is the best index structure for NVM-based systems and how to design such index structures. The design of an NVM-friendly index structure faces a lot of challenges. First, in order to prolong the lifetime of NVM, the write activities on NVM should be minimized. To this end, the index structure should be as simple as possible. The index proposed in this paper is based on the simplest data structure, i.e., linked list. Second, the simple structure brings challenges to achieve high-performance data retrieval operations. To …",3
Performance optimization for in-memory file systems on NUMA machines,"Zhixiang Liu, Edwin H-M Sha, Xianzhang Chen, Weiwen Jiang, Qingfeng Zhuge",2016/12/16,"Conference 2016 17th International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT)","The growing demand for high-performance data processing stimulates the development of in-memory file systems, which exploit the advanced features of emerging non-volatile memory techniques for achieving high-speed file accesses. Existing in-memory file systems, however, are all designed for the systems with uniformed memory accesses. Their performance is poor on Non-Uniform Memory Access (NUMA) machines as they do not consider the asymmetric memory access speed and the architecture of multiple nodes. In this paper, we propose a new design of NUMA-aware in-memory file systems. We propose a distributed file system layout for leveraging the loads of in-memory file accesses on different nodes, a thread-file binding algorithm and a buffer assignment technique for increasing local memory accesses during run-time. Based on the proposed techniques, we implement a functional NUMA-aware in …",3
Prevent Deadlock and Remove Blocking for Self-Timed Systems,"Edwin H -M Sha, Weiwen Jiang, Qingfeng Zhuge, Xianzhang Chen, Lei Yang",2015,"Conference Algorithms and Architectures for Parallel Processing: 15th International Conference, ICA3PP 2015, Zhangjiajie, China, November 18-20, 2015, Proceedings, Part I 15","In the design of distributed embedded systems, designers face two problems: how to prevent deadlock and how to improve performance. An accurate model providing abstractions for functionality and performance is important to solve these problems. Self-timed system model that conducts communications based on handshaking protocols is suitable to model these distributed embedded systems. This paper studies the fundamental properties of self-timed systems and proposes solutions of the above two problems. First, we present the necessary and sufficient conditions for a self-timed system constructed from an application to incur deadlocks; then we propose approaches to prevent any deadlocks in constructing self-timed systems. Second, we observe that the different pace of data progressing on two paths, having common source/destination nodes, may cause blocking events (not deadlock) which …",3
Work in progress: Mobile or FPGA? A comprehensive evaluation on energy efficiency and a unified optimization framework,"Geng Yuan, Peiyan Dong, Mengshu Sun, Wei Niu, Zhengang Li, Yuxuan Cai, Jun Liu, Weiwen Jiang, Xue Lin, Bin Ren, Xulong Tang, Yanzhi Wang",2021/5/18,Conference 2021 IEEE 27th Real-Time and Embedded Technology and Applications Symposium (RTAS),"Efficient deployment of Deep Neural Networks (DNNs) on edge devices (i.e., FPGAs and mobile platforms) is very challenging, especially under a recent witness of the increasing DNN model size and complexity. Although various optimization approaches have been proven to be effective in many DNNs on edge devices, most state-of-the-art work focuses on ad-hoc optimizations, and there lacks a thorough study to comprehensively reveal the potentials and constraints of different edge devices when considering different optimizations. In this paper, we qualitatively and quantitatively compare the energyefficiency of FPGA-based and mobile-based DNN executions, and provide detailed analysis.",2
Real-time execution of large-scale language models on mobile,"Wei Niu, Zhenglun Kong, Geng Yuan, Weiwen Jiang, Jiexiong Guan, Caiwen Ding, Pu Zhao, Sijia Liu, Bin Ren, Yanzhi Wang",2020/9/15,Journal arXiv preprint arXiv:2009.06823,"Pre-trained large-scale language models have increasingly demonstrated high accuracy on many natural language processing (NLP) tasks. However, the limited weight storage and computational speed on hardware platforms have impeded the popularity of pre-trained models, especially in the era of edge computing. In this paper, we seek to find the best model structure of BERT for a given computation size to match specific devices. We propose the first compiler-aware neural architecture optimization framework. Our framework can guarantee the identified model to meet both resource and real-time specifications of mobile devices, thus achieving real-time execution of large transformer-based models like BERT variants. We evaluate our model on several NLP tasks, achieving competitive results on well-known benchmarks with lower latency on mobile devices. Specifically, our model is 5.2x faster on CPU and 4.1x faster on GPU with 0.5-2% accuracy loss compared with BERT-base. Our overall framework achieves up to 7.8x speedup compared with TensorFlow-Lite with only minor accuracy loss.",2
Achieving real-time execution of transformer-based large-scale models on mobile with compiler-aware neural architecture optimization,"Wei Niu, Zhenglun Kong, Geng Yuan, Weiwen Jiang, Jiexiong Guan, Caiwen Ding, Pu Zhao, Sijia Liu, Bin Ren, Yanzhi Wang",2020,Journal arXiv preprint arXiv: 2009.06823,,2
On the design of reliable heterogeneous systems via checkpoint placement and core assignment,"Edwin Sha, Hailiang Dong, Weiwen Jiang, Qingfeng Zhuge, Xianzhang Chen, Lei Yang",2018/5/30,Book Proceedings of the 2018 on Great Lakes Symposium on VLSI,"This paper studies two basic problems in the design of high-performance and high-reliability heterogeneous systems: (1) what type of core to execute each task, and (2) where to place checkpoints in the execution of tasks. The implementation of checkpointing techniques on the novel persistent memory (e.g., 3D Xpoint memory) based heterogeneous systems faces a bundle of new problems. First, the assignments of tasks may greatly influence the execution time of the whole application. Therefore, with the same time constraint, the reliability of the resultant system can be significantly affected. Second, creating checkpoints will incur heavy writes on persistent memories and reduce the lifetime of devices. In this paper, we optimally construct reliable systems by assigning tasks to the most suitable cores and placing minimum number of checkpoints in the application, such that the resultant system can satisfy the time …",2
Work-in-progress: Communication optimization for thermal reliable many-core systems,"Weichen Liu, Lei Yang, Weiwen Jiang, Nan Guan",2017/10/15,Conference 2017 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ ISSS),"System-level thermal management techniques normally map applications on non-adjacent cores to guarantee the safe temperature in many-core systems, while the communication efficiency will be oppositely affected by long-distance data transmission over conventional Network-on-Chips (NoC). SMART NoC has enabled single-cycle multi-hop bypass channels between distant cores, which can significantly reduce inter-processor communication latency. However, communication efficiency of SMART will be significantly diminished by express bypass break due to communication conflict. In order to achieve communication optimization with guaranteed system thermal reliability, we propose a dynamic reconfiguration method for logical interconnection topology through task mapping on top of SMART NoC. Active cores are physically decentralized on chip for better heat dissipation, while communication overhead …",2
The larger the fairer? small neural networks can achieve fairness for edge devices,"Yi Sheng, Junhuan Yang, Yawen Wu, Kevin Mao, Yiyu Shi, Jingtong Hu, Weiwen Jiang, Lei Yang",2022/7/10,Book Proceedings of the 59th ACM/IEEE Design Automation Conference,"Along with the progress of AI democratization, neural networks are being deployed more frequently in edge devices for a wide range of applications. Fairness concerns gradually emerge in many applications, such as face recognition and mobile medical. One fundamental question arises: what will be the fairest neural architecture for edge devices? By examining the existing neural networks, we observe that larger networks typically are fairer. But, edge devices call for smaller neural architectures to meet hardware specifications. To address this challenge, this work proposes a novel Fairness- and Hardware-aware Neural architecture search framework, namely FaHaNa. Coupled with a model freezing approach, FaHaNa can efficiently search for neural networks with balanced fairness and accuracy, while guaranteed to meet hardware specifications. Results show that FaHaNa can identify a series of neural networks …",1
A compression-compilation framework for on-mobile real-time bert applications,"Wei Niu, Zhenglun Kong, Geng Yuan, Weiwen Jiang, Jiexiong Guan, Caiwen Ding, Pu Zhao, Sijia Liu, Bin Ren, Yanzhi Wang",2021/5/30,Journal arXiv preprint arXiv:2106.00526,"Transformer-based deep learning models have increasingly demonstrated high accuracy on many natural language processing (NLP) tasks. In this paper, we propose a compression-compilation co-design framework that can guarantee the identified model to meet both resource and real-time specifications of mobile devices. Our framework applies a compiler-aware neural architecture optimization method (CANAO), which can generate the optimal compressed model that balances both accuracy and latency. We are able to achieve up to 7.8x speedup compared with TensorFlow-Lite with only minor accuracy loss. We present two types of BERT applications on mobile devices: Question Answering (QA) and Text Generation. Both can be executed in real-time with latency as low as 45ms. Videos for demonstrating the framework can be found on https://www.youtube.com/watch?v=_WIRvK_2PZI",1
A mining pool solution for novel proof-of-neural-architecture consensus,"Boyang Li, Qing Lu, Weiwen Jiang, Taeho Jung, Yiyu Shi",2021/5/3,Conference 2021 IEEE International Conference on Blockchain and Cryptocurrency (ICBC),"In many recent novel blockchain consensuses, deep learning training procedure becomes the task for miners to prove their workload, thus the computation power of miners will not purely be spent on the hash puzzle. Therefore, the hardware and energy will support the blockchain service and deep learning training at the same time. The incentive of miners is to earn tokens and individual miners will find mining pools become more competitive. To the best of our knowledgeWe are the first to demonstrate a mining pool solution for novel consensuses based on deep learning. This work adopts from exist Proof-of-Deep-Learning (PoDL) as the consensus and Neural Architecture Search (NAS) as the workload. The mining pool manager partitions the full searching space into subspaces and all miners contributes to the NAS task in the assigned tasks. The strong miners are assigned for exploration and the weak miners …",1
RMSMP: A Novel Deep Neural Network Quantization Framework with Row-wise Mixed Schemes and Multiple Precisions,"Sung-En Chang, Yanyu Li, Mengshu Sun, Weiwen Jiang, Sijia Liu, Yanzhi Wang, Xue Lin",2021,Conference Proceedings of the IEEE/CVF International Conference on Computer Vision,"This work proposes a novel Deep Neural Network (DNN) quantization framework, namely RMSMP, with a\underline R ow-wise\underline M ixed-\underline S cheme and\underline M ulti-\underline P recision approach. Specifically, this is the first effort to assign mixed quantization schemes and multiple precisions within layers--among rows of the DNN weight matrix, for simplified operations in hardware inference, while preserving accuracy. Furthermore, this paper makes a different observation from the prior work that the quantization error does not necessarily exhibit the layer-wise sensitivity, and actually can be mitigated as long as a certain portion of the weights in every layer are in higher precisions. This observation enables layer-wise uniformality in the hardware implementation towards guaranteed inference acceleration, while still enjoying row-wise flexibility of mixed schemes and multiple precisions to boost accuracy. The candidates of schemes and precisions are derived practically and effectively with a highly hardware-informative strategy to reduce the problem search space. With the offline determined ratio of different quantization schemes and precisions for all the layers, the RMSMP quantization algorithm uses Hessian and variance based method to effectively assign schemes and precisions for each row. The proposed RMSMP is tested for the image classification and natural language processing (BERT) applications, and achieves the best accuracy performance among state-of-the-arts under the same equivalent precisions. The RMSMP is implemented on FPGA devices, achieving 3.65 xspeedup in the end-to-end inference time for …",1
VACSEN: A Visualization Approach for Noise Awareness in Quantum Computing,"Shaolun Ruan, Yong Wang, Weiwen Jiang, Ying Mao, Qiang Guan",1912,Journal IEEE Transactions on Visualization and Computer Graphics,"Quantum computing has attracted considerable public attention due to its exponential speedup over classical computing. Despite its advantages, today's quantum computers intrinsically suffer from noise and are error-prone. To guarantee the high fidelity of the execution result of a quantum algorithm, it is crucial to inform users of the noises of the used quantum computer and the compiled physical circuits. However, an intuitive and systematic way to make users aware of the quantum computing noise is still missing. In this paper, we fill the gap by proposing a novel visualization approach to achieve noise-aware quantum computing. It provides a holistic picture of the noise of quantum computing through multiple interactively coordinated views: a Computer Evolution View with a circuit-like design overviews the temporal evolution of the noises of different quantum computers, a Circuit Filtering View facilitates quick …",1
Quantization Through Search: A Novel Scheme to Quantize Convolutional Neural Networks in Finite Weight Space,"Qing Lu, Weiwen Jiang, Xiaowei Xu, Jingtong Hu, Yiyu Shi",2023/1/16,Book Proceedings of the 28th Asia and South Pacific Design Automation Conference,"Quantization has become an essential technique in compressing deep neural networks for deployment onto resource-constrained hardware. It is noticed that, the hardware efficiency of implementing quantized networks is highly coupled with the actual values to be quantized into, and therefore, with given bit widths, we can smartly choose a value space to further boost the hardware efficiency. For example, using weights of only integer powers of two, multiplication can be fulfilled by bit operations. Under such circumstances, however, existing quantization-aware training methods are either not suitable to apply or unable to unleash the expressiveness of very low bit-widths. For the best hardware efficiency, we revisit the quantization of convolutional neural networks and propose to address the training process from a weight-searching angle, as opposed to optimizing the quantizer functions as in existing works …",
Mobile or FPGA? A Comprehensive Evaluation on Energy Efficiency and a Unified Optimization Framework,"Geng Yuan, Peiyan Dong, Mengshu Sun, Wei Niu, Zhengang Li, Yuxuan Cai, Yanyu Li, Jun Liu, Weiwen Jiang, Xue Lin, Bin Ren, Xulong Tang, Yanzhi Wang",2022/12/9,Journal ACM Transactions on Embedded Computing Systems,"Efficient deployment of Deep Neural Networks (DNNs) on edge devices (i.e., FPGAs and mobile platforms) is very challenging, especially under a recent witness of the increasing DNN model size and complexity. Model compression strategies, including weight quantization and pruning, are widely recognized as effective approaches to significantly reduce computation and memory intensities, and have been implemented in many DNNs on edge devices. However, most state-of-the-art works focus on ad hoc optimizations, and there lacks a thorough study to comprehensively reveal the potentials and constraints of different edge devices when considering different compression strategies. In this article, we qualitatively and quantitatively compare the energy efficiency of FPGA-based and mobile-based DNN executions using mobile GPU and provide a detailed analysis. Based on the observations obtained from the …",
Hardware and neural architecture co-search,"Sakyasingha Dasgupta, Weiwen Jiang, Yiyu Shi",2022/12/6,Patent office US,"Hardware and neural architecture co-search may be performed by operations including obtaining a specification of a function and a plurality of hardware design parameters. The hardware design parameters include a memory capacity, a number of computational resources, a communication bandwidth, and a template configuration for performing neural architecture inference. The operations further include determining, for each neural architecture among a plurality of neural architectures, an overall latency of performance of inference of the neural architecture by an accelerator within the hardware design parameters. Each neural architecture having been trained to perform the function with an accuracy. The operations further include selecting, from among the plurality of neural architectures, a neural architecture based on the overall latency and the accuracy.",
A collaboration strategy in the mining pool for proof-of-neural-architecture consensus,"Boyang Li, Qing Lu, Weiwen Jiang, Taeho Jung, Yiyu Shi",2022/12/1,Journal Blockchain: Research and Applications,"In most popular public accessible cryptocurrency systems, the mining pool plays a key role because mining cryptocurrency with the mining pool turns the non-profitable situation into profitable for individual miners. In many recent novel blockchain consensuses, the deep learning training procedure becomes the task for miners to prove their workload. Thus, the computation power of miners will not purely be spent on the hash puzzle. In this way, the hardware and energy will support the blockchain service and deep learning training simultaneously. While the incentive of miners is to earn tokens, individual miners are motivated to join mining pools to become more competitive. In this paper, we are the first to demonstrate a mining pool solution for novel consensuses based on deep learning.",
Seismic Waveform Inversion Capability on Resource-Constrained Edge Devices,"Daniel Manu, Petro Mushidi Tshakwanda, Youzuo Lin, Weiwen Jiang, Lei Yang",2022/11/22,Journal Journal of Imaging,"Seismic full wave inversion (FWI) is a widely used non-linear seismic imaging method used to reconstruct subsurface velocity images, however it is time consuming, has high computational cost and depend heavily on human interaction. Recently, deep learning has accelerated it’s use in several data-driven techniques, however most deep learning techniques suffer from overfitting and stability issues. In this work, we propose an edge computing-based data-driven inversion technique based on supervised deep convolutional neural network to accurately reconstruct the subsurface velocities. Deep learning based data-driven technique depends mostly on bulk data training. In this work, we train our deep convolutional neural network (DCN) (UNet and InversionNet) on the raw seismic data and their corresponding velocity models during the training phase to learn the non-linear mapping between the seismic data and velocity models. The trained network is then used to estimate the velocity models from new input seismic data during the prediction phase. The prediction phase is performed on a resource-constrained edge device such as Raspberry Pi. Raspberry Pi provides real-time and on-device computational power to execute the inference process. In addition, we demonstrate robustness of our models to perform inversion in the presence on noise by performing both noise-aware and no-noise training and feeding the resulting trained models with noise at different signal-to-noise (SNR) ratio values. We make great efforts to achieve very feasible inference times on the Raspberry Pi for both models. Specifically, the inference times per prediction for …",
Category: Publications,Pear Deck,2022/11/15,Journal Timeline,"The CALICO Journal, founded in 1983, moved to Equinox in 2015. CALICO Journal is the official publication of the Computer Assisted Language Instruction Consortium (CALICO) and is devoted to the dissemination of information concerning the application of technology to language teaching and language learning. The journal is published online-only, is fully refereed and publishes research articles and studies and software and book reviews. Three issues appear annually and normally one of them is a thematic issue on current discourses and developments in Computer-Assisted Language Learning. CALICO’s international editorial board and large group of authors and reviewers reflect its global readership.",
Iterative Qubits Management for Quantum Index Searching in a Hybrid System,"Wenrui Mu, Ying Mao, Long Cheng, Qingle Wang, Weiwen Jiang, Pin-Yu Chen",2022/11/11,"Conference 2022 IEEE International Performance, Computing, and Communications Conference (IPCCC)","Recent advances in quantum computing systems attract tremendous attention. Commercial companies, such as IBM, Amazon, and IonQ, have started to provide access to noisy intermediate-scale quantum computers. Researchers and entrepreneurs attempt to deploy their applications that aim to achieve a quantum speedup. Grover’s algorithm and quantum phase estimation are the foundations of many applications with the potential for such a speedup. While these algorithms, in theory, obtain marvelous performance, deploying them on existing quantum devices is a challenging task. For example, quantum phase estimation requires extra qubits and a large number of controlled operations, which are impractical due to low-qubit and noisy hardware. To fully utilize the limited onboard qubits, we propose IQuCS, which aims at index searching and counting in a quantum-classical hybrid system. IQuCS is based on …",
TorchQuantum Case Study for Robust Quantum Circuits,"Hanrui Wang, Zhiding Liang, Jiaqi Gu, Zirui Li, Yongshan Ding, Weiwen Jiang, Yiyu Shi, David Z Pan, Frederic T Chong, Song Han",2022/10/30,Book Proceedings of the 41st IEEE/ACM International Conference on Computer-Aided Design,"Quantum Computing has attracted much research attention because of its potential to achieve fundamental speed and efficiency improvements in various domains. Among different quantum algorithms, Parameterized Quantum Circuits (PQC) for Quantum Machine Learning (QML) show promises to realize quantum advantages on the current Noisy Intermediate-Scale Quantum (NISQ) Machines. Therefore, to facilitate the QML and PQC research, a recent python library called TorchQuantum has been released. It can construct, simulate, and train PQC for machine learning tasks with high speed and convenient debugging supports. Besides quantum for ML, we want to raise the community's attention on the reversed direction: ML for quantum. Specifically, the TorchQuantum library also supports using data-driven ML models to solve problems in quantum system research, such as predicting the impact of quantum noise …",
All-in-One: A Highly Representative DNN Pruning Framework for Edge Devices with Dynamic Power Management,"Yifan Gong, Zheng Zhan, Pu Zhao, Yushu Wu, Chao Wu, Caiwen Ding, Weiwen Jiang, Minghai Qin, Yanzhi Wang",2022/10/30,Book Proceedings of the 41st IEEE/ACM International Conference on Computer-Aided Design,"During the deployment of deep neural networks (DNNs) on edge devices, many research efforts are devoted to the limited hardware resource. However, little attention is paid to the influence of dynamic power management. As edge devices typically only have a budget of energy with batteries (rather than almost unlimited energy support on servers or workstations), their dynamic power management often changes the execution frequency as in the widely-used dynamic voltage and frequency scaling (DVFS) technique. This leads to highly unstable inference speed performance, especially for computation-intensive DNN models, which can harm user experience and waste hardware resources. We firstly identify this problem and then propose All-in-One, a highly representative pruning framework to work with dynamic power management using DVFS. The framework can use only one set of model weights and soft …",
On the Design of Quantum Graph Convolutional Neural Network in the NISQ-Era and Beyond,"Zhirui Hu, Jinyang Li, Zhenyu Pan, Shanglin Zhou, Lei Yang, Caiwen Ding, Omer Khan, Tong Geng, Weiwen Jiang",2022/10/23,Conference 2022 IEEE 40th International Conference on Computer Design (ICCD),"The rapid growth in the size of Graph Convolutional Neural Networks (GCNs) encounters both computational- and memory-wall on classical computing platforms (e.g., CPU, GPU, FPGA, etc.). Quantum computing, on the other hand, provides extremely high parallelism for computation. Although quantum neural networks have been recently studied, the research on quantum graph neural networks is still in its infancy. The key challenge here is how to integrate both the graph topology information and the learning ability of GCNs into quantum circuits. In this work, we leverage the Givens rotations and its quantum implementation to encode graph information; in addition, we employ the widely used variational quantum circuit to bring the learnable parameters. On top of these, we present a full-quantum design of Graph Convolutional Neural Networks, namely ""QuGCN"", for semi-supervised learning on graph-structured …",
Towards Real-Time Temporal Graph Learning,"Deniz Gurevin, Mohsin Shan, Tong Geng, Weiwen Jiang, Caiwen Ding, Omer Khan",2022/10/23,Conference 2022 IEEE 40th International Conference on Computer Design (ICCD),"In recent years, graph representation learning has gained significant popularity, which aims to generate node embeddings that capture features of graphs. One of the methods to achieve this is employing a technique called random walks that captures node sequences in a graph and then learns embeddings for each node using a natural language processing technique called Word2Vec. These embeddings are then used for deep learning on graph data for classification tasks, such as link prediction or node classification. Prior work operates on pre-collected temporal graph data and is not designed to handle updates on a graph in real-time. Real world graphs change dynamically and their entire temporal updates are not available upfront. In this paper, we propose an end-to-end graph learning pipeline that performs temporal graph construction, creates low-dimensional node embeddings, and trains multi-layer …",
Hardware-aware Automated Architecture Search for Brain-inspired Hyperdimensional Computing,"Junhuan Yang, Venkat Kalyan Reddy Yasa, Yi Sheng, Dayane Reis, Xun Jiao, Weiwen Jiang, Lei Yang",2022/7/4,Conference 2022 IEEE Computer Society Annual Symposium on VLSI (ISVLSI),"Brain-inspired neural network, a.k.a., hyperdimensional computing (HDC), has been becoming a promising candidate for resource-limited edge computing, due to its small size and robustness. However, the previous HDC architecture exploration only considers the software aspects, like HDC operations. This paper presents a hardware-aware automated architecture search framework, namely HwAwHDC, for HDC, which can consider both hardware and software characters in a uniform reinforcement learning based optimization loop. It fills the gap in the automatic design of HDC architectures for given applications and hardware constraints. We do a thorough analysis to formulate the search spaces for HwAwHDC. On top of this, we design a hardware-friendly reward and employ reinforcement learning (RL) to explore the HDC architectures. The encouraging experimental evidence shows the effectiveness of our …",
Hardware/Software Co-Exploration for Graph Neural Architectures on FPGAs,"Qing Lu, Weiwen Jiang, Meng Jiang, Jingtong Hu, Yiyu Shi",2022/7/4,Conference 2022 IEEE Computer Society Annual Symposium on VLSI (ISVLSI),"The success of graph neural networks (GNNs) in the past years has aroused growing interest and effort in designing the best models to handle graph-structured data. Meanwhile, the neural architecture search (NAS) technique has been witnessed to rival against human experts in discovering efficient network topology. Most recently, it has been applied to the field of GNN engineering. However, despite the growing interest in GNN accelerator designs, existing works on graph neural architecture search all concentrate on software (SW) and do not consider hardware (HW) constraints at all, which often leads to sub-optimal system performance when the resulting networks are deployed on hardware accelerators. To address this problem, in this paper we propose a SW-HW co-design framework, namely FGNAS, for automating the search and deployment of GNNs on FPGAs. Experimental results on common benchmark …",
One Proxy Device Is Enough for Hardware-Aware Neural Architecture Search,"Bingqian Lu, Jianyi Yang, Weiwen Jiang, Yiyu Shi, Shaolei Ren",2022/6/6,Journal ACM SIGMETRICS Performance Evaluation Review,Convolutional neural networks (CNNs) are used in numerous realworld applications such as vision-based autonomous driving and video content analysis.,
Automated Architecture Search for Brain-inspired Hyperdimensional Computing,"Junhuan Yang, Yi Sheng, Sizhe Zhang, Ruixuan Wang, Kenneth Foreman, Mikell Paige, Xun Jiao, Weiwen Jiang, Lei Yang",2022/2/11,Journal arXiv preprint arXiv:2202.05827,"This paper represents the first effort to explore an automated architecture search for hyperdimensional computing (HDC), a type of brain-inspired neural network. Currently, HDC design is largely carried out in an application-specific ad-hoc manner, which significantly limits its application. Furthermore, the approach leads to inferior accuracy and efficiency, which suggests that HDC cannot perform competitively against deep neural networks. Herein, we present a thorough study to formulate an HDC architecture search space. On top of the search space, we apply reinforcement-learning to automatically explore the HDC architectures. The searched HDC architectures show competitive performance on case studies involving a drug discovery dataset and a language recognition task. On the Clintox dataset, which tries to learn features from developed drugs that passed/failed clinical trials for toxicity reasons, the searched HDC architecture obtains the state-of-the-art ROC-AUC scores, which are 0.80% higher than the manually designed HDC and 9.75% higher than conventional neural networks. Similar results are achieved on the language recognition task, with 1.27% higher performance than conventional methods.",
Privacy-Preserving Medical Image Segmentation via Hybrid Trusted Execution Environment,"Song Bian, Weiwen Jiang, Takashi Sato",2021/12/5,Conference 2021 58th ACM/IEEE Design Automation Conference (DAC),"Recently, it is reported that the-state-of-the-art secure protocol is able to segment a three-dimensional heart CT scan in roughly 3,000 seconds, without revealing any sensitive information related to the parties involved in the computation. In this work, building upon the existing mix-protocol approach, we make use of the trusted execution environment (TEE) to implement a more efficient privacy-preserving medical image segmentation protocol. In the experiment, we show that by offloading the computations of single-party operators to trusted hardware, the latency for a round of privacy-preserving segmentation can be further reduced by 25×.",
On the Design of Time-Constrained and Buffer-Optimal Self-Timed Pipelines,"Weiwen Jiang, Edwin Hsing-Mean Sha, Qingfeng Zhuge, Lei Yang, Xianzhang Chen, Jingtong Hu",2018/6/12,Journal IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,"Pipelining is a powerful technique to achieve high performance in computing systems. However, as computing platforms become large-scale and integrate with heterogeneous processing elements (PEs) (CPUs, GPUs, field-programmable gate arrays, etc.), it is difficult to employ a global clock to achieve synchronous pipelines. Therefore, self-timed (or asynchronous) pipelines are usually adopted. Nevertheless, due to their complex running behavior, the performance modeling and systematic optimizations for self-timed pipeline (STP) systems are more complicated than those for synchronous ones. This paper employs marked graph theory to model STPs and presents algorithms to detect performance bottlenecks. Based on the proposed model, we observe that the system performance can be improved by inserting buffers. Due to the limited memory resources on the PEs, it is critical to minimize the number of buffers …",
Communication optimization for thermal reliable many-core systems: work-in-progress,"Weichen Liu, Lei Yang, Weiwen Jiang, Nan Guan",2017/10/15,Book Proceedings of the Twelfth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis Companion,"System-level thermal management techniques normally map applications on non-adjacent cores to guarantee the safe temperature in many-core systems, while the communication efficiency will be oppositely affected by long-distance data transmission over conventional Network-on-Chips (NoC). SMART NoC has enabled single-cycle multi-hop bypass channels between distant cores, which can significantly reduce inter-processor communication latency. However, communication efficiency of SMART will be significantly diminished by express bypass break due to communication conflict. In order to achieve communication optimization with guaranteed system thermal reliability, we propose a dynamic reconfiguration method for logical interconnection topology through task mapping on top of SMART NoC. Active cores are physically decentralized on chip for better heat dissipation, while communication overhead …",
Towards the design of optimal range assignment for elevator groups under fluctuant traffic loads,"Hailiang Dong, Edwin H-M Sha, Weiwen Jiang, Xianzhang Chen, Runyu Zhang, Qingfeng Zhuge",2017/8/16,Conference 2017 IEEE 23rd International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA),"With the development of embedded devices, elevator group systems that manage elevators can be designed in an intelligent way. In the design of elevator group systems, one of the most important problems is to determine the “range assignment” for each elevator, which indicates the floors that an elevator will serve. In reality, the traffic loads of a building are different in terms of time periods, called fluctuant traffic loads, which makes the above problem much more challenging. The objective of this paper is to determine the optimal range assignment that can maximize the number of passengers served in a certain amount of time. The elevator group system can adapt to varying traffic loads and achieve fault tolerance by conducting range reassignment. In this paper, we build a Mixed Integer Linear Programming (MILP) to find the optimal range assignment. However, MILP suffers from large computational complexities …",
The Design and Implementation of an Efficient Data Consistency Mechanism for In-Memory File Systems,"Xianzhang Chen, Edwin H-M Sha, Zhilong Sun, Qingfeng Zhuge, Weiwen Jiang",2016/8/13,Conference 2016 13th International Conference on Embedded Software and Systems (ICESS),"The Non-Volatile Memory (NVM) based in-memory file systems show great potential in supporting real-time data processing for their extremely high performance. The reliability of file systems is ensured by data consistency mechanisms. The existing data consistency mechanisms, however, largely degrades the performance of the in-memory file system without fully exploiting the characteristics of NVM. In this paper, we propose an efficient data consistency mechanism, Amphibian Update Strategy (AUS), taking advantages of the virtual address space of NVM. In the proposed AUS technique, the backup spaces of file data are organized and accessed by the contiguous virtual address space of the kernel. We present the Direct-Copy and Exchanging approaches to efficiently update the primary file data for the requests with different sizes. We implemented different data consistency mechanisms in a real in-memory file …",
Optimal Functional Assignment and Communication Selection under Timing Constraint for Self-Timed Pipelines,"Weiwen Jiang, Edwin H-M Sha, Xianzhang Chen, Qingfeng Zhuge, Lin Wu",2016/8/13,Conference 2016 13th International Conference on Embedded Software and Systems (ICESS),"In high-level synthesis for application-specific embedded systems, it is critical to employ a proper model to measure the performance of a system containing both computation and communication. The self-timed system model, which describes the process of computation and communication as timed transitions, is able to accurately model the distributed embedded systems. In the design of a self-timed system, there are two realistic problems: how to assign heterogeneous functional units to task nodes and how to select communication protocols for pairs of task nodes. This paper focuses on the application with pipeline structure where task nodes are organized in a linear topology. Given a serial of task nodes, our objective is find the optimal functional assignment and communication selection, such that the resultant self-timed pipeline can satisfy the timing constraint with the minimum total cost. In this paper, we present …",
The Design and Implementation of a High-Performance Hybrid Memory File System,"Edwin H-M Sha, Jun Chen, Xianzhang Chen, Weiwen Jiang, Qingfeng Zhuge",2016/8/13,Conference 2016 International Conference on Advanced Cloud and Big Data (CBD),"The emerging Non-Volatile Memory (NVM) connected to the memory bus provides opportunities for high-performance file accesses for its near-DRAM speed and byte-addressability. In this paper, a high-performance hybrid file system, called Hybrid Memory File System (HMFS), is designed and implemented to exploit the high speed of NVM and the large capacity of block devices. A file in HMFS can be stored across the NVM and block devices. In HMFS, each opened file is mapped to a contiguous virtual address space of the kernel. Using the related virtual address space, the physical locations of file data can be efficiently located by the hardware MMU or a dedicated page fault handler for HMFS. The file data in the NVM are accessed with high performance using the corresponding virtual addresses. The file data stored in the block devices are pre-fetched to take advantages of the NVM. Extensive experiments are …",
Isolation of Physical and Logical Views of Dark-Silicon Many-Core Systems for Reliability and Performance Co-Optimization,"Lei Yang, Weichen Liu, Weiwen Jiang, Mengquan Li, Jie Wang",2015,"Conference Embedded System Technology: 13th National Conference, ESTC 2015, Beijing, China, October 10–11, 2015, Revised Selected Papers 13","A fraction of a many-core chip has to become powered off in order to maintain allowable power budget and safe temperature in the dark silicon era. Techniques have been developed to selectively activate cores in distributed physical locations to avoid temperature hotspot. It results in the unexpected increase of communication overhead due to longer average distance between active cores on Network-on-Chip (NoC). We propose a physical and logical isolated framework based on Folded Torus-like NoC for heterogeneous many-core systems to achieve the guaranteed temperature reliability and satisfied application performance requirement. Physically distributed cores are interconnected through folded torus-like NoC and organized in clusters to enable logically condensed intercommunications within it. Compared to traditional mesh-like systems, the proposed folded torus-like organization can achieve on …",
Graph Transformer for Quantum Circuit Reliability Prediction,"Hanrui Wang, Pengyu Liu, Jinglei Cheng, Zhiding Liang, Jiaqi Gu, Zirui Li, Yongshan Ding, Weiwen Jiang, Yiyu Shi, Xuehai Qian, David Z Pan, Frederic T Chong, Song Han","Quantum Computing has attracted much research attention because of its potential to achieve fundamental speed and efficiency improvements in various domains. Among different quantum algorithms, Parameterized Quantum Circuits (PQC) for Quantum Machine Learning (QML) show promises to realize quantum advantages on the current Noisy Intermediate-Scale Quantum (NISQ) Machines. Therefore, to facilitate the QML and PQC research, a recent python library called TorchQuantum has been released. It can construct, simulate, and train PQC for machine learning tasks with high speed and convenient debugging supports. Besides quantum for ML, we want to raise the community’s attention on the reversed direction: ML for quantum. Specifically, the TorchQuantum library also supports using data-driven ML models to solve problems in quantum system research, such as predicting the impact of quantum noise on circuit fidelity and improving the quantum circuit compilation efficiency.This paper presents a case study of the ML for quantum part in TorchQuantum. Since estimating the noise impact on circuit reliability is an essential step toward understanding and mitigating noise, we propose to leverage classical ML to predict noise impact on circuit fidelity. Inspired by the natural graph representation of quantum circuits, we propose to leverage a graph transformer model to predict the noisy circuit fidelity. We firstly collect a large dataset with a variety of quantum circuits and obtain their fidelity on noisy simulators and real machines. Then we embed each circuit into a graph with gate and noise properties as node features, and adopt a graph …","Scholar articles Graph Transformer for Quantum Circuit Reliability PredictionH Wang, P Liu, J Cheng, Z Liang, J Gu, Z Li, Y Ding…Related articles ","Quantum Computing has attracted much research attention because of its potential to achieve fundamental speed and efficiency improvements in various domains. Among different quantum algorithms, Parameterized Quantum Circuits (PQC) for Quantum Machine Learning (QML) show promises to realize quantum advantages on the current Noisy Intermediate-Scale Quantum (NISQ) Machines. Therefore, to facilitate the QML and PQC research, a recent python library called TorchQuantum has been released. It can construct, simulate, and train PQC for machine learning tasks with high speed and convenient debugging supports. Besides quantum for ML, we want to raise the community’s attention on the reversed direction: ML for quantum. Specifically, the TorchQuantum library also supports using data-driven ML models to solve problems in quantum system research, such as predicting the impact of quantum noise on circuit fidelity and improving the quantum circuit compilation efficiency.",
IEEE CIRCUITS AND SYSTEMS SOCIETY,"YAJUN HA, EDOARDO BONIZZONI, SEBASTIAN HOYOS, BIJAN ALIZADEH, JASON ANDERSON, JOHAN BAUWELINCK, HANSRAJ SINGH BHAMRA, SOUMYA BOSE, ANDREA CALIMERA, LUIS CAMU NAS-MESA, LI CHAI, MRITYUNJOY CHAKRABORTY, MINGYI CHEN, CHI-TSUN CHENG, CARLO CONDO, LUIS FERNANDO COSTA ALBERTO, JINLIANG DING, ZHENGTAO DING, GORDANA JOVANOVIC DOLECEK, HAIRONG DONG, HAIBIN DUAN, YONGCHUN FANG, QUANYUAN FENG, LU GAN, WEINAN GAO, XIAOHUA GE, LI GENG, PATRICK GIRARD, JOAO GOES, JIE GU, ULKUHAN GULER, NAVNEET GUPTA, CHANGCHUN HUA, CHENG HUANG, KEJIE HUANG, MIAOQING HUANG, HERBERT HC IU, HANJUN JIANG, WEIWEN JIANG, JUNMIN JIANG, ZHONG-PING JIANG, DEEPU JOHN, SANTANU KAPAT, RAJENDRA KATTI, KYU-HYOUN KIM, JAYDEEP KULKARNI, AKASH KUMAR, XIAOWEI LI, GUANGYONG LI, YINGYAN LIN, JUN LIN, QIYUAN LIU, JIANXING LIU, HAO LIU, SHIBING LONG, XIN LOU, DELIN LUO, JINGJING MENG, XIANGSHUI MIAO, VEERACHARY MUMMADI, DANTE MURATORE, ERIVELTON GERALDO NEPOMUCENO, LUIS B OLIVEIRA, HANGUE PARK, LIANG QI, LIBO QIAN, GANG QU, XINBO RUAN, VISHAL SAXENA, CHIU-WING SHAM, SAI-WENG SIN, RAMALINGAM SRIDHAR, CHRISTOPH STUDER, TADASHI SUETSUGU, SACHIN TANEJA, SHUILIN TIAN, KINFAI TONG, RANGHARAJAN VENKATESAN, KHURRAM WAHEED, JEFFREY WALLING, CONG WANG, YANZHI WANG, JING WANG, YIN WANG, XIAOQUN WU, YONGLE WU, YINSHUI XIA, JUNFEI XIE, JINJUN XIONG, MUSTAK ERHAN YALCIN, HAIGANG YANG, JUN YANG, MOHAMMAD YAVARI, XIANG YI, HENG YU, JUNZHI YU, ZHIYI YU, XIAOYANG ZENG, CHUAN ZHANG, XI ZHANG","Presents a listing of the editorial board, board of governors, current staff, committee members, and/or society editors for this issue of the publication.","Scholar articles IEEE CIRCUITS AND SYSTEMS SOCIETYY HA, E BONIZZONI, S HOYOS, B ALIZADEH…All 2 versions ","Presents a listing of the editorial board, board of governors, current staff, committee members, and/or society editors for this issue of the publication.",
Speaker,"Weiwen Jiang, Man-Zhong Wang, Shi-Pei Zhang","QuantumFlow: Co-Design Neural Network and Quantum Circuit towards Quantum Advantage 
Page 1 QuantumFlow: Co-Design Neural Network and Quantum Circuit towards Quantum 
Advantage Weiwen Jiang, Ph.D. Assistant Professor Electrical and Computer Engineering 
George Mason University wjiang8@gmu.edu https://jqub.ece.gmu.edu Page 2 HW/SW 
Co-Design Framework FNAS [DAC’19*] [TCAD’20*] A p p lic a tio n Medical Imaging 3D Cardiac 
MRI Seg. [ICCAD’20] NAS for Medical Image Seg. [MICCAI’20] NLP (Transformer) FPGA 
[ICCD’20] Mobile [DAC’21] GPU [GLSVLSI’21] Graph-Based Social Net [GLSVLSI’21] Drug 
Discovery [ICCAD’21] A lg o rith m NAS Acc. HotNAS [CODES+ISSS’20] Model Compression 
NAS for Quan. [ICCAD’19] Compre.-Compilation [IJCAI’21] Secure Infernece NASS [ECAI’20] 
BUNET [MICCAI’20] H a rd w a re FPGA XFER [CODES+ISSS’19*] ASIC NANDS [ASP-DAC’20*] …","Scholar articles SpeakerW Jiang, MZ Wang, SP ZhangAll 4 versions ",,
On the Universal Approximability and Complexity Bounds of Deep Learning in Hybrid Quantum-Classical Computing,"Weiwen Jiang, Yukun Ding, Yiyu Shi","With the continuously increasing number of quantum bits in quantum computers, there are growing interests in exploring applications that can harvest the power of them. Recently, several attempts were made to implement neural networks, known to be computationally intensive, in hybrid quantum-classical scheme computing. While encouraging results are shown, two fundamental questions need to be answered: (1) whether neural networks in hybrid quantum-classical computing can leverage quantum power and meanwhile approximate any function within a given error bound, i.e., universal approximability; (2) how do these neural networks compare with ones on a classical computer in terms of representation power? This work sheds light on these two questions from a theoretical perspective.","Scholar articles On the Universal Approximability and Complexity Bounds of Deep Learning in Hybrid Quantum-Classical ComputingW Jiang, Y Ding, Y ShiRelated articles ","With the continuously increasing number of quantum bits in quantum computers, there are growing interests in exploring applications that can harvest the power of them. Recently, several attempts were made to implement neural networks, known to be computationally intensive, in hybrid quantum-classical scheme computing. While encouraging results are shown, two fundamental questions need to be answered: (1) whether neural networks in hybrid quantum-classical computing can leverage quantum power and meanwhile approximate any function within a given error bound, i.e., universal approximability; (2) how do these neural networks compare with ones on a classical computer in terms of representation power? This work sheds light on these two questions from a theoretical perspective.",
Machine Learning on Quantum Computing: From Classical to Quantum,Weiwen Jiang,"Click to add heading Page 1 Weiwen Jiang, Ph.D. Postdoc Research Associate Department 
of Computer Science and Engineering University of Notre Dame wjiang2@nd.edu | https://wjiang.nd.edu 
Machine Learning on Quantum Computing: From Classical to Quantum (Week 4 – Session 2) 
IBM Qiskit Hands-on Training Course at Notre Dame (Winter Break 2020-2021) Page 2 
Weiwen Jiang IBM Qiskit Hands-On Course at ND in 20-21 Winter Break Review of 
Previous Session --- Goal 1: Implementing Perceptron Correctly! 𝑂 = 1 4 ෍ 𝑖∈ 0,4 𝐼𝑖 × 𝑊𝑖 
2 1 +1 −1 +1 −1 𝑥0 𝑥1 𝑥2 𝑥3 𝑂 𝑞0 𝑞1 H H X X X 𝑂 input Z Z Pre-Processing Post-Processing 
Quantum Circuit UP UN |0> |0> |0> U P U N Page 3 Weiwen Jiang IBM Qiskit Hands-On 
Course at ND in 20-21 Winter Break Have a Try on PreP + U P + U N + M + PostP ! 2 +1 −1 −1 
−1 𝑥0 𝑥1 𝑥2 𝑥3 𝑂 0.3 0.5 0.7 0.9 PreP Given inputs and weights U P + U N 𝑞0 𝑞1 𝑞2 𝑞3 ? …",Scholar articles Machine Learning on Quantum Computing: From Classical to QuantumW JiangRelated articles All 3 versions ,,
Efficient Hardware and Neural Architecture Co-Search with Hot Start——A New Road for NN to HW (ROAD4NN2HW),Weiwen Jiang,"Click to add heading Page 1 Weiwen Jiang, Ph.D. Postdoc Research Associate Department of 
Computer Science and Engineering University of Notre Dame wjiang2@nd.edu | https://wjiang.nd.edu 
Efficient Hardware and Neural Architecture Co-Search with Hot Start —— A New Road for NN 
to HW (ROAD4NN2HW) A series of ROAD4NN2HW works are conducted at Univ. of Notre 
Dame in Prof. Yiyu Shi's group and Univ. of Pittsburgh in Prof. Jingtong Hu's group 
International Workshop on Research Open Automatic Design for Neural Networks (ROAD4NN) 
Page 2 Weiwen Jiang Mini Lecture 1 Agriculture Military Power System Manufacture Education 
Medical Operation Finance …… Embedded Computing Hardware Has Been in Every Corner 
Page 3 Weiwen Jiang Mini Lecture Today, AI is Going to Every Embedded Computing 
Hardware 2 Agriculture Military Power System Manufacture Education Medical Operation …",Scholar articles Efficient Hardware and Neural Architecture Co-Search with Hot Start——A New Road for NN to HW (ROAD4NN2HW)W JiangRelated articles ,,
CO1B. 1-SWARAM: Portable Energy and Cost Efficient Embedded System for Genomic Processing,"Ram Mohanty, Hasindu Gamaarachchi, Andrew Lambert, Sri Parameswaran, Jihye Kim, Jiwon Lee, Hankyung Ko, Donghwan Oh, Semin Han, Gwonho Jeong, Hyunok Oh, Daniel D Fong, Vivek J Srinivasan, Kourosh Vali, Soheil Ghiasi, Lokesh Siddhu, Preeti Ranjan Panda, Chenlin Ma, Zhaoyan Shen, Lei Han, Zili Shao, Yu-Pei Liang, Tseng-Yi Chen, Yuan-Hao Chang, Shuo-Han Chen, Kam-Yiu Lam, Wei-Hsin Li, Wei-Kuan Shih, Weiwen Jiang, Edwin Sha, Xinyi Zhang, Lei Yang, Qingfeng Zhuge, Yiyu Shi, Jingtong Hu, Wei-Chen Wang, Tei-Wei Kuo, Chien-Chung Ho, Yu-Ming Chang, Hung-Sheng Chang","International Conference on Compilers, Architecture, and Synthesis for Embedded Systems 
(CODES &#x002B;ISSS) 2019 Page 1 International Conference on Compilers, Architecture, 
and Synthesis for Embedded Systems (CODES +ISSS) 2019 Table of Contents 1 CO1B.1- 
SWARAM: Portable Energy and Cost Efficient Embedded System for Genomic Processing Ram 
Mohanty, Hasindu Gamaarachchi, Andrew Lambert, Sri Parameswaran CO1B.2- Authcropper: 
Authenticated Image Cropper for Privacy Preserving Surveillance Systems Jihye Kim, Jiwon 
Lee, Hankyung Ko, Donghwan Oh, Semin Han, Gwonho Jeong, Hyunok Oh CO1B.3- Optode 
Design Space Exploration for Clinically-robust Non-invasive Fetal Oximetry Daniel D. Fong, 
Vivek J. Srinivasan, Kourosh Vali, Soheil Ghiasi CO2B.1- PredictNcool: Leakage Aware 
Thermal Management for 3D Memories Using a Lightweight Temperature Predictor Lokesh …","Scholar articles CO1B. 1-SWARAM: Portable Energy and Cost Efficient Embedded System for Genomic ProcessingR Mohanty, H Gamaarachchi, A Lambert…",,
