titles,authors,date,source,descriptions,citations
On-line lda: Adaptive topic models for mining text streams with applications to topic detection and tracking,"Loulwah AlSumait, Daniel Barbará, Carlotta Domeniconi",2008/12/15,Conference 2008 eighth IEEE international conference on data mining,"This paper presents Online Topic Model (OLDA), a topic model that automatically captures the thematic patterns and identifies emerging topics of text streams and their changes over time. Our approach allows the topic modeling framework, specifically the Latent Dirichlet Allocation (LDA) model, to work in an online fashion such that it incrementally builds an up-to-date model (mixture of topics per document and mixture of words per topic) when a new document (or a set of documents) appears. A solution based on the Empirical Bayes method is proposed. The idea is to incrementally update the current model according to the information inferred from the new stream of data with no need to access previous data. The dynamics of the proposed approach also provide an efficient mean to track the topics over time and detect the emerging topics in real time. Our method is evaluated both qualitatively and quantitatively …",613
Locally adaptive metric nearest-neighbor classification,"Carlotta Domeniconi, Jing Peng, Dimitrios Gunopulos",2002/9,Journal IEEE transactions on pattern analysis and machine intelligence,"Nearest-neighbor classification assumes locally constant class conditional probabilities. This assumption becomes invalid in high dimensions with finite samples due to the curse of dimensionality. Severe bias can be introduced under these conditions when using the nearest-neighbor rule. We propose a locally adaptive nearest-neighbor classification method to try to minimize bias. We use a chi-squared distance analysis to compute a flexible metric for producing neighborhoods that are highly adaptive to query locations. Neighborhoods are elongated along less relevant feature dimensions and constricted along most influential ones. As a result, the class conditional probabilities are smoother in the modified neighborhoods, whereby better classification performance can be achieved. The efficacy of our method is validated and compared against other techniques using both simulated and real-world data.",427
Locally adaptive metrics for clustering high dimensional data,"Carlotta Domeniconi, Dimitrios Gunopulos, Sheng Ma, Bojun Yan, Muna Al-Razgan, Dimitris Papadopoulos",2007/2,Journal Data Mining and Knowledge Discovery,"Clustering suffers from the curse of dimensionality, and similarity functions that use all input features with equal relevance may not be effective. We introduce an algorithm that discovers clusters in subspaces spanned by different combinations of dimensions via local weightings of features. This approach avoids the risk of loss of information encountered in global dimensionality reduction techniques, and does not assume any data distribution model. Our method associates to each cluster a weight vector, whose values capture the relevance of features within the corresponding cluster. We experimentally demonstrate the gain in perfomance our method achieves with respect to competitive methods, using both synthetic and real datasets. In particular, our results show the feasibility of the proposed technique to perform simultaneous clustering of genes and conditions in gene expression data, and clustering of …",309
Building semantic kernels for text classification using wikipedia,"Pu Wang, Carlotta Domeniconi",2008/8/24,Book Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining,"Document classification presents difficult challenges due to the sparsity and the high dimensionality of text data, and to the complex semantics of the natural language. The traditional document representation is a word-based vector (Bag of Words, or BOW), where each dimension is associated with a term of the dictionary containing all the words that appear in the corpus. Although simple and commonly used, this representation has several limitations. It is essential to embed semantic information and conceptual patterns in order to enhance the prediction capabilities of classification algorithms. In this paper, we overcome the shortages of the BOW approach by embedding background knowledge derived from Wikipedia into a semantic kernel, which is then used to enrich the representation of documents. Our empirical evaluation with real data sets demonstrates that our approach successfully achieves improved …",290
Approximating multi-dimensional aggregate range queries over real attributes,"Dimitrios Gunopulos, George Kollios, Vassilis J Tsotras, Carlotta Domeniconi",2000/5/16,Journal Acm Sigmod Record,"Finding approximate answers to multi-dimensional range queries over real valued attributes has significant applications in data exploration and database query optimization. In this paper we consider the following problem: given a table of d attributes whose domain is the real numbers, and a query that specifies a range in each dimension, find a good approximation of the number of records in the table that satisfy the query.",261
Non-linear dimensionality reduction techniques for classification and visualization,"Michail Vlachos, Carlotta Domeniconi, Dimitrios Gunopulos, George Kollios, Nick Koudas",2002/7/23,Book Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining,"In this paper we address the issue of using local embeddings for data visualization in two and three dimensions, and for classification. We advocate their use on the basis that they provide an efficient mapping procedure from the original dimension of the data, to a lower intrinsic dimension. We depict how they can accurately capture the user's perception of similarity in high-dimensional data for visualization purposes. Moreover, we exploit the low-dimensional mapping provided by these embeddings, to develop new classification techniques, and we show experimentally that the classification accuracy is comparable (albeit using fewer dimensions) to a number of other classification procedures.",246
Incremental support vector machine construction,"Carlotta Domeniconi, Dimitrios Gunopulos",2001/12,Conference Proceedings 2001 ieee international conference on data mining,"SVMs (support vector machines) suffer from the problem of large memory requirement and CPU time when trained in batch mode on large data sets. We overcome these limitations, and at the same time make SVMs suitable for learning with data streams, by constructing incremental learning algorithms. We first introduce and compare different incremental learning techniques, and show that they are capable of producing performance results similar to the batch algorithm, and in some cases superior condensation properties. We then consider the problem of training SVMs using stream data. Our objective is to maintain an updated representation of recent batches of data. We apply incremental schemes to the problem and show that their accuracy is comparable to the batch algorithm.",238
Weighted cluster ensembles: Methods and analysis,"Carlotta Domeniconi, Muna Al-Razgan",2009/1/16,Journal ACM Transactions on Knowledge Discovery from Data (TKDD),"Cluster ensembles offer a solution to challenges inherent to clustering arising from its ill-posed nature. Cluster ensembles can provide robust and stable solutions by leveraging the consensus across multiple clustering results, while averaging out emergent spurious structures that arise due to the various biases to which each participating algorithm is tuned. In this article, we address the problem of combining multiple weighted clusters that belong to different subspaces of the input space. We leverage the diversity of the input clusterings in order to generate a consensus partition that is superior to the participating ones. Since we are dealing with weighted clusters, our consensus functions make use of the weight vectors associated with the clusters. We demonstrate the effectiveness of our techniques by running experiments with several real datasets, including high-dimensional text data. Furthermore, we investigate …",228
Topic significance ranking of LDA generative models,"Loulwah AlSumait, Daniel Barbará, James Gentle, Carlotta Domeniconi",2009,"Conference Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2009, Bled, Slovenia, September 7-11, 2009, Proceedings, Part I 20","Topic models, like Latent Dirichlet Allocation (LDA), have been recently used to automatically generate text corpora topics, and to subdivide the corpus words among those topics. However, not all the estimated topics are of equal importance or correspond to genuine themes of the domain. Some of the topics can be a collection of irrelevant words, or represent insignificant themes. Current approaches to topic modeling perform manual examination to find meaningful topics. This paper presents the first automated unsupervised analysis of LDA models to identify junk topics from legitimate ones, and to rank the topic significance. Basically, the distance between a topic distribution and three definitions of “junk distribution” is computed using a variety of measures, from which an expressive figure of the topic significance is implemented using 4-phase Weighted Combination approach. Our experiments on …",215
Subspace clustering of high dimensional data,"Carlotta Domeniconi, Dimitris Papadopoulos, Dimitrios Gunopulos, Sheng Ma",2004/4/22,Book Proceedings of the 2004 SIAM international conference on data mining,"Clustering suffers from the curse of dimensionality, and similarity functions that use all input features with equal relevance may not be effective. We introduce an algorithm that discovers clusters in subspaces spanned by different combinations of dimensions via local weightings of features. This approach avoids the risk of loss of information encountered in global dimensionality reduction techniques, and does not assume any data distribution model. Our method associates to each cluster a weight vector, whose values capture the relevance of features within the corresponding cluster. We experimentally demonstrate the gain in perfomance our method achieves, using both synthetic and real data sets. In particular, our results show the feasibility of the proposed technique to perform simultaneous clustering of genes and conditions in microarray data.",207
Adaptive nearest neighbor classification using support vector machines,"Carlotta Domeniconi, Dimitrios Gunopulos",2001,Journal Advances in neural information processing systems,"The nearest neighbor technique is a simple and appealing method to address classification problems. It relies on t he assumption of locally constant class conditional probabilities. This assumption becomes invalid in high dimensions with a finite number of exam (cid: 173) ples due to the curse of dimensionality. We propose a technique that computes a locally flexible metric by means of Support Vector Machines (SVMs). The maximum margin boundary found by the SVM is used to determine the most discriminant direction over the query's neighborhood. Such direction provides a local weighting scheme for input features. We present experimental evidence of classification performance improvement over the SVM algorithm alone and over a variety of adaptive learning schemes, by using both simulated and real data sets.",144
Matrix factorization-based data fusion for the prediction of lncRNA–disease associations,"Guangyuan Fu, Jun Wang, Carlotta Domeniconi, Guoxian Yu",2018/5/1,Journal Bioinformatics,"Long non-coding RNAs (lncRNAs) play crucial roles in complex disease diagnosis, prognosis, prevention and treatment, but only a small portion of lncRNA–disease associations have been experimentally verified. Various computational models have been proposed to identify lncRNA–disease associations by integrating heterogeneous data sources. However, existing models generally ignore the intrinsic structure of data sources or treat them as equally relevant, while they may not be.",143
Selectivity estimators for multidimensional range queries over real attributes,"Dimitrios Gunopulos, George Kollios, Vassilis J Tsotras, Carlotta Domeniconi",2005/4,Journal the VLDB Journal,"Estimating the selectivity of multidimensional range queries over real valued attributes has significant applications in data exploration and database query optimization. In this paper, we consider the following problem: given a table of d attributes whose domain is the real numbers and a query that specifies a range in each dimension, find a good approximation of the number of records in the table that satisfy the query. The simplest approach to tackle this problem is to assume that the attributes are independent. More accurate estimators try to capture the joint data distribution of the attributes. In databases, such estimators include the construction of multidimensional histograms, random sampling, or the wavelet transform. In statistics, kernel estimation techniques are being used. Many traditional approaches assume that attribute values come from discrete, finite domains, where different values have high …",130
Large margin nearest neighbor classifiers,"Carlotta Domeniconi, Dimitrios Gunopulos, Jing Peng",2005/7/18,Journal IEEE transactions on neural networks,"The nearest neighbor technique is a simple and appealing approach to addressing classification problems. It relies on the assumption of locally constant class conditional probabilities. This assumption becomes invalid in high dimensions with a finite number of examples due to the curse of dimensionality. Severe bias can be introduced under these conditions when using the nearest neighbor rule. The employment of a locally adaptive metric becomes crucial in order to keep class conditional probabilities close to uniform, thereby minimizing the bias of estimates. We propose a technique that computes a locally flexible metric by means of support vector machines (SVMs). The decision function constructed by SVMs is used to determine the most discriminant direction in a neighborhood around the query. Such a direction provides a local feature weighting scheme. We formally show that our method increases the …",121
Detecting outliers using transduction and statistical testing,"Daniel Barbará, Carlotta Domeniconi, James P Rogers",2006/8/20,Book Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining,"Outlier detection can uncover malicious behavior in fields like intrusion detection and fraud analysis. Although there has been a significant amount of work in outlier detection, most of the algorithms proposed in the literature are based on a particular definition of outliers (e.g., density-based), and use ad-hoc thresholds to detect them. In this paper we present a novel technique to detect outliers with respect to an existing clustering model. However, the test can also be successfully utilized to recognize outliers when the clustering information is not available. Our method is based on Transductive Confidence Machines, which have been previously proposed as a mechanism to provide individual confidence measures on classification decisions. The test uses hypothesis testing to prove or disprove whether a point is fit to be in each of the clusters of the model. We experimentally demonstrate that the test is highly robust …",115
Semi-supervised classification based on random subspace dimensionality reduction,"Guoxian Yu, Guoji Zhang, Carlotta Domeniconi, Zhiwen Yu, Jane You",2012/3/1,Journal Pattern Recognition,"Graph structure is vital to graph based semi-supervised learning. However, the problem of constructing a graph that reflects the underlying data distribution has been seldom investigated in semi-supervised learning, especially for high dimensional data. In this paper, we focus on graph construction for semi-supervised learning and propose a novel method called Semi-Supervised Classification based on Random Subspace Dimensionality Reduction, SSC-RSDR in short. Different from traditional methods that perform graph-based dimensionality reduction and classification in the original space, SSC-RSDR performs these tasks in subspaces. More specifically, SSC-RSDR generates several random subspaces of the original space and applies graph-based semi-supervised dimensionality reduction in these random subspaces. It then constructs graphs in these processed random subspaces and trains semi …",94
Nonparametric bayesian co-clustering ensembles,"Pu Wang, Kathryn B Laskey, Carlotta Domeniconi, Michael I Jordan",2011/4/28,Book Proceedings of the 2011 SIAM International Conference on Data Mining,"A nonparametric Bayesian approach to co-clustering ensembles is presented. Similar to clustering ensembles, co-clustering ensembles combine various base co-clustering results to obtain a more robust consensus co-clustering. To avoid pre-specifying the number of co-clusters, we specify independent Dirichlet process priors for the row and column clusters. Thus, the numbers of row- and column-clusters are unbounded a priori; the actual numbers of clusters can be learned a posteriori from observations. Next, to model non-independence of row- and column-clusters, we employ a Mondrian Process as a prior distribution over partitions of the data matrix. As a result, the co-clusters are not restricted to a regular grid partition, but form nested partitions with varying resolutions. The empirical evaluation demonstrates the effectiveness of nonparametric Bayesian co-clustering ensembles and their advantages over …",94
Weighted clustering ensembles,"Muna Al-Razgan, Carlotta Domeniconi",2006/4/20,Book Proceedings of the 2006 SIAM International Conference on Data Mining,"Cluster ensembles offer a solution to challenges inherent to clustering arising from its ill-posed nature. Cluster ensembles can provide robust and stable solutions by leveraging the consensus across multiple clustering results, while averaging out emergent spurious structures that arise due to the various biases to which each participating algorithm is tuned. In this paper, we address the problem of combining multiple weighted clusters which belong to different subspaces of the input space. We leverage the diversity of the input clusterings in order to generate a consensus partition that is superior to the participating ones. Since we are dealing with weighted clusters, our consensus function makes use of the weight vectors associated with the clusters. The experimental results show that our ensemble technique is capable of producing a partition that is as good as or better than the best individual clustering.",94
Nearest neighbor ensemble,"Carlotta Domeniconi, Bojun Yan",2004/8/26,"Conference Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.","Recent empirical work has shown that combining predictors can lead to significant reduction in generalization error. The individual predictors (weak learners) can be very simple, such as two terminal-node trees; it is the aggregating scheme that gives them the power of increasing prediction accuracy. Unfortunately, many combining methods do not improve nearest neighbor (NN) classifiers at all. This is because NN methods are very robust with respect to variations of a data set. In contrast, they are sensitive to input features. We exploit the instability of NN classifiers with respect to different choices of features to generate an effective and diverse set of NN classifiers with possibly uncorrelated errors. Interestingly, the approach takes advantage of the high dimensionality of the data. The experimental results show that our technique offers significant performance improvements with respect to competitive methods.",82
An evaluation of gene selection methods for multi-class microarray data classification,"Hong Chai, Carlotta Domeniconi",2004/9/24,Journal Proceedings of the Second European Workshop on Data Mining and Text Mining in Bioinformatics,"The fundamental power of microarrays lies in the ability to conduct parallel surveys of gene expression patterns for tens of thousands of genes across a wide range of cellular responses, phenotypes and conditions. Thus microarray data contain an overwhelming number of genes relative to the number of samples, presenting challenges for meaningful pattern discovery. This paper provides a comparative study of gene selection methods for multi-class classification of microarray data. We compare several feature ranking techniques, including new variants of correlation coefficients, and Support Vector Machine (SVM) method based on Recursive Feature Elimination (RFE). The results show that feature selection methods improve SVM classification accuracy in different kernel settings. The performance of feature selection techniques is problem-dependent. SVM-RFE shows an excellent performance in general, but often gives lower accuracy than correlation coefficients in low dimensions.",80
An adaptive metric machine for pattern classification,"Carlotta Domeniconi, Jing Peng, Dimitrios Gunopulos",2000,Journal Advances in Neural Information Processing Systems,"Nearest neighbor classification assumes locally constant class con (cid: 173) ditional probabilities. This assumption becomes invalid in high dimensions with finite samples due to the curse of dimensionality. Severe bias can be introduced under these conditions when using the nearest neighbor rule. We propose a locally adaptive nearest neighbor classification method to try to minimize bias. We use a Chi-squared distance analysis to compute a flexible metric for pro (cid: 173) ducing neighborhoods that are elongated along less relevant feature dimensions and constricted along most influential ones. As a result, the class conditional probabilities tend to be smoother in the mod (cid: 173) ified neighborhoods, whereby better classification performance can be achieved. The efficacy of our method is validated and compared against other techniques using a variety of real world data.",78
Protein function prediction using multilabel ensemble classification,"Guoxian Yu, Huzefa Rangwala, Carlotta Domeniconi, Guoji Zhang, Zhiwen Yu",2013/9/16,Journal IEEE/ACM Transactions on Computational Biology and Bioinformatics,"High-throughput experimental techniques produce several kinds of heterogeneous proteomic and genomic data sets. To computationally annotate proteins, it is necessary and promising to integrate these heterogeneous data sources. Some methods transform these data sources into different kernels or feature representations. Next, these kernels are linearly (or nonlinearly) combined into a composite kernel. The composite kernel is utilized to develop a predictive model to infer the function of proteins. A protein can have multiple roles and functions (or labels). Therefore, multilabel learning methods are also adapted for protein function prediction. We develop a transductive multilabel classifier (TMC) to predict multiple functions of proteins using several unlabeled proteins. We also propose a method called transductive multilabel ensemble classifier (TMEC) for integrating the different data sources using an ensemble …",74
Incomplete multi-view weak-label learning.,"Qiaoyu Tan, Guoxian Yu, Carlotta Domeniconi, Jun Wang, Zili Zhang",2018/7/13,Conference Ijcai,"Learning from multi-view multi-label data has wide applications. Two main challenges characterize this learning task: incomplete views and missing (weak) labels. The former assumes that views may not include all data objects. The weak label setting implies that only a subset of relevant labels are provided for training objects while other labels are missing. Both incomplete views and weak labels can lead to significant performance degradation. In this paper, we propose a novel model (iMVWL) to jointly address the two challenges. iMVWL learns a shared subspace from incomplete views with weak labels, local label correlations, and a predictor in this subspace, simultaneously. The latter can capture not only cross-view relationships but also weak-label information of training samples. We further develop an alternative solution to optimize our model; this solution can avoid suboptimal results and reinforce their reciprocal effects, and thus further improve the performance. Extensive experimental results on real-world datasets validate the effectiveness of our model against other competitive algorithms.",69
Transductive multi-label ensemble classification for protein function prediction,"Guoxian Yu, Carlotta Domeniconi, Huzefa Rangwala, Guoji Zhang, Zhiwen Yu",2012/8/12,Book Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining,"Advances in biotechnology have made available multitudes of heterogeneous proteomic and genomic data. Integrating these heterogeneous data sources, to automatically infer the function of proteins, is a fundamental challenge in computational biology. Several approaches represent each data source with a kernel (similarity) function. The resulting kernels are then integrated to determine a composite kernel, which is used for developing a function prediction model. Proteins are also found to have multiple roles and functions. As such, several approaches cast the protein function prediction problem within a multi-label learning framework. In our work we develop an approach that takes advantage of several unlabeled proteins, along with multiple data sources and multiple functions of proteins. We develop a graph-based transductive multi-label classifier (TMC) that is evaluated on a composite kernel, and also …",68
Projective clustering ensembles,"Francesco Gullo, Carlotta Domeniconi, Andrea Tagarelli",2013/5,Journal Data Mining and Knowledge Discovery,"A considerable amount of work has been done in data clustering research during the last four decades, and a myriad of methods has been proposed focusing on different data types, proximity functions, cluster representation models, and cluster presentation. However, clustering remains a challenging problem due to its ill-posed nature: it is well known that off-the-shelf clustering methods may discover different patterns in a given set of data, mainly because every clustering algorithm has its own bias resulting from the optimization of different criteria. This bias becomes even more important as in almost all real-world applications, data is inherently high-dimensional and multiple clustering solutions might be available for the same data collection. In this respect, the problems of projective clustering and clustering ensembles have been recently defined to deal with the high dimensionality and multiple clusterings …",61
An adaptive kernel method for semi-supervised clustering,"Bojun Yan, Carlotta Domeniconi",2006/1/1,Conference ECML,"Semi-supervised clustering uses the limited background knowledge to aid unsupervised clustering algorithms. Recently, a kernel method for semi-supervised clustering has been introduced, which has been shown to outperform previous semi-supervised clustering approaches. However, the setting of the kernel’s parameter is left to manual tuning, and the chosen value can largely affect the quality of the results. Thus, the selection of kernel’s parameters remains a critical and open problem when only limited supervision, provided in terms of pairwise constraints, is available. In this paper, we derive a new optimization criterion to automatically determine the optimal parameter of an RBF kernel, directly from the data and the given constraints. Our approach integrates the constraints into the clustering objective function, and optimizes the parameter of a Gaussian kernel iteratively during the clustering process. Our …",61
Feature-induced partial multi-label learning,"Guoxian Yu, Xia Chen, Carlotta Domeniconi, Jun Wang, Zhao Li, Zili Zhang, Xindong Wu",2018/11/17,Conference 2018 IEEE International Conference on Data Mining (ICDM),"Current efforts on multi-label learning generally assume that the given labels of training instances are noise-free. However, obtaining noise-free labels is quite difficult and often impractical, and the presence of noisy labels may compromise the performance of multi-label learning. Partial multi-label learning (PML) addresses the scenario in which each instance is annotated with a set of candidate labels, of which only a subset corresponds to the ground-truth. The PML problem is more challenging than partial-label learning, since the latter assumes that only one label is valid and may ignore the correlation among candidate labels. To tackle the PML challenge, we introduce a feature induced PML approach called fPML, which simultaneously estimates noisy labels and trains multi-label classifiers. In particular, fPML simultaneously factorizes the observed instance-label association matrix and the instance-feature …",58
Uncovering trajectories of informal learning in large online communities of creators,"Seungwon Yang, Carlotta Domeniconi, Matt Revelle, Mack Sweeney, Ben U Gelman, Chris Beckley, Aditya Johri",2015/3/14,Book Proceedings of the Second (2015) ACM Conference on Learning@ Scale,"We analyzed informal learning in Scratch Online -- an online community with over 4.3 million users and 6.7 million user-generated content. Users develop projects, which are graphical interfaces involving manipulation of programming blocks. We investigated two fundamental questions: how can we model informal learning, and what patterns of informal learning emerge. We proceeded in two phases. First, we modeled learning as a trajectory of cumulative programming block usage by long-term users who created at least 50 projects. Second, we applied K-means++ clustering to uncover patterns of learning and corresponding subpopulations. We found four groups of users manifesting four different patterns of learning, ranging from the smallest to the largest improvement. At one end of the spectrum, users learned more and in a faster manner. At the opposite end, users did not show much learning, even after …",58
Using wikipedia for co-clustering based cross-domain text classification,"Pu Wang, Carlotta Domeniconi, Jian Hu",2008/12/15,Conference 2008 Eighth IEEE international conference on Data Mining,"Traditional approaches to document classification requires labeled data in order to construct reliable and accurate classifiers. Unfortunately, labeled data are seldom available, and often too expensive to obtain. Given a learning task for which training data are not available, abundant labeled data may exist for a different but related domain. One would like to use the related labeled data as auxiliary information to accomplish the classification task in the target domain. Recently, the paradigm of transfer learning has been introduced to enable effective learning strategies when auxiliary data obey a different probability distribution. A co-clustering based classification algorithm has been previously proposed to tackle cross-domain text classification. In this work, we extend the idea underlying this approach by making the latent semantic relationship between the two domains explicit. This goal is achieved with the use of …",57
Weighted-object ensemble clustering: methods and analysis,"Yazhou Ren, Carlotta Domeniconi, Guoji Zhang, Guoxian Yu",2017/5,Journal Knowledge and Information Systems,"Ensemble clustering has attracted increasing attention in recent years. Its goal is to combine multiple base clusterings into a single consensus clustering of increased quality. Most of the existing ensemble clustering methods treat each base clustering and each object as equally important, while some approaches make use of weights associated with clusters, or to clusterings, when assembling the different base clusterings. Boosting algorithms developed for classification have led to the idea of considering weighted objects during the clustering process. However, not much effort has been put toward incorporating weighted objects into the consensus process. To fill this gap, in this paper, we propose a framework called Weighted-Object Ensemble Clustering (WOEC). We first estimate how difficult it is to cluster an object by constructing the co-association matrix that summarizes the base clustering results, and …",56
Ranking-based deep cross-modal hashing,"Xuanwu Liu, Guoxian Yu, Carlotta Domeniconi, Jun Wang, Yazhou Ren, Maozu Guo",2019/7/17,Journal Proceedings of the AAAI conference on artificial intelligence,"Cross-modal hashing has been receiving increasing interests for its low storage cost and fast query speed in multi-modal data retrievals. However, most existing hashing methods are based on hand-crafted or raw level features of objects, which may not be optimally compatible with the coding process. Besides, these hashing methods are mainly designed to handle simple pairwise similarity. The complex multilevel ranking semantic structure of instances associated with multiple labels has not been well explored yet. In this paper, we propose a ranking-based deep cross-modal hashing approach (RDCMH). RDCMH firstly uses the feature and label information of data to derive a semi-supervised semantic ranking list. Next, to expand the semantic representation power of hand-crafted features, RDCMH integrates the semantic ranking information into deep cross-modal hashing and jointly optimizes the compatible parameters of deep feature representations and of hashing functions. Experiments on real multi-modal datasets show that RDCMH outperforms other competitive baselines and achieves the state-of-the-art performance in cross-modal retrieval applications.",50
Activehne: Active heterogeneous network embedding,"Xia Chen, Guoxian Yu, Jun Wang, Carlotta Domeniconi, Zhao Li, Xiangliang Zhang",2019/5/14,Journal arXiv preprint arXiv:1905.05659,"Heterogeneous network embedding (HNE) is a challenging task due to the diverse node types and/or diverse relationships between nodes. Existing HNE methods are typically unsupervised. To maximize the profit of utilizing the rare and valuable supervised information in HNEs, we develop a novel Active Heterogeneous Network Embedding (ActiveHNE) framework, which includes two components: Discriminative Heterogeneous Network Embedding (DHNE) and Active Query in Heterogeneous Networks (AQHN). In DHNE, we introduce a novel semi-supervised heterogeneous network embedding method based on graph convolutional neural network. In AQHN, we first introduce three active selection strategies based on uncertainty and representativeness, and then derive a batch selection method that assembles these strategies using a multi-armed bandit mechanism. ActiveHNE aims at improving the performance of HNE by feeding the most valuable supervision obtained by AQHN into DHNE. Experiments on public datasets demonstrate the effectiveness of ActiveHNE and its advantage on reducing the query cost.",50
Multi-label co-training,"Yuying Xing, Guoxian Yu, Carlotta Domeniconi, Jun Wang, Zili Zhang",2018/7/13,Book Proceedings of the 27th international joint conference on artificial intelligence,"Multi-label learning aims at assigning a set of appropriate labels to multi-label samples. Although it has been successfully applied in various domains in recent years, most multi-label learning methods require sufficient labeled training samples, because of the large number of possible label sets. Co-training, as an important branch of semi-supervised learning, can leverage unlabeled samples, along with scarce labeled ones, and can potentially help with the large labeled data requirement. However, it is a difficult challenge to combine multi-label learning with co-training. Two distinct issues are associated with the challenge: (i) how to solve the widely-witnessed class-imbalance problem in multilabel learning; and (ii) how to select samples with confidence, and communicate their predicted labels among classifiers for model refinement. To address these issues, we introduce an approach called Multi-Label Co …",50
A clustering framework based on subjective and objective validity criteria,"Maria Halkidi, Dimitrios Gunopulos, Michalis Vazirgiannis, Nitin Kumar, Carlotta Domeniconi",2008/2/2,Journal ACM Transactions on Knowledge Discovery from Data (TKDD),"Clustering, as an unsupervised learning process is a challenging problem, especially in cases of high-dimensional datasets. Clustering result quality can benefit from user constraints and objective validity assessment. In this article, we propose a semisupervised framework for learning the weighted Euclidean subspace, where the best clustering can be achieved. Our approach capitalizes on: (i) user constraints; and (ii) the quality of intermediate clustering results in terms of their structural properties. The proposed framework uses the clustering algorithm and the validity measure as its parameters. We develop and discuss algorithms for learning and tuning the weights of contributing dimensions and defining the “best” clustering obtained by satisfying user constraints. Experimental results on benchmark datasets demonstrate the superiority of the proposed approach in terms of improved clustering accuracy.",48
Predicting protein functions using incomplete hierarchical labels,"Guoxian Yu, Hailong Zhu, Carlotta Domeniconi",2015/12,Journal BMC bioinformatics,"Protein function prediction is to assign biological or biochemical functions to proteins, and it is a challenging computational problem characterized by several factors: (1) the number of function labels (annotations) is large; (2) a protein may be associated with multiple labels; (3) the function labels are structured in a hierarchy; and (4) the labels are incomplete. Current predictive models often assume that the labels of the labeled proteins are complete, i.e. no label is missing. But in real scenarios, we may be aware of only some hierarchical labels of a protein, and we may not know whether additional ones are actually present. The scenario of incomplete hierarchical labels, a challenging and practical problem, is seldom studied in protein function prediction. In this paper, we propose an algorithm to Predict protein functions using Incomplete hierarchical LabeLs (PILL in short). PILL takes into account the hierarchical and the flat taxonomy similarity between function labels, and defines a Combined Similarity (ComSim) to measure the correlation between labels. PILL estimates the missing labels for a protein based on ComSim and the known labels of the protein, and uses a regularization to exploit the interactions between proteins for function prediction. PILL is shown to outperform other related techniques in replenishing the missing labels and in predicting the functions of completely unlabeled proteins on publicly available PPI datasets annotated with MIPS Functional Catalogue and Gene Ontology labels. The empirical study shows that it is important to consider the incomplete annotation for protein function prediction. The proposed method (PILL …",47
Latent dirichlet bayesian co-clustering,"Pu Wang, Carlotta Domeniconi, Kathryn Blackmond Laskey",2009,"Conference Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2009, Bled, Slovenia, September 7-11, 2009, Proceedings, Part II 20","Co-clustering has emerged as an important technique for mining contingency data matrices. However, almost all existing co-clustering algorithms are hard partitioning, assigning each row and column of the data matrix to one cluster. Recently a Bayesian co-clustering approach has been proposed which allows a probability distribution membership in row and column clusters. The approach uses variational inference for parameter estimation. In this work, we modify the Bayesian co-clustering model, and use collapsed Gibbs sampling and collapsed variational inference for parameter estimation. Our empirical evaluation on real data sets shows that both collapsed Gibbs sampling and collapsed variational inference are able to find more accurate likelihood estimates than the standard variational Bayesian co-clustering approach.",47
Multi-view multiple clusterings using deep matrix factorization,"Shaowei Wei, Jun Wang, Guoxian Yu, Carlotta Domeniconi, Xiangliang Zhang",2020/4/3,Journal Proceedings of the AAAI conference on artificial intelligence,"Multi-view clustering aims at integrating complementary information from multiple heterogeneous views to improve clustering results. Existing multi-view clustering solutions can only output a single clustering of the data. Due to their multiplicity, multi-view data, can have different groupings that are reasonable and interesting from different perspectives. However, how to find multiple, meaningful, and diverse clustering results from multi-view data is still a rarely studied and challenging topic in multi-view clustering and multiple clusterings. In this paper, we introduce a deep matrix factorization based solution (DMClusts) to discover multiple clusterings. DMClusts gradually factorizes multi-view data matrices into representational subspaces layer-by-layer and generates one clustering in each layer. To enforce the diversity between generated clusterings, it minimizes a new redundancy quantification term derived from the proximity between samples in these subspaces. We further introduce an iterative optimization procedure to simultaneously seek multiple clusterings with quality and diversity. Experimental results on benchmark datasets confirm that DMClusts outperforms state-of-the-art multiple clustering solutions.",44
Semi-supervised ensemble classification in subspaces,"Guoxian Yu, Guoji Zhang, Zhiwen Yu, Carlotta Domeniconi, Jane You, Guoqiang Han",2012/5/1,Journal Applied Soft Computing,"Graph-based semi-supervised classification depends on a well-structured graph. However, it is difficult to construct a graph that faithfully reflects the underlying structure of data distribution, especially for data with a high dimensional representation. In this paper, we focus on graph construction and propose a novel method called semi-supervised ensemble classification in subspaces, SSEC in short. Unlike traditional methods that execute graph-based semi-supervised classification in the original space, SSEC performs semi-supervised linear classification in subspaces. More specifically, SSEC first divides the original feature space into several disjoint feature subspaces. Then, it constructs a neighborhood graph in each subspace, and trains a semi-supervised linear classifier on this graph, which will serve as the base classifier in an ensemble. Finally, SSEC combines the obtained base classifiers into an ensemble …",42
Composite kernels for semi-supervised clustering,"Carlotta Domeniconi, Jing Peng, Bojun Yan",2011/7,Journal Knowledge and information systems,"A critical problem related to kernel-based methods is how to select optimal kernels. A kernel function must conform to the learning target in order to obtain meaningful results. While solutions to the problem of estimating optimal kernel functions and corresponding parameters have been proposed in a supervised setting, it remains a challenge when no labeled data are available, and all we have is a set of pairwise must-link and cannot-link constraints. In this paper, we address the problem of optimizing the kernel function using pairwise constraints for semi-supervised clustering. We propose a new optimization criterion for automatically estimating the optimal parameters of composite Gaussian kernels, directly from the data and given constraints. We combine our proposal with a semi-supervised kernel-based algorithm to demonstrate experimentally the effectiveness of our approach. The results show that our …",39
Multi-view multiple clustering,"Shixing Yao, Guoxian Yu, Jun Wang, Carlotta Domeniconi, Xiangliang Zhang",2019/5/13,Journal arXiv preprint arXiv:1905.05053,"Multiple clustering aims at exploring alternative clusterings to organize the data into meaningful groups from different perspectives. Existing multiple clustering algorithms are designed for single-view data. We assume that the individuality and commonality of multi-view data can be leveraged to generate high-quality and diverse clusterings. To this end, we propose a novel multi-view multiple clustering (MVMC) algorithm. MVMC first adapts multi-view self-representation learning to explore the individuality encoding matrices and the shared commonality matrix of multi-view data. It additionally reduces the redundancy (i.e., enhancing the individuality) among the matrices using the Hilbert-Schmidt Independence Criterion (HSIC), and collects shared information by forcing the shared matrix to be smooth across all views. It then uses matrix factorization on the individual matrices, along with the shared matrix, to generate diverse clusterings of high-quality. We further extend multiple co-clustering on multi-view data and propose a solution called multi-view multiple co-clustering (MVMCC). Our empirical study shows that MVMC (MVMCC) can exploit multi-view data to generate multiple high-quality and diverse clusterings (co-clusterings), with superior performance to the state-of-the-art methods.",38
Protein function prediction using dependence maximization,"Guoxian Yu, Carlotta Domeniconi, Huzefa Rangwala, Guoji Zhang",2013,"Conference Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2013, Prague, Czech Republic, September 23-27, 2013, Proceedings, Part I 13","Protein function prediction is one of the fundamental tasks in the post genomic era. The vast amount of available proteomic data makes it possible to computationally annotate proteins. Most computational approaches predict protein functions by using the labeled proteins and assuming that the annotation of labeled proteins is complete, and without any missing functions. However, partially annotated proteins are common in real-world scenarios, that is a protein may have some confirmed functions, and whether it has other functions is unknown.",35
Individuality-and commonality-based multiview multilabel learning,"Qiaoyu Tan, Guoxian Yu, Jun Wang, Carlotta Domeniconi, Xiangliang Zhang",2019/11/19,Journal IEEE transactions on cybernetics,"In multiview multilabel learning, each object is represented by several heterogeneous feature representations and is also annotated with a set of discrete nonexclusive labels. Previous studies typically focus on capturing the shared latent patterns among multiple views, while not sufficiently considering the diverse characteristics of individual views, which can cause performance degradation. In this article, we propose a novel approach [individuality- and commonality-based multiview multilabel learning (ICM2L)] to explicitly explore the individuality and commonality information of multilabel multiple view data in a unified model. Specifically, a common subspace is learned across different views to capture the shared patterns. Then, multiple individual classifiers are exploited to explore the characteristics of individual views. Next, an ensemble strategy is adopted to make a prediction. Finally, we develop an alternative …",34
Predicting protein function via downward random walks on a gene ontology,"Guoxian Yu, Hailong Zhu, Carlotta Domeniconi, Jiming Liu",2015/12,Journal BMC bioinformatics,"High-throughput bio-techniques accumulate ever-increasing amount of genomic and proteomic data. These data are far from being functionally characterized, despite the advances in gene (or gene’s product proteins) functional annotations. Due to experimental techniques and to the research bias in biology, the regularly updated functional annotation databases, i.e., the Gene Ontology (GO), are far from being complete. Given the importance of protein functions for biological studies and drug design, proteins should be more comprehensively and precisely annotated. We proposed downward Random Walks (dRW) to predict missing (or new) functions of partially annotated proteins. Particularly, we apply downward random walks with restart on the GO directed acyclic graph, along with the available functions of a protein, to estimate the probability of missing functions. To further boost the prediction accuracy, we extend dRW to dRW-kNN. dRW-kNN computes the semantic similarity between proteins based on the functional annotations of proteins; it then predicts functions based on the functions estimated by dRW, together with the functions associated with the k nearest proteins. Our proposed models can predict two kinds of missing functions: (i) the ones that are missing for a protein but associated with other proteins of interest; (ii) the ones that are not available for any protein of interest, but exist in the GO hierarchy. Experimental results on the proteins of Yeast and Human show that dRW and dRW-kNN can replenish functions more accurately than other related approaches, especially for sparse functions associated with no more than 10 proteins …",34
Weighted-object ensemble clustering,"Yazhou Ren, Carlotta Domeniconi, Guoji Zhang, Guoxian Yu",2013/12/7,Conference 2013 IEEE 13th International Conference on Data Mining,"Ensemble clustering, also known as consensus clustering, aims to generate a stable and robust clustering through the consolidation of multiple base clusterings. In recent years many ensemble clustering methods have been proposed, most of which treat each clustering and each object as equally important. Some approaches make use of weights associated with clusters, or with clusterings, when assembling the different base clusterings. Boosting algorithms developed for classification have also led to the idea of considering weighted objects during the clustering process. However, not much effort has been put towards incorporating weighted objects into the consensus process. To fill this gap, in this paper we propose an approach called Weighted-Object Ensemble Clustering (WOEC). We first estimate how difficult it is to cluster an object by constructing the co-association matrix that summarizes the base …",34
Protein function prediction with incomplete annotations,"Guoxian Yu, Huzefa Rangwala, Carlotta Domeniconi, Guoji Zhang, Zhiwen Yu",2013/11/4,Journal IEEE/ACM Transactions on Computational Biology and Bioinformatics,"Automated protein function prediction is one of the grand challenges in computational biology. Multi-label learning is widely used to predict functions of proteins. Most of multi-label learning methods make prediction for unlabeled proteins under the assumption that the labeled proteins are completely annotated, i.e., without any missing functions. However, in practice, we may have a subset of the ground-truth functions for a protein, and whether the protein has other functions is unknown. To predict protein functions with incomplete annotations, we propose a Protein Function Prediction method with Weak-label Learning (ProWL) and its variant ProWL-IF. Both ProWL and ProWL-IF can replenish the missing functions of proteins. In addition, ProWL-IF makes use of the knowledge that a protein cannot have certain functions, which can further boost the performance of protein function prediction. Our experimental results …",34
Text clustering with local semantic kernels,"Loulwah AlSumait, Carlotta Domeniconi",2008,"Journal Survey of text mining II: Clustering, classification, and retrieval","Document clustering is a fundamental task of text mining, by which efficient organization, navigation, summarization, and retrieval of documents can be achieved. The clustering of documents presents difficult challenges due to the sparsity and the high dimensionality of text data, and to the complex semantics of natural language. Subspace clustering is an extension of traditional clustering that is designed to cap-ture local feature relevance, and to group documents with respect to the features (or words) that matter the most.",34
Weighted matrix factorization on multi-relational data for LncRNA-disease association prediction,"Yuehui Wang, Guoxian Yu, Jun Wang, Guangyuan Fu, Maozu Guo, Carlotta Domeniconi",2020/2/15,Journal Methods,"Influx evidences show that red long non-coding RNAs (lncRNAs) play important roles in various critical biological processes, and they afffect the development and progression of various human diseases. Therefore, it is necessary to precisely identify the lncRNA-disease associations. The identification precision can be improved by developing data integrative models. However, current models mainly need to project heterogeneous data onto the homologous networks, and then merge these networks into a composite one for integrative prediction. We recognize that this projection overrides the individual structure of the heterogeneous data, and the combination is impacted by noisy networks. As a result, the performance is compromised. Given that, we introduce a weighted matrix factorization model on multi-relational data to predict LncRNA-disease associations (WMFLDA). WMFLDA firstly uses a heterogeneous …",32
A classification approach for prediction of target events in temporal sequences,"Carlotta Domeniconi, Chang-shing Perng, Ricardo Vilalta, Sheng Ma",2002,"Conference Principles of Data Mining and Knowledge Discovery: 6th European Conference, PKDD 2002 Helsinki, Finland, August 19–23, 2002 Proceedings 6","Learning to predict significant events from sequences of data with categorical features is an important problem in many application areas. We focus on events for system management, and formulate the problem of prediction as a classification problem. We perform co-occurrence analysis of events by means of Singular Value Decomposition (SVD) of the examples constructed from the data. This process is combined with Support Vector Machine (SVM) classification, to obtain efficient and accurate predictions. We conduct an analysis of statistical properties of event data, which explains why SVM classification is suitable for such data, and perform an empirical study using real data.",32
Predicting protein function using multiple kernels,"Guoxian Yu, Huzefa Rangwala, Carlotta Domeniconi, Guoji Zhang, Zili Zhang",2014/8/26,Journal IEEE/ACM Transactions on Computational Biology and Bioinformatics,"High-throughput experimental techniques provide a wide variety of heterogeneous proteomic data sources. To exploit the information spread across multiple sources for protein function prediction, these data sources are transformed into kernels and then integrated into a composite kernel. Several methods first optimize the weights on these kernels to produce a composite kernel, and then train a classifier on the composite kernel. As such, these approaches result in an optimal composite kernel, but not necessarily in an optimal classifier. On the other hand, some approaches optimize the loss of binary classifiers and learn weights for the different kernels iteratively. For multi-class or multi-label data, these methods have to solve the problem of optimizing weights on these kernels for each of the labels, which are computationally expensive and ignore the correlation among labels. In this paper, we propose a method …",31
Integrating multiple networks for protein function prediction,"Guoxian Yu, Hailong Zhu, Carlotta Domeniconi, Maozu Guo",2015/12,Conference BMC systems biology,"High throughput techniques produce multiple functional association networks. Integrating these networks can enhance the accuracy of protein function prediction. Many algorithms have been introduced to generate a composite network, which is obtained as a weighted sum of individual networks. The weight assigned to an individual network reflects its benefit towards the protein functional annotation inference. A classifier is then trained on the composite network for predicting protein functions. However, since these techniques model the optimization of the composite network and the prediction tasks as separate objectives, the resulting composite network is not necessarily optimal for the follow-up protein function prediction.",30
Embedding semantics in LDA topic models,"Loulwah Alsumait, Pu Wang, Carlotta Domeniconi, Daniel Barbará",2010/3/26,Journal Text mining: applications and theory,"This chapter investigates the role of semantic embedding in two main directions. The first is to embed semantics from an external prior‐knowledge source to enhance the generative process of the model parameters. The second direction which suits the online knowledge discovery problem is to embed data‐driven semantics. The idea is to construct the current latent Dirichlet alglocation (LDA) model based on information propagated from topic models that were learned from previously seen documents of the domain. The chapter focuses on three major advancements to solve the problem such as vector space modeling, latent semantic analysis and probabilistic latent semantic analysis. It introduces the LDA topic model with a brief description of its graphical model and generative process and the posterior inference. The chapter investigates the role of embedding semantics from a source by enhancing the …",29
Random subspace ensembles for clustering categorical data,"Muna Al-Razgan, Carlotta Domeniconi, Daniel Barbará",2008,Journal Supervised and unsupervised ensemble methods and their applications,"Cluster ensembles provide a solution to challenges inherent to clustering arising from its ill-posed nature. In fact, cluster ensembles can find robust and stable solutions by leveraging the consensus across multiple clustering results, while averaging out spurious structures that arise due to the various biases to which each participating algorithm is tuned. In this chapter we focus on the design of ensembles for categorical data. Our techniques build upon diverse input clusterings discovered in random subspaces, and reduce the problem of defining a consensus function to a graph partitioning problem. We experimentally demonstrate the efficacy of our approach in combination with the categorical clustering algorithm COOLCAT.",29
A framework for semi-supervised learning based on subjective and objective clustering criteria,"Maria Halkidi, Dimitrios Gunopulos, Nitin Kumar, Michalis Vazirgiannis, Carlotta Domeniconi",2005/11/27,Conference Fifth IEEE International Conference on Data Mining (ICDM'05),"In this paper, we propose a semi-supervised framework for learning a weighted Euclidean subspace, where the best clustering can be achieved. Our approach capitalizes on user-constraints and the quality of intermediate clustering results in terms of its structural properties. It uses the clustering algorithm and the validity measure as parameters.",29
Multi-view weak-label learning based on matrix completion,"Qiaoyu Tan, Guoxian Yu, Carlotta Domeniconi, Jun Wang, Zili Zhang",2018/5/7,Book Proceedings of the 2018 SIAM International conference on data mining,"Weak-label learning is an important branch of multi-label learning; it deals with samples annotated with incomplete (weak) labels. Previous work on weak-label learning mainly considers data represented by a single view. An intuitive way to leverage multiple features obtained from different views is to concatenate the features into a single vector. However, this process is not only prone to over-fitting and often results in very high time-complexity, but also ignores the potentially useful complementary information spread across the different views. In this paper, we propose an approach based on Matrix Completion for multi-view Weak-label Learning (McWL). Matrix completion (MC) has sound theoretical properties and is robust to missing values in both feature and label spaces. Our method enforces the optimization of multiple view integration and of MC-based classification within a unified objective function …",27
Finding community topics and membership in graphs,"Matt Revelle, Carlotta Domeniconi, Mack Sweeney, Aditya Johri",2015,"Conference Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2015, Porto, Portugal, September 7-11, 2015, Proceedings, Part II 15","Community detection in networks is a broad problem with many proposed solutions. Existing methods frequently make use of edge density and node attributes; however, the methods ultimately have different definitions of community and build strong assumptions about community features into their models. We propose a new method for community detection, which estimates both per-community feature distributions (topics) and per-node community membership. Communities are modeled as connected subgraphs with nodes sharing similar attributes. Nodes may join multiple communities and share common attributes with each. Communities have an associated probability distribution over attributes and node attributes are modeled as draws from a mixture distribution. We make two basic assumptions about community structure: communities are densely connected and have a small network diameter …",27
Protein Function Prediction by Integrating Multiple Kernels.,"Guo-Xian Yu, Huzefa Rangwala, Carlotta Domeniconi, Guoji Zhang, Zili Zhang",2013/1/1,Conference IJCAI,"Determining protein function constitutes an exercise in integrating information derived from several heterogeneous high-throughput experiments. To utilize the information spread across multiple sources in a combined fashion, these data sources are transformed into kernels. Several protein function prediction methods follow a two-phased approach: they first optimize the weights on individual kernels to produce a composite kernel, and then train a classifier on the composite kernel. As such, these methods result in an optimal composite kernel, but not necessarily in an optimal classifier. On the other hand, some methods optimize the loss of binary classifiers, and learn weights for the different kernels iteratively. A protein has multiple functions, and each function can be viewed as a label. These methods solve the problem of optimizing weights on the input kernels for each of the labels. This is computationally expensive and ignores inter-label correlations. In this paper, we propose a method called Protein Function Prediction by Integrating Multiple Kernels (ProMK). ProMK iteratively optimizes the phases of learning optimal weights and reducing the empirical loss of a multi-label classifier for each of the labels simultaneously, using a combined objective function. ProMK can assign larger weights to smooth kernels and downgrade the weights on noisy kernels. We evaluate the ability of ProMK to predict the function of proteins using several standard benchmarks. We show that our approach performs better than previously proposed protein function prediction approaches that integrate data from multiple networks, and multi-label multiple kernel learning …",27
Isoform function prediction based on bi-random walks on a heterogeneous network,"Guoxian Yu, Keyao Wang, Carlotta Domeniconi, Maozu Guo, Jun Wang",2020/1/1,Journal Bioinformatics,"Alternative splicing contributes to the functional diversity of protein species and the proteoforms translated from alternatively spliced isoforms of a gene actually execute the biological functions. Computationally predicting the functions of genes has been studied for decades. However, how to distinguish the functional annotations of isoforms, whose annotations are essential for understanding developmental abnormalities and cancers, is rarely explored. The main bottleneck is that functional annotations of isoforms are generally unavailable and functional genomic databases universally store the functional annotations at the gene level.",26
Cross-domain Text Classification using Wikipedia.,"Pu Wang, Carlotta Domeniconi, Jian Hu",2008/11,Journal IEEE Intell. Informatics Bull.,"Traditional approaches to document classification requires labeled data in order to construct reliable and accurate classifiers. Unfortunately, labeled data are seldom available, and often too expensive to obtain, especially for large domains and fast evolving scenarios. Given a learning task for which training data are not available, abundant labeled data may exist for a different but related domain. One would like to use the related labeled data as auxiliary information to accomplish the classification task in the target domain. Recently, the paradigm of transfer learning has been introduced to enable effective learning strategies when auxiliary data obey a different probability distribution. A co-clustering based classification algorithm has been previously proposed to tackle cross-domain text classification. In this work, we extend the idea underlying this approach by making the latent semantic relationship between the two domains explicit. This goal is achieved with the use of Wikipedia. As a result, the pathway that allows to propagate labels between the two domains not only captures common words, but also semantic concepts based on the content of documents. We empirically demonstrate the efficacy of our semantic-based approach to cross-domain classification using a variety of real data.",26
Co-clustering ensembles based on multiple relevance measures,"Xianxue Yu, Guoxian Yu, Jun Wang, Carlotta Domeniconi",2019/9/17,Journal IEEE transactions on knowledge and data engineering,"Co-clustering aims at discovering groups of both objects and features from a given data matrix. Co-clustering ensembles can produce robust co-clusters by combining multiple base co-clusterings. However, current co-clustering ensemble solutions either ignore the constraints resulting from feature-to-feature and object-to-object relevance information, or ignore feature-to-object relevance information. In this paper, we advocate that all three information sources contribute to the achievement of good consensus solutions, and propose a co-clustering ensemble (CoCE) approach based on multiple relevance measures. CoCE first evaluates the quality of base co-clusters and consequently measures feature-to-object relevance. The latter, along with feature-to-feature and object-to-object relevance measures, contribute to the definition of a hybrid graph. The consensus process uses the resulting hybrid graph; it's …",25
Multi-view multi-instance multi-label learning based on collaborative matrix factorization,"Yuying Xing, Guoxian Yu, Carlotta Domeniconi, Jun Wang, Zili Zhang, Maozu Guo",2019/7/17,Journal Proceedings of the AAAI Conference on Artificial Intelligence,"Multi-view Multi-instance Multi-label Learning (M3L) deals with complex objects encompassing diverse instances, represented with different feature views, and annotated with multiple labels. Existing M3L solutions only partially explore the inter or intra relations between objects (or bags), instances, and labels, which can convey important contextual information for M3L. As such, they may have a compromised performance.\",25
Boosted mean shift clustering,"Yazhou Ren, Uday Kamath, Carlotta Domeniconi, Guoji Zhang",2014,"Conference Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2014, Nancy, France, September 15-19, 2014. Proceedings, Part II 14","Mean shift is a nonparametric clustering technique that does not require the number of clusters in input and can find clusters of arbitrary shapes. While appealing, the performance of the mean shift algorithm is sensitive to the selection of the bandwidth, and can fail to capture the correct clustering structure when multiple modes exist in one cluster. DBSCAN is an efficient density based clustering algorithm, but it is also sensitive to its parameters and typically merges overlapping clusters. In this paper we propose Boosted Mean Shift Clustering (BMSC) to address these issues. BMSC partitions the data across a grid and applies mean shift locally on the cells of the grid, each providing a number of intermediate modes (iModes). A mode-boosting technique is proposed to select points in denser regions iteratively, and DBSCAN is utilized to partition the obtained iModes iteratively. Our proposed BMSC can …",25
Categorization and keyword identification of unlabeled documents,"Ning Kang, Carlotta Domeniconi, Daniel Barbará",2005/11/27,Conference Fifth IEEE International Conference on Data Mining (ICDM'05),"In this paper, we first propose a global unsupervised feature selection approach for text, based on frequent itemset mining. As a result, each document is represented as a set of words that co-occur frequently in the given corpus of documents. We then introduce a locally adaptive clustering algorithm, designed to estimate (local) word relevance and, simultaneously, to group the documents. We present experimental results to demonstrate the feasibility of our approach. Furthermore, the analysis of the weights credited to terms provides evidence that the identified keywords can guide the process of label assignment to clusters. We take into consideration both spam email filtering and general classification datasets. Our analysis of the distribution of weights in the two cases provides insights on how the spam problem distinguishes from the general classification case.",25
Direct gray scale ridge reconstruction in fingerprint images,"Carlotta Domeniconi, Sibel Tari, Ping Liang",1998/5/15,"Conference Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP'98 (Cat. No. 98CH36181)","An original technique, based on ridge point detection directly from gray scale fingerprint images, is proposed. Our method avoids serious problems that algorithms which perform binarization of fingerprint images have. Each step can be easily hardware implemented, allowing a relevant speed up of the whole process.",25
Differentiating isoform functions with collaborative matrix factorization,"Keyao Wang, Jun Wang, Carlotta Domeniconi, Xiangliang Zhang, Guoxian Yu",2020/3/1,Journal Bioinformatics,"Isoforms are alternatively spliced mRNAs of genes. They can be translated into different functional proteoforms, and thus greatly increase the functional diversity of protein variants (or proteoforms). Differentiating the functions of isoforms (or proteoforms) helps understanding the underlying pathology of various complex diseases at a deeper granularity. Since existing functional genomic databases uniformly record the annotations at the gene-level, and rarely record the annotations at the isoform-level, differentiating isoform functions is more challenging than the traditional gene-level function prediction.",23
Acting the Same Differently: A Cross-Course Comparison of User Behavior in MOOCs.,"Ben Gelman, Matt Revelle, Carlotta Domeniconi, Aditya Johri, Kalyan Veeramachaneni",2016,Journal International Educational Data Mining Society,"Recent studies of MOOCs demonstrate their ability to reach a large number of users, but also caution against the high rate of dropout. Some have looked closely at MOOC participation in order to better understand how and when users start to disengage, and, if they remain engaged, in what activities they participate. Most of this prior work relies heavily on descriptive statistics or clustering methodologies to highlight basic user participation characteristics. In this paper, we adapt NMF to provide a multi-dimensional view of user participation. We use log data to create a bottom-up understanding of user participation, and identify five basic behaviors associated with participants' use of content and their engagement with assessment. Furthermore, we do a cross-course analysis across four courses and find that these five behaviors are present in all courses. Interestingly, users' participation patterns - how they engage in these five behaviors - vary across courses even when the",23
A weighted adaptive mean shift clustering algorithm,"Yazhou Ren, Carlotta Domeniconi, Guoji Zhang, Guoxian Yu",2014/4/28,Book Proceedings of the 2014 SIAM International Conference on Data Mining,"The mean shift algorithm is a nonparametric clustering technique that does not make assumptions on the number of clusters and on their shapes. It achieves this goal by performing kernel density estimation, and iteratively locating the local maxima of the kernel mixture. The set of points that converge to the same mode defines a cluster. While appealing, the performance of the mean shift algorithm significantly deteriorates with high dimensional data due to the sparsity of the input space. In addition, noisy features can create challenges for the mean shift procedure.",23
Multi-label answer aggregation based on joint matrix factorization,"Jinzheng Tu, Guoxian Yu, Carlotta Domeniconi, Jun Wang, Guoqiang Xiao, Maozu Guo",2018/11/17,Conference 2018 IEEE International Conference on Data Mining (ICDM),"Crowdsourcing is a useful and economic approach to data annotation. To obtain annotation of high quality, various aggregation approaches have been developed, which take into account different factors that impact the quality of aggregated answers. However, existing methods generally focus on single-label (multi-class and binary) tasks, and they ignore the inter-correlation between labels, and thus may have compromised quality. In this paper, we introduce a Multi-Label answer aggregation approach based on Joint Matrix Factorization (ML-JMF). ML-JMF selectively and jointly factorizes the sample-label association matrices collected from different annotators into products of individual and shared low-rank matrices. As such, it takes advantage of the robustness of low-rank matrix approximation to noise, and reduces the impact of unreliable annotators by assigning small (zero) weights to their annotation matrices …",22
Subspace metric ensembles for semi-supervised clustering of high dimensional data,"Bojun Yan, Carlotta Domeniconi",2006,"Conference Machine Learning: ECML 2006: 17th European Conference on Machine Learning Berlin, Germany, September 18-22, 2006 Proceedings 17","A critical problem in clustering research is the definition of a proper metric to measure distances between points. Semi-supervised clustering uses the information provided by the user, usually defined in terms of constraints, to guide the search of clusters. Learning effective metrics using constraints in high dimensional spaces remains an open challenge. This is because the number of parameters to be estimated is quadratic in the number of dimensions, and we seldom have enough side-information to achieve accurate estimates. In this paper, we address the high dimensionality problem by learning an ensemble of subspace metrics. This is achieved by projecting the data and the constraints in multiple subspaces, and by learning positive semi-definite similarity matrices therein. This methodology allows leveraging the given side-information while solving lower dimensional problems. We demonstrate …",22
Attributed heterogeneous network fusion via collaborative matrix tri-factorization,"Guoxian Yu, Yuehui Wang, Jun Wang, Carlotta Domeniconi, Maozu Guo, Xiangliang Zhang",2020/11/1,Journal Information Fusion,"Heterogeneous network based data fusion can encode diverse inter- and intra-relations between objects, and has been sparking increasing attention in recent years. Matrix factorization based data fusion models have been invented to fuse multiple data sources. However, these models generally suffer from the widely-witnessed insufficient relations between nodes and from information loss when heterogeneous attributes of diverse network nodes are transformed into ad-hoc homologous networks for fusion. In this paper, we introduce a general data fusion model called Attributed Heterogeneous Network Fusion (AHNF). AHNF firstly constructs an attributed heterogeneous network composed with different types of nodes and the diverse attribute vectors of these nodes. It uses indicator matrices to differentiate the observed inter-relations from the latent ones, and thus reduces the impact of insufficient relations …",21
Clustering ensembles with active constraints,"Muna Al-Razgan, Carlotta Domeniconi",2009,Journal Applications of Supervised and Unsupervised Ensemble Methods,"In this work we combine clustering ensembles and semi-supervised clustering to address the ill-posed nature of clustering. We introduce a hybrid approach that extends our previous work on clustering ensembles to situations where some knowledge from the end user is available, by enforcing constraints during the partitioning process. The experimental results show that our constrained ensemble technique is capable of producing a partition that is as good as, or better, than those computed by other semi-supervised clustering approaches.",21
Multi-label zero-shot learning with graph convolutional networks,"Guangjin Ou, Guoxian Yu, Carlotta Domeniconi, Xuequan Lu, Xiangliang Zhang",2020/12/1,Journal Neural Networks,"The goal of zero-shot learning (ZSL) is to build a classifier that recognizes novel categories with no corresponding annotated training data. The typical routine is to transfer knowledge from seen classes to unseen ones by learning a visual-semantic embedding. Existing multi-label zero-shot learning approaches either ignore correlations among labels, suffer from large label combinations, or learn the embedding using only local or global visual features. In this paper, we propose a Graph Convolution Networks based Multi-label Zero-Shot Learning model, abbreviated as MZSL-GCN. Our model first constructs a label relation graph using label co-occurrences and compensates the absence of unseen labels in the training phase by semantic similarity. It then takes the graph and the word embedding of each seen (unseen) label as inputs to the GCN to learn the label semantic embedding, and to obtain a set of inter …",20
Active multilabel crowd consensus,"Guoxian Yu, Jinzheng Tu, Jun Wang, Carlotta Domeniconi, Xiangliang Zhang",2020/4/16,Journal IEEE Transactions on Neural Networks and Learning Systems,"Crowdsourcing is an economic and efficient strategy aimed at collecting annotations of data through an online platform. Crowd workers with different expertise are paid for their service, and the task requester usually has a limited budget. How to collect reliable annotations for multilabel data and how to compute the consensus within budget are an interesting and challenging, but rarely studied, problem. In this article, we propose a novel approach to accomplish active multilabel crowd consensus (AMCC). AMCC accounts for the commonality and individuality of workers and assumes that workers can be organized into different groups. Each group includes a set of workers who share a similar annotation behavior and label correlations. To achieve an effective multilabel consensus, AMCC models workers' annotations via a linear combination of commonality and individuality and reduces the impact of unreliable …",19
Locally adaptive techniques for pattern classification,"Carlotta Domeniconi, Dimitrios Gunopulos",2009,"Book Encyclopedia of Data Warehousing and Mining, Second Edition","Pattern classification is a very general concept with numerous applications ranging from science, engineering, target marketing, medical diagnosis and electronic commerce to weather forecast based on satellite imagery. A typical application of pattern classification is mass mailing for marketing. For example, credit card companies often mail solicitations to consumers. Naturally, they would like to target those consumers who are most likely to respond. Often, demographic information is available for those who have responded previously to such solicitations, and this information may be used in order to target the most likely respondents. Another application is electronic commerce of the new economy. E-commerce provides a rich environment to advance the state-of-the-art in classification because it demands effective means for text classification in order to make rapid product and market recommendations. Recent …",19
Multiple independent subspace clusterings,"Xing Wang, Jun Wang, Carlotta Domeniconi, Guoxian Yu, Guoqiang Xiao, Maozu Guo",2019/7/17,Journal Proceedings of the AAAI conference on artificial intelligence,"Multiple clustering aims at discovering diverse ways of organizing data into clusters. Despite the progress made, it’s still a challenge for users to analyze and understand the distinctive structure of each output clustering. To ease this process, we consider diverse clusterings embedded in different subspaces, and analyze the embedding subspaces to shed light into the structure of each clustering. To this end, we provide a two-stage approach called MISC (Multiple Independent Subspace Clusterings). In the first stage, MISC uses independent subspace analysis to seek multiple and statistical independent (ie non-redundant) subspaces, and determines the number of subspaces via the minimum description length principle. In the second stage, to account for the intrinsic geometric structure of samples embedded in each subspace, MISC performs graph regularized semi-nonnegative matrix factorization to explore clusters. It additionally integrates the kernel trick into matrix factorization to handle non-linearly separable clusters. Experimental results on synthetic datasets show that MISC can find different interesting clusterings from the sought independent subspaces, and it also outperforms other related and competitive approaches on real-world datasets.",18
Advancing data clustering via projective clustering ensembles,"Francesco Gullo, Carlotta Domeniconi, Andrea Tagarelli",2011/6/12,Book Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,"Projective Clustering Ensembles (PCE) are a very recent advance in data clustering research which combines the two powerful tools of clustering ensembles and projective clustering.Specifically, PCE enables clustering ensemble methods to handle ensembles composed by projective clustering solutions. PCE has been formalized as an optimization problem with either a two-objective or a single-objective function. Two-objective PCE has shown to generally produce more accurate clustering results than its single-objective counterpart, although it can handle the object-based and feature-based cluster representations only independently of one other. Moreover, both the early formulations of PCE do not follow any of the standard approaches of clustering ensembles, namely instance-based, cluster-based, and hybrid. In this paper, we propose an alternative formulation to the PCE problem which overcomes the above …",18
Discovering multiple co-clusterings in subspaces,"Shixin Yao, Guoxian Yu, Xing Wang, Jun Wang, Carlotta Domeniconi, Maozu Guo",2019/5/6,Book Proceedings of the 2019 SIAM International Conference on Data Mining,"Multiple clustering approaches aim at exploring alternative ways of organizing a given collection of data into various clusters from different perspectives. Although multiple one-way clusterings have been studied for more than a decade, how to explore alternative two-way clusterings (or co-clusterings) still remains an untouched topic, and an important one from an application standpoint. To solve this interesting but yet unexplored topic, we assume the existence of alternative co-clusterings embedded in different subspaces and simultaneously pursue multiple co-clusterings therein. We initially specify a subspace indicator matrix for each feature subspace, and employ matrix tri-factorization to seek row-wise and column-wise cluster indicator matrices in each subspace. To ensure diversity, we quantify the redundancy between pairwise co-clusterings using the cluster indicator and the subspace indicator matrices. We …",17
Selective matrix factorization for multi-relational data fusion,"Yuehui Wang, Guoxian Yu, Carlotta Domeniconi, Jun Wang, Xiangliang Zhang, Maozu Guo",2019/4/24,"Book Database Systems for Advanced Applications: 24th International Conference, DASFAA 2019, Chiang Mai, Thailand, April 22–25, 2019, Proceedings, Part I","Matrix factorization based data fusion solutions can account for the intrinsic structures of multi-relational data sources, but most solutions equally treat these sources or prefer sparse ones, which may be irrelevant for the target task. In this paper, we introduce a Selective Matrix Factorization based Data Fusion approach (SelMFDF) to collaboratively factorize multiple inter-relational data matrices into low-rank representation matrices of respective object types and optimize the weights of them. To avoid preference to sparse data matrices, it additionally regularizes these low-rank matrices by approximating them to multiple intra-relational data matrices and also optimizes the weights of them. Both weights contribute to automatically integrate relevant data sources. Finally, it reconstructs the target relational data matrix using the optimized low-rank matrices. We applied SelMFDF for predicting inter-relations …",17
Online urbanism: Interest-based subcultures as drivers of informal learning in an online community,"Ben U Gelman, Chris Beckley, Aditya Johri, Carlotta Domeniconi, Seungwon Yang",2016/4/25,Book Proceedings of the third (2016) ACM conference on learning@ scale,"Online communities continue to be an important resource for informal learning. Although many facets of online learning communities have been studied, we have limited understanding of how such communities grow over time to productively engage a large number of learners. In this paper we present a study of a large online community called Scratch which was created to help users learn software programming. We analyzed 5 years of data consisting of 1 million users and their 1.9 million projects. Examination of interactional patterns among highly active members of the community uncovered a markedly temporal dimension to participation. As membership of the Scratch online community grew over time, interest-based subcultures started to emerge. This pattern was uncovered even when clustering was based solely on social network of members. This process, which closely resembles urbanism or the growth of …",17
Metacluster-based projective clustering ensembles,"Francesco Gullo, Carlotta Domeniconi, Andrea Tagarelli",2015/1,Journal Machine Learning,"The Projective Clustering Ensemble (PCE) problem is a recent clustering advance aimed at combining the two powerful tools of clustering ensembles and projective clustering. PCE has been formalized as either a two-objective or a single-objective optimization problem. Two-objective PCE has been recognized as more accurate than its single-objective counterpart, although it is unable to jointly handle the object-based and feature-based cluster representations.",17
Towards a universal text classifier: Transfer learning using encyclopedic knowledge,"Pu Wang, Carlotta Domeniconi",2009/12/6,Conference 2009 IEEE international conference on data mining workshops,"Document classification is a key task for many text mining applications. However, traditional text classification requires labeled data to construct reliable and accurate classifiers. Unfortunately, labeled data are seldom available. In this work, we propose a universal text classifier, which does not require any labeled document. Our approach simulates the capability of people to classify documents based on background knowledge. As such, we build a classifier that can effectively group documents based on their content, under the guidance of few words describing the classes of interest. Background knowledge is modeled using encyclopedic knowledge, namely Wikipedia. The universal text classifier can also be used to perform document retrieval. In our experiments with real data we test the feasibility of our approach for both the classification and retrieval tasks.",17
Mining relevant text from unlabelled documents,"Daniel Barbará, Carlotta Domeniconi, Ning Kang",2003/11/22,Conference Third IEEE International Conference on Data Mining,"Automatic classification of documents is an important area of research with many applications in the fields of document searching, forensics and others. Methods to perform classification of text rely on the existence of a sample of documents whose class labels are known. However, in many situations, obtaining this sample may not be an easy (or even possible) task. We focus on the classification of unlabelled documents into two classes: relevant and irrelevant, given a topic of interest. By dividing the set of documents into buckets (for instance, answers returned by different search engines), and using association rule mining to find common sets of words among the buckets, we can efficiently obtain a sample of documents that has a large percentage of relevant ones. This sample can be used to train models to classify the entire set of documents. We prove, via experimentation, that our method is capable of filtering …",17
Unsupervised boosting-based autoencoder ensembles for outlier detection,"Hamed Sarvari, Carlotta Domeniconi, Bardh Prenkaj, Giovanni Stilo",2021/5/9,"Book Advances in Knowledge Discovery and Data Mining: 25th Pacific-Asia Conference, PAKDD 2021, Virtual Event, May 11–14, 2021, Proceedings, Part I","Autoencoders have been recently applied to outlier detection. However, neural networks are known to be vulnerable to overfitting, and therefore have limited potential in the unsupervised outlier detection setting. The majority of existing deep learning methods for anomaly detection is sensitive to contamination of the training data to anomalous instances. To overcome the aforementioned limitations we develop a Boosting-based Autoencoder Ensemble approach (BAE). BAE is an unsupervised ensemble method that, similarly to boosting, builds an adaptive cascade of autoencoders to achieve improved and robust results. BAE trains the autoencoder components sequentially by performing a weighted sampling of the data, aimed at reducing the amount of outliers used during training, and at injecting diversity in the ensemble. We perform extensive experiments and show that the proposed methodology outperforms …",16
Cross-modal zero-shot hashing,"Xuanwu Liu, Zhao Li, Jun Wang, Guoxian Yu, Carlotta Domenicon, Xiangliang Zhang",2019/11/8,Conference 2019 IEEE International Conference on Data Mining (ICDM),"Hashing has been widely studied for big data retrieval due to its low storage cost and fast query speed. Zero-shot hashing (ZSH) aims to learn a hashing model that is trained using only samples from seen categories, but can generalize well to samples of unseen categories. ZSH generally uses category attributes to seek a semantic embedding space to transfer knowledge from seen categories to unseen ones. As a result, it may perform poorly when labeled data are insufficient. ZSH methods are mainly designed for single-modality data, which prevents their application to the widely spread multi-modal data. On the other hand, existing cross-modal hashing solutions assume that all the modalities share the same category labels, while in practice the labels of different data modalities may be different. To address these issues, we propose a general Cross-modal Zero-shot Hashing (CZHash) solution to effectively …",16
Kernel pooled local subspaces for classification,"Peng Zhang, Jing Peng, Carlotta Domeniconi",2005/5/16,"Journal IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",We investigate the use of subspace analysis methods for learning low-dimensional representations for classification. We propose a kernel-pooled local discriminant subspace method and compare it against competing techniques: kernel principal component analysis (KPCA) and generalized discriminant analysis (GDA) in classification problems. We evaluate the classification performance of the nearest-neighbor rule with each subspace representation. The experimental results using several data sets demonstrate the effectiveness and performance superiority of the kernel-pooled subspace method over competing methods such as KPCA and GDA in some classification problems.,16
Efficient local flexible nearest neighbor classification,"Carlotta Domeniconi, Dimitrios Gunopulos",2002/4/11,Book Proceedings of the 2002 SIAM International Conference on Data Mining,"The nearest neighbor technique is a simple and appealing method to address classification problems. It relies on the assumption of locally constant class conditional probabilities. This assumption becomes invalid in high dimensions with a finite number of examples due to the curse of dimensionality. Severe bias can be introduced under these conditions when using the nearest neighbor rule. The employment of a local adaptive metric becomes crucial in order to keep class conditional probabilities close to uniform, and therefore to minimize the bias of estimates. We propose a technique that computes a locally flexible metric by means of Support Vector Machines (SVMs). The maximum margin boundary found by the SVM is used to determine the most discriminant direction over the query's neighborhood. Such direction provides a local weighting scheme for input features. We present experimental evidence …",16
Adaptive metric nearest neighbor classification,"Carlotta Domeniconi, Jing Peng, Dimitrios Gunopulos",2000/6/15,Conference Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No. PR00662),"Nearest neighbor classification assumes locally constant class conditional probabilities. This assumption becomes invalid in high dimensions with finite samples due to the curse of dimensionality. Severe bias can be introduced under these conditions when using the nearest neighbor rule. We propose a locally adaptive nearest neighbor classification method to try to minimize bias. We use a Chi-squared distance analysis to compute a flexible metric for producing neighborhoods that are highly adaptive to query locations. Neighborhoods are elongated along less relevant feature dimensions and constricted along most influential ones. As a result, the class conditional probabilities tend to be smoother in the modified neighborhoods, whereby better classification performance can be achieved. The efficacy of our method is validated and compared against other techniques using a variety of simulated and real world data.",15
Cmal: Cost-effective multi-label active learning by querying subexamples,"Guoxian Yu, Xia Chen, Carlotta Domeniconi, Jun Wang, Zhao Li, Zili Zhang, Xiangliang Zhang",2020/6/22,Journal IEEE Transactions on Knowledge and Data Engineering,"Multi-label active learning (MAL) aims to learn an accurate multi-label classifier by selecting which examples (or example-label pairs) will be annotated and reducing query effort. MAL is a more complicated and expensive process than single-label active learning, due to one example can be associated with a set of non-exclusive labels and the annotator has to scrutinize the whole example and label space to provide correct annotations. Instead of scrutinizing the whole example for annotation, we may just examine some of its subexamples with respect to a label for annotation. In this way, we can not only save the annotation cost but also speedup the annotation process. Given this observation, we introduce CMAL, a two-stage Cost-effective MAL strategy (CMAL) by querying subexamples. CMAL first selects the most informative example-label pairs by leveraging uncertainty, label correlation and label space sparsity …",14
Discovering multiple co-clusterings with matrix factorization,"Jun Wang, Xing Wang, Guoxian Yu, Carlotta Domeniconi, Zhiwen Yu, Zili Zhang",2019/11/19,Journal IEEE Transactions on Cybernetics,"Clustering is a fundamental data exploration task which aims at discovering the hidden grouping structure in the data. The traditional clustering methods typically compute a single partition. However, there often exist different and equally meaningful clusterings in complex data. To solve this issue, multiple clustering approaches have emerged with the goal of exploring alternative clusterings from different perspectives. Existing solutions to this problem mainly focus on one-way clustering, that is, they cluster either the samples or the features. However, for many practical tasks, it is meaningful and desirable to explore alternative two-way clusterings (or co-clusterings), which capture not only the sample cluster structure but also the feature cluster structure. To tackle this interesting and unresolved task, we introduce an approach, called multiple co-clusterings (MultiCCs), to generate multiple alternative co-clusterings at …",14
Weighted matrix factorization based data fusion for predicting lncRNA-disease associations,"Guoxian Yu, Yuehui Wang, Jun Wang, Guangyuan Fu, Maozu Guo, Carlotta Domeniconi",2018/12/3,Conference 2018 IEEE international conference on bioinformatics and biomedicine (BIBM),"Increasing biomedical studies have demonstrated important associations between lncRNAs and various human complex diseases. Developing data integrative models can boost the performance of lncRNA-disease association identification. However, existing models generally have to transform heterogenous data into homologous networks, and then sum up these networks into a composite network for integrative prediction. The transformation may conceal the intrinsic structure of the heterogeneous data, and the summation process may suffer from noisy networks. Both these issues compromise the performance. In this paper, we introduce a Weighted Matrix Factorization based data fusion solution to predict LncRNA-Disease Associations (WMFLDA). WMFLDA first directly encodes the inter-associations between different types of biological entities (such as genes, lncRNAs, and Disease Ontology terms) via a …",14
Cost effective multi-label active learning via querying subexamples,"Xia Chen, Guoxian Yu, Carlotta Domeniconi, Jun Wang, Zhao Li, Zili Zhang",2018/11/17,Conference 2018 IEEE International Conference on Data Mining (ICDM),"Multi-label active learning addresses the scarce labeled example problem by querying the most valuable unlabeled examples, or example-label pairs, to achieve a better performance with limited query cost. Current multi-label active learning methods require the scrutiny of the whole example in order to obtain its annotation. In contrast, one can find positive evidence with respect to a label by examining specific patterns (i.e., subexample), rather than the whole example, thus making the annotation process more efficient. Based on this observation, we propose a novel two-stage cost effective multi-label active learning framework, called CMAL. In the first stage, a novel example-label pair selection strategy is introduced. Our strategy leverages label correlation and label space sparsity of multi-label examples to select the most uncertain example-label pairs. Specifically, the unknown relevant label of an example can be …",14
Persistent roles in online social networks,"Matt Revelle, Carlotta Domeniconi, Aditya Johri",2016,"Conference Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2016, Riva del Garda, Italy, September 19-23, 2016, Proceedings, Part II 16","Users in online social networks often have very different structural positions which may be attributed to a latent factor: roles. In this paper, we analyze dynamic networks from two datasets (Facebook and Scratch) to find roles which define users’ structural positions. Each dynamic network is partitioned into snapshots and we independently find roles for each network snapshot. We present our role discovery methodology and investigate how roles differ between snapshots and datasets. Six persistent roles are found and we investigate user role membership, transitions between roles, and interaction preferences.",14
Detection of communities and bridges in weighted networks,"Tanwistha Saha, Carlotta Domeniconi, Huzefa Rangwala",2011,"Conference Machine Learning and Data Mining in Pattern Recognition: 7th International Conference, MLDM 2011, New York, NY, USA, August 30–September 3, 2011. Proceedings 7","Traditional graph-based clustering methods group vertices into non-intersecting clusters under the assumption that each vertex can belong to only a single cluster. On the other hand, recent research on graph-based clustering methods, applied to real world networks (e.g., protein-protein interaction networks and social networks), shows overlapping patterns among the underlying clusters. For example, in social networks, an individual is expected to belong to multiple clusters (or communities), rather than strictly confining himself/herself to just one. As such, overlapping clusters enable better models of real-life phenomena. Soft clustering (e.g., fuzzy c-means) has been used with success for network data as well as non-graph data, when the objects are allowed to belong to multiple clusters with a certain degree of membership. In this paper, we propose a fuzzy clustering based approach for community …",14
Enhancing single-objective projective clustering ensembles,"Francesco Gullo, Carlotta Domeniconi, Andrea Tagarelli",2010/12/13,Conference 2010 IEEE International Conference on Data Mining,"Projective Clustering Ensembles (PCE) has recently been formulated to solve the problem of deriving a robust projective consensus clustering from an ensemble of projective clustering solutions. PCE is formalized as an optimization problem with either a two-objective or a single-objective function, depending on whether the object-based and the feature-based representations of the clusters in the ensemble are treated separately. A major result in is that single-objective PCE outperforms two-objective PCE in terms of efficiency, at the cost of lower accuracy in consensus clustering. In this paper, we enhance the single-objective PCE formulation, with the ultimate goal of providing more effective formulations capable of reducing the accuracy gap with the two-objective counterpart, while maintaining the efficiency advantages. We provide theoretical insights into the single-objective function, and introduce two heuristics …",14
Clustering gene expression data in SQL using locally adaptive metrics,"Dimitris Papadopoulos, Carlotta Domeniconi, Dimitrios Gunopulos, Sheng Ma",2003/6/13,Book Proceedings of the 8th ACM SIGMOD workshop on Research issues in data mining and knowledge discovery,"The clustering problem concerns the discovery of homogeneous groups of data according to a certain similarity measure. Clustering suffers from the curse of dimensionality. It is not meaningful to look for clusters in high dimensional spaces as the average density of points anywhere in input space is likely to be low. As a consequence, distance functions that equally use all input features may be ineffective. We introduce an algorithm that discovers clusters in subspaces spanned by different combinations of dimensions via local weightings of features. This approach avoids the risk of loss of information encountered in global dimensionality reduction techniques. Our method associates to each cluster a weight vector, whose values capture the relevance of features within the corresponding cluster. In this paper we present an efficient SQL implementation of our algorithm, that enables the discovery of clusters on data …",14
Multi-label crowd consensus via joint matrix factorization,"Jinzheng Tu, Guoxian Yu, Carlotta Domeniconi, Jun Wang, Guoqiang Xiao, Maozu Guo",2020/4,Journal Knowledge and Information Systems,"Crowdsourcing is a useful and economic approach to annotate data. Various computational solutions have been developed to pursue a consensus of high quality. However, available solutions mainly target single-label tasks, and they neglect correlations among labels. In this paper, we introduce a multi-label crowd consensus (MLCC) model based on a joint matrix factorization. Specifically, MLCC selectively and jointly factorizes the sample-label association matrices into products of individual and shared low-rank matrices. As such, it makes use of the robustness of low-rank matrix approximation to noisy annotations and diminishes the impact of unreliable annotators by assigning small weights to their annotation matrices. To obtain coherent low-rank matrices, MLCC additionally leverages the shared low-rank matrix to model correlations among labels, and the individual low-rank matrices to measure the …",13
Multiple co-clusterings,"Xing Wang, Guoxian Yu, Carlotta Domeniconi, Jun Wang, Zhiwen Yu, Zili Zhang",2018/11/17,Conference 2018 IEEE International Conference on Data Mining (ICDM),"The goal of multiple clusterings is to discover multiple independent ways of organizing a dataset into clusters. Current approaches to this problem just focus on one-way clustering. In many real-world applications, though, it's meaningful and desirable to explore alternative two-way clustering (or co-clusterings), where both samples and features are clustered. To tackle this challenge and unexplored problem, in this paper we introduce an approach, called Multiple Co-Clusterings (MultiCC), to discover non-redundant alternative co-clusterings. MultiCC makes use of matrix tri-factorization to optimize the sample-wise and feature-wise co-clustering indicator matrices, and introduces two non-redundancy terms to enforce diversity among co-clusterings. We then combine the objective of matrix tri-factorization and two non-redundancy terms into a unified objective function and introduce an iterative solution to optimize the …",13
Local semantic kernels for text document clustering,"Loulwah AlSumait, Carlotta Domeniconi",2007/1/1,Journal SIAM international conference on data mining workshop on text mining,"Document clustering is a fundamental task of text mining, by which efficient organization, navigation, summarization and retrieval of documents can be achieved. The clustering of documents presents difficult challenges due to the sparsity and the high dimensionality of text data, and to the complex semantics of the natural language. Subspace clustering is an extension of traditional clustering that is designed to capture local feature relevance, and to group documents with respect to the features (or words) that matter the most. This paper presents a subspace clustering technique based on a Locally Adaptive Clustering (LAC) algorithm. To improve the subspace clustering of documents and the identification of keywords achieved by LAC, kernel methods and semantic distances are deployed. The basic idea is to define a local kernel for each cluster by which semantic distances between pairs of words are computed to derive the clustering and the local term weightings. The proposed approach, called Semantic LAC, is evaluated using benchmark datasets. Our experiments show that Semantic LAC is capable of improving the clustering quality.",13
Crowdwt: Crowdsourcing via joint modeling of workers and tasks,"Jinzheng Tu, Guoxian Yu, Jun Wang, Carlotta Domeniconi, Maozu Guo, Xiangliang Zhang",2020/12/7,Journal ACM Transactions on Knowledge Discovery from Data (TKDD),"Crowdsourcing is a relatively inexpensive and efficient mechanism to collect annotations of data from the open Internet. Crowdsourcing workers are paid for the provided annotations, but the task requester usually has a limited budget. It is desirable to wisely assign the appropriate task to the right workers, so the overall annotation quality is maximized while the cost is reduced. In this article, we propose a novel task assignment strategy (CrowdWT) to capture the complex interactions between tasks and workers, and properly assign tasks to workers. CrowdWT first develops a Worker Bias Model (WBM) to jointly model the worker’s bias, the ground truths of tasks, and the task features. WBM constructs a mapping between task features and worker annotations to dynamically assign the task to a group of workers, who are more likely to give correct annotations for the task. CrowdWT further introduces a Task Difficulty …",12
Detecting suspicious behavior in surveillance images,"Daniel Barbará, Carlotta Domeniconi, Zoran Duric, Maurizio Filippone, Richard Mansfield, Edgard Lawson",2008/12/15,Conference 2008 IEEE International Conference on Data Mining Workshops,"We introduce a novel technique to detect anomalies in images. The notion of normalcy is given by a baseline of images, under the assumption that the majority of such images is normal. The key of our approach is a featureless probabilistic representation of images, based on the length of the codeword necessary to represent each image. Such codeword's lengths are then used for anomaly detection based on statistical testing. Our techniques were tested on synthetic and real data sets. The results show that our approach can achieve high true positive and low false positive rates.",12
On error correlation and accuracy of nearest neighbor ensemble classifiers,"Carlotta Domeniconi, Bojun Yan",2005/4/21,Book Proceedings of the 2005 SIAM International Conference on Data Mining,"Recent empirical work has shown that combining predictors can lead to significant reduction in generalization error. Unfortunately, many combining methods do not improve nearest neighbor (NN) classifiers at all. This is because NN methods are very robust with respect to variations of a data set. In contrast, they are sensitive to input features. We exploit the instability of NN classifiers with respect to different choices of features to generate an effective and diverse set of NN classifiers. Interestingly, the approach takes advantage of the high dimensionality of the data. We investigate techniques to decorrelate errors while keeping the individual classifiers accurate. We analyze the results both in terms of error rates and error correlations. The experimental results show that our technique can offer significant performance improvements with respect to competitive methods.",12
Classifying documents without labels,"Daniel Barbará, Carlotta Domeniconi, Ning Kang",2004/4/22,Book Proceedings of the 2004 SIAM International Conference on Data Mining,"Automatic classification of documents is an important area of research with many applications in the fields of document searching, forensics and others. Methods to perform classification of text rely on the existence of a sample of documents whose class labels are known. However, in many situations, obtaining this sample may not be an easy (or even possible) task. Consider for instance, a set of documents that is returned as a result of a query. If we want to separate the documents that are truly relevant to the query from those that are not, it is unlikely that we will have at hand labelled documents to train classification models to perform this task. In this paper we focus on the classification of an unlabelled set of documents into two classes: relevant and irrelevant, given a topic of interest. By dividing the set of documents into buckets (for instance, answers returned by different search engines), and using association …",12
Flexible cross-modal hashing,"Guoxian Yu, Xuanwu Liu, Jun Wang, Carlotta Domeniconi, Xiangliang Zhang",2020/10/14,Journal IEEE Transactions on Neural Networks and Learning Systems,"Hashing has been widely adopted for large-scale data retrieval in many domains due to its low storage cost and high retrieval speed. Existing cross-modal hashing methods optimistically assume that the correspondence between training samples across modalities is readily available. This assumption is unrealistic in practical applications. In addition, existing methods generally require the same number of samples across different modalities, which restricts their flexibility. We propose a flexible cross-modal hashing approach (FlexCMH) to learn effective hashing codes from weakly paired data, whose correspondence across modalities is partially (or even totally) unknown. FlexCMH first introduces a clustering-based matching strategy to explore the structure of each cluster and, thus, to find the potential correspondence between clusters (and samples therein) across modalities. To reduce the impact of an incomplete …",11
Protein function prediction using weak-label learning,"Guoxian Yu, Guoji Zhang, Huzefa Rangwala, Carlotta Domeniconi, Zhiwen Yu",2012/10/7,"Book Proceedings of the ACM Conference on Bioinformatics, Computational Biology and Biomedicine","Protein function prediction is one of the fundamental issues in the post-genomic era. Multi-label learning is widely used for predicting functions of proteins. Most multi-label learning methods assume that the proteins with annotation do not have any missing functions. However, in practice, we may have a subset of the ground-truth functions for a protein, and whether the protein has other functions is unknown. To complete the partial annotation of proteins, we propose a Protein Function Prediction method with Weak-label Learning (ProWL), and a variant of ProWL (ProWL-IF). Both ProWL and ProWL-IF replenish the functions of proteins under the assumption that proteins are partially annotated. In addition, ProWL-IF takes advantage of the knowledge that a protein cannot have certain functions (called irrelevant functions), which can further boost the performance of protein function prediction. Our experimental results …",11
Attention-aware answers of the crowd,"Jingzheng Tu, Guoxian Yu, Jun Wang, Carlotta Domeniconi, Xiangliang Zhang",2020,Book Proceedings of the 2020 SIAM International Conference on Data Mining,"Crowdsourcing is a relatively economic and efficient solution to collect annotations from the crowd through online platforms. Answers collected from workers with different expertise may be noisy and unreliable, and the quality of annotated data needs to be further maintained. Various solutions have been attempted to obtain high-quality annotations. However, they all assume that workers' label quality is stable over time (always at the same level whenever they conduct the tasks). In practice, workers' attention level changes over time, and the ignorance of which can affect the reliability of the annotations. In this paper, we focus on a novel and realistic crowdsourcing scenario involving attention-aware annotations. We propose a new probabilistic model that takes into account workers' attention to estimate the label quality. Expectation propagation is adopted for efficient Bayesian inference of our model, and a …",10
Sparsification and sampling of networks for collective classification,"Tanwistha Saha, Huzefa Rangwala, Carlotta Domeniconi",2013,"Conference Social Computing, Behavioral-Cultural Modeling and Prediction: 6th International Conference, SBP 2013, Washington, DC, USA, April 2-5, 2013. Proceedings 6","Network analysis has been an active area of research for the past few decades. Out of many open research questions that have been extensively studied, relational classification, community detection, link prediction are only to name a few. Collective classification is a well-known relational classification method for classifying entities (nodes) within a network which involves using both node based features and topological features of each node. It involves collective prediction of the unknown labels of all the test nodes in the network using label information of the training nodes. Even though this has been a well researched topic for years, very little has been done to address the following two challenges: (1) how to actively select the labeled nodes from the network to be used for training, and (2) how to efficiently obtain a sparse representation of the original network without losing much information, so that …",10
Multiobjective optimization of co-clustering ensembles,"Francesco Gullo, AKM Khaled Talukder, Sean Luke, Carlotta Domeniconi, Andrea Tagarelli",2012/7/7,Book Proceedings of the 14th annual conference companion on Genetic and evolutionary computation,"Co-clustering is a machine learning task where the goal is to simultaneously develop clusters of the data and of their respective features. We address the use of co-clustering ensembles to establish a consensus co-clustering over the data. In this paper we develop a new preference-based multiobjective optimization algorithm to compete with a previous gradient ascent approach in finding optimal co-clustering ensembles. Unlike the gradient ascent algorithm, our approach once tackles the co-clustering problem with multiple heuristics, then applies the gradient ascent algorithm's joint heuristic as a preference selection procedure. We are able to significantly outperform the gradient ascent algorithm on feature clustering and on problems with smaller datasets.",10
Information bottleneck co-clustering,"Pu Wang, Carlotta Domeniconi, Kathryn Blackmond Laskey",2010/5,Journal Workshop TextMining@ SIAM DM,"Co-clustering has emerged as an important approach for mining contingency data matrices. We present a novel approach to co-clustering based on the Information Bottleneck principle, called Information Bottleneck Co-clustering (IBCC), which supports both soft-partition and hardpartition co-clusterings, and leverages an annealing-style strategy to bypass local optima. Existing co-clustering methods require the user to define the number of row-and column-clusters respectively. In practice, though, the number of row-and column-clusters may not be independent. To address this issue, we also present an agglomerative Information Bottleneck Co-clustering (aIBCC) approach, which automatically captures the relation between the numbers of clusters. The experimental results demonstrate the effectiveness and efficiency of our techniques.",10
Detecting spatio-temporal outliers with kernels and statistical testing,"James P Rogers, Daniel Barbara, Carlotta Domeniconi",2009/8/12,Conference 2009 17th International Conference on Geoinformatics,"Outlier detection is the discovery of points that are exceptional when compared with a set of observations that are considered normal. Such points are important since they often lead to the discovery of exceptional events. In spatio-temporal data, observations are vectors of feature values, tagged with a geographical location and a timestamp. A spatio-temporal outlier is an observation whose attribute values are significantly different from those of other spatially and temporally referenced objects in a spatio-temporal neighborhood. It represents an object that is significantly different from its neighbors, even though it may not be significantly different from the entire population. The discovery of outliers in spatio-temporal data is then complicated by the fact that one needs to focus the search on appropriate spatio-temporal neighborhoods of points. The work in this paper leverages an algorithm, StrOUD (strangeness-based …",10
Reducing ensembles of protein tertiary structures generated de novo via clustering,"Ahmed Bin Zaman, Parastoo Kamranfar, Carlotta Domeniconi, Amarda Shehu",2020/5/9,Journal Molecules,"Controlling the quality of tertiary structures computed for a protein molecule remains a central challenge in de-novo protein structure prediction. The rule of thumb is to generate as many structures as can be afforded, effectively acknowledging that having more structures increases the likelihood that some will reside near the sought biologically-active structure. A major drawback with this approach is that computing a large number of structures imposes time and space costs. In this paper, we propose a novel clustering-based approach which we demonstrate to significantly reduce an ensemble of generated structures without sacrificing quality. Evaluations are related on both benchmark and CASP target proteins. Structure ensembles subjected to the proposed approach and the source code of the proposed approach are publicly-available at the links provided in Section 1.",9
Weakly supervised cross-modal hashing,"Xuanwu Liu, Guoxian Yu, Carlotta Domeniconi, Jun Wang, Guoqiang Xiao, Maozu Guo",2019/11/20,Journal IEEE Transactions on Big Data,"Cross-modal hashing can efficiently retrieve data across different modalities and has been successfully applied in various domains. Although many supervised cross-modal hashing methods have been proposed, they generally focus on two modals only and assume that the labels of training data are sufficient and complete. This assumption is not practical in real scenarios. In this article, we propose the weakly supervised cross-modal hashing (WCHash), which takes into account the widely witnessed weakly supervised information ( incomplete  and  insufficient labels ) of training data. Specifically, WCHash first optimizes a latent central modality with respect to other modalities. Next, it uses an efficient multi-label weak-label method to enrich the labels of training data and measures the semantic similarity between data points based on the enriched labels. After that, it uses this similarity to guide the correlation …",9
Network-based anomaly detection for insider trading,"Adarsh Kulkarni, Priya Mani, Carlotta Domeniconi",2017/2/19,Journal arXiv preprint arXiv:1702.05809,"Insider trading is one of the numerous white collar crimes that can contribute to the instability of the economy. Traditionally, the detection of illegal insider trades has been a human-driven process. In this paper, we collect the insider tradings made available by the US Securities and Exchange Commissions (SEC) through the EDGAR system, with the aim of initiating an automated large-scale and data-driven approach to the problem of identifying illegal insider tradings. The goal of the study is the identification of interesting patterns, which can be indicators of potential anomalies. We use the collected data to construct networks that capture the relationship between trading behaviors of insiders. We explore different ways of building networks from insider trading data, and argue for a need of a structure that is capable of capturing higher order relationships among traders. Our results suggest the discovery of interesting patterns.",9
Predicting preference tags to improve item recommendation,"Tanwistha Saha, Huzefa Rangwala, Carlotta Domeniconi",2015/6/30,Book Proceedings of the 2015 SIAM International Conference on Data Mining,"Collaborative filtering (CF) based recommender systems identify and recommend interesting items to a given user based on the user's past rating activity. These systems improve their recommendations by identifying user preferences and item related information from external sources, like reviews written by users, or concept tags shared by users about these items. These preferences are often reflected through a multi-criterion rating. In this study, we seek to improve recommender systems by integrating user preferences as side information within standard neighborhood-based and matrix factorization based methods. We assume that a user's choice of tags for an item provides additional information about the user's personal preference and additional features about the item. Since, querying users to provide tags and multi-criteria rating imposes an additional burden on the user base, we propose using collective …",9
An analysis of a spatial ea parallel boosting algorithm,"Uday Kamath, Carlotta Domeniconi, Kenneth A De Jong",2013/7/6,Book Proceedings of the 15th annual conference on Genetic and evolutionary computation,"The scalability of machine learning (ML) algorithms has become a key issue as the size of training datasets continues to increase. To address this issue in a reasonably general way, a parallel boosting algorithm has been developed that combines concepts from spatially structured evolutionary algorithms (SSEAs) and ML boosting techniques. To get more insight into the algorithm, a proper theoretical and empirical analysis is required. This paper is a first step in that direction. First, it establishes the connection between this algorithm and well known density estimation and mixture model approaches used by the machine learning community. The paper then analyzes the algorithm in terms of varioustheoretical and empirical properties such as convergence to large margins, scalability effects on accuracy and speed, robustness to noise, and connections to support vector machines in terms of instances converged to.",9
Multi-label collective classification using adaptive neighborhoods,"Tanwistha Saha, Huzefa Rangwala, Carlotta Domeniconi",2012/12/12,Conference 2012 11th International Conference on Machine Learning and Applications,"Multi-label learning in graph-based relational data has gained popularity in recent years due to the increasingly complex structures of real world applications. Collective Classification deals with the simultaneous classification of neighboring instances in relational data, until a convergence criterion is reached. The rationale behind collective classification stems from the fact that an entity in a network (or relational data) is most likely influenced by the neighboring entities, and can be classified accordingly, based on the class assignment of the neighbors. Although extensive work has been done on collective classification of single labeled data, the domain of multi-labeled relational data has not been sufficiently explored. In this paper, we propose a neighborhood ranking method for multi-label classification, which can be further used in the Multi-label Collective Classification framework. We test our methods on real …",9
Local Feature Selection for Classiﬁcation,"Carlotta Domeniconi, Dimitrios Gunopulos",2007/10/29,Book Computational methods of feature selection,"In a classiﬁcation problem, we are given C classes and M training observations. The training observations consist of N feature measurements x = (x1, · · · , xN )T ∈ N and the known class labels y = 1, . . . , C. The goal is to predict the class label of a given query x0.",9
An efficient density-based approach for data mining tasks,"Carlotta Domeniconi, Dimitrios Gunopulos",2004/11,Journal Knowledge and information systems,"We propose a locally adaptive technique to address the problem of setting the bandwidth parameters for kernel density estimation. Our technique is efficient and can be performed in only two dataset passes. We also show how to apply our technique to efficiently solve range query approximation, classification and clustering problems for very large datasets. We validate the efficiency and accuracy of our technique by presenting experimental results on a variety of both synthetic and real datasets. ",9
"Cooperative driver pathway discovery via fusion of multi-relational data of genes, miRNAs and pathways","Jun Wang, Ziying Yang, Carlotta Domeniconi, Xiangliang Zhang, Guoxian Yu",2021/3,Journal Briefings in Bioinformatics,"Discovering driver pathways is an essential step to uncover the molecular mechanism underlying cancer and to explore precise treatments for cancer patients. However, due to the difficulties of mapping genes to pathways and the limited knowledge about pathway interactions, most previous work focus on identifying individual pathways. In practice, two (or even more) pathways interplay and often cooperatively trigger cancer. In this study, we proposed a new approach called CDPathway to discover cooperative driver pathways. First, CDPathway introduces a driver impact quantification function to quantify the driver weight of each gene. CDPathway assumes that genes with larger weights contribute more to the occurrence of the target disease and identifies them as candidate driver genes. Next, it constructs a heterogeneous network composed of genes, miRNAs and pathways nodes based on the known intra(inter …",8
Crowdsourcing with multiple-source knowledge transfer,"Guangyang Han, Jinzheng Tu, Guoxian Yu, Jun Wang, Carlotta Domeniconi",2021/1/7,Book Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence,"Crowdsourcing is a new computing paradigm that harnesses human effort to solve computer-hard problems. Budget and quality are two fundamental factors in crowdsourcing, but they are antagonistic and their balance is crucially important. Induction and inference are principled ways for humans to acquire knowledge. Transfer learning can also enable induction and inference processes. When a new task comes, we may not know how to go about approaching it. On the other hand, we may have easy access to relevant knowledge that can help us with the new task. As such, via appropriate knowledge transfer, for example, an improved annotation can be achieved for the task at a small cost. To make this idea concrete, we introduce the Crowdsourcing with Multiple-source Knowledge Transfer (CrowdMK-T) approach to transfer knowledge from multiple, similar, but different domains for a new task, and to reduce the negative impact of irrelevant sources. CrowdMKT first learns a set of concentrated highlevel feature vectors of tasks using knowledge transfer from multiple sources, and then introduces a probabilistic graphical model to jointly model the tasks with high-level features, workers, and their annotations. Finally, it adopts an EM algorithm to estimate the workers’ strengths and consensus. Experimental results on real-world image and text datasets prove the effectiveness of CrowdMKT in improving the quality and reducing the budget.",8
Partial multi-label learning using label compression,"Tingting Yu, Guoxian Yu, Jun Wang, Carlotta Domeniconi, Xiangliang Zhang",2020/11/17,Conference 2020 IEEE International Conference on Data Mining (ICDM),"Partial multi-label learning (PML) aims at learning a robust multi-label classifier from partial multi-label data, where a sample is annotated with a set of candidate labels, while only a subset of those labels is valid. The existing PML algorithms generally suffer from the high computational cost when learning with large label spaces. In this paper, we introduce a PML approach (PML-LCom) that uses Label Compression to efficiently learn from partial multi-label data. PML-LCom firstly splits the observed label data matrix into a latent relevant label matrix and an irrelevant one, and then factorizes the relevant label matrix into two low-rank matrices, one encodes the compressed labels of samples, and the other explores the underlying label correlations. Next, it optimizes the coefficient matrix of the multi-label predictor with respect to the compressed label matrix. In addition, it regularizes the compressed label matrix with …",8
Deep incomplete multi-view multiple clusterings,"Shaowei Wei, Jun Wang, Guoxian Yu, Carlotta Domeniconi, Xiangliang Zhang",2020/11/17,Conference 2020 IEEE International Conference on Data Mining (ICDM),"Multi-view clustering aims at exploiting information from multiple heterogeneous views to promote clustering. Most previous works search for only one optimal clustering based on the predefined clustering criterion, but devising such a criterion that captures what users need is difficult. Due to the multiplicity of multi-view data, we can have meaningful alternative clusterings. In addition, the incomplete multi-view data problem is ubiquitous in real world but has not been studied for multiple clusterings. To address these issues, we introduce a deep incomplete multi-view multiple clusterings (DiMVMC) framework, which achieves the completion of data view and multiple shared representations simultaneously by optimizing multiple groups of decoder deep networks. In addition, it minimizes a redundancy term to simultaneously control the diversity among these representations and among parameters of different networks …",8
Weakly-supervised multi-view multi-instance multi-label learning,"Yuying Xing, Guoxian Yu, Jun Wang, Carlotta Domeniconi, Xiangliang Zhang",2020,Publisher International Joint Conferences on Artificial Intelligence,"Multi-view, Multi-instance, and Multi-label Learning (M3L) can model complex objects (bags), which are represented with different feature views, made of diverse instances, and annotated with discrete nonexclusive labels. Existing M3L approaches assume a complete correspondence between bags and views, and also assume a complete annotation for training. However, in practice, neither the correspondence between bags, nor the bags' annotations are complete. To tackle such a weakly-supervised M3L task, a solution called WSM3L is introduced. WSM3L adapts multimodal dictionary learning to learn a shared dictionary (representational space) across views and individual encoding vectors of bags for each view. The label similarity and feature similarity of encoded bags are jointly used to match bags across views. In addition, it replenishes the annotations of a bag based on the annotations of its neighborhood bags, and introduces a dispatch and aggregation term to dispatch bag-level annotations to instances and to reversely aggregate instance-level annotations to bags. WSM3L unifies these objectives and processes in a joint objective function to predict the instance-level and bag-level annotations in a coordinated fashion, and it further introduces an alternative solution for the objective function optimization. Extensive experimental results show the effectiveness of WSM3L on benchmark datasets.",8
FLIP: active learning for relational network classification,"Tanwistha Saha, Huzefa Rangwala, Carlotta Domeniconi",2014,"Conference Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2014, Nancy, France, September 15-19, 2014. Proceedings, Part III 14","Active learning in relational networks has gained popularity in recent years, especially for scenarios when the costs of obtaining training samples are very high. We investigate the problem of active learning for both single- and multi-labeled relational network classification in the absence of node features during training. The problem becomes harder when the number of labeled nodes available for training a model is limited due to budget constraints. The inability to use a traditional learning setup for classification of relational data, has motivated researchers to propose Collective Classification algorithms that jointly classifies all the test nodes in a network by exploiting the underlying correlation between the labels of a node and its neighbors. In this paper, we propose active learning algorithms based on different query strategies using a collective classification model where each node in a network can belong …",8
Multiview multi-instance multilabel active learning,"Guoxian Yu, Yuying Xing, Jun Wang, Carlotta Domeniconi, Xiangliang Zhang",2021/2/12,Journal IEEE Transactions on Neural Networks and Learning Systems,"Multiview multi-instance multilabel learning (M3L) is a framework for modeling complex objects. In this framework, each object (or bag) contains one or more instances, is represented with different feature views, and simultaneously annotated with a set of nonexclusive semantic labels. Given the multiplicity of the studied objects, traditional M3L methods generally demand a large number of labeled bags to train a predictive model to annotate bags (or instances) with semantic labels. However, annotating sufficient bags is very expensive and often impractical. In this article, we present an active learning-based M3L approach (M3AL) to reduce the labeling costs of bags and to improve the performance as much as possible. M3AL first adapts the multiview self-representation learning to evacuate the shared and individual information of bags and to learn the shared/individual similarities between bags across/within views …",7
Parallel boosted clustering,"Yazhou Ren, Uday Kamath, Carlotta Domeniconi, Zenglin Xu",2019/7/25,Journal Neurocomputing,"Scalability of clustering algorithms is a critical issue in real world clustering applications. Usually, data sampling and parallelization are two common ways to address the scalability issue. Despite their wide utilization in a number of clustering algorithms, they suffer from several major drawbacks. For example, most data sampling can often lead to biased solutions due to its inability in accurately capturing the distribution of the entire data set. On the other hand, the performance of parallelization highly depends on the original clustering routines which are not parallel algorithms in nature, such that customizing each algorithm to be parallel may hurt the clustering performance. To alleviate these problems, we propose a general two-step framework for scalable clustering in this work, where the first step is to obtain skeleton structure of data and the second step is to obtain the final clustering. Concretely, data are first …",7
A new framework for centrality measures in multiplex networks,"Carlo Spatocco, Giovanni Stilo, Carlotta Domeniconi, Alessandro D'Andrea",2018/1/24,Journal arXiv preprint arXiv:1801.08026,"The non-trivial structure of such complex systems makes the analysis of their collective behavior a challenge. The problem is even more difficult when the information is distributed across networks (e.g., communication networks in different media); in this case, it becomes impossible to have a complete, or even partial picture, if situations are analyzed separately within each network due to sparsity. A multiplex network is well-suited to model the complexity of this kind of systems by preserving the semantics associated with each network. Centrality measures are fundamental for the identification of key players, but existing approaches are typically designed to capture a predefined aspect of the system, ignoring or merging the semantics of the individual layers.",7
The role of semantic history on online generative topic modeling,"Loulwah AlSumait, Daniel Barbará, Carlotta Domeniconi",2009,"Journal Proceedings of the Workshop on Text Mining, held in conjunction with the SIAM International Conference on Data Mining","Online processing of text streams is an essential task of many genuine applications. The objective is to identify the underlying structure of evolving themes in the incoming streams online at the time of their arrival. As many topics tend to reappear consistently in text streams, incorporating semantics that were discovered in previous streams would eventually enhance the identification and description of topics in the future. Latent Dirichlet Allocation (LDA) topic model is a probabilistic technique that has been successfully used to automatically extract the topical or semantic content of documents. In this paper, we investigate the role of past semantics in estimating future topics under the framework of LDA topic modeling, based on the online version implemented in [1]. The idea is to construct the current model based on information propagated from topic models that fall within a “sliding history window”. Then, this model is incrementally updated according to the information inferred from the new stream of data with no need to access previous data. Since the proposed approach is totally unsupervised and data-driven, we analyze the effect of different factors that are involved in this model, including the window size, history weight, and equal/decaying history contribution. The proposed approach is evaluated using benchmark datasets. Our experiments show that the embedded semantics from the past improved the quality of the document modeling. We also found that the role of history varies according to the domain and nature of text data.",7
Penta-training: Clustering ensembles with bootstrapping of constraints,"Carlotta Domeniconi, Muna Al-Razgan",2008,Journal Workshop on Supervised and Unsupervised Ensemble Methods and their Applications,"In this paper we combine clustering ensembles and semisupervised clustering to address the ill-posed nature of clustering. We introduce a mechanism which leverages the ensemble framework to bootstrap informative constraints directly from the data and from the various clusterings, without intervention from the user. Our approach is well suited for problems where the information available from an external source is very limited. We demonstrate the effectiveness of our proposed technique with experiments using real datasets and other state-of-the-art semi-supervised techniques.",7
Decoy ensemble reduction in template-free protein structure prediction,"Ahmed Bin Zaman, Parastoo Kamranfar, Carlotta Domeniconi, Amarda Shehu",2019/9/4,"Book Proceedings of the 10th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics","The primary challenge in template-free protein structure prediction is controlling the quality of computed tertiary structures, also known as decoys. While research on how to do so is highly active, the main rule of thumb is to generate as many decoys as can be afforded. This rule acknowledges that more decoys increase the likelihood that some will reside near the sought biologically-active/native structure. Generating large numbers of decoys imposes time and space costs. These costs percolate down to decoy selection algorithms that need to select from the generated decoys a few sufficiently near-native. In this paper, we evaluate the hypothesis that the generated decoy ensemble can be significantly reduced without sacrificing decoy quality. Evaluation on diverse proteins shows that drastic reductions can be achieved in the number of preserved decoys while retaining the quality of generated decoys via clustering …",6
Feature Enriched Nonparametric Bayesian Co-clustering.,"Pu Wang, Carlotta Domeniconi, Huzefa Rangwala, Kathryn B Laskey",2012/5/29,Conference PAKDD (1),"Co-clustering has emerged as an important technique for mining relational data, especially when data are sparse and high-dimensional. Coclustering simultaneously groups the different kinds of objects involved in a relation. Most co-clustering techniques typically only leverage the entries of the given contingency matrix to perform the two-way clustering. As a consequence, they cannot predict the interaction values for new objects. In many applications, though, additional features associated to the objects of interest are available. The Infinite Hidden Relational Model (IHRM) has been proposed to make use of these features. As such, IHRM has the capability to forecast relationships among previously unseen data. The work on IHRM lacks an evaluation of the improvement that can be achieved when leveraging features to make predictions for unseen objects. In this work, we fill this gap and re-interpret IHRM from a co-clustering point of view. We focus on the empirical evaluation of forecasting relationships between previously unseen objects by leveraging object features. The empirical evaluation demonstrates the effectiveness of the feature-enriched approach and identifies the conditions under which the use of features is most useful, ie, with sparse data.",6
DMIL-IsoFun: predicting isoform function using deep multi-instance learning,"Guoxian Yu, Guangjie Zhou, Xiangliang Zhang, Carlotta Domeniconi, Maozu Guo",2021/12/11,Journal Bioinformatics,"Alternative splicing creates the considerable proteomic diversity and complexity on relatively limited genome. Proteoforms translated from alternatively spliced isoforms of a gene actually execute the biological functions of this gene, which reflect the functional knowledge of genes at a finer granular level. Recently, some computational approaches have been proposed to differentiate isoform functions using sequence and expression data. However, their performance is far from being desirable, mainly due to the imbalance and lack of annotations at isoform-level, and the difficulty of modeling gene–isoform relations.",5
Multi-typed objects multi-view multi-instance multi-label learning,"Yuanlin Yang, Guoxian Yu, Jun Wang, Carlotta Domeniconi, Xiangliang Zhang",2020/11/17,Conference 2020 IEEE International Conference on Data Mining (ICDM),"Multi-typed objects Multi-view Multi-instance Multi-label Learning (M4L) deals with interconnected multi-typed objects (or bags) that are made of diverse instances, represented with heterogeneous feature views and annotated with a set of non-exclusive but semantically related labels. M4L is more general and powerful than the typical Multi-view Multi-instance Multi-label Learning (M3L), which only accommodates single-typed bags and lacks the power to jointly model the naturally interconnected multi-typed objects in the physical world. To combat with this novel and challenging learning task, we develop a joint matrix factorization based solution (M4L-JMF). Particularly, M4L-JMF firstly encodes the diverse attributes and multiple inter(intra)-associations among multi-typed bags into respective data matrices, and then jointly factorizes these matrices into low-rank ones to explore the composite latent representation of …",5
The hubness phenomenon in high-dimensional spaces,"Priya Mani, Marilyn Vazquez, Jessica Ruth Metcalf-Burton, Carlotta Domeniconi, Hillary Fairbanks, Gülce Bal, Elizabeth Beer, Sibel Tari",2019,Journal Research in Data Science,"High-dimensional data analysis is often negatively affected by the curse of dimensionality. In high-dimensional spaces, data becomes extremely sparse and distances between points become indistinguishable. As a consequence, reliable estimations of density, or meaningful distance-based similarity measures, cannot be obtained. This issue is particularly prevalent in clustering, which is commonly employed in exploratory data analysis. Another challenge for clustering high-dimensional data is that data often exist in subspaces consisting of combinations of dimensions, with different subspaces being relevant for different clusters. The hubness phenomenon is a recently discovered aspect of high-dimensional spaces. It is observed that the distribution of neighbor occurrences becomes skewed in intrinsically high-dimensional data, with few points, the hubs, having high occurrence counts. Hubness is observed …",5
Matrix factorization for identifying noisy labels of multi-label instances,"Xia Chen, Guoxian Yu, Carlotta Domeniconi, Jun Wang, Zili Zhang",2018,"Conference PRICAI 2018: Trends in Artificial Intelligence: 15th Pacific Rim International Conference on Artificial Intelligence, Nanjing, China, August 28–31, 2018, Proceedings, Part II 15","Current effort on multi-label learning generally assumes that the given labels are noise-free. However, obtaining noise-free labels is quite difficult and often impractical. In this paper, we study how to identify a subset of relevant labels from a set of candidate ones given as annotations to instances, and introduce a matrix factorization based method called MF-INL. It first decomposes the original instance-label association matrix into two low-rank matrices using nonnegative matrix factorization with feature-based and label-based constraints to retain the geometric structure of instances and label correlations. MF-INL then reconstructs the association matrix using the product of the decomposed matrices, and identifies associations with the lowest confidence as noisy associations. An empirical study on real-world multi-label datasets with injected noisy labels shows that MF-INL can identify noisy labels more …",5
Regression databases: Probabilistic querying using sparse learning sets,"Alexander Brodsky, Carlotta Domeniconi, David Etter",2006/12/14,Conference 2006 5th International Conference on Machine Learning and Applications (ICMLA'06),"We introduce regression databases (REDB) to formalize and automate probabilistic querying using sparse learning sets. The REDB data model involves observation data, learning set data, views definitions, and a regression model instance. The observation data is a collection of relational tuples over a set of attributes; the learning data set involves a subset of observation tuples, augmented with learned attributes, which are modeled as random variables; the views are expressed as linear combinations of observation and learned attributes; and the regression model involves functions that map observation tuples to probability distributions of the random variables, which are learned dynamically from the learning data set. The REDB query language extends relational algebra project-select queries with conditions on probabilities of first-order logical expressions, which in turn involve linear combinations of learned …",5
Discorsi sulle reti neurali e l'apprendimento,"Carlotta Domeniconi, Michael Jordan",2001,Publisher F. Angeli,,5
Few-shot partial multi-label learning,"Yunfeng Zhao, Guoxian Yu, Lei Liu, Zhongmin Yan, Carlotta Domeniconi, Lizhen Cui",2021/12/7,Conference 2021 IEEE International Conference on Data Mining (ICDM),"Partial multi-label learning (PML) aims at learning a robust multi-label classifier by training on ambiguous data, where each sample is associated with a set of candidate labels, among which only a subset are valid labels. A basic premise of existing PML solutions is to obtain enough partial multi-label samples for inducing the classification model. However, when dealing with new tasks, we may only have a few PML samples for those tasks. Furthermore, existing few-shot learning approaches assume the support (training) samples are precisely labeled; as such, irrelevant labels in the candidate label set may seriously mislead the meta-learner and thus result in a compromised performance. How to achieve PML with limited few-shot support samples is an important and practical problem, but not yet well studied. In this paper, we propose an approach called FsPML (Few-shot PML) to tackle this problem. Specifically …",4
Crowdsourcing with self-paced workers,"Xiangping Kang, Guoxian Yu, Carlotta Domeniconi, Jun Wang, Wei Guo, Yazhou Ren, Lizhen Cui",2021/12/7,Conference 2021 IEEE International Conference on Data Mining (ICDM),"Crowdsourcing is a popular and relatively economic way to harness human intelligence to process computer-hard tasks. Due to diverse factors (i.e., task difficulty, worker capability, and incentives), the collected answers from various crowd workers are of different quality. Many approaches have been proposed to manage high quality answers and to reduce the budget by modelling tasks, workers, or both. However, most of the existing approaches implicitly assume that the capability of workers is fixed during the crowdsourcing process. But in practice, such capability can be improved by gradually completing easy to hard tasks, alike human beings’ intrinsic self-paced learning ability. In this paper, we investigate crowdsourcing with self-paced workers, whose capability can be gradually boosted as he/she scrutinises and completes easy to hard tasks. Our proposed SPCrowd (Self-Paced Crowd worker) first asks …",4
Multiple clusterings of heterogeneous information networks,"Shaowei Wei, Guoxian Yu, Jun Wang, Carlotta Domeniconi, Xiangliang Zhang",2021/6,Journal Machine Learning,"Traditional clustering algorithms focus on a single clustering result; as such, they cannot explore potential diverse patterns of complex real world data. To deal with this problem, approaches that exploit meaningful alternative clusterings in data have been developed in recent years. Existing algorithms, including single view/multi-view multiple clustering methods, are designed for applications with i.i.d. data samples, and cannot handle the data samples with dependency presented in networks, especially in heterogeneous information networks (HIN). In this paper, we propose a framework (NetMCs) that can explore multiple clusterings in HIN. Specifically, NetMCs adopts a set of meta-path schemes with different semantics on HIN, and considers each meta-path scheme as a base clustering aspect. Guided by the meta-path schemes, NetMCs then introduces a variation of the skip-gram framework that can jointly …",4
Hub-based subspace clustering,"Priya Mani, Carlotta Domeniconi",2020/11/6,Journal Neurocomputing,"Data often exists in subspaces embedded within a high-dimensional space. Subspace clustering seeks to group data according to the dimensions relevant to each subspace. This requires the estimation of subspaces as well as the clustering of data. Subspace clustering becomes increasingly challenging in high dimensional spaces due to the curse of dimensionality which affects reliable estimations of distances and density. Recently, another aspect of high-dimensional spaces has been observed, known as the hubness phenomenon, whereby few data points appear frequently as nearest neighbors of the rest of the data. The distribution of neighbor occurrences becomes skewed with increasing intrinsic dimensionality of the data, and few points with high neighbor occurrences emerge as hubs. Hubs exhibit useful geometric properties and have been leveraged for clustering data in the full-dimensional space. In this …",4
Neural networks and learning systems come together,Derong Liu,2011/12/28,Journal IEEE Transactions on Neural Networks and Learning Systems,"This issue marks the beginning of the IEEE Transactions on Neural Networks and Learning Systems (TNNLS). By adding ""Learning Systems"" to the title, we now state explicitly the scope of the Transactions to include neural networks as well as related learning systems. This issue marks a new era in the history of our Transactions. The Transactions is now ready to face the challenges of the next 10-20 years. With the evolution of the fields of neural networks in particular and computational intelligence in general, the IEEE Transactions on Neural Networks and Learning Systems will continue to grow and to succeed in this ever-changing world. Also included are a few comments about the review process of TNN manuscripts and the introduction of 14 new TNNLS Associate Editors. Short biographies are included for the new Associate Editors.",4
Kernel optimization using pairwise constraints for semi-supervised clustering,"Bojun Yan, Carlotta Domeniconi",2006,"Publisher Technical report ISE-TR-06-09, Information and Software Engineering Department, George Mason University, Fairfax, Virginia, USA","A critical problem related to kernel-based methods is the selection of an optimal kernel for the problem at hand. The kernel function in use must conform with the learning target in order to obtain meaningful results. While solutions to estimate optimal kernel functions and their parameters have been proposed in a supervised setting, the problem presents open challenges when no labeled data are provided, and all we have available is a set of pairwise must-link and cannot-link constraints. In this paper we address the problem of optimizing the kernel function using pairwise constraints for semi-supervised clustering. To this end we derive a new optimization criterion to automatically estimate the optimal parameters of composite Gaussian kernels, directly from the data and the given constraints. We combine the optimal kernel function computed by our technique with a recently introduced semi-supervised kernel-based algorithm to demonstrate experimentally the effectivess of our approach. The results show that our method enables the practical utilization of powerful kernel-based semi-supervised clustering approaches by providing a mechanism to automatically set the involved critical parameters.",4
An E cient Approach for Approximating Multi-dimensional Range Queries and Nearest Neighbor Classification in Large Datasets,"Carlotta Domeniconi, Dimitrios Gunopulos",2001/6/28,"Description We propose a locally adaptive technique to address the problem of setting the bandwidth parameters optimally for kernel density estimation. Our technique is e cient and can be performed in only two dataset passes. We also show how to apply our technique to e ciently solve range query approximation, classi cation and clustering problems for very large datasets. We validate the e ciency and accuracy of our technique by presenting experimental results on a variety of both synthetic and real datasets.","We propose a locally adaptive technique to address the problem of setting the bandwidth parameters optimally for kernel density estimation. Our technique is e cient and can be performed in only two dataset passes. We also show how to apply our technique to e ciently solve range query approximation, classi cation and clustering problems for very large datasets. We validate the e ciency and accuracy of our technique by presenting experimental results on a variety of both synthetic and real datasets.",4
Few-shot partial-label learning,"Yunfeng Zhao, Guoxian Yu, Lei Liu, Zhongmin Yan, Lizhen Cui, Carlotta Domeniconi",2021/6/2,Journal arXiv preprint arXiv:2106.00984,"Partial-label learning (PLL) generally focuses on inducing a noise-tolerant multi-class classifier by training on overly-annotated samples, each of which is annotated with a set of labels, but only one is the valid label. A basic promise of existing PLL solutions is that there are sufficient partial-label (PL) samples for training. However, it is more common than not to have just few PL samples at hand when dealing with new tasks. Furthermore, existing few-shot learning algorithms assume precise labels of the support set; as such, irrelevant labels may seriously mislead the meta-learner and thus lead to a compromised performance. How to enable PLL under a few-shot learning setting is an important problem, but not yet well studied. In this paper, we introduce an approach called FsPLL (Few-shot PLL). FsPLL first performs adaptive distance metric learning by an embedding network and rectifying prototypes on the tasks previously encountered. Next, it calculates the prototype of each class of a new task in the embedding network. An unseen example can then be classified via its distance to each prototype. Experimental results on widely-used few-shot datasets (Omniglot and miniImageNet) demonstrate that our FsPLL can achieve a superior performance than the state-of-the-art methods across different settings, and it needs fewer samples for quickly adapting to new tasks.",3
Deep Multi-type Objects Muli-view Multi-instance Multi-label Learning,"Yuanlin Yang, Guoxian Yu, Carlotta Domeniconi, Xiangliang Zhang",2021,Book Proceedings of the 2021 SIAM International Conference on Data Mining (SDM),"Multi-view multi-instance multi-label learning (M3L) can model complex objects (bags) that are composed of multiple instances, represented with heterogeneous feature views and annotated with multiple related semantic labels. Although significant progress has been made toward M3L tasks, the current solutions still focus on a single-type of complex objects, and cannot effectively mine the widely-witnessed interconnected objects of multi-types. To bridge this gap, we propose a Deep Multi-type objects Multi-view Multi-instance Multi-label Learning solution (DeepM4L) based on heterogeneous network embedding. DeepM4L first encodes the inter- and intra-relations among multi-type objects using a heterogeneous network, and performs instance neighbor embedding to learn the representation vectors of instances. Next, it obtains the instance-label score tensor for each view and uses a max pooling operation to …",3
Graph-based selective outlier ensembles,"Hamed Sarvari, Carlotta Domeniconi, Giovanni Stilo",2019/4/8,Book Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing,"An ensemble technique is characterized by the mechanism that generates the components and by the mechanism that combines them. A common way to achieve the consensus is to enable each component to equally participate in the aggregation process. A problem with this approach is that poor components are likely to negatively affect the quality of the consensus result. To address this issue, alternatives have been explored in the literature to build selective classifier and cluster ensembles, where only a subset of the components contributes to the computation of the consensus. Of the family of ensemble methods, outlier ensembles are the least studied. Only recently, the selection problem for outlier ensembles has been discussed. In this work we define a new graph-based class of ranking selection methods. A method in this class is characterized by two main steps: (1) Mapping the rankings onto a graph …",3
Semi-supervised rank learning for multimedia known-item search,"David Etter, Carlotta Domeniconi",2014/4/1,Book Proceedings of International Conference on Multimedia Retrieval,"Known Item Search (KIS) is a specialized task of the general multimedia search problem. It describes the scenario where a user has previously seen a video and wants to find it again in a large collection using a text description. While there exists only one correct answer to a query (or topic), the goal is to return a ranked list of videos most likely to satisfy the request. This search problem includes content from speech, visual, and meta-data, and it is not clear how the individual modalities should be combined in the final result. Reranking models have been shown to be effective in problems such as image search, but the single ground truth video for a topic presents a challenge for building a model. In this paper, we propose a semi-supervised rank learning approach to the multimedia problem. We use a large training set of topics and ground truth videos to learn a pairwise ranking model based on gradient boosted …",3
Exploration of different constraints and query methods with kernel-based semi-supervised clustering,"Bojun Yan, Carlotta Domeniconi",2006/10/8,"Conference 2006 IEEE International Conference on Systems, Man and Cybernetics","Semi-supervised clustering makes use of a small amount of supervised data to aid unsupervised learning. The method used to obtain the supervised information, and the way such information is integrated within the learning algorithm can greatly affect the final result. This paper introduces two different kernel-based semi-supervised clustering algorithms, and investigates the power of kernel methods in principle. Moreover, driven by practice, two methods to obtain supervised data are considered. We compare our kernel-based semi-supervised clustering approaches with semi-supervised K-means and unsupervised kernel K-means. The experimental results show that both our methods can outperform the others, regardless of the technique used to generate the supervised data.",3
Direct gray scale ridge reconstruction in fingerprint images,"Carlotta Domeniconi, Sibel Tari, Ping Liang",1998/5/15,"Conference Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP'98 (Cat. No. 98CH36181)","An original technique, based on ridge point detection directly from gray scale fingerprint images, is proposed. Our method avoids serious problems that algorithms which perform binarization of fingerprint images have. Each step can be easily hardware implemented, allowing a relevant speed up of the whole process.",25
Personalized Federated Few-Shot Learning,"Yunfeng Zhao, Guoxian Yu, Jun Wang, Carlotta Domeniconi, Maozu Guo, Xiangliang Zhang, Lizhen Cui",2022/7/21,Journal IEEE Transactions on Neural Networks and Learning Systems,"Personalized federated learning (PFL) learns a personalized model for each client in a decentralized manner, where each client owns private data that are not shared and data among clients are non-independent and identically distributed (i.i.d.) However, existing PFL solutions assume that clients have sufficient training samples to jointly induce personalized models. Thus, existing PFL solutions cannot perform well in a few-shot scenario, where most or all clients only have a handful of samples for training. Furthermore, existing few-shot learning (FSL) approaches typically need centralized training data; as such, these FSL methods are not applicable in decentralized scenarios. How to enable PFL with limited training samples per client is a practical but understudied problem. In this article, we propose a solution called personalized federated few-shot learning (pFedFSL) to tackle this problem. Specifically, pFedFSL …",2
Group-node attention for community evolution prediction,"Matt Revelle, Carlotta Domeniconi, Ben Gelman",2021/11/8,Book Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,"Communities in social networks evolve over time as people enter and leave the network and their activity behaviors shift. The task of predicting structural changes in communities over time is known as community evolution prediction. Existing work in this area has focused on the development of frameworks for defining events while using traditional classification methods to perform the actual prediction. We present a novel graph neural network for predicting community evolution events from structural and temporal information. The model (GNAN) includes a group-node attention component which enables support for variable-sized inputs and learned representation of groups based on member and neighbor node features. A comparative evaluation with standard baseline methods is performed and we demonstrate that our model outperforms the baselines. Additionally, we show the effects of network trends on model …",2
Estimator vectors: OOV word embeddings based on subword and context clue estimates,"Raj Patel, Carlotta Domeniconi",2020/7/19,Conference 2020 International Joint Conference on Neural Networks (IJCNN),"Semantic representations of words have been successfully extracted from unlabeled corpuses using neural network models like word2vec. These representations are generally high quality and are computationally inexpensive to train, making them popular. However, these approaches generally fail to approximate out of vocabulary (OOV) words, a task humans can do quite easily, using word roots and context clues. This paper proposes a neural network model that learns high quality word representations, subword representations, and context clue representations jointly. Learning all three types of representations together enhances the learning of each, leading to enriched word vectors, along with strong estimates for OOV words, via the combination of the corresponding context clue and subword embeddings. Our model, called Estimator Vectors (EV), learns strong word embeddings and is competitive with state of …",2
"EML: a scalable, transparent meta-learning paradigm for big data applications","Uday Kamath, Carlotta Domeniconi, Amarda Shehu, Kenneth De Jong",2019,Journal Innovations in Big Data Mining and Embedded Knowledge,"The work presentedKamath, Uday in this chapter is motivated by two important challenges that arise when applying ML techniques to big data applications: the scalability of an ML technique as the training dataDomeniconi, Carlotta increases significantly in size, and the transparency (understandability) of the induced models. To address these issues we describe andShehu, Amarda analyze a meta-learning paradigm, EML, that combines techniques from evolutionary computation and supervised learning to produceDe Jong, Kenneth a powerful approach for inducing transparent models for big data ML applications.",2
Temporal artifacts from edge accumulation in social interaction networks,"Matt Revelle, Carlotta Domeniconi, Aditya Johri",2019,Journal Neural Advances in Processing Nonlinear Dynamic Signals 27,"There has been extensive research on social networks and methods for specific tasks such as: community detection, link prediction, and tracing information cascades; and a recent emphasis on using temporal dynamics of social networks to improve method performance. The underlying models are based on structural properties of the network, some of which we believe to be artifacts introduced from common misrepresentations of social networks. Specifically, representing a social network or series of social networks as an accumulation of network snapshots is problematic. In this paper, we use datasets with timestamped interactions to demonstrate how cumulative graphs differ from activity-based graphs and may introduce temporal artifacts.",2
Evidence of Temporal Artifacts in Social Networks.,"Matt Revelle, Carlotta Domeniconi, Aditya Johri",2015/9/7,Conference MUSE@ PKDD/ECML,"There has been extensive research on social networks and methods for specific tasks such as: community detection, link prediction, and tracing information cascades; and a recent emphasis on using temporal dynamics of social networks to improve method performance. The underlying models are based on structural properties of the network, some of which we believe to be artifacts introduced from common misrepresentations of social networks. Specifically, representing a social network or series of social networks as an accumulation of network snapshots is problematic. In this paper, we use a dataset with timestamped interactions to demonstrate how cumulative graphs differ from activity-based graphs and may introduce temporal artifacts.",2
Bayesian co‐clustering,"Carlotta Domeniconi, Kathryn Laskey",2015/9,Source Wiley Interdisciplinary Reviews: Computational Statistics,"Co‐clustering means simultaneously identifying natural clusters in different kinds of objects. Examples include simultaneously clustering customers and products for a recommender application; simultaneously clustering proteins and molecules in microbiology; or simultaneously clustering documents and words in a text mining application. Important insights into a problem can be gained by understanding the interactions between clusters for the different kinds of objects. This paper considers Bayesian models for co‐clustering. The Bayesian approach begins by developing a model for the data generating process, and inverting that model through Bayesian inference to infer cluster membership, learn characteristics of the clusters, and fill in missing observations. We consider a basic Bayesian clustering model and several extensions to the model. Experimental evaluations and comparisons among the clustering …",2
Multi2Rank: multimedia multiview ranking,"David Etter, Carlotta Domeniconi",2015/4/20,Conference 2015 IEEE International Conference on Multimedia Big Data,"Multimedia retrieval is a search and ranking task defined over multiple modalities. These modalities include speech, image, and text, which provide different views of the multimedia object. Queries to a multimedia retrieval system often take the form of a text only query and return a ranked result set which combines these multiple views. The text only query includes multiple phrases which identify features of a specific view. This multiview problem presents a challenge in mapping these phrases into the correct view feature space. A second challenge for the multimedia retrieval system is in building a ranking model which considers the unique feature space of each view. In this paper, we propose a hierarchical multimedia multiview rank learning model, called Multi 2 Rank, to overcome the challenges of this unique ranking problem. The first layer of our model uses natural language processing techniques to identify …",2
Data-Mining Techniques for Microarray data analysis,"Carlotta Domeniconi, Daniel Barbará, Harsh Chaudhary, Ali Al-Timimi, Curtis Jamison",2005/3/8,Journal Next Generation of Data-Mining Applications,"Gene expression profiling studies via DNA microarrays offer unprecedented opportunities for advancing fundamental biological research and clinical practice (Schena et al., 1995; Debouck and Goodfellow, 1999; Aitman, 2001). Microarray technology allows researchers to simultaneously measure the expression level of tens of thousands of genes, creating a comprehensive overview of exactly what genes are being expressed in a specific tissue under various conditions. However, these studies produce a massive amount of data which need to be treated using informatics and algorithms that are sensitive to the biological context to produce meaningful results.",2
Dimensionality reduction using kernel pooled local discriminant information,"Peng Zhang, Jing Peng, Carlotta Domeniconi",2003/11/22,Conference Third IEEE International Conference on Data Mining,We study the use of kernel subspace methods for learning low-dimensional representations for classification. We propose a kernel pooled local discriminant subspace method and compare it against several competing techniques: generalized Fisher discriminant analysis (GDA) and kernel principal components analysis (KPCA) in classification problems. We evaluate the classification performance of the nearest-neighbor rule with each subspace representation. The experimental results demonstrate the efficacy of the kernel pooled local subspace method and the potential for substantial improvements over competing methods such as KPCA in some classification problems.,2
Isoform function prediction by Gene Ontology embedding,"Sichao Qiu, Guoxian Yu, Xudong Lu, Carlotta Domeniconi, Maozu Guo",2022/10/1,Journal Bioinformatics,"High-resolution annotation of gene functions is a central task in functional genomics. Multiple proteoforms translated from alternatively spliced isoforms from a single gene are actual function performers and greatly increase the functional diversity. The specific functions of different isoforms can decipher the molecular basis of various complex diseases at a finer granularity. Multi-instance learning (MIL)-based solutions have been developed to distribute gene(bag)-level Gene Ontology (GO) annotations to isoforms(instances), but they simply presume that a particular annotation of the gene is responsible by only one isoform, neglect the hierarchical structures and semantics of massive GO terms (labels), or can only handle dozens of terms.",1
Cross-modal Zero-shot Hashing by Label Attributes Embedding,"Runmin Wang, Guoxian Yu, Lei Liu, Lizhen Cui, Carlotta Domeniconi, Xiangliang Zhang",2021/11/7,Journal arXiv preprint arXiv:2111.04080,"Cross-modal hashing (CMH) is one of the most promising methods in cross-modal approximate nearest neighbor search. Most CMH solutions ideally assume the labels of training and testing set are identical. However, the assumption is often violated, causing a zero-shot CMH problem. Recent efforts to address this issue focus on transferring knowledge from the seen classes to the unseen ones using label attributes. However, the attributes are isolated from the features of multi-modal data. To reduce the information gap, we introduce an approach called LAEH (Label Attributes Embedding for zero-shot cross-modal Hashing). LAEH first gets the initial semantic attribute vectors of labels by word2vec model and then uses a transformation network to transform them into a common subspace. Next, it leverages the hash vectors and the feature similarity matrix to guide the feature extraction network of different modalities. At the same time, LAEH uses the attribute similarity as the supplement of label similarity to rectify the label embedding and common subspace. Experiments show that LAEH outperforms related representative zero-shot and cross-modal hashing methods.",1
Open-set crowdsourcing using multiple-source transfer learning,"Guangyang Han, Guoxian Yu, Lei Liu, Lizhen Cui, Carlotta Domeniconi, Xiangliang Zhang",2021/11/7,Journal arXiv preprint arXiv:2111.04073,"We raise and define a new crowdsourcing scenario, open set crowdsourcing, where we only know the general theme of an unfamiliar crowdsourcing project, and we don't know its label space, that is, the set of possible labels. This is still a task annotating problem, but the unfamiliarity with the tasks and the label space hampers the modelling of the task and of workers, and also the truth inference. We propose an intuitive solution, OSCrowd. First, OSCrowd integrates crowd theme related datasets into a large source domain to facilitate partial transfer learning to approximate the label space inference of these tasks. Next, it assigns weights to each source domain based on category correlation. After this, it uses multiple-source open set transfer learning to model crowd tasks and assign possible annotations. The label space and annotations given by transfer learning will be used to guide and standardize crowd workers' annotations. We validate OSCrowd in an online scenario, and prove that OSCrowd solves the open set crowdsourcing problem, works better than related crowdsourcing solutions.",1
Role detection and prediction in dynamic political networks,"Emily Evans, Weihong Guo, Asli Genctav, Sibel Tari, Carlotta Domeniconi, Anarina Murillo, Julia Chuang, Loulwah AlSumait, Priya Mani, Noha El-Zehiry",2021,Journal Advances in Data Science,"The interaction of users, either online or in real-life, can be modeled via a network (or graph). In such networks, users engage in activities and take on specific roles. Users who manifest similar structural and connectivity patterns assume similar roles. The analysis of a network in terms of the component roles can facilitate the discovery of communities. By compressing big and complex networks, roles can also enable the discovery of important patterns, as well as important differences across networks.",1
Unsupervised Selective Manifold Regularized Matrix Factorization,"Priya Mani, Carlotta Domeniconi, Igor Griva",2021,Book Proceedings of the 2021 SIAM International Conference on Data Mining (SDM),"Manifold regularization methods for matrix factorization rely on the cluster assumption, whereby the neighborhood structure of data in the input space is preserved in the factorization space. We argue that using the k-neighborhoods of all data points as regularization constraints can negatively affect the quality of the factorization, and propose an unsupervised and selective regularized matrix factorization algorithm to tackle this problem. Our approach jointly learns a sparse set of representatives and their neighbor affinities, and the data factorization. We further propose a fast approximation of our approach by relaxing the selectivity constraints on the data. Our proposed algorithms are competitive against baselines and state-of-the-art manifold regularization and clustering algorithms.",1
Effects of Model Misspecification on BayesianBandits: Case Studies in UX Optimization,"Mack Sweeney, Matthew van Adelsberg, Kathryn Laskey, Carlotta Domeniconi",2020/11/17,Conference 2020 IEEE International Conference on Data Mining (ICDM),"Bayesian bandits using Thompson Sampling have seen increasing success in recent years. Yet existing value models (of rewards) are misspecified on many real-world problem. We demonstrate this on the User Experience Optimization (UXO) problem, providing a novel formulation as a restless, sleeping bandit with unobserved confounders plus optional stopping. Our case studies show how common misspecifications can lead to sub-optimal rewards, and we provide model extensions to address these, along with a scientific model building process practitioners can adopt or adapt to solve their own unique problems. To our knowledge, this is the first study showing the effects of overdispersion on bandit explore/exploit efficacy, tying the common notions of under- and over-confidence to over- and under-exploration, respectively. We also present the first model to demonstrate that vanishing regret and fast and …",1
Theoretical and empirical analysis of a spatial EA parallel boosting algorithm,"Uday Kamath, Carlotta Domeniconi, Kenneth De Jong",2018/3/2,Journal Evolutionary Computation,"Many real-world problems involve massive amounts of data. Under these circumstances learning algorithms often become prohibitively expensive, making scalability a pressing issue to be addressed. A common approach is to perform sampling to reduce the size of the dataset and enable efficient learning. Alternatively, one customizes learning algorithms to achieve scalability. In either case, the key challenge is to obtain algorithmic efficiency without compromising the quality of the results. In this article we discuss a meta-learning algorithm (PSBML) that combines concepts from spatially structured evolutionary algorithms (SSEAs) with concepts from ensemble and boosting methodologies to achieve the desired scalability property. We present both theoretical and empirical analyses which show that PSBML preserves a critical property of boosting, specifically, convergence to a distribution centered around the …",1
"MultiClust 2013: Multiple Clusterings, Multiview Data, and Multisource Knowledgedriven Clustering: [Workshop Report]","Ira Assent, Carlotta Domeniconi, Francesco Gullo, Andrea Tagarelli, Arthur Zimek",2016/8/1,Journal Acm Sigkdd Explorations Newsletter,"In this workshop report, we give a summary of the Multi-Clust workshop held in Chicago in conjunction with KDD 2013. We provide an overview on the history of this workshop series and the general topics covered. Furthermore, we provide summaries of the invited talks and of the contributed papers.",1
Theoretical and Empirical Analysis of a Parallel Boosting Algorithm,"Uday Kamath, Carlotta Domeniconi, Kenneth De Jong",2015/8/6,Journal arXiv preprint arXiv:1508.01549,"Many real-world problems involve massive amounts of data. Under these circumstances learning algorithms often become prohibitively expensive, making scalability a pressing issue to be addressed. A common approach is to perform sampling to reduce the size of the dataset and enable efficient learning. Alternatively, one customizes learning algorithms to achieve scalability. In either case, the key challenge is to obtain algorithmic efficiency without compromising the quality of the results. In this paper we discuss a meta-learning algorithm (PSBML) which combines features of parallel algorithms with concepts from ensemble and boosting methodologies to achieve the desired scalability property. We present both theoretical and empirical analyses which show that PSBML preserves a critical property of boosting, specifically, convergence to a distribution centered around the margin. We then present additional empirical analyses showing that this meta-level algorithm provides a general and effective framework that can be used in combination with a variety of learning classifiers. We perform extensive experiments to investigate the tradeoff achieved between scalability and accuracy, and robustness to noise, on both synthetic and real-world data. These empirical results corroborate our theoretical analysis, and demonstrate the potential of PSBML in achieving scalability without sacrificing accuracy.",1
Population MCMC for Dirichlet Diffusion Trees,"Pu Wang, Kathryn B Laskey, Carlotta Domeniconi",2011,Journal The Learning Workshop,"Dirichlet Diffusion Trees (DDT)[3, 4] are an interesting nonparametric Bayesian model, which defines a nonparametric Bayesian prior over binary trees, with an a priori unbounded depth. MCMC is a natural choise to perform inference with DDT. However, MCMC suffers from getting trapped in local optima. This presents a serious problem when performing inference with tree structures, since the resulting solution space is very complex and highly multi-modal. In this scenario, the local nature of the moves of MCMC makes convergence prohibitive. Population MCMC (PopMCMC)[2, 1] has been proposed to try to avoid local optima when using MCMC for inference. PopMCMC runs multiple chains at the same time, and exchanges information between the chains, in order to propose non-local moves for each chain. In this work, we apply PopMCMC to DDT inference to try to overcome the local optima problem. DDT is a generative model, and data generated from DDT are exchangeable [3]. DDT generates data points sequentially, and assumes all data points diffuse from the origin for unit time, say [0, 1], according to brownian motion N (x1; 0, It). For each data point, at time t, it diverges from a branch shared by m previous points with probability a (t) dt/m, where a (t) is the predefined diverging function. The way DDT generates data can be represented as a tree. Figure 1, illustrates how DDT generates four points, where the detailed diffusion paths are suppressed and replaced by straight lines between diverging points and data points. One nice property of DDT is that the joint probability of observing a tree (xb, tb)(xa, ta)(xc, tc) x1 x2 x3 x4",1
Latent topic models of surface syntactic information,"Roberto Basili, Cristina Giannone, Danilo Croce, Carlotta Domeniconi",2011,"Conference AI* IA 2011: Artificial Intelligence Around Man and Beyond: XIIth International Conference of the Italian Association for Artificial Intelligence, Palermo, Italy, September 15-17, 2011. Proceedings 12","Topic Models like Latent Dirichlet Allocation have been widely used for their robustness in estimating text models through mixtures of latent topics. Although LDA has been mostly used as a strictly lexicalized approach, it can be effectively applicable to a much richer set of linguistic structures. A novel application of LDA is here presented that acquires suitable grammatical generalizations for semantic tasks tightly dependent on NL syntax. We show how the resulting topics represent suitable generalizations over syntactic structures and lexical information as well. The evaluation on two different classification tasks, such as predicate recognition and question classification, shows that state of the art results are obtained.",1
Nonparametric Bayesian Methods for Relational Clustering,"Pu Wang, Kathryn B Laskey, Carlotta Domeniconi",2010,Journal Snowbird Learning Workshop,"An important task in data mining is to identify natural clusters in data. Relational clustering [1], also known as co-clustering for dyadic data, uses information about related objects to help identify the cluster to which an object belongs. For example, words can be used to help cluster documents in which the words occur; conversely, documents can be used to help cluster the words occurring in them. Algorithms for coclustering have become popular in data mining (cf.,[2],[3]). Empirical evaluations have shown improvement in both model fit and predictive performance from leveraging relational information in clustering. Bayesian methods for co-clustering (eg,[3],[4]) have advantages such as the ability to represent uncertainty about cluster assignments, theoretical soundness, and natural protection against overfitting [5]. Several studies demonstrate that these advantages can translate into performance improvements ([3],[4]). Figure 1, taken from [6], shows a latent Dirichlet Bayesian co-clustering model for dyadic data. In this model, each entry xrc of the matrix is sampled from a mixture of multinomial distributions, with mixture components indexed by latent row cluster and column cluster indicator variables z1r and z2c. The Dirichlet parameters π1r and π2c represent membership probabilities for row and column clusters. The common distribution for cluster indicators of objects in the same row [column] introduces dependence between entries in the same row [column]. Given observations xrc, the row and column clusters z1r and z2c are correlated: thus, information about row objects influences the cluster assignments for column objects, and vice versa …",1
Categorization of Unlabeled Documents driven by Word Weighting,"Ning Kang, Carlotta Domeniconi, Daniel Barbará",2006,"Description In text mining we often have to handle large document collections. The labeling of such large corpuses of documents is too expensive and impractical. Thus, there is a need to develop (unsupervised) clustering techniques for text data, where the distributions of words can vary significantly from one category to another.The vector space model of documents easily leads to a 30000 or more dimensions. In such high dimensionality, the effectiveness of any distance function that equally uses all input features is severely compromised. Furthermore, it is expected that different words may have different degrees of relevance for a given category of documents, and a single word may have a different importance across different categories.","In text mining we often have to handle large document collections. The labeling of such large corpuses of documents is too expensive and impractical. Thus, there is a need to develop (unsupervised) clustering techniques for text data, where the distributions of words can vary significantly from one category to another.",1
Gene expression analysis of HIV-1 linked p24-specific CD4+ T-cell responses for identifying genetic markers,Sanjeev Raman,2005,Institution George Mason University,"The Human Immunodeficiency Virus (HIV) presents a complex knot for scientists to unravel. After initial contact and attachment to a cell of the immune system (eg lymphocytes, monocytes), there is a cascade of intracellular events. The endproduct of these events is the production of massive numbers of new viral particles, death of the infected cells, and ultimate devastation of the immune system. HIV is an epidemic and a crisis in many continents. Since there are many variations of the virus and differences in people's genetic make-up, rapid diagnosis and monitoring of tailored treatments are essential for future medicine. To combat this problem, microarray technology can perform a single scan on thousands of genes. However, without a proper research design and data mining techniques, the results from such a technology can be very skewed. Thus, using a normalized, clean dataset (time-series) from the CD4+ T …",1
Within-cluster adaptive metric for clustering,"Carlotta Domeniconi, D Gunopulos, Sheng Ma",2004,Journal Proceedings of SIAM International Conference on Data Mining,"The clustering problem concerns the discovery of homogeneous groups of data according to a certain similarity measure. Clustering suffers from the curse of dimensionality. It is not meaningful to look for clusters in high dimensional spaces as the average density of points anywhere in input space is likely to be low. As a consequence, distance functions that equally use all input features may be ineffective. We introduce an algorithm that discovers clusters in subspaces spanned by different combinations of dimensions via local weightings of features. This approach avoids the risk of loss of information encountered in global dimensionality reduction techniques. Our method associates to each cluster a weight vector, whose values give information of the degree of relevance of features for each set in the partition. We formally prove that our algorithm converges, and experimentally demonstrate the gain in perfomance we achieve with our method.",1
Proposal of a Darwin-Neural Network for a Robot Implementation,Carlotta Domeniconi,1997,"Conference Neural Nets WIRN VIETRI-96: Proceedings of the 8th Italian Workshop on Neural Nets, Vietri sul Mare, Salerno, Italy, 23–25 May 1996","The objective of this work is the proposal of a Darwin-neural network that simulates an automaton with an adaptive behavior. We describe the environmental framework within the automaton can move, the areas the automaton is made of the network dynamic, the transfer function that characterizes the state transition of neurons, the learning algorithm and the overall behavior of the network.",1
Meta Multi-Instance Multi-Label learning by heterogeneous network fusion,"Sichao Qiu, Mengyi Wang, Yuanlin Yang, Guoxian Yu, Jun Wang, Zhongmin Yan, Carlotta Domeniconi, Maozu Guo",2023/2/9,Journal Information Fusion,"Multi-Instance Multi-Label Learning (MIML) models complex objects (bags), each of which is composed with a set of instances and associated with a set of labels. Current MIML solutions still focus on a single-type of bags and assume an independent and identically distribution (IID) of training data. But these bags are linked with objects of other types, which also encode the semantics of bags. In addition, they generally need abundant labeled data for training. To effectively mine MIML objects linked with objects of other types, we propose a heterogeneous network embedding and meta learning based approach (MetaMIML). MetaMIML introduces the context learner with network embedding to learn context representations of bags for structure information extraction, the task learner to extract the meta knowledge for fast adapting to new tasks with scarce training objects, and finally fuses the structural and attribute …",
Gradient-Based Local Causal Structure Learning,"Jiaxuan Liang, Jun Wang, Guoxian Yu, Carlotta Domeniconi, Xiangliang Zhang, Maozu Guo",2023/1/31,Journal IEEE Transactions on Cybernetics,"Finding the causal structure from a set of variables given observational data is a crucial task in many scientific areas. Most algorithms focus on discovering the global causal graph but few efforts have been made toward the local causal structure (LCS), which is of wide practical significance and easier to obtain. LCS learning faces the challenges of neighborhood determination and edge orientation. Available LCS algorithms build on conditional independence (CI) tests, they suffer the poor accuracy due to noises, various data generation mechanisms, and small-size samples of real-world applications, where CI tests do not work. In addition, they can only find the Markov equivalence class, leaving some edges undirected. In this article, we propose a GradieNt-based LCS learning approach (GraN-LCS) to determine neighbors and orient edges simultaneously in a gradient-descent way, and, thus, to explore LCS more …",
Few-shot partial multi-label learning via prototype rectification,"Yunfeng Zhao, Guoxian Yu, Lei Liu, Zhongmin Yan, Carlotta Domeniconi, Xiayan Zhang, Lizhen Cui",2023/1/3,Journal Knowledge and Information Systems,"Partial multi-label learning (PML) models the scenario where each training sample is annotated with a candidate label set, among which only a subset corresponds to the ground-truth labels. Existing PML approaches generally promise that there are sufficient partial multi-label samples for training the predictor. Nevertheless, when dealing with new tasks, it is more common that we only have a few PML samples associated with those tasks at hand. Furthermore, existing few-shot learning solutions typically assume the labels of support (training) samples are noise-free; as a result, noisy labels concealed within the candidate labels may seriously misinform the meta-learner and thus lead to a compromised performance. We formalize this problem as new learning paradigm called few-shot partial multi-label learning (FsPML), which aims to induce a noise-robust multi-label classifier with limited PML samples related to …",
Few-shot Partial Multi-label Learning with Synthetic Features Network,"Yifan Sun, Yunfeng Zhao, Guoxian Yu, Zhongmin Yan, Carlotta Domeniconi",2023/1/2,"Description In partial multi-label learning (PML) problems, each training sample is partially annotated with a candidate label set, among which only a subset of labels are valid. The major hardship for PML is that its training procedure is prone to be misled by false positive labels concealed in the candidate label set. To train a noise-robust multi-label predictor for PML problem, most existing methods hold the assumption that sufficient training samples are available. However, in actual fact, especially when dealing with new tasks, we more often only have a few PML samples for the target task. In this paper, we propose a unified model called FsPML-SF (Fewshot Partial Multi-Label Learning with Synthetic Features Network). FsPML-SF includes three modules: label disambiguation, data augmentation and classifier induction. Specifically, FsPML-SF attempts to update the label credibility of each PML sample by leveraging the feature and semantic similarities, the label credibility of other samples and label co-occurrence in a unified objective function. Next, FsPML-SF introduces a synthetic feature network to generate more training samples from pairs of given samples with corresponding label credibility values. FsPML-SF then utilizes the original and synthesized samples to induce a noise-tolerant multi-label classifier. We conducted extensive experiments on benchmark datasets, FsPML-SF outperforms recent competitive PML baselines and few-shot solutions. Both the label denoising and data augmentation improve the performance of PML on fewshot data.","In partial multi-label learning (PML) problems, each training sample is partially annotated with a candidate label set, among which only a subset of labels are valid. The major hardship for PML is that its training procedure is prone to be misled by false positive labels concealed in the candidate label set. To train a noise-robust multi-label predictor for PML problem, most existing methods hold the assumption that sufficient training samples are available. However, in actual fact, especially when dealing with new tasks, we more often only have a few PML samples for the target task. In this paper, we propose a unified model called FsPML-SF (Fewshot Partial Multi-Label Learning with Synthetic Features Network). FsPML-SF includes three modules: label disambiguation, data augmentation and classifier induction. Specifically, FsPML-SF attempts to update the label credibility of each PML sample by leveraging the feature and semantic similarities, the label credibility of other samples and label co-occurrence in a unified objective function. Next, FsPML-SF introduces a synthetic feature network to generate more training samples from pairs of given samples with corresponding label credibility values. FsPML-SF then utilizes the original and synthesized samples to induce a noise-tolerant multi-label classifier. We conducted extensive experiments on benchmark datasets, FsPML-SF outperforms recent competitive PML baselines and few-shot solutions. Both the label denoising and data augmentation improve the performance of PML on fewshot data.",
Self-paced annotations of crowd workers,"Xiangping Kang, Guoxian Yu, Carlotta Domeniconi, Jun Wang, Wei Guo, Yazhou Ren, Xiayan Zhang, Lizhen Cui",2022/12,Journal Knowledge and Information Systems,"Crowdsourcing can harness human intelligence to handle computer-hard tasks in a relatively economic way. The collected answers from various crowd workers are of different qualities, due to the task difficulty, worker capability, incentives and other factors. To maintain high-quality answers while reducing the cost, various strategies have been developed by modeling tasks, workers, or both. Nevertheless, they typically deem that the capability of workers is static when assigning/completing all the tasks. However, in actual fact, crowd workers can improve their capability by gradually completing easy to hard tasks, alike human beings’ intrinsic self-paced learning ability. In this paper, we study crowdsourcing with self-paced workers, whose capability can be progressively improved as they scrutinize and complete tasks from to easy to hard. We introduce a Self-paced Crowd-worker model (SPCrowder). In SPCrowder …",
Few-shot Partial Multi-label Learning with Data Augmentation,"Yifan Sun, Yunfeng Zhao, Guoxian Yu, Zhongmin Yan, Carlotta Domeniconi",2022/11/28,Conference 2022 IEEE International Conference on Data Mining (ICDM),"Partial multi-label learning (PML) models the scenario where each training sample is annotated with a set of candidate labels, but only a subset of them corresponds to the ground-truths. The key challenge for PML is how to minimize the negative impact of incorrect labels concealed within the candidate ones. Most existing PML solutions require abundant samples to train a noise-robust multi-label predictor. However, due to privacy, safety or ethic issues, we more often have a handful of training samples for the target task. In this paper, we propose an approach named FsPML-DA (Few-shot Partial Multi-Label Learning with Data Augmentation) to simultaneously estimate label confidence, perform data augmentation and induce multilabel classifier. Specifically, FsPML-DA disambiguates the label confidence vector of each PML sample by jointly modeling the feature and semantic similarity, label credibility of other …",
Incentive-boosted Federated Crowdsourcing,"Xiangping Kang, Guoxian Yu, Jun Wang, Wei Guo, Carlotta Domeniconi, Jinglin Zhang",2022/11/28,Journal arXiv preprint arXiv:2211.14439,"Crowdsourcing is a favorable computing paradigm for processing computer-hard tasks by harnessing human intelligence. However, generic crowdsourcing systems may lead to privacy-leakage through the sharing of worker data. To tackle this problem, we propose a novel approach, called iFedCrowd (incentive-boosted Federated Crowdsourcing), to manage the privacy and quality of crowdsourcing projects. iFedCrowd allows participants to locally process sensitive data and only upload encrypted training models, and then aggregates the model parameters to build a shared server model to protect data privacy. To motivate workers to build a high-quality global model in an efficacy way, we introduce an incentive mechanism that encourages workers to constantly collect fresh data to train accurate client models and boosts the global model training. We model the incentive-based interaction between the crowdsourcing platform and participating workers as a Stackelberg game, in which each side maximizes its own profit. We derive the Nash Equilibrium of the game to find the optimal solutions for the two sides. Experimental results confirm that iFedCrowd can complete secure crowdsourcing projects with high quality and efficiency.",
Long-tail Cross Modal Hashing,"Zijun Gao, Jun Wang, Guoxian Yu, Zhongmin Yan, Carlotta Domeniconi, Jinglin Zhang",2022/11/28,Journal arXiv preprint arXiv:2211.15162,"Existing Cross Modal Hashing (CMH) methods are mainly designed for balanced data, while imbalanced data with long-tail distribution is more general in real-world. Several long-tail hashing methods have been proposed but they can not adapt for multi-modal data, due to the complex interplay between labels and individuality and commonality information of multi-modal data. Furthermore, CMH methods mostly mine the commonality of multi-modal data to learn hash codes, which may override tail labels encoded by the individuality of respective modalities. In this paper, we propose LtCMH (Long-tail CMH) to handle imbalanced multi-modal data. LtCMH firstly adopts auto-encoders to mine the individuality and commonality of different modalities by minimizing the dependency between the individuality of respective modalities and by enhancing the commonality of these modalities. Then it dynamically combines the individuality and commonality with direct features extracted from respective modalities to create meta features that enrich the representation of tail labels, and binaries meta features to generate hash codes. LtCMH significantly outperforms state-of-the-art baselines on long-tail datasets and holds a better (or comparable) performance on datasets with balanced labels.",
Hub-VAE: Unsupervised Hub-based Regularization of Variational Autoencoders,"Priya Mani, Carlotta Domeniconi",2022/11/18,Journal arXiv preprint arXiv:2211.10469,"Exemplar-based methods rely on informative data points or prototypes to guide the optimization of learning algorithms. Such data facilitate interpretable model design and prediction. Of particular interest is the utility of exemplars in learning unsupervised deep representations. In this paper, we leverage hubs, which emerge as frequent neighbors in high-dimensional spaces, as exemplars to regularize a variational autoencoder and to learn a discriminative embedding for unsupervised down-stream tasks. We propose an unsupervised, data-driven regularization of the latent space with a mixture of hub-based priors and a hub-based contrastive loss. Experimental evaluation shows that our algorithm achieves superior cluster separability in the embedding space, and accurate data reconstruction and generation, compared to baselines and state-of-the-art techniques.",
A Diversified Attention Model for Interpretable Multiple Clusterings,"Liangrui Ren, Guoxian Yu, Jun Wang, Lei Liu, Carlotta Domeniconi, Xiangliang Zhang",2022/11/2,Journal IEEE Transactions on Knowledge and Data Engineering,"Multiple clusterings can explore the same set of data from different perspectives by discovering different and meaningful clusterings. However, most, if not all, of the existing approaches overwhelmingly focus on the diversity between clustering subspaces, and pay much less attention on the salience of the subspaces. As a consequence, the quality of the produced clusterings is an understudied aspect of the problem. Furthermore, existing methods cannot explain the unique internal subspace structure of each clustering, and cannot incorporate multi-facet knowledge to generate different clusterings. In this paper, we propose a solution named  iMClusts  ( i nterpretable  M ultiple  Clust ering s  by diversified attention). iMClusts makes use of the expressive representational power of deep autoencoders and multi-head attention to generate multiple salient embedding matrices, and multiple clusterings therein. In addition …",
Mitigation of Optimized Pharmaceutical Supply Chain Disruptions by Criminal Agents,"Abhisekh Rana, Hamdi Kavak, Andrew Crooks, Sean Luke, Carlotta Domeniconi, Jim Jones",2022/9/18,"Book Social, Cultural, and Behavioral Modeling: 15th International Conference, SBP-BRiMS 2022, Pittsburgh, PA, USA, September 20–23, 2022, Proceedings","Disruption to supply chains can significantly influence the operation of the world economy and this has been shown to permeate and affect a large majority of countries and their citizens. We present initial results from a model that explores the disruptions to supply chains by a criminal agent and possible mitigation strategies. We construct a model of a typical pharmaceutical manufacturing supply chain, which is implemented via discrete event simulation. The criminal agent optimizes its resource allocation to maximize disruption to the supply chain. Our findings show criminal agents can cause cascading damage and exploit vulnerabilities, which inherently exist within the supply chain itself. We also demonstrate how basic mitigation strategies can efficaciously alleviate this potential damage.",
Hypergraph Simultaneous Generators,"Bahman Pedrood, Carlotta Domeniconi, Kathryn Laskey",2022/5/3,Conference International Conference on Artificial Intelligence and Statistics,"Generative models for affiliation networks condition the edges on the membership of their nodes to communities. The problem of community detection under these models is addressed by inferring the membership parameters from the network structure. Current models make several unrealistic assumptions to make the inference feasible, and are mostly designed to work on regular graphs that cannot handle multi-way connections between nodes. While the models designed for hypergraphs attempt to capture the latter, they add further strict assumptions on the structure and size of hyperedges and are usually computationally intractable for real data. This paper proposes an efficient probabilistic generative model for detecting overlapping communities that process hyperedges without any changes or restrictions on their size. Our model represents the entire state space of the hyperedges, which is exponential in the number of nodes. We develop a mathematical computation reduction scheme that reduces the inference time to linear in the volume of the hypergraph without sacrificing precision. Our experimental results validate the effectiveness and scalability of our model and demonstrate the superiority of our approach over state-of-the-art community detection methods.",
Incomplete Multi-view Multi-label Active Learning,"Chuanwei Qu, Kuangmeng Wang, Hong Zhang, Guoxian Yu, Carlotta Domeniconi",2021/12/7,Conference 2021 IEEE International Conference on Data Mining (ICDM),"The label information of training data is crucial for effective machine learning in many domains, while it is expensive to annotate data at a large-scale by domain experts. The problem was intensified by the multiplicity and incompleteness of multiview multi-label (MVML) objects, which is ignored by almost all existing multi-view multi-label active learning approaches. In this paper, we propose an incomplete multi-view multi-label active learning (iMVMAL) approach to reduce the cost of querying MVML data. iMVMAL firstly extends under-complete Autoencoder to learn the shared/individual representations of samples across/within incomplete views by an indicator matrix to indicate the missing samples of respective view. As such, the optimization of the Autoencoder’s parameters will not be impacted by the missing samples. Next, it uses the extracted shared/individual information to train multiple classifiers and to …",
MetaMIML: Meta Multi-Instance Multi-Label Learning,"Yuanlin Yang, Guoxian Yu, Jun Wang, Lei Liu, Carlotta Domeniconi, Maozu Guo",2021/11/7,Journal arXiv preprint arXiv:2111.04112,"Multi-Instance Multi-Label learning (MIML) models complex objects (bags), each of which is associated with a set of interrelated labels and composed with a set of instances. Current MIML solutions still focus on a single-type of objects and assumes an IID distribution of training data. But these objects are linked with objects of other types, %(i.e., pictures in Facebook link with various users), which also encode the semantics of target objects. In addition, they generally need abundant labeled data for training. To effectively mine interdependent MIML objects of different types, we propose a network embedding and meta learning based approach (MetaMIML). MetaMIML introduces the context learner with network embedding to capture semantic information of objects of different types, and the task learner to extract the meta knowledge for fast adapting to new tasks. In this way, MetaMIML can naturally deal with MIML objects at data level improving, but also exploit the power of meta-learning at the model enhancing. Experiments on benchmark datasets demonstrate that MetaMIML achieves a significantly better performance than state-of-the-art algorithms.",
Meta Cross-Modal Hashing on Long-Tailed Data,"Runmin Wang, Guoxian Yu, Carlotta Domeniconi, Xiangliang Zhang",2021/11/7,Journal arXiv preprint arXiv:2111.04086,"Due to the advantage of reducing storage while speeding up query time on big heterogeneous data, cross-modal hashing has been extensively studied for approximate nearest neighbor search of multi-modal data. Most hashing methods assume that training data is class-balanced.However, in practice, real world data often have a long-tailed distribution. In this paper, we introduce a meta-learning based cross-modal hashing method (MetaCMH) to handle long-tailed data. Due to the lack of training samples in the tail classes, MetaCMH first learns direct features from data in different modalities, and then introduces an associative memory module to learn the memory features of samples of the tail classes. It then combines the direct and memory features to obtain meta features for each sample. For samples of the head classes of the long tail distribution, the weight of the direct features is larger, because there are enough training data to learn them well; while for rare classes, the weight of the memory features is larger. Finally, MetaCMH uses a likelihood loss function to preserve the similarity in different modalities and learns hash functions in an end-to-end fashion. Experiments on long-tailed datasets show that MetaCMH performs significantly better than state-of-the-art methods, especially on the tail classes.",
Crowdsourcing with Meta-Workers: A New Way to Save the Budget,"Guangyang Han, Guoxian Yu, Lizhen Cui, Carlotta Domeniconi, Xiangliang Zhang",2021/11/7,Journal arXiv preprint arXiv:2111.04068,"Due to the unreliability of Internet workers, it's difficult to complete a crowdsourcing project satisfactorily, especially when the tasks are multiple and the budget is limited. Recently, meta learning has brought new vitality to few-shot learning, making it possible to obtain a classifier with a fair performance using only a few training samples. Here we introduce the concept of \emph{meta-worker}, a machine annotator trained by meta learning for types of tasks (i.e., image classification) that are well-fit for AI. Unlike regular crowd workers, meta-workers can be reliable, stable, and more importantly, tireless and free. We first cluster unlabeled data and ask crowd workers to repeatedly annotate the instances nearby the cluster centers; we then leverage the annotated data and meta-training datasets to build a cluster of meta-workers using different meta learning algorithms. Subsequently, meta-workers are asked to annotate the remaining crowdsourced tasks. The Jensen-Shannon divergence is used to measure the disagreement among the annotations provided by the meta-workers, which determines whether or not crowd workers should be invited for further annotation of the same task. Finally, we model meta-workers' preferences and compute the consensus annotation by weighted majority voting. Our empirical study confirms that, by combining machine and human intelligence, we can accomplish a crowdsourcing project with a lower budget than state-of-the-art task assignment methods, while achieving a superior or comparable quality.",
Role Detection and Prediction in Dynamic Political Networks,"Aslı Gençtav, Emily J Evans, Weihong Guo, Sibel Tari, Carlotta Domeniconi, Anarina L Murillo, Julia Chuang, Loulwah AlSumait, Priya Mani, Noha Youssry El-Zehiry",2021,Publisher Springer Science and Business Media Deutschland GmbH,"The interaction of users, either online or in real-life, can be modeled via a network (or graph). In such networks, users engage in activities and take on specific roles. Users who manifest similar structural and connectivity patterns assume similar roles. The analysis of a network in terms of the component roles can facilitate the discovery of communities. By compressing big and complex networks, roles can also enable the discovery of important patterns, as well as important differences across networks. While role detection in network data has been recently applied in a variety of domains, limited work has been done on the use of roles for predictive modeling in dynamic networks. In this work, we discuss a methodology to discover roles, and predict future role distributions in dynamic networks. We adapt previously developed feature-based techniques to discover roles associated to nodes. We verify the persistency of …",
Introduction to the special issue of the ECML PKDD 2020 journal track,"Ira Assent, Carlotta Domeniconi, Aristides Gionis, Eyke Hüllermeier",2020/9,Journal Data mining and knowledge discovery,"The papers contained in this special issue have been accepted for the ECML PKDD 2020 journal track, which allows authors to combine a journal publication with a conference presentation of their work. The journal track was launched in 2013 and has accompanied the European Conference on Machine Learning and Knowledge Discovery in Databases (ECML PKDD) since then. It solicits high quality papers combining the timeliness and novelty of conference contributions with the maturity and sophistication of journal publications—survey papers or extensions of previously published conference papers are normally excluded. Authors can submit to the Machine Learning Journal or the Data Mining and Knowledge Discovery Journal. This year, the journal track offered four submission deadlines between September 2019 and May 2020. Accepted papers were presented (virtually) at the ECML PKDD 2020 …",
Multi-View Multiple Clusterings using Deep Matrix Factorization Supplementary File,"Shaowei Wei, Jun Wang, Guoxian Yu, Carlotta Domeniconi, Xiangliang Zhang",2020,"Description Proof. To prove the theorem 1, we now fix Z(v) m and α (v) m, then solve Hm by imposing non-negativity constrains. To show that the final factors of the solution for the update rule of Hm in the following Eq.(2) is correct, we can show that at convergence it satisfies the KKT condition. Additionally, we show that the iteration of the update rule for Hm converges.","Proof. To prove the theorem 1, we now fix Z(v) m and α (v) m, then solve Hm by imposing non-negativity constrains. To show that the final factors of the solution for the update rule of Hm in the following Eq.(2) is correct, we can show that at convergence it satisfies the KKT condition. Additionally, we show that the iteration of the update rule for Hm converges.",
Weakly-paired Cross-Modal Hashing,"Xuanwu Liu, Jun Wang, Guoxian Yu, Carlotta Domeniconi, Xiangliang Zhang",2019/5/29,Journal arXiv preprint arXiv:1905.12203,"Hashing has been widely adopted for large-scale data retrieval in many domains, due to its low storage cost and high retrieval speed. Existing cross-modal hashing methods optimistically assume that the correspondence between training samples across modalities are readily available. This assumption is unrealistic in practical applications. In addition, these methods generally require the same number of samples across different modalities, which restricts their flexibility. We propose a flexible cross-modal hashing approach (Flex-CMH) to learn effective hashing codes from weakly-paired data, whose correspondence across modalities are partially (or even totally) unknown. FlexCMH first introduces a clustering-based matching strategy to explore the local structure of each cluster, and thus to find the potential correspondence between clusters (and samples therein) across modalities. To reduce the impact of an incomplete correspondence, it jointly optimizes in a unified objective function the potential correspondence, the cross-modal hashing functions derived from the correspondence, and a hashing quantitative loss. An alternative optimization technique is also proposed to coordinate the correspondence and hash functions, and to reinforce the reciprocal effects of the two objectives. Experiments on publicly multi-modal datasets show that FlexCMH achieves significantly better results than state-of-the-art methods, and it indeed offers a high degree of flexibility for practical cross-modal hashing tasks.",
Multi-view Multi-instance Multi-label Learning based on Collaborative Matrix Factorization Supplementary file,"Yuying Xing, Guoxian Yu, Carlotta Domeniconi, Jun Wang, Zili Zhang, Maozu Guo",2019,"Description This supplementary file elaborates on how to iteratively optimize G, α and β in the objective function (Eq.(3) of the main text) of M3L. Due to the fact that the objective function is not convex with respect to G1, G2 and G3, it is therefore unrealistic to find the global optimal solutions for them at the same time. Follow the idea of standard nonnegative matrix factorization (Lee and Seung 2001), we optimize G1, G2 and G3 using an alternative optimization technique by iteratively fixing two of them as constants while optimizing the other one. Due to the fact that both tr (Rv 11 (Rv 11) T) and tr (Rv","This supplementary file elaborates on how to iteratively optimize G, α and β in the objective function (Eq.(3) of the main text) of M3L. Due to the fact that the objective function is not convex with respect to G1, G2 and G3, it is therefore unrealistic to find the global optimal solutions for them at the same time. Follow the idea of standard nonnegative matrix factorization (Lee and Seung 2001), we optimize G1, G2 and G3 using an alternative optimization technique by iteratively fixing two of them as constants while optimizing the other one. Due to the fact that both tr (Rv 11 (Rv 11) T) and tr (Rv",
The Projective Clustering Ensemble Problem for Advanced Data Clustering.,"Carlotta Domeniconi, Francesco Gullo, Andrea Tagarelli",2017,Conference SEBD,"After more than five decades, a huge number of models and algorithms have been developed for data clustering. While most attention has been devoted to data types, algorithmic features, and application targets, in the last years there has also been an increasing interest in developing advanced dataclustering tools. In this respect, projective clustering and clustering ensembles represent two of the most important directions: the former is concerned with the discovery of subsets of the input data having different, possibly overlapping subsets of features associated with them, while the latter allows for the induction of a prototype consensus clustering from an available ensemble of clustering solutions.",
Annotating Proteins with Incomplete Label Information,"Guoxian Yu, Huzefa Rangwala, Carlotta Domeniconi",2015/11/19,Journal Pattern Recognition in Computational Molecular Biology: Techniques and Approaches,"This chapter studies protein function prediction using partially annotated proteins. It reviews related work on multi‐label learning algorithms for network‐based protein function prediction and weak‐label learning approaches. The chapter then introduces protein function prediction using dependency maximization (ProDM) and details the experimental setup. It investigates the performance of ProDM on replenishing missing functions and predicting protein functions on three different protein‐protein interaction (PPI) benchmarks. The first data set, Saccharomyces cerevisiae PPIs (ScPPI), is extracted from BioGrid. The second data set, KroganPPI, is obtained from the study of Krogan et al. The third data set, HumanPPI is obtained from the study of Mostafavi and Morris. The experimental results demonstrate the benefit of integrating the guilt by association rule, function correlations, and dependency maximization in …",
Supplementary file of ‘Prediction protein functions via downward random walks on a gene ontology’,"Guoxian Yu, Hailong Zhu, Carlotta Domeniconi, Jiming Liu",2015/8/2,"Description To better understand the pattern of missing functions of a protein, we separately illustrate the BP GO annotations of Human proteins ALG6 and CLDN16 from an old GO annotation (GOA) file to a recent GOA file in Figure S1. In the figure, GO terms in the yellow boxes not circled by blue eclipses are the available GO annotations of the protein by 2010-01-20, and the GO terms in the yellow box circled by blue eclipses are the appended GO annotations of the protein by 2014-06-09. These appended functions are the missing functions of the protein. From the figure, it is easy to find that the missing functions of a partially annotated protein are the descendants of the terms that already associated with the protein.","To better understand the pattern of missing functions of a protein, we separately illustrate the BP GO annotations of Human proteins ALG6 and CLDN16 from an old GO annotation (GOA) file to a recent GOA file in Figure S1. In the figure, GO terms in the yellow boxes not circled by blue eclipses are the available GO annotations of the protein by 2010-01-20, and the GO terms in the yellow box circled by blue eclipses are the appended GO annotations of the protein by 2014-06-09. These appended functions are the missing functions of the protein. From the figure, it is easy to find that the missing functions of a partially annotated protein are the descendants of the terms that already associated with the protein.",
SemRank: Semantic rank learning for multimedia retrieval,"David Etter, Carlotta Domeniconi",2015/2/7,Conference Proceedings of the 2015 IEEE 9th International Conference on Semantic Computing (IEEE ICSC 2015),"Multimedia retrieval suffers from the lack of common feature representation between a text based query and the visual content of a video repository. One approach to bridging this representation gap is known as query-by-concept, where a query and video are mapped into a common semantic feature space. One of the challenges with using semantic concepts for multimedia retrieval, is that the available vocabulary size is generally not sufficient for representing the content of the query and video. In addition, the lack of training data and visual feature representation often leads to low precision models. In this work, we explore the use of a query-by-concept approach for the multimedia Known Item Search (KIS) problem. We propose a semantic rank learning model, called SemRank, to overcome the challenges of the vocabulary size and lack of training data. First, we construct a semantic fusion model to combine the …",
Supplementary file of ‘Matrix factorization based data fusion for predicting lncRNA-disease associations’,"Guangyuan Fu, Jun Wang, Carlotta Domeniconi, Guoxian Yu",2015,Description Name Website Reference Description LncRNADisease http://www. cuilab. cn/lncrnadisease Chen et al.(2012) experimentally supported lncRNA-disease associations Lnc2Cancer http://www. bio-bigdata. net/lnc2cancer Ning et al.(2015) experimentally supported lncRNA-cancer associations GeneRIF ftp://ftp. ncbi. nih. gov/gene/GeneRIF/ Lu et al.(2007) a short (255 characters or fewer) statement about the functions of lncRNAs StarBase v2. 0 http://starbase. sysu. edu. cn/mirLncRNA. php Li et al.(2013a) miRNA-lncRNA interactions LncRNA2Target http://www. lncrna2target. org Jiang et al.(2014) gene-lncRNA interactions HMDD http://www. cuilab. cn/hmdd Li et al.(2013b) human miRNA-disease database miRTarBase http://mirtarbase. mbc. nctu. edu. tw Hsu et al.(2014) experimentally validated microRNA-target gene interactions GO Annotation http://geneontology. org/ Ashburner et al.(2000) Gene Ontology annotations of genes DisGeNET http://www. disgenet. org/ Pinero et al.(2015) a database of gene-disease associations DrugBank https://www. drugbank. ca/ Law et al.(2013) a unique bioinformatics and cheminformatics resource of drug BioGrid https://thebiogrid. org/ Stark et al.(2006) an curated interaction repository of genes/proteins where◦ denotes the Hadamard product. Eq.(5) is a fixed point equation and the solution must satisfy it at convergence. We can let,Name Website Reference Description LncRNADisease http://www. cuilab. cn/lncrnadisease Chen et al.(2012) experimentally supported lncRNA-disease associations Lnc2Cancer http://www. bio-bigdata. net/lnc2cancer Ning et al.(2015) experimentally supported lncRNA-cancer associations GeneRIF ftp://ftp. ncbi. nih. gov/gene/GeneRIF/ Lu et al.(2007) a short (255 characters or fewer) statement about the functions of lncRNAs StarBase v2. 0 http://starbase. sysu. edu. cn/mirLncRNA. php Li et al.(2013a) miRNA-lncRNA interactions LncRNA2Target http://www. lncrna2target. org Jiang et al.(2014) gene-lncRNA interactions HMDD http://www. cuilab. cn/hmdd Li et al.(2013b) human miRNA-disease database miRTarBase http://mirtarbase. mbc. nctu. edu. tw Hsu et al.(2014) experimentally validated microRNA-target gene interactions GO Annotation http://geneontology. org/ Ashburner et al.(2000) Gene Ontology annotations of genes DisGeNET http://www. disgenet. org/ Pinero et al.(2015) a database of gene-disease associations DrugBank https://www. drugbank. ca/ Law et al.(2013) a unique bioinformatics and cheminformatics resource of drug BioGrid https://thebiogrid. org/ Stark et al.(2006) an curated interaction repository of genes/proteins where◦ denotes the Hadamard product. Eq.(5) is a fixed point equation and the solution must satisfy it at convergence. We can let,
Supplementary file of ‘Integrating multiple networks for protein function prediction’,"Guoxian Yu, Hailong Zhu, Carlotta Domeniconi, Maozu Guo",2014/11/21,"Description Some algorithms depend on the tuning of parameters. We reported the parameter tuning ranges of these algorithms in Table 1. For MNet, we found λ in the specified range can get rather stable performance. Given that, we set λ= 1 for the experiments on all the datasets. ProMK [1] requires to tune λ1 and λ2, given the weight αm mainly depends on λ2, we simply set λ1= 1 and optimize λ2 in the specified range. OMG [2] needs to specify λ1 and r, similar to ProMK, we set λ1= 1 and tuned r in the range specified in the third row of Table 1. LIG [3] needs to specify several parameters, we used the default parameter settings provided by the authors and tuned C (the number of subgraphs for each input graph) in the specified range. We observed that LIG (C= 5) often produced the best performance, and it sometimes got similar results with LIG (C= 1). We set C= 5 for LIG for the experiments on all the datasets.","Some algorithms depend on the tuning of parameters. We reported the parameter tuning ranges of these algorithms in Table 1. For MNet, we found λ in the specified range can get rather stable performance. Given that, we set λ= 1 for the experiments on all the datasets. ProMK [1] requires to tune λ1 and λ2, given the weight αm mainly depends on λ2, we simply set λ1= 1 and optimize λ2 in the specified range. OMG [2] needs to specify λ1 and r, similar to ProMK, we set λ1= 1 and tuned r in the range specified in the third row of Table 1. LIG [3] needs to specify several parameters, we used the default parameter settings provided by the authors and tuned C (the number of subgraphs for each input graph) in the specified range. We observed that LIG (C= 5) often produced the best performance, and it sometimes got similar results with LIG (C= 1). We set C= 5 for LIG for the experiments on all the datasets.",
2014 Index IEEE/ACM Transactions on Computational Biology and Bioinformatics Vol. 11,"R Acharya, AA Adl, M Agostini, HA Ahmed, A Airola, K Al Nasr, O Al-Azzam, C Albanese, M Amit, C Amornbunchornvej, M Andreatta, M Antonello, RJ Arceci, A Assawamakin, M Avantaggiati, R Azencott, R Backofen, M Baginski, V Baladandayuthapani, P Baldi, S Bandyopadhyay, C Bedin, N Beerenwinkel, J Bentahar, N Berlow, B Bhanu, C Bhattacharya, DK Bhattacharyya, M Bitar, A Bockmayr, S Bonilla, A Bouamrani, C Boucher, F Burkowski, L Cai, Z Cai, RJ Campello, Z Cao, D Chambers, D Chan, R Chan, A Charuvaka, H Chen, L Chen, P Chen, Y Chen, JW Choi, T Chow, C Chuang, R Clarke, M Comin, M Considine, KR Coombes, B Cule, AF da Conceicao, A Daemen, L David, R Davidson, LE Davis, B De Baets, MG de la Banda, B De Moor, A Dehzangi, S Deng, AM Denton, D Devaraj, F Disanto, C Domeniconi",2014/11,Journal IEEE TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS,"This index covers all technical items-papers, correspondence, reviews, etc.-that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the co-authors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under the primary entry in the Author Index.",
Semantic analysis of documents workshop (SemADoc) extended abstract,"Evangelos Milios, Carlotta Domeniconi",2014/9/16,Book Proceedings of the 2014 ACM symposium on Document engineering,"A large number of document management problems would benefit from having the semantics of documents explicitly represented. However, manually assigning semantic descriptions to documents is labour intensive and error prone. At the same time, the manual generation of domain specific taxonomies is not only labour intensive, but it also needs to be repeated often as the domains themselves and their key concepts shift with time.",
Erratum to “Protein Function Prediction Using Multilabel Ensemble Classification”,"Guoxian Yu, Huzefa Rangwala, Carlotta Domeniconi, Guoji Zhang, Zhiwen Yu",2014/5/13,Journal IEEE/ACM Transactions on Computational Biology and Bioinformatics,"The authors of ""Protein Function Prediction Using Multilabel Ensemble Classification"" [ibid., vol. 10, no. 4, pp. 1045-1057, July/Aug. 2013] point out a typo that occurred in the Acknowledgments section. The acknowledgment should instead read: ""The authors would like to thank the anonymous reviewers and editors for their valuable comments. This paper was partially supported by grants from the US National Science Foundation (NSF) (no. IIS-0905117), the NSF Career Award (no. IIS-1252318), Natural Science Foundation of China (project nos. 61070090, 61003174, 61101234, 61372138), the Natural Science Foundation of Guangdong Province (S2012010009961), Specialized Research Fund for the Doctoral Program of Higher Education (20110172120027), Fundamental Research Funds for the Central Universities of China (project nos. XDJK2010B002, XDJK2013C026, XDJK2013C123, XDJK2014C044 …",
Subspace Clustering Ensembles.,Carlotta Domeniconi,2012/4/28,Conference MultiClust@ SDM,"Objects maintain their association with the ensemble clusters (and their subspaces), and are finally assigned to meta-clusters (ie, sets of the original clusters in the ensemble) 2 The other approaches will not work: Instance-based: object-and feature-to-cluster assignments would be performed independently Hybrid: same issue as instance-based SCE",
Learning Kernels for Semi-Supervised Clustering,Bojun Yan,2009,"Book Encyclopedia of Data Warehousing and Mining, Second Edition","As a recent emerging technique, semi-supervised clustering has attracted significant research interest. Compared to traditional clustering algorithms, which only use unlabeled data, semi-supervised clustering employs both unlabeled and supervised data to obtain a partitioning that conforms more closely to the user’s preferences. Several recent papers have discussed this problem (Cohn, Caruana, & McCallum, 2003; Bar-Hillel, Hertz, Shental, & Weinshall, 2003; Xing, Ng, Jordan, & Russell, 2003; Basu, Bilenko, & Mooney, 2004; Kulis, Dhillon, & Mooney, 2005). In semi-supervised clustering, limited supervision is provided as input. The supervision can have the form of labeled data or pairwise constraints. In many applications it is natural to assume that pairwise constraints are available (Bar-Hillel, Hertz, Shental, & Weinshall, 2003; Wagstaff, Cardie, Rogers, & Schroedl, 2001). For example, in protein interaction …",
Learning Distance Measures.,Carlotta Domeniconi,2009,Book Encyclopedia of Database Systems,,
Techniques for Weighted Clustering Ensembles,Carlotta Domeniconi,2009,"Book Encyclopedia of Data Warehousing and Mining, Second Edition","In an effort to achieve improved classifier accuracy, extensive research has been conducted in classifier ensembles. Very recently, cluster ensembles have emerged. It is well known that off-the-shelf clustering methods may discover different structures in a given set of data. This is because each clustering algorithm has its own bias resulting from the optimization of different criteria. Furthermore, there is no ground truth against which the clustering result can be validated. Thus, no cross-validation technique can be carried out to tune input parameters involved in the clustering process. As a consequence, the user is not equipped with any guidelines for choosing the proper clustering method for a given dataset. Cluster ensembles offer a solution to challenges inherent to clustering arising from its ill-posed nature. Cluster ensembles can provide more robust and stable solutions by leveraging the consensus across …",
2004 KAIS Reviewers,Springer London Ltd,2004/11,Journal Knowledge and Information Systems,"Knowledge and Information Systems wishes to acknowledge and thank the individuals listed below, who have provided their time and valuable experience to review manuscripts during the past year. It is only through the dedicated efforts of these individuals and those on the Editorial Board listed on the inner front cover, who have also provided valuable input and support, that the quality of publication in the Journal can be maintained.",
Mining Relevant Text from Unlabelled Documents,"Carlotta Domeniconi, Ning Kang",2003/11/19,Conference null,"Automatic classification of documents is an important area of research with many applications in the fields of document searching, forensics and others. Methods to perform classification of text rely on the existence of a sample of documents whose class labels are known. However, in many situations, obtaining this sample may not be an easy (or even possible) task. In this paper we focus on the classification of unlabelled documents into two classes: relevant and irrelevant, given a topic of interest. By dividing the set of documents into buckets (for instance, answers returned by different search engines), and using association rule mining to find common sets of words among the buckets, we can efficiently obtain a sample of documents that has a large percentage of relevant ones. This sample can be used to train models to classify the entire set of documents. We prove, via experimentation, that our method is capable …",
Kernel Pooled Local Subspaces for Classification,"Peng Zhang, Jing Peng, Carlotta Domeniconi",2003/6/16,Conference 2003 Conference on Computer Vision and Pattern Recognition Workshop,"We study the use of kernel subspace methods for learning low-dimensional representations for classification. We propose a kernel pooled local discriminant subspace method and compare it against several competing techniques: Principal Component Analysis (PCA), Kernel PCA (KPCA), and linear local pooling in classification problems. We evaluate the classification performance of the nearest-neighbor rule with each subspace representation. The experimental results demonstrate the effectiveness and performance superiority of the kernel pooled subspace method over competing methods such as PCA and KPCA in some classification problems.",
Area Chairs,"Ankit Agrawal, Leman Akoglu, Elena Baralis, Christian Boehm, Francesco Bonchi, Chris Clifton, Diane Cook, Carlotta Domeniconi, Panagiotis Karras, Eamonn Keogh, Danai Koutra, Xiaoli Li, Jessica Lin, Xuemin Lin, Huan Liu, Shirui Pan, Evangelos Papalexakis, Jian Pei, Naren Ramakrishnan, Chandan Reddy, Thomas Seidl, Kyuseok Shim, Myra Spiliopoulou, Karthik Subbian, Jie Tang, Hanghang Tong, Vincent S Tseng, Jilles Vreeken, Fei Wang, Jianyong Wang, Jia Wu, Hui Xiong, Shuicheng Yan, Aidong Zhang, Chengqi Zhang, Min-Ling Zhang, Weinan Zhang, Zhongfei Zhang, Xiaofang Zhou, Fuzhen Zhuang","Area Chairs and Program Committee Toggle navigation IEEE Computer Society Digital Library 
Jobs Tech News Resource Center Press Room Advertising About Us IEEE IEEE Computer 
Society IEEE Computer Society Digital Library My Subscriptions Magazines Journals Conference 
Proceedings Institutional Subscriptions IEEE IEEE Computer Society More Jobs Tech News 
Resource Center Press Room Advertising About Us Cart All Advanced Search Conference 
Cover Image Download 1.Home 2.Proceedings 3.icdm 2022 Area Chairs and Program 
Committee 2022, pp. 32-41, DOI Bookmark: 10.1109/ICDM54844.2022.00008 Keywords 
Authors Area Chairs Ankit Agrawal, Northwestern University, USA Leman Akoglu, Carnegie 
Mellon University, USA Elena Baralis, Politecnico di Torino, Italy Christian Boehm, University 
of Munich, Germany Francesco Bonchi, ISI Foundation, Italy Chris Clifton, Purdue University, …","Scholar articles Area ChairsA Agrawal, L Akoglu, E Baralis, C Boehm, F Bonchi…All 2 versions ",,
Detecting Suspicious Behavior in Surveillance Images,"Carlotta Domeniconi, Zoran Duric, Maurizio Filippone, Wallace E Lawson","We introduce a novel technique to detect anomalies in images. The notion of normalcy is given by a baseline of images, under the assumption that the majority of such images is normal. The key of our approach is a featureless probabilistic representation of images, based on the length of the codeword necessary to represent each image. Such codeword’s lengths are then used for anomaly detection based on statistical testing. Our techniques were tested on synthetic and real data sets. The results show that our approach can achieve high true positive and low false positive rates.","Scholar articles Detecting Suspicious Behavior in Surveillance ImagesC Domeniconi, Z Duric, M Filippone, WE LawsonRelated articles All 2 versions ","We introduce a novel technique to detect anomalies in images. The notion of normalcy is given by a baseline of images, under the assumption that the majority of such images is normal. The key of our approach is a featureless probabilistic representation of images, based on the length of the codeword necessary to represent each image. Such codeword’s lengths are then used for anomaly detection based on statistical testing. Our techniques were tested on synthetic and real data sets. The results show that our approach can achieve high true positive and low false positive rates.",
DSAA 2019,"Luca Aiello, David Anastasiu, Longbing Cao, Fabio Casati, Sanjay Chawla, Giuseppe Di Fatta, Carlotta Domeniconi, Francesco Gullo, Mohammad Hasan, Danai Koutra, Olfa Nasraoui, Xia Ning, Evangelos Papalexakis, Huzefa Rangwala, Chandan K Reddy, Paolo Rosso, Rossano Schifanella, Panayiotis Tsaparas, Jilles Vreeken, Ke Wang, Wei Wang, Ingmar Weber, Natalia Adler, Nesreen Ahmed, Hugo Alatrista-Salas, Aris Anagnostopoulos, Cigdem Aslay, Renato Assuncao, Abraham Bagherjeiran, Senjuti Basu Roy, Roberto Bayardo, Eric Bloedorn, Petko Bogdanov, Ludovico Boratto, Marco Brambilla, Janez Brank, Kailash Budhathoki, Mete Celik, Aniket Chakrabarti, Lin Chen, Rui Chen","List of Names - Program Committee Page 1 Program Committee DSAA 2019 Senior PC 
Member Luca Aiello, Nokia-Bell Labs David Anastasiu, San Jose State University Longbing 
Cao, Faculty of IT, University of Technology Sydney Fabio Casati, University of Trento Sanjay 
Chawla, Qatar Computing Research Institute Giuseppe Di Fatta, University of Reading Carlotta 
Domeniconi, George Mason University Francesco Gullo, Unicredit R&D Lab Mohammad Hasan, 
Indiana University Purdue University, Indianapolis Danai Koutra, University of Michigan Olfa 
Nasraoui, University of Louisville Xia Ning, The Ohio State University Evangelos Papalexakis, 
University of California Riverside Huzefa Rangwala, George Mason University Chandan K. 
Reddy, Virginia Tech Paolo Rosso, Universitat Politècnica de València Rossano Schifanella, 
University of Turin Andrea Tagarelli, DIMES, University of Calabria Panayiotis Tsaparas…","Scholar articles DSAA 2019L Aiello, D Anastasiu, L Cao, F Casati, S Chawla…",,
TransAI 2019,"Martin Atzmueller, Elena Baralis, Rohan Baxter, Roberto Bayardo, Mohsin Bilal, Christos Bouras, Alessandro Caforio, Beth Carls, Keith Chan, Kent Charugundla, Nitesh Chawla, Theodora Chaspari, Arbee Chen, Ming-Syan Chen, Ping Chen, Xueqi Cheng, Fu-Lai Chung, David Conover, Alfredo Cuzzocrea, Eresto Damiani, Nemanja Djuric, Carlotta Domeniconi, Dejing Dou, Christoph Eick, Vladimir Estivill-Castro, Hassan Ghasemzadeh, Ginger Gossman, Sergio Ilarri, Omer Inan, Tanya Joosten, Jaap Kamps, Charalampos Karagiannidis, Kamalakar Karlapalem, Gabor Kiss, Lam Kwok, Adamantios Koumpis, Anne Laurent, Michael Lawrence, Grigorios Loukides, Euripides Loukis, George Magoulas, Bradley Malin, Brandeis Marshall, Antoanela Naaji","Program Committee Toggle navigation IEEE Computer Society Digital Library Jobs Tech News 
Resource Center Press Room Advertising About Us IEEE IEEE Computer Society IEEE 
Computer Society Digital Library My Subscriptions Magazines Journals Conference 
Proceedings Institutional Subscriptions IEEE IEEE Computer Society More Jobs Tech News 
Resource Center Press Room Advertising About Us Cart All Advanced Search Conference 
Cover Image Download 1.Home 2.Proceedings 3.transai 2019 Program Committee 2019, pp. 
11-12, DOI Bookmark: 10.1109/TransAI46475.2019.00008 Keywords Authors Abstract Provides 
a listing of current committee members and society officers. Program Committee TransAI 2019 
Martin Atzmueller, Tilburg University, The Netherlands Elena Baralis, Politecnico di Torino, Italy 
Rohan Baxter, Australian Taxation Office, Australia Roberto Bayardo, Google, USA Mohsin …","Scholar articles TransAI 2019M Atzmueller, E Baralis, R Baxter, R Bayardo, M Bilal…All 2 versions ",,
Matrix Factorization for Identifying Noisy Labels of Multi-label Instances,"Carlotta Domeniconi, Jun Wang, Zili Zhang","Current effort on multi-label learning generally assumes that the given labels are noise-free. However, obtaining noise-free labels is quite difficult and often impractical. In this paper, we study how to identify a subset of relevant labels from a set of candidate ones given as annotations to instances, and introduce a matrix factorization based method called MF-INL. It first decomposes the original instance-label association matrix into two low-rank matrices using nonnegative matrix factorization with feature-based and label-based constraints to retain the geometric structure of instances and label correlations. MF-INL then reconstructs the association matrix using the product of the decomposed matrices, and identifies associations with the lowest confidence as noisy associations. An empirical study on real-world multi-label datasets with injected noisy labels shows that MF-INL can identify noisy labels more accurately than other related solutions and is robust to input parameters. We empirically demonstrate that both feature-based and label-based constraints contribute to boosting the performance of MF-INL.","Scholar articles Matrix Factorization for Identifying Noisy Labels of Multi-label InstancesC Domeniconi, J Wang, Z ZhangRelated articles ","Current effort on multi-label learning generally assumes that the given labels are noise-free. However, obtaining noise-free labels is quite difficult and often impractical. In this paper, we study how to identify a subset of relevant labels from a set of candidate ones given as annotations to instances, and introduce a matrix factorization based method called MF-INL. It first decomposes the original instance-label association matrix into two low-rank matrices using nonnegative matrix factorization with feature-based and label-based constraints to retain the geometric structure of instances and label correlations. MF-INL then reconstructs the association matrix using the product of the decomposed matrices, and identifies associations with the lowest confidence as noisy associations. An empirical study on real-world multi-label datasets with injected noisy labels shows that MF-INL can identify noisy labels more accurately than other related solutions and is robust to input parameters. We empirically demonstrate that both feature-based and label-based constraints contribute to boosting the performance of MF-INL.",
Finding Communities and Bridges in Multi-labeled Weighted Networks,"Tanwistha Saha, Carlotta Domeniconi, Huzefa Rangwala","Multi-label learning in relational data (aka network data) has gained popularity due to the increasingly complex structures of real world applications. Relational data often contain multi-labeled instances, and can not render much information when addressed with traditional machine learning algorithms. Our research is focused on studying relational data which captures information that is otherwise hidden in the network. Recent research on graphbased learning methods applied to real world relational datasets (eg, protein-protein interaction networks and social networks) has shown promising results. Traditional graph-based clustering methods group vertices into non-intersecting clusters under the assumption that each vertex can belong to only a single cluster. On the other hand, recent research on real world networks, shows overlapping patterns among the underlying clusters. As such, overlapping clusters enable better models of real-life phenomena. We propose a fuzzy clustering based approach for community detection in a weighted graphical representation of networks, for which the ground truth associated to the nodes is available. We compare our results with a baseline method for both multi-labeled and singlelabeled datasets.","Scholar articles Finding Communities and Bridges in Multi-labeled Weighted NetworksT Saha, C Domeniconi, H RangwalaRelated articles All 2 versions ","Multi-label learning in relational data (aka network data) has gained popularity due to the increasingly complex structures of real world applications. Relational data often contain multi-labeled instances, and can not render much information when addressed with traditional machine learning algorithms. Our research is focused on studying relational data which captures information that is otherwise hidden in the network. Recent research on graphbased learning methods applied to real world relational datasets (eg, protein-protein interaction networks and social networks) has shown promising results. Traditional graph-based clustering methods group vertices into non-intersecting clusters under the assumption that each vertex can belong to only a single cluster. On the other hand, recent research on real world networks, shows overlapping patterns among the underlying clusters. As such, overlapping clusters enable better models of real-life phenomena. We propose a fuzzy clustering based approach for community detection in a weighted graphical representation of networks, for which the ground truth associated to the nodes is available. We compare our results with a baseline method for both multi-labeled and singlelabeled datasets.",
Detection of Communities and Bridges in Weighted Networks,Carlotta Domeniconi,"Traditional graph-based clustering methods group vertices into discrete non-intersecting clusters under the assumption that each vertex can belong to only a single cluster. On the other hand, recent research on graphbased clustering methods, applied to real world networks (eg, protein-protein interaction networks and social networks), shows overlapping patterns among the underlying clusters. For example, in social networks, an individual is expected to belong to multiple clusters (or communities), rather than strictly confining himself/herself to just one. As such, overlapping clusters enable better models of real-life phenomena. Soft clustering (eg, fuzzy c-means) has been used with success for non-graph data, when the objects are allowed to belong to multiple clusters with a certain degree of membership. In this paper, we propose a fuzzy clustering based approach for community detection in a weighted graphical representation of social and biological networks, for which the ground truth associated to the nodes is available. We compare our results with a baseline method for both multi-labeled and single labeled datasets.",Scholar articles Detection of Communities and Bridges in Weighted NetworksC DomeniconiRelated articles ,"Traditional graph-based clustering methods group vertices into discrete non-intersecting clusters under the assumption that each vertex can belong to only a single cluster. On the other hand, recent research on graphbased clustering methods, applied to real world networks (eg, protein-protein interaction networks and social networks), shows overlapping patterns among the underlying clusters. For example, in social networks, an individual is expected to belong to multiple clusters (or communities), rather than strictly confining himself/herself to just one. As such, overlapping clusters enable better models of real-life phenomena. Soft clustering (eg, fuzzy c-means) has been used with success for non-graph data, when the objects are allowed to belong to multiple clusters with a certain degree of membership. In this paper, we propose a fuzzy clustering based approach for community detection in a weighted graphical representation of social and biological networks, for which the ground truth associated to the nodes is available. We compare our results with a baseline method for both multi-labeled and single labeled datasets.",
Protein Function Prediction withIncomplete Annotations,"Guoxian Yu, Huzefa Rangwala, Carlotta Domeniconi, Guoji Zhang, Zhiwen Yu","Automated protein function prediction is one of the grand challenges in computational biology. Multi-label learning is widely used to predict functions of proteins. Most of multi-label learning methods make prediction for unlabeled proteins under the assumption that the labeled proteins are completely annotated, ie, without any missing functions. However, in practice, we may have a subset of the ground-truth functions for a protein, and whether the protein has other functions is unknown. To predict protein functions with incomplete annotations, we propose a Protein Function Prediction method with Weak-label Learning (ProWL) and its variant ProWL-IF. Both ProWL and ProWL-IF can replenish the missing functions of proteins. In addition, ProWL-IF makes use of the knowledge that a protein cannot have certain functions, which can further boost the performance of protein function prediction. Our experimental results …","Scholar articles Protein Function Prediction withIncomplete AnnotationsG Yu, H Rangwala, C Domeniconi, G Zhang, Z YuRelated articles ","Automated protein function prediction is one of the grand challenges in computational biology. Multi-label learning is widely used to predict functions of proteins. Most of multi-label learning methods make prediction for unlabeled proteins under the assumption that the labeled proteins are completely annotated, ie, without any missing functions. However, in practice, we may have a subset of the ground-truth functions for a protein, and whether the protein has other functions is unknown. To predict protein functions with incomplete annotations, we propose a Protein Function Prediction method with Weak-label Learning (ProWL) and its variant ProWL-IF. Both ProWL and ProWL-IF can replenish the missing functions of proteins. In addition, ProWL-IF makes use of the knowledge that a protein cannot have certain functions, which can further boost the performance of protein function prediction. Our experimental results …",
Detecting outliers using transduction and statistical significance testing,"Daniel Barbará, Carlotta Domeniconi, James P Rogers, James P Rogers II","Finding points that are outliers with respect to a set of other points is an important task in data mining. Outlier detection can uncover important anomalies in fields like intrusion detection and fraud analysis. In data streaming, the presence of a large number of outliers indicates that the underlying process that is generating the data is undergoing significant changes and the models that attempt to characterize it need to be updated. Although there has been a significant amount of work in outlier detection, most of the algorithms in the literature resort to a particular definition of what an outlier is (eg, density-based), and use thresholds to detect them. In this paper we present a novel technique to detect outliers that does not impose any particular definition for them. The test we propose aims to diagnose whether a given point is an outlier with respect to an existing clustering model (ie, a set of points partitioned in groups). However, the test can also be successfully utilize to recognize outliers when the clustering information is not available. This test is based on Transductive Confidence Machines, which have been previously proposed as a mechanism to provide individual confidence measures on classification decisions. The test uses hypothesis testing to prove or disprove whether a point is fit to be in each of the clusters of the model. We demonstrate, experimentally, that the test is highly robust, and produces very few misdiagnosed points, even when no clustering information is available. We also show that the test can be succesfully applied to identify outliers present inside a data set for which no other information is available, thereby provinding the user …","Scholar articles Detecting outliers using transduction and statistical significance testingD Barbará, C Domeniconi, JP Rogers, JP Rogers IIRelated articles ","Finding points that are outliers with respect to a set of other points is an important task in data mining. Outlier detection can uncover important anomalies in fields like intrusion detection and fraud analysis. In data streaming, the presence of a large number of outliers indicates that the underlying process that is generating the data is undergoing significant changes and the models that attempt to characterize it need to be updated. Although there has been a significant amount of work in outlier detection, most of the algorithms in the literature resort to a particular definition of what an outlier is (eg, density-based), and use thresholds to detect them. In this paper we present a novel technique to detect outliers that does not impose any particular definition for them. The test we propose aims to diagnose whether a given point is an outlier with respect to an existing clustering model (ie, a set of points partitioned in groups). However, the test can also be successfully utilize to recognize outliers when the clustering information is not available. This test is based on Transductive Confidence Machines, which have been previously proposed as a mechanism to provide individual confidence measures on classification decisions. The test uses hypothesis testing to prove or disprove whether a point is fit to be in each of the clusters of the model. We demonstrate, experimentally, that the test is highly robust, and produces very few misdiagnosed points, even when no clustering information is available. We also show that the test can be succesfully applied to identify outliers present inside a data set for which no other information is available, thereby provinding the user …",
"Multi-Label Co-Training Yuying Xing1, Guoxian Yu1, Carlotta Domeniconi2, Jun Wang1 and Zili Zhang1, 3 1College of Computer and Information Science, Southwest University …","Yuying Xing, Guoxian Yu, Carlotta Domeniconi, Jun Wang, Zili Zhang","Multi-label learning aims at assigning a set of appropriate labels to multi-label samples. Although it has been successfully applied in various domains in recent years, most multi-label learning methods require sufficient labeled training samples, because of the large number of possible label sets. Co-training, as an important branch of semi-supervised learning, can leverage unlabeled samples, along with scarce labeled ones, and can potentially help with the large labeled data requirement. However, it is a difficult challenge to combine multi-label learning with co-training. Two distinct issues are associated with the challenge:(i) how to solve the widely-witnessed class-imbalance problem in multilabel learning; and (ii) how to select samples with confidence, and communicate their predicted labels among classifiers for model refinement. To address these issues, we introduce an approach called Multi-Label Co-Training (MLCT). MLCT leverages information concerning the co-occurrence of pairwise labels to address the class-imbalance challenge; it introduces a predictive reliability measure to select samples, and applies label-wise filtering to confidently communicate labels of selected samples among co-training classifiers. MLCT performs favorably against related competitive multi-label learning methods on benchmark datasets and it is also robust to the input parameters.","Scholar articles Multi-Label Co-Training Yuying Xing1, Guoxian Yu1, Carlotta Domeniconi2, Jun Wang1 and Zili Zhang1, 3 1College of Computer and Information Science, Southwest University, Chongqing 400715, China 2Department of Computer Science, George Mason University, Fairfax 22030, USA 3School of Information Technology, Deakin University, Geelong, VIC 3220, AustraliaY Xing, G Yu, C Domeniconi, J Wang, Z ZhangRelated articles All 3 versions ","Multi-label learning aims at assigning a set of appropriate labels to multi-label samples. Although it has been successfully applied in various domains in recent years, most multi-label learning methods require sufficient labeled training samples, because of the large number of possible label sets. Co-training, as an important branch of semi-supervised learning, can leverage unlabeled samples, along with scarce labeled ones, and can potentially help with the large labeled data requirement. However, it is a difficult challenge to combine multi-label learning with co-training. Two distinct issues are associated with the challenge:(i) how to solve the widely-witnessed class-imbalance problem in multilabel learning; and (ii) how to select samples with confidence, and communicate their predicted labels among classifiers for model refinement. To address these issues, we introduce an approach called Multi-Label Co-Training (MLCT). MLCT leverages information concerning the co-occurrence of pairwise labels to address the class-imbalance challenge; it introduces a predictive reliability measure to select samples, and applies label-wise filtering to confidently communicate labels of selected samples among co-training classifiers. MLCT performs favorably against related competitive multi-label learning methods on benchmark datasets and it is also robust to the input parameters.",
ICDMW 2016,"Carlotta Domeniconi, Francesco Gullo, Francesco Bonchi, Josep Domingo-Ferrer, Ricardo Baeza-Yates, Zhi-Hua Zhou, Xindong Wu",The following topics are dealt with: data mining; data integration; and Big Data analytics.,"Scholar articles ICDMW 2016C Domeniconi, F Gullo, F Bonchi, J Domingo-Ferrer…",The following topics are dealt with: data mining; data integration; and Big Data analytics.,
16th IEEE International Conference on Data Mining Workshops,"Carlotta Domeniconi, Francesco Gullo, Francesco Bonchi, Josep Domingo-Ferrer, Ricardo Baeza-Yates, Zhi-Hua Zhou, Xindong Wu","[Title page iii] | IEEE Conference Publication | IEEE Xplore Skip to Main Content [Title page iii] 
Abstract: Presents the title page of the proceedings record. Published in: 2016 IEEE 16th 
International Conference on Data Mining Workshops (ICDMW) Article #: Date of Conference: 
12-15 December 2016 Date Added to IEEE Xplore: 02 February 2017 ISBN Information: 
Electronic ISBN: 978-1-5090-5910-2 Print on Demand(PoD) ISBN: 978-1-5090-5911-9 ISSN 
Information: Electronic ISSN: 2375-9259 INSPEC Accession Number: Persistent Link: 
https://xplorestaging.ieee.org/servlet/opac?punumber=7836069 More » Publisher: IEEE IEEE 
Account Change Username/Password Update Address Purchase Details Payment Options Order 
History View Purchased Documents Profile Information Communications Preferences Profession 
and Education Technical Interests Need Help? US & Canada: +1 800 678 4333 Worldwide: +…","Scholar articles 16th IEEE International Conference on Data Mining WorkshopsC Domeniconi, F Gullo, F Bonchi, J Domingo-Ferrer…",,
Supplementary file of ‘Predicting protein functions using incomplete hierarchical labels’,"Guoxian Yu, Hailong Zhu, Carlotta Domeniconi","Figure S1 Illustration of incomplete hierarchical labels for proteins labeled with Gene Ontology terms. A rectangle represents a protein (pi, i∈{1, 2, 3}); an ellipse denotes a function label, and a undirected line between rectangles captures a protein-protein interaction (the more reliable the interaction is, the thicker the line is). All the functional labels (including the missing function labels denoted by colored ellipses labeled with question marks ‘?’) in the ellipses should be associated with the proteins, but only the functional labels in the white ellipses are known. For better visualization, other functional labels (ie,‘GO: 0001906’and ‘GO: 0009987’, which are not ground-truth labels for these proteins), are not plotted in the Figure.In the main paper, we illustrated the scenario of incomplete hierarchical labels of proteins under MIPS FunCat labels. The corresponding scenario under GO labels is shown in Fig. S1. The missing labels are leaf function labels. If a non-leaf function label of a protein is missing, we can directly append this function","Scholar articles Supplementary file of ‘Predicting protein functions using incomplete hierarchical labels’G Yu, H Zhu, C DomeniconiRelated articles ","Figure S1 Illustration of incomplete hierarchical labels for proteins labeled with Gene Ontology terms. A rectangle represents a protein (pi, i∈{1, 2, 3}); an ellipse denotes a function label, and a undirected line between rectangles captures a protein-protein interaction (the more reliable the interaction is, the thicker the line is). All the functional labels (including the missing function labels denoted by colored ellipses labeled with question marks ‘?’) in the ellipses should be associated with the proteins, but only the functional labels in the white ellipses are known. For better visualization, other functional labels (ie,‘GO: 0001906’and ‘GO: 0009987’, which are not ground-truth labels for these proteins), are not plotted in the Figure.",
Issues and Techniques in Pattern Classification,Carlotta Domeniconi,"Issues and Techniques in Pattern Classification Page 1 1 Issues and Techniques in Pattern 
Classification Carlotta Domeniconi www.ise.gmu.edu/~carlotta Machine Learning Given a 
collection of data, a machine learner explains the underlying process that generated the data 
in a general and simple fashion. Different learning paradigms: supervised learning 
unsupervised learning semi-supervised learning reinforcement learning Page 2 2 Supervised 
Learning • Sample data comprises input vectors along with the corresponding target values 
(labeled data) • Supervised learning uses the given labeled data to find a model (hypothesis) 
that predicts the target values for previously unseen data Supervised Learning: Classification • 
Each element in the sample is labeled as belonging to some class (eg, apple or orange). • The 
learner builds a model to predict classes for all input data. • There is no order among classes. …",Scholar articles Issues and Techniques in Pattern ClassificationC Domeniconi,,
of the research: Gene Expression Analysis of HIV-1 Linked p24-specific CD4+ T-Cell Responses for Identifying Genetic Markers.,Carlotta Domeniconi,"The Human Immunodeficiency Virus (HIV) presents a complex knot for scientists to unravel. After initial contact and attachment to a cell of the immune system (eg lymphocytes, monocytes), the virus causes a cascade of intracellular events. The endproduct of these events is the production of a massive number of new viral particles, death of the infected cells, and ultimate devastation of the immune system. HIV is an epidemic and a crisis in many continents. Since there are many variations of the virus and differences in people’s genetic make-up, rapid diagnosis and monitoring of tailored treatments are essential for future medicine. To combat this problem, microarray technology can perform a single scan of thousands of genes. However, without a proper research design and data mining techniques, the results from this technology can be very skewed. Thus, using a normalized, clean dataset (time-series) from the CD4+ T-cell line CEM-CCRF, we designed and implemented hierarchical clustering and pattern-based clustering algorithms to identify specific cellular genes influenced by the HIV-1 viral infection. This research can contribute to the HIV Pharmacogenomics field by confirming HIV genetic markers, which would lead to rapid diagnosis and customized treatments.",Scholar articles of the research: Gene Expression Analysis of HIV-1 Linked p24-specific CD4+ T-Cell Responses for Identifying Genetic Markers.C Domeniconi,"The Human Immunodeficiency Virus (HIV) presents a complex knot for scientists to unravel. After initial contact and attachment to a cell of the immune system (eg lymphocytes, monocytes), the virus causes a cascade of intracellular events. The endproduct of these events is the production of a massive number of new viral particles, death of the infected cells, and ultimate devastation of the immune system. HIV is an epidemic and a crisis in many continents. Since there are many variations of the virus and differences in people’s genetic make-up, rapid diagnosis and monitoring of tailored treatments are essential for future medicine. To combat this problem, microarray technology can perform a single scan of thousands of genes. However, without a proper research design and data mining techniques, the results from this technology can be very skewed. Thus, using a normalized, clean dataset (time-series) from the CD4+ T-cell line CEM-CCRF, we designed and implemented hierarchical clustering and pattern-based clustering algorithms to identify specific cellular genes influenced by the HIV-1 viral infection. This research can contribute to the HIV Pharmacogenomics field by confirming HIV genetic markers, which would lead to rapid diagnosis and customized treatments.",
Area Chairs,"Ankit Agrawal, Leman Akoglu, Elena Baralis, Christian Boehm, Francesco Bonchi, Chris Clifton, Diane Cook, Carlotta Domeniconi, Panagiotis Karras, Eamonn Keogh, Danai Koutra, Xiaoli Li, Jessica Lin, Xuemin Lin, Huan Liu, Shirui Pan, Evangelos Papalexakis, Jian Pei, Naren Ramakrishnan, Chandan Reddy, Thomas Seidl, Kyuseok Shim, Myra Spiliopoulou, Karthik Subbian, Jie Tang, Hanghang Tong, Vincent S Tseng, Jilles Vreeken, Fei Wang, Jianyong Wang, Jia Wu, Hui Xiong, Shuicheng Yan, Aidong Zhang, Chengqi Zhang, Min-Ling Zhang, Weinan Zhang, Zhongfei Zhang, Xiaofang Zhou, Fuzhen Zhuang","Area Chairs and Program Committee Toggle navigation IEEE Computer Society Digital Library 
Jobs Tech News Resource Center Press Room Advertising About Us IEEE IEEE Computer 
Society IEEE Computer Society Digital Library My Subscriptions Magazines Journals Conference 
Proceedings Institutional Subscriptions IEEE IEEE Computer Society More Jobs Tech News 
Resource Center Press Room Advertising About Us Cart All Advanced Search Conference 
Cover Image Download 1.Home 2.Proceedings 3.icdm 2022 Area Chairs and Program 
Committee 2022, pp. 32-41, DOI Bookmark: 10.1109/ICDM54844.2022.00008 Keywords 
Authors Area Chairs Ankit Agrawal, Northwestern University, USA Leman Akoglu, Carnegie 
Mellon University, USA Elena Baralis, Politecnico di Torino, Italy Christian Boehm, University 
of Munich, Germany Francesco Bonchi, ISI Foundation, Italy Chris Clifton, Purdue University, …","Scholar articles Area ChairsA Agrawal, L Akoglu, E Baralis, C Boehm, F Bonchi…All 2 versions ",,
Composite Kernels for Semi-Supervised Clustering,"Bojun Yan, Carlotta Domeniconi, Jing Peng","A critical problem related to kernel-based methods is how to select optimal kernels. A kernel function must conform to the learning target in order to obtain meaningful results. While solutions to the problem of estimating optimal kernel functions and corresponding parameters have been proposed in a supervised setting, it remains a challenge when no labeled data are available, and all we have is a set of pairwise must-link and cannot-link constraints. In this paper we address the problem of optimizing the kernel function using pairwise constraints for semi-supervised clustering. We propose a new optimization criterion for automatically estimating the optimal parameters of composite Gaussian kernels, directly from the data and given constraints. We combine our proposal with a semi-supervised kernel-based algorithm to demonstrate experimentally the effectivess of our approach. The results show that our method is very effective for kernel-based semi-supervised clustering.","Scholar articles Composite Kernels for Semi-Supervised ClusteringB Yan, C Domeniconi, J PengRelated articles ","A critical problem related to kernel-based methods is how to select optimal kernels. A kernel function must conform to the learning target in order to obtain meaningful results. While solutions to the problem of estimating optimal kernel functions and corresponding parameters have been proposed in a supervised setting, it remains a challenge when no labeled data are available, and all we have is a set of pairwise must-link and cannot-link constraints. In this paper we address the problem of optimizing the kernel function using pairwise constraints for semi-supervised clustering. We propose a new optimization criterion for automatically estimating the optimal parameters of composite Gaussian kernels, directly from the data and given constraints. We combine our proposal with a semi-supervised kernel-based algorithm to demonstrate experimentally the effectivess of our approach. The results show that our method is very effective for kernel-based semi-supervised clustering.",
IEEE/ACM TCBB,"M Mina, PH Guzzi, Q Shen, H Tian, D Tang, W Yao, X Gao, G Yu, H Rangwala, C Domeniconi, G Zhang, Z Yu, F Lόpez-Caamal, DA Oyarzún, RH Middleton, MR García, BX Guan, B Bhanu, P Talbot, S Lin","(TCBB) publishes archival research results related to the algorithmic, mathematical, statistical, and computational methods that are central in bioinformatics and computational biology; the development and testing of effective computer programs in bioinformatics; the development and optimization of biological databases; and important biological results that are obtained from the use of these methods, programs, and databases.","Scholar articles IEEE/ACM TCBBM Mina, PH Guzzi, Q Shen, H Tian, D Tang, W Yao…All 2 versions ","(TCBB) publishes archival research results related to the algorithmic, mathematical, statistical, and computational methods that are central in bioinformatics and computational biology; the development and testing of effective computer programs in bioinformatics; the development and optimization of biological databases; and important biological results that are obtained from the use of these methods, programs, and databases.",
Transactions/Journals Department,"DERONG LIU, HOJJAT ADELI, CESARE ALIPPI, MARCO BAGLIETTO, LUBICA BENUSKOVA, AMIT BHAYA, IVO BUKOVSKY, SHENG CHEN, TIANPING CHEN, PAU-CHOO JULIA CHUNG, MING DONG, EL-SAYED EL-ALFY, PABLO A ESTEVEZ, HAIBO HE, TOM HESKES, AKIRA HIROSE, ZENG-GUANG HOU, SANQING HU, AMIR HUSSAIN, KAZUSHI IKEDA, HOSSEIN JAVAHERIAN, YAOCHU JIN, FAKHRI KARRAY, RHEE MAN KIL, IRWIN KING, LIWEILEO KO, JAMES KWOK, ROBERT LEGENSTEIN, FRANK L LEWIS, ARISTIDIS LIKAS, GUO-PING LIU, JINHU LU, YUNQIAN MA, MALIK MAGDON-ISMAIL, DANILO P MANDIC, SEIICHI OZAWA, MIKE PAULIN, ROBI POLIKAR, DANIL PROKHOROV, V SREE HARI RAO, MARCELLO SANGUINETI, ALESSANDRO SPERDUTI, STEFANO SQUARTINI, DIPTI SRINIVASAN, SERGIOS THEODORIDIS, MARC M VAN HULLE, DRAGUNA VRABIE, ZIDONG WANG, MARCO WIERING, ZHANG YI, VICENTE ZARZOSO, ZHIGANG ZENG, G PETER ZHANG, HUAGUANG ZHANG, NIAN ZHANG, LIANG ZHAO, NANNING ZHENG","IEEE Transactions on Neural Networks publication information Page 1 IEEE 
TRANSACTIONS ON NEURAL NETWORKS IEEE TRANSACTIONS ON NEURAL 
NETWORKS is published by the IEEE Computational Intelligence Society. Members may 
subscribe to this TRANSACTIONS for $22.00 per year. IEEE student members may 
subscribe for $11.00 per year. Nonmembers may subscribe for $1,750.00. For additional 
subscription information visit http://www.ieee.org/nns/pubs. For information on receiving this 
TRANSACTIONS, write to the IEEE Service Center at the address below. Member copies of 
Transactions/Journals are for personal use only. For more information about this 
TRANSACTIONS see http://www.ieee-cis/org/pubs/tnn. Editor-in-Chief DERONG LIU 
Institute of Automation Chinese Academy of Sciences Beijing 100190, China Dept. of 
Electrical and Computer Engineering University of Illinois Chicago, IL …","Scholar articles Transactions/Journals DepartmentD LIU, H ADELI, C ALIPPI, M BAGLIETTO…All 3 versions ",,
"Seung-won Hwang, POSTECH, Korea Nitin Indurkhya, eBay Research Laboratories, USA Hasan Jamil, Wayne State University, USA Szymon Jaroszewicz, Institute of Computer Science …","Anirban Dasgupta, Tamraparni Dasu, Ayhan Demiriz, Anne Denton, Wei Ding, Carlotta Domeniconi, Guozhu Dong, Murat Dundar, Haimonti Dutta, William Eberle, Christoph F Eick, Mohammad El-Hajj, Tina Eliassi-Rad, Tapio Elomaa, Floriana Esposito, Wei Fan, Ad Feelders, Zhu Feida, Ronen Feldman, Takeshi Fukuda, Benjamin CM Fung, Johannes Fürnkranz, Byron Gao, Jing Gao, Rayid Ghani, Amol Ghoting, C Lee Giles, Aristides Gionis, Marko Grobelnik, Fabrice Guillet, Maria Halkidi","Program Committee Page 1 Program Committee Osman Abul, TOBB University, Turkey 
Rajendra Akerkar, Western Norway Research Institute, Norway Reda Alhajj, University of 
Calgary, Canada Kamal Ali, Yahoo, USA Aijun An, York University, Canada Annalisa Appice, 
Università degli Studi di Bari Aldo Moro, Italy Ira Assent, Aarhus University, Denmark Ricardo 
Baeza-Yates, Yahoo! Research, Spain James Bailey, The University of Melbourne, Australia 
Arindam Banerjee, University of Minnesota, United States Elena Baralis, Politecnico di Torino, 
Italy Lotfi Ben Romdhane, University of Sousse, Tunisia Sadok Ben Yahia, Faculty of Sciences 
of Tunis, Tunisia Kristin Bennett, Rensselaer Polytechnic Institute, USA Bettina Berendt, Dept. 
of Computer Science, KU Leuven, Belgium Michael R. Berthold, University of Konstanz, 
Germany Kanishka Bhaduri, NASA Ames Research Center & MCT, USA Smriti Bhagat, …","Scholar articles Seung-won Hwang, POSTECH, Korea Nitin Indurkhya, eBay Research Laboratories, USA Hasan Jamil, Wayne State University, USA Szymon Jaroszewicz, Institute of Computer Science, Polish Academy of Sciences, Poland David Jensen, University of Massachusetts Amherst, USAA Dasgupta, T Dasu, A Demiriz, A Denton, W Ding…All 2 versions ",,
Program Co-Chairs,"Jing Peng, Xiuwen Liu, Marian Bartlett, Stefano Cagnoni, Tom Dietterich, Carlotta Domeniconi, Bruce Draper, Riad Hammoud, Delphi Doug Heisterkamp, Katsu Ikeuchi, Anil Jain, Chris Krawiec, Peter Meer, Ram Nevatia, Lucas Paletta, Gregory Power, Air Force, Mateen Rizki, Paul Sajda","Learning in Computer Vision and Pattern Recognition LCVPR 2005 - Committess Toggle 
navigation IEEE Computer Society Digital Library Jobs Tech News Resource Center Press 
Room Browse By Date Advertising About Us IEEE IEEE Computer Society IEEE Computer 
Society Digital Library My Subscriptions Magazines Journals Conference Proceedings 
Institutional Subscriptions IEEE IEEE Computer Society More Jobs Tech News Resource Center 
Press Room Browse By Date Advertising About Us Cart All Advanced Search Conference Cover 
Image Download 1.Home 2.Proceedings 3.cvprw 2005 Learning in Computer Vision and Pattern 
Recognition LCVPR 2005 - Committess 2005, pp. xxvi, DOI Bookmark: 10.1109/CVPR.2005.484 
Keywords Authors Committees,General Chair: ,Bir Bhanu, University of California, 
Riverside ,Program Co-Chairs: ,Jing Peng, Tulane University ,Xiuwen Liu, Florida State …","Scholar articles Program Co-ChairsJ Peng, X Liu, M Bartlett, S Cagnoni, T Dietterich…All 4 versions ",,
Topic Significance Ranking of LDA Generative Models,"Loulwah AlSumait1 Daniel Barbará1 James Gentle, Carlotta Domeniconi","Topic models, like Latent Dirichlet Allocation (LDA), have been recently used to automatically generate text corpora topics, and to subdivide the corpus words among those topics. However, not all the estimated topics are of equal importance or correspond to genuine themes of the domain. Some of the topics can be a collection of irrelevant or background words, or represent insignificant themes. Current approaches to topic modeling perform manual examination of their output to find meaningful and important topics. This paper presents the first automated unsupervised analysis of LDA models to identify and distinguish junk topics from legitimate ones, and to rank the topic significance. The basic idea consists of measuring the distance between a topic distribution and a” junk distribution”. In particular, three definitions of” junk distribution” are introduced, and a variety of metrics are used to compute the distances, from which an expressive figure of topic significance is implemented using a 4-phase Weighted Combination approach. Our experiments on synthetic and benchmark datasets show the effectiveness of the proposed approach in expressively ranking the significance of topics.","Scholar articles Topic Significance Ranking of LDA Generative ModelsLASDBJ Gentle, C DomeniconiRelated articles All 6 versions ","Topic models, like Latent Dirichlet Allocation (LDA), have been recently used to automatically generate text corpora topics, and to subdivide the corpus words among those topics. However, not all the estimated topics are of equal importance or correspond to genuine themes of the domain. Some of the topics can be a collection of irrelevant or background words, or represent insignificant themes. Current approaches to topic modeling perform manual examination of their output to find meaningful and important topics. This paper presents the first automated unsupervised analysis of LDA models to identify and distinguish junk topics from legitimate ones, and to rank the topic significance. The basic idea consists of measuring the distance between a topic distribution and a” junk distribution”. In particular, three definitions of” junk distribution” are introduced, and a variety of metrics are used to compute the distances, from which an expressive figure of topic significance is implemented using a 4-phase Weighted Combination approach. Our experiments on synthetic and benchmark datasets show the effectiveness of the proposed approach in expressively ranking the significance of topics.",
General and Program Chairs,"NCGIA Silvia Nittel, Dimitrios Gunopulos, Peter Buneman, Carol Bult, Susan Davidson, Alex Delis, Carlotta Domeniconi, Johann-Christoph Freytag, Minos Garofalakis, Johannes Gehrke, Jiawei Han, Joe Hellerstein, Yannis Ioannidis, Christian Jensen, Manolis Koubarakis, Stefano Lonardi, HIIT Heikki Mannila, Finland Richard Muntz, Torsten Suel, HIIT Hannu Toivonen, Finland Vassilis Tsotras, Michalis Vazirgiannis, Oikonomiko Panepistimio, Greece X Athens, Marianne Winslett, Mohammed Zaki, George Kollios, Theodoros Folias","Issue Image no(s) - Scientific and Statistical Database Management, 2003. 15th International 
Conference on Page 1 viii Foreword he 15th International Conference on Scientific and 
Statistical Database Management, held in Cambridge, MA, USA, July 9-11, 2003, brought 
together researchers, practitioners and developers for the presentation and exchange of current 
research on concepts, tools and techniques for scientific and statistical database applications. 
This year’s conference focused on the priority themes of Bioinformatics (Genomics, Biodiversity 
informatics including Biological Databases), and Geospatial and Sensor Databases. The 
call for papers attracted 48 full paper submissions, 5 short papers and 7 demo submissions. 
For the conference, 20 full papers were accepted by the program committee, as well as 12 
poster and demo papers. Most of these papers present preliminary reports of continuing …","Scholar articles General and Program ChairsN Silvia Nittel, D Gunopulos, P Buneman, C Bult…",,
ICDM 2008,"Gennady Andrienko, Ricardo Baeza-Yates, Elena Baralis, Roberto Bayardo, Toon Calders, Gautam Das, Luc De Raedt, Amol Deshpande, Carlotta Domeniconi, Charles Elkan, Tapio Elomaa, Wei Fan, Johannes Gehrke, Aris Gionis, Hillol Kargupta, Eamonn Keogh, Ravi Kumar, Laks VS Lakshmanan, Ling Liu, Nikos Mamoulis, Giuseppe Manco, Heikki Mannila, Mirco Nanni, Srinivasan Parthasarathy, Jian Pei, Rajeev Rastogi, Yucel Saygin, Fabrizio Sebastiani, Kyuseok Shim, Yannis Theodoridis, Michalis Vazirgiannis, Zhi-Hua Zhou","Program Committee Page 1 Program Committee ICDM 2008 Program Committee Vice 
Chairs Gennady Andrienko, Fraunhofer Institute Autonomous Intelligent Systems Ricardo 
Baeza-Yates, Yahoo! Research Barcelona Elena Baralis, Politecnico di Torino Roberto 
Bayardo, Google, Inc. Toon Calders, Eindhoven Technical University Gautam Das, 
University of Texas at Arlington Luc De Raedt, Katholieke Universiteit Leuven Amol 
Deshpande, University of Maryland Carlotta Domeniconi, George Mason University Charles 
Elkan, University of California, San Diego Tapio Elomaa, University of Helsinki Wei Fan, 
IBM TJWatson Research Johannes Gehrke, Cornell University Aris Gionis, Yahoo! 
Research Barcelona Hillol Kargupta, University of Maryland Eamonn Keogh, University of 
California — Riverside Ravi Kumar, Yahoo! Research Silicon Valley Laks VS Lakshmanan, 
University of British Columbia Ling Liu, Georgia …","Scholar articles ICDM 2008G Andrienko, R Baeza-Yates, E Baralis, R Bayardo…",,
Theory and Practice of Temporal Data Mining (TPTDM 2006),"Tao Li, Charles Perng, Haixun Wang, Carlotta Domeniconi","This paper addresses the problem of knowledge extraction among multiple parties involved in a data mining task, without disclosing the data between the parties. Specifically, we provide solutions for privacy-preserving sequential pattern mining which is one of data mining tasks. Our objective is to obtain accurate data mining results and minimize private data disclosure. 1","Scholar articles Theory and Practice of Temporal Data Mining (TPTDM 2006)T Li, C Perng, H Wang, C DomeniconiRelated articles ","This paper addresses the problem of knowledge extraction among multiple parties involved in a data mining task, without disclosing the data between the parties. Specifically, we provide solutions for privacy-preserving sequential pattern mining which is one of data mining tasks. Our objective is to obtain accurate data mining results and minimize private data disclosure. 1",
Clustering Ensembles for Categorical Data,"Muna Al-Razgan, Carlotta Domeniconi, Daniel Barbará",Cluster ensembles offer a solution to challenges inherent to clustering arising from its ill-posed nature. In this paper we focus on the design of ensembles for categorical data. Our approach leverages diverse input clusterings discovered in random subspaces. We experimentally demostrate the efficacy of our technique in combination with the categorical clustering algorithm COOLCAT.,"Scholar articles Clustering Ensembles for Categorical DataM Al-Razgan, C Domeniconi, D BarbaráRelated articles All 6 versions ",Cluster ensembles offer a solution to challenges inherent to clustering arising from its ill-posed nature. In this paper we focus on the design of ensembles for categorical data. Our approach leverages diverse input clusterings discovered in random subspaces. We experimentally demostrate the efficacy of our technique in combination with the categorical clustering algorithm COOLCAT.,
"Clustering, Subspace Clustering, and Clustering Ensembles",Carlotta Domeniconi,"Clustering, Subspace Clustering, and Clustering Ensembles Page 1 Clustering, Subspace 
Clustering, and Clustering Ensembles Carlotta Domeniconi Information and Software 
Engineering Department George Mason University www.ise.gmu.edu/~carlotta Joint work 
with: Ning Kang and Muna Al-Razgan Page 2 Outline ➢ Clustering and The Curse of 
Dimensionality ➢ Discovering local structures: Subspace Clustering ➢ A Locally Adaptive 
Clustering Technique ➢ Applications to Categorization and Keyword Identification of 
Unlabeled Documents ➢ Clustering Ensemble Techniques Page 3 Clustering ➢ 
Fundamental to all clustering techniques is the choice of distance measure between data 
points; ➢ Assumption: All features are equally important; ➢ Such approaches fail in high 
dimensional spaces ( ) ( )2 1 , ∑ = − = q k jk ik j i xx D xx Squared Euclidean distance Page 
4 Clustering: The Curse of Dimensionality ➢ A full…","Scholar articles Clustering, Subspace Clustering, and Clustering EnsemblesC DomeniconiRelated articles All 2 versions ",,
IEEE CIDM 2011 Committee Symposium on Computational Intelligence and Data Mining (IEEE CIDM 2011),"Nitesh Chawla, Irwin King, Alessandro Sperduti, Wil MP van der Aalst, Elia Biganzoli, KMUTT Jonathan Chan, Thailand Ouyang Chen-Sen, Sven F Crone, Alfredo Cuzzocrea, Carlotta Domeniconi, DUAN Hai-Bin, Floriana Esposito, Antonella Guzzo, Larry Hall, Barbara Hammer, Qi He, Kaizhu Huang, Eyke Hllermeier, Mehmed Kantardzic, Nikola Kasabov, Tamara G Kolda, Wai Lam, Vincent CS Lee, Paulo Lisboa","The 2011 IEEE Symposium on Computational Intelligence and Data Mining (IEEE CIDM 2011) is a forum for the presentation of recent results concerning Computational Intelligence for data and process mining. The topics covered by the Symposium include CI/probabilistic/statistical and other methods, mining spatial and temporal data, recognition and interpretation of images, text, graph and web mining, medical data analysis, process mining.","Scholar articles IEEE CIDM 2011 Committee Symposium on Computational Intelligence and Data Mining (IEEE CIDM 2011)N Chawla, I King, A Sperduti, WMP van der Aalst…Related articles ","The 2011 IEEE Symposium on Computational Intelligence and Data Mining (IEEE CIDM 2011) is a forum for the presentation of recent results concerning Computational Intelligence for data and process mining. The topics covered by the Symposium include CI/probabilistic/statistical and other methods, mining spatial and temporal data, recognition and interpretation of images, text, graph and web mining, medical data analysis, process mining.",
Approximating multi-dimensional aggregate range queries over real attributes Dimitrios Gunopulos Univ. of California Riverside,"Vassilis J Tsotras, Carlotta Domeniconi","Finding approximate answers to multi-dimensional range queries over real valued attributes has significant applications in data exploration and database query optimization. In this paper we consider the following problem: given a table of d attributes whose domain is the real numbers, and a query that specifies a range in each dimension, find a good approximation of the number of records in the table that satisfy the query. We present a new histogram technique that is designed to approximate the density of multi-dimensional datasets with real attributes. Our technique finds buckets of variable size, and allows the buckets to overlap. Overlapping buckets allow more efficient approximation of the density. The size of the cells is based on the local density of the data. This technique leads to a faster and more compact approximation of the data distribution. We also show how to generalize kernel density estimators, and …","Scholar articles Approximating multi-dimensional aggregate range queries over real attributes Dimitrios Gunopulos Univ. of California RiversideVJ Tsotras, C DomeniconiRelated articles ","Finding approximate answers to multi-dimensional range queries over real valued attributes has significant applications in data exploration and database query optimization. In this paper we consider the following problem: given a table of d attributes whose domain is the real numbers, and a query that specifies a range in each dimension, find a good approximation of the number of records in the table that satisfy the query. We present a new histogram technique that is designed to approximate the density of multi-dimensional datasets with real attributes. Our technique finds buckets of variable size, and allows the buckets to overlap. Overlapping buckets allow more efficient approximation of the density. The size of the cells is based on the local density of the data. This technique leads to a faster and more compact approximation of the data distribution. We also show how to generalize kernel density estimators, and …",
Approximating multi-dimensional,"Dimitrios Gunopulos, George Kollios, Vassilis J Tsotras, Carlotta Domeniconi","Finding approximate answers to multi-dimensional range queries over real valued attributes has significant applications in data exploration and database query optimization. In this paper we consider the following problem: given a table of d attributes whose domain is the real numbers, and a query that specifies a range in each dimension, find a good approximation of the number of records in the table that satisfy the query. We present a new histogram technique that is designed to approximate the density of multi-dimensional datasets with real attributes. Our technique finds buckets of variable size, and allows the buckets to overlap. Overlapping buckets allow more efficient approximation of the density. The size of the cells is based on the local density of the data. This technique leads to a faster and more compact approximation of the data distribution. We also show how to generalize kernel density estimators, and …","Scholar articles Approximating multi-dimensionalD Gunopulos, G Kollios, VJ Tsotras, C DomeniconiRelated articles ","Finding approximate answers to multi-dimensional range queries over real valued attributes has significant applications in data exploration and database query optimization. In this paper we consider the following problem: given a table of d attributes whose domain is the real numbers, and a query that specifies a range in each dimension, find a good approximation of the number of records in the table that satisfy the query. We present a new histogram technique that is designed to approximate the density of multi-dimensional datasets with real attributes. Our technique finds buckets of variable size, and allows the buckets to overlap. Overlapping buckets allow more efficient approximation of the density. The size of the cells is based on the local density of the data. This technique leads to a faster and more compact approximation of the data distribution. We also show how to generalize kernel density estimators, and …",
"Ryszard Tadeusiewicz AGH University Krakow Poland Shenghuo Zhu NEC Laboratories America, USA Shi Zhong Yahoo! Inc Taghi Khoshgoftaar Florida Atlantic University Tao Xiong …","Alan Sprague, Carlotta Domeniconi, Chang-Tien Lu, Charles Perng, Dongyi Ye, Feng Luo, Giri Narasimhan, Graham Kendall, Guizhen Yang, Iryna Skrypnyk, Istvan Jonyer, James Tin-Yau Kwok, Ji Xiang, Jianping Fan, John Anderson, Jungpil Shin, Kim Seungchan, Larry Hall, Liao Li, Lukasz Kurgan, Luke Huan, Marek Reformat, Maumita Bhattacharya, Mihai Boicu, Qi Li","Program Committees Page 1 xi Program Committee Alan Sprague University of Alabama at 
Birmingham Carlotta Domeniconi George Mason University Chang-Tien Lu Virginia Tech 
Charles Perng IBM Research Dongyi Ye Fuzhou University, China Du Zhang California State 
University Sacramento, USA Feng Luo Clemson University Giri Narasimhan Florida International 
University Graham Kendall University of Nottingham UK Guizhen Yang SRI International, USA 
Iryna Skrypnyk University of Jyvaskyla Istvan Jonyer Oklahoma State University James 
Tin-Yau Kwok Hong Kong University, Hong Kong Ji Xiang NEC Labs America, USA Jianping 
Fan UNC-Charlotte, USA Jinbo Bi Siemens, Medical Solutions, USA John Anderson University 
of Manitoba, Canada Jungpil Shin The University of AIZU, Japan Kim Seungchan Arizona 
State University Larry Hall University of South Florida Liao Li University of Delaware Lukasz …","Scholar articles Ryszard Tadeusiewicz AGH University Krakow Poland Shenghuo Zhu NEC Laboratories America, USA Shi Zhong Yahoo! Inc Taghi Khoshgoftaar Florida Atlantic University Tao Xiong University of MinnesotaA Sprague, C Domeniconi, CT Lu, C Perng, D Ye…",,
Program Committee Vice Chairs,"Daniel Barbara, Tamraparni Dasu, Inderjit Dhillon, Venkatesh Ganti, Bart Goethals, Dimitrios Gunopulos, Hillol Kargupta, George Karypis, S Muthu Muthukrishnan, Dino Pedreschi, Jian Pei, Sunita Sarawagi, Arno Siebes, Jeffrey Xu Yu, Dimitris Achlioptas, Gediminas Adomavicius, Gagan Agarwal, Charu Aggarwal, Eugene Agichtein, Hiroki Arimura, Arindam Banerjee, Francesco Bonchi, Jean-Francois Boulicaut, Paul Bradley, Erick Cantu-Paz, Philip Chan, Kevin Chang, Sanjay Chawla, Hsinchun Chen, Ming-Syan Chen, David Wai-lok Cheung, Chris Clifton, Frans Coenen, Diane Cook, Rob Cooley, Graham Cormode, Honghua Dai, Gautam Das, Chris Ding, Alin Dobra, Carlotta Domeniconi","Program Committee Page 1 xxi Program Committee Program Committee Vice Chairs 
Daniel Barbara, George Mason University, USA Tamraparni Dasu, AT&T Research Labs, 
USA Inderjit Dhillon, University of Texas at Austin, USA Venkatesh Ganti, Microsoft 
Research, USA Bart Goethals, University of Antwerp, Belgium Dimitrios Gunopulos, 
University of California, Riverside, USA Hillol Kargupta, University of Maryland, Baltimore 
County & Agnik, LLC, USA George Karypis, University of Minnesota, USA S. Muthu 
Muthukrishnan, Rutgers University, USA Dino Pedreschi, Univ. of Pisa, Italy Jian Pei, State 
University of New York at Buffalo, USA Sunita Sarawagi, Indian Institute of Technology, 
Bombay, India Arno Siebes, Utrecht University, Netherlands Jeffrey Xu Yu, Chinese 
University of Hong Kong, PR China Program Committee Members Dimitris Achlioptas, 
Microsoft Research, USA Gediminas Adomavicius, University …","Scholar articles Program Committee Vice ChairsD Barbara, T Dasu, I Dhillon, V Ganti, B Goethals…All 2 versions ",,
ASONAM 2010 Program Committee,"Ajith Abraham, Nitin Agarwal, Harith Alani, Ira Assent, Guido Barbian, Marenglen Biba, Francesco Bonchi, Dan Braha, Bin Cao, Andre Carvalho, Chien-Chung Chan, Nitesh V Chawla, Richard Chbeir, Li Chen, Yunwei Chen, James Cheng, Yun Chi, Been-Chian Chien, Tung-Hsiang Chou, Munmun De Choudhury, Gao Cong, Ioanna Constantiou, Diane Cook, Xiaohui Cui, Alfredo Cuzzocrea, Min-Yuh Day, Petra Deger, Jana Diesner, Ying Ding, Carlotta Domeniconi, Artur Dubrawski, Schahram Dustdar, Yuval Elovici, Behrouz Far, Michael Farrugia","Program Committee Page 1 ASONAM 2011 Program Committee Ajith Abraham, Norwegian 
University of Science and Technology, Norway Nitin Agarwal, University of Arkansas at Little 
Rock, USA Harith Alani, University of Southampton, UK Ira Assent, Aalborg University, 
Denmark Guido Barbian, University of Lüneburg, Germany Kanishka Bhaduri, NASA, USA 
Marenglen Biba, University of New York Tirana, Albania Francesco Bonchi, Yahoo! Research 
Barcelona, Spain Dan Braha, New England Complex Systems Institute, USA Bin Cao, The 
Hong Kong University of Science and Technology, China Andre Carvalho, Universidade de 
Sao Paulo, Brazil Chien-Chung Chan, University of Akron, USA Nitesh V. Chawla, University of 
Notre Dame, USA Richard Chbeir, LE2I-CNRS, France Li Chen, Hong Kong Baptist University, 
HK Yunwei Chen, National Science Library, Chinese Academy of Sciences, China James …","Scholar articles ASONAM 2010 Program CommitteeA Abraham, N Agarwal, H Alani, I Assent, G Barbian…All 2 versions ",,
"Roberto Bayardo, Google, USA","Chiranjib Bhattacharya, Indrajit Bhattacharya, Sourav Bhowmick, Mary Elaine Califf, Juan Pedro Caraça-Valente, Kaushik Chakrabarti, Philip Chan, Jiyang Chen, Frans Coenen, Alfredo Cuzzocrea, Honghua Dai, Tamraparni Dasu, Ian Davidson, Chris Ding, Carlotta Domeniconi, Guozhu Dong, Margaret Dunham, Kemal Efe, Christoph F Eick, Mohammad El-Hajj, Tina Eliassi-Rad, Martin Ester, Vladimir Estivill-Castro, Wei Fan, Ronen Feldman, Ling Feng, Peter Flach, Andrew Foss, Ada Fu, Johannes Fürnkranz, Efstratios Gallopoulos, Matjaz Gams, Chris Giannella, Aristides Gionis, Attilio Giordana, Bart Goethals, Ananth Grama","Program Committee Page 1 Program Committee Gagan Agarwal, Ohio State University, USA 
Aijun An, York University, Canada Peter Andreae, Victoria University of Wellington, New 
Zealand Luiza Antonie, University of Alberta, Canada Chris Bailey-Kellogg, Dartmouth College, 
USA Arindam Banerjee, University of Minnesota, Twin Cities, USA Rohan Baxter, ATO, 
Australia Roberto Bayardo, Google, USA Chiranjib Bhattacharya, Indian Institute of Science, 
Bangalore, India Indrajit Bhattacharya, IBM Research, Delhi, India Sourav Bhowmick, Nanyang 
Technological University, Singapore Michael Burl, JPL, USA Mary Elaine Califf, Illinois State 
University, USA Juan Pedro Caraça-Valente, Universidad Politécnica de Madrid, Spain Kaushik 
Chakrabarti, Microsoft Research, USA Philip Chan, Florida Institute of Technology, USA 
Jiyang Chen, University of Alberta, Canada Frans Coenen, University of Liverpool, UK Alfredo …","Scholar articles Roberto Bayardo, Google, USAC Bhattacharya, I Bhattacharya, S Bhowmick, ME Califf…",,
Locally Adaptive Metrics for Clustering,"Carlotta Domeniconi, Bojun Yan, Dimitris Papadopoulos, Dimitrios Gunopulos, Sheng Ma","Clustering suffers from the curse of dimensionality, and similarity functions that use all input features with equal relevance may not be effective. We introduce an algorithm that discovers clusters in subspaces spanned by different combinations of dimensions via local weightings of features. This approach avoids the risk of loss of information encountered in global dimensionality reduction techniques, and does not assume any data distribution model. Our method associates to each cluster a weight vector, whose values capture the relevance of features within the corresponding cluster. We experimentally demonstrate the gain in perfomance our method achieves, using both synthetic and real data sets. In particular, our results show the feasibility of the proposed technique to perform simultaneous clustering of genes and conditions in microarray data.","Scholar articles Locally Adaptive Metrics for ClusteringC Domeniconi, B Yan, D Papadopoulos, D Gunopulos…Related articles All 3 versions ","Clustering suffers from the curse of dimensionality, and similarity functions that use all input features with equal relevance may not be effective. We introduce an algorithm that discovers clusters in subspaces spanned by different combinations of dimensions via local weightings of features. This approach avoids the risk of loss of information encountered in global dimensionality reduction techniques, and does not assume any data distribution model. Our method associates to each cluster a weight vector, whose values capture the relevance of features within the corresponding cluster. We experimentally demonstrate the gain in perfomance our method achieves, using both synthetic and real data sets. In particular, our results show the feasibility of the proposed technique to perform simultaneous clustering of genes and conditions in microarray data.",
