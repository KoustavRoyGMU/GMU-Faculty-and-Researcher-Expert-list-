titles,authors,date,source,descriptions,citations
Analysis of energy intensity in manufacturing industry using mixed-effects models,"D Kepplinger, M Templ, S Upadhyaya",2013/9/15,Journal Energy,"The paper makes a cross country analysis of the energy intensity in manufacturing sectors. Empirical data for this purpose is gathered from the databases of two international agencies namely the IEA (International Energy Agency) and the UNIDO (UN International Development Organization), which provide energy consumption and manufacturing output data respectively.",52
Robust elastic net estimators for variable selection and identification of proteomic biomarkers,"Gabriela V Cohen Freue, David Kepplinger, Matías Salibián-Barrera, Ezequiel Smucler",2019/12/1,Volume 13,"Supplementary material for “Robust elastic net estimators for variable selection and identification of proteomic biomarkers”. We provide additional details on PENSE algorithm, properties and mathematical proofs.",20
How industrial development matters to the well-being of the population: Some statistical evidence,"Shyam Upadhyaya, David Kepplinger",2014,Journal Vienna: UNIDO,,12
Variable selection with genetic algorithms using repeated cross-validation of PLS regression models as fitness measure,"David Kepplinger, Peter Filzmoser, Kurt Varmuza",2017/11/17,Journal arXiv preprint arXiv:1711.06695,"Genetic algorithms are a widely used method in chemometrics for extracting variable subsets with high prediction power. Most fitness measures used by these genetic algorithms are based on the ordinary least-squares fit of the resulting model to the entire data or a subset thereof. Due to multicollinearity, partial least squares regression is often more appropriate, but rarely considered in genetic algorithms due to the additional cost for estimating the optimal number of components. We introduce two novel fitness measures for genetic algorithms, explicitly designed to estimate the internal prediction performance of partial least squares regression models built from the variable subsets. Both measures estimate the optimal number of components using cross-validation and subsequently estimate the prediction performance by predicting the response of observations not included in model-fitting. This is repeated multiple times to estimate the measures' variations due to different random splits. Moreover, one measure was optimized for speed and more accurate estimation of the prediction performance for observations not included during variable selection. This leads to variable subsets with high internal and external prediction power. Results on high-dimensional chemical-analytical data show that the variable subsets acquired by this approach have competitive internal prediction power and superior external prediction power compared to variable subsets extracted with other fitness measures.",5
Pense: A penalized elastic net s-estimator,"Gabriela V Cohen Freue, David Kepplinger, Matıas Salibián-Barrera, Ezequiel Smucler",2017/10/26,"Description Penalized regression estimators have been widely used in recent years to improve the prediction properties of linear models, particularly when the number of explanatory variables is large. It is well-known that different penalties result in regularized estimators with varying statistical properties. Motivated by the analysis of plasma proteomic biomarkers that tend to form groups of correlated predictors, we focus here on estimators with an Elastic Net penalty, in order to keep these groups of variables together as they enter or leave the model. Given the presence of potential outliers in our data, we propose a class of penalized S-estimators which have very good robustness properties. Furthermore, these penalized S-estimators can be used as initial values to compute more efficient penalized M-estimators. In this paper we derive an algorithm to compute our proposed estimators, and also a data-driven method to select the penalty term, which is a critical part of any application with real data. Our robust penalized estimators have very good robustness properties and are also consistent under relatively weak assumptions. Our numerical experiments show that our proposals compare favourably to other robust penalized estimators. When applied to our motivating example, the robust estimators identify new potentially relevant biomarkers that are not found with non-robust alternatives. Moreover, the robust estimators identify two patients with a suspected low obstruction in the artery examined. Further measurements by a more accurate technique validated our predictions.","Penalized regression estimators have been widely used in recent years to improve the prediction properties of linear models, particularly when the number of explanatory variables is large. It is well-known that different penalties result in regularized estimators with varying statistical properties. Motivated by the analysis of plasma proteomic biomarkers that tend to form groups of correlated predictors, we focus here on estimators with an Elastic Net penalty, in order to keep these groups of variables together as they enter or leave the model. Given the presence of potential outliers in our data, we propose a class of penalized S-estimators which have very good robustness properties. Furthermore, these penalized S-estimators can be used as initial values to compute more efficient penalized M-estimators. In this paper we derive an algorithm to compute our proposed estimators, and also a data-driven method to select the penalty term, which is a critical part of any application with real data. Our robust penalized estimators have very good robustness properties and are also consistent under relatively weak assumptions. Our numerical experiments show that our proposals compare favourably to other robust penalized estimators. When applied to our motivating example, the robust estimators identify new potentially relevant biomarkers that are not found with non-robust alternatives. Moreover, the robust estimators identify two patients with a suspected low obstruction in the artery examined. Further measurements by a more accurate technique validated our predictions.",4
Proteomic biomarker study using novel robust penalized elastic net estimators,"Gabriela V Cohen Freue, David Kepplinger, Matías Salibián-Barrera, Ezequiel Smucler","the Annals of Applied Statistics, submitted","Description In large-scale quantitative proteomic studies, scientists measure the abundance of hundreds or thousands of proteins from the human proteome in search of novel biomarkers for a given disease. Despite current innovations in biomedical technologies, advanced statistical and computational methods are still required to harness the rich information contained in these large and complex datasets. While penalized regression estimators can be used to identify potential biomarkers among a large set of molecular features, it is well-known that the performance and statistical properties of the selected model depend on the loss and penalty functions used to construct the regularized estimator. For example, the presence of outlying observations in the data can seriously affect classical estimators that penalize the square error loss function. Similarly, the choice of the penalty function in these estimators is important to be able to preserve groups of correlated proteins in the selected model. Thus, in this paper we propose a new class of penalized robust estimators based on the elastic net penalty, which can be tuned to keep groups of correlated variables together as they enter or leave the model, while protecting the resulting estimator against possibly aberrant observations in the dataset. Our robust penalized estimators have very good robustness properties and are also consistent under relatively weak assumptions. In this paper we also propose an efficient algorithm to compute our robust penalized estimators and we derive a data-driven method to select the penalty term, which is a critical part of any application with real data. Our numerical experiments …","In large-scale quantitative proteomic studies, scientists measure the abundance of hundreds or thousands of proteins from the human proteome in search of novel biomarkers for a given disease. Despite current innovations in biomedical technologies, advanced statistical and computational methods are still required to harness the rich information contained in these large and complex datasets. While penalized regression estimators can be used to identify potential biomarkers among a large set of molecular features, it is well-known that the performance and statistical properties of the selected model depend on the loss and penalty functions used to construct the regularized estimator. For example, the presence of outlying observations in the data can seriously affect classical estimators that penalize the square error loss function. Similarly, the choice of the penalty function in these estimators is important to be able to preserve groups of correlated proteins in the selected model. Thus, in this paper we propose a new class of penalized robust estimators based on the elastic net penalty, which can be tuned to keep groups of correlated variables together as they enter or leave the model, while protecting the resulting estimator against possibly aberrant observations in the dataset. Our robust penalized estimators have very good robustness properties and are also consistent under relatively weak assumptions. In this paper we also propose an efficient algorithm to compute our robust penalized estimators and we derive a data-driven method to select the penalty term, which is a critical part of any application with real data. Our numerical experiments …",3
Robust estimation and variable selection in high-dimensional linear regression models,David Kepplinger,2020,Institution University of British Columbia,"Linear regression models are commonly used statistical models for predicting a response from a set of predictors. Technological advances allow for simultaneous collection of many predictors, but often only a small number of these is relevant for prediction. Identifying this set of predictors in high-dimensional linear regression models with emphasis on accurate prediction is thus a common goal of quantitative data analyses. While a large number of predictors promises to capture as much information as possible, it bears a risk of containing contaminated values. If not handled properly, contamination can affect statistical analyses and lead to spurious scientific discoveries, jeopardizing the generalizability of findings. In this dissertation I propose robust regularized estimators for sparse linear regression with reliable prediction and variable selection performance under the presence of contamination in the response and one or more predictors. I present theoretical and extensive empirical results underscoring that the penalized elastic net S-estimator is robust towards aberrant contamination and leads to better predictions for heavy tailed error distributions than competing estimators. Especially in these more challenging scenarios, competing robust methods reliant on an auxiliary estimate of the residual scale, are more affected by contamination due to the high finite-sample bias introduced by regularization. For improved variable selection I propose the adaptive penalized elastic net S-estimator. I show this estimator identifies the truly irrelevant predictors with high probability as sample size increases and estimates the parameters of the truly relevant …",1
PGCA: An algorithm to link protein groups created from MS/MS data,"David Kepplinger, Mandeep Takhar, Mayu Sasaki, Zsuzsanna Hollander, Derek Smith, Bruce McManus, W Robert McMaster, Raymond T Ng, Gabriela V Cohen Freue",2017/5/31,Journal Plos one,"The quantitation of proteins using shotgun proteomics has gained popularity in the last decades, simplifying sample handling procedures, removing extensive protein separation steps and achieving a relatively high throughput readout. The process starts with the digestion of the protein mixture into peptides, which are then separated by liquid chromatography and sequenced by tandem mass spectrometry (MS/MS). At the end of the workflow, recovering the identity of the proteins originally present in the sample is often a difficult and ambiguous process, because more than one protein identifier may match a set of peptides identified from the MS/MS spectra. To address this identification problem, many MS/MS data processing software tools combine all plausible protein identifiers matching a common set of peptides into a protein group. However, this solution introduces new challenges in studies with multiple experimental runs, which can be characterized by three main factors: i) protein groups’ identifiers are local, i.e., they vary run to run, ii) the composition of each group may change across runs, and iii) the supporting evidence of proteins within each group may also change across runs. Since in general there is no conclusive evidence about the absence of proteins in the groups, protein groups need to be linked across different runs in subsequent statistical analyses. We propose an algorithm, called Protein Group Code Algorithm (PGCA), to link groups from multiple experimental runs by forming global protein groups from connected local groups. The algorithm is computationally inexpensive and enables the connection and analysis of lists of …",1
Discriminant analysis based on robust regularized covariance estimation,David Kepplinger,2015,"Description Its simple form makes linear discriminant analysis (LDA) a prevalent tool for classification, yet the dependency on an estimate of the precision matrix is a major drawback. In many applications more features than observations are available and some of these observations may be contaminated, impeding use of this simple tool. Regularization techniques, or sparse methods, are well known to give good estimates of the precision matrix when the sample covariance matrix is rank-deficient or ill-conditioned, however contamination also breaks these methods. By borrowing ideas from the FAST-MCD algorithm for robust multivariate location and scale estimation, a robust regularized estimate of the precision matrix can be obtained and used for LDA. In consideration of the classification context, a measure similar to the deviance measure used in other classification methods is defined and used to obtain the optimal value …","Its simple form makes linear discriminant analysis (LDA) a prevalent tool for classification, yet the dependency on an estimate of the precision matrix is a major drawback. In many applications more features than observations are available and some of these observations may be contaminated, impeding use of this simple tool. Regularization techniques, or sparse methods, are well known to give good estimates of the precision matrix when the sample covariance matrix is rank-deficient or ill-conditioned, however contamination also breaks these methods. By borrowing ideas from the FAST-MCD algorithm for robust multivariate location and scale estimation, a robust regularized estimate of the precision matrix can be obtained and used for LDA. In consideration of the classification context, a measure similar to the deviance measure used in other classification methods is defined and used to obtain the optimal value …",1
Robust variable selection and estimation via adaptive elastic net S-estimators for linear regression,David Kepplinger,2023/3/1,Journal Computational Statistics & Data Analysis,"Heavy-tailed error distributions and predictors with anomalous values are ubiquitous in high-dimensional regression problems and can seriously jeopardize the validity of statistical analyses if not properly addressed. For more reliable variable selection and prediction under these adverse conditions, adaptive PENSE, a new robust regularized regression estimator, is proposed. Adaptive PENSE yields reliable variable selection and coefficient estimates even under aberrant contamination in the predictors or residuals. It is shown that the adaptive penalty leads to more robust and reliable variable selection than other penalties, particularly in the presence of gross outliers in the predictor space. It is further demonstrated that adaptive PENSE has strong variable selection properties and that it possesses the oracle property even under heavy-tailed errors and without the need to estimate the error scale. Numerical studies …",
Recording animal-view videos of the natural world,"Vera Vasas, Mark C Lowell, Juliana Villa, Quentin D Jamison, Anna G Siegle, Pavan Kumar Reddy Katta, Pushyami Bhagavathula, Peter G Kevan, Drew Fulton, Neil Losin, David Kepplinger, Shakiba Salehian, Rebecca E Forkner, Daniel Hanley",2022,Journal bioRxiv,"Plants, animals, and fungi display a rich tapestry of colors. Animals, in particular, use colors in dynamic displays performed in spatially complex environments. In such natural settings, light is reflected or refracted from objects with complex shapes that cast shadows and generate highlights. In addition, the illuminating light changes continuously as viewers and targets move through heterogeneous, continually fluctuating, light conditions. Although traditional spectrophotometric approaches for studying colors are objective and repeatable, they fail to document this complexity. Worse, they miss the temporal variation of color signals entirely. Here, we introduce hardware and software that provide ecologists and filmmakers the ability to accurately record animal-perceived colors in motion. Specifically, our Python codes transform photos or videos into perceivable units (quantum catches) for any animal of known photoreceptor sensitivity. We provide the plans, codes, and validation tests necessary for end-users to capture animal-view videos. This approach will allow ecologists to investigate how animals use colors in dynamic behavioral displays, the ways natural illumination alters perceived colors, and other questions that remained unaddressed until now due to a lack of suitable tools. Finally, our pipeline provides scientists and filmmakers with a new, empirically grounded approach for depicting the perceptual worlds of non-human animals.",
Robust Prediction and Protein Selection with Adaptive PENSE,"David Kepplinger, Gabriela V Cohen Freue",2021/8/25,Book Statistical Analysis of Proteomic Data: Methods and Tools,"Adaptive PENSE is a method that can be used to build models for predicting clinical outcomes from a small subset of a potentially large number of candidate proteins. Adaptive PENSE is designed to give reliable results under two common challenges often encountered in these kinds of studies: (1) the number of samples with known clinical outcome and proteomic data is small, while the number of candidate proteins is large and/or (2) proteomic data and the clinical outcome measurements suffer from data quality issues in a small fraction of samples. Even in the presence of these challenges, adaptive PENSE reliably identifies proteins relevant for prediction and estimates accurate predictive models. Adaptive PENSE is designed to be resilient to data quality issues in up to 50% of samples. Almost half of the samples could have aberrant values in the measured protein levels and clinical outcome values without …",
APPENDIX for PGCA: an algorithm to link protein groups created from MS/MS data,"David Kepplinger, Mandeep Takhar, Mayu Sasaki, Zsuzsanna Hollander, Derek Smith, Bruce McManus, W Robert McMaster, Raymond T Ng, Gabriela V Cohen Freue","Lemma 1 Let L be the set of local groups from a file F (ie, 4 L= CreateLocalGroups (F)), G be the set of global groups from a dictionary D, and 5 B= L∪ G. Let D= UpdateDictionary (D, L) be the output dictionary from the 6 UdpdateDictionary algorithm. Given B, a set of accession numbers from those in B, and 7 A={E∈ B such that B∩ E= E}, B is a global group in D if and only if A is 8 non-empty and connected, and B∩ E=∅,∀ E∈ B\A. 9Outline of Proof Lemma 1 10=⇒) If B is a global group in D, by step 9 in Algorithm 3 in the main text, B resulted 11 from updating a local group b in B, and B can be written as the union of all sets in B 12 connected with b (including b). Thus, by construction, these sets are included in B and 13 form a non-empty and connected set A. Moreover, if B overlaps a set C not in A, then 14 C is connected with b (by B), which is a contradiction. 15⇐=) As A is non-empty and connected, then there exists a local group b∈ A, which, 16 updated by UpdateDictionary, became a global group B in D. It is sufficient to prove 17 that B= B. By construction, B can be written as the union of all sets in B connected 18 with b (including b). As b is included B, any set E in B connected with b must also be 19 connected with B. Moreover, as sets overlapping with B must be included in B, E∈ A, 20 implying that B⊆ B. Moreover, all sets in A are connected and thus connected with b. 21 As B can be written as the union of all sets in A, then B⊆ B. This proves that B= B 22 is a global group in D.■ 23","Scholar articles APPENDIX for PGCA: an algorithm to link protein groups created from MS/MS dataD Kepplinger, M Takhar, M Sasaki, Z Hollander…","Lemma 1 Let L be the set of local groups from a file F (ie, 4 L= CreateLocalGroups (F)), G be the set of global groups from a dictionary D, and 5 B= L∪ G. Let D= UpdateDictionary (D, L) be the output dictionary from the 6 UdpdateDictionary algorithm. Given B, a set of accession numbers from those in B, and 7 A={E∈ B such that B∩ E= E}, B is a global group in D if and only if A is 8 non-empty and connected, and B∩ E=∅,∀ E∈ B\A. 9",
