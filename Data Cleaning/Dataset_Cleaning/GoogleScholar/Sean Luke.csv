titles,authors,date,source,descriptions,citations
Cooperative multi-agent learning: The state of the art,"Liviu Panait, Sean Luke",2005/11,Source Autonomous agents and multi-agent systems,"Cooperative multi-agent systems (MAS) are ones in which several agents attempt, through their interaction, to jointly solve tasks or to maximize utility. Due to the interactions among the agents, multi-agent problem complexity can rise rapidly with the number of agents or their behavioral sophistication. The challenge this presents to the task of programming solutions to MAS problems has spawned increasing interest in machine learning techniques to automate the search and optimization process. We provide a broad survey of the cooperative multi-agent learning literature. Previous surveys of this area have largely focused on issues common to specific subareas (for example, reinforcement learning, RL or robotics). In this survey we attempt to draw from multi-agent learning work in a spectrum of areas, including RL, evolutionary computation, game theory, complex systems, agent modeling, and robotics. We …",1632
Mason: A multiagent simulation environment,"Sean Luke, Claudio Cioffi-Revilla, Liviu Panait, Keith Sullivan, Gabriel Balan",2005/7,Journal Simulation,"MASON is a fast, easily extensible, discrete-event multi-agent simulation toolkit in                 Java, designed to serve as the basis for a wide range of multi-agent simulation                 tasks ranging from swarm robotics to machine learning to social complexity                 environments. MASON carefully delineates between model and visualization, allowing                 models to be dynamically detached from or attached to visualizers, and to change                 platforms mid-run. This paper describes the MASON system, its motivation, and its                 basic architectural design. It then compares MASON to related multi-agent libraries                 in the public domain, and discusses six applications of the system built over the                 past year which suggest its breadth of utility.",1386
Essentials of Metaheuristics,Sean Luke,2009,Publisher Lulu,,1114
Mason: A new multi-agent simulation toolkit,"Sean Luke, Claudio Cioffi-Revilla, Liviu Panait, Keith Sullivan",2004/5/9,Journal Proceedings of the 2004 swarmfest workshop,"We introduce MASON, a fast, easily extendable, discreteevent multi-agent simulation toolkit in Java. MASON was designed to serve as the basis for a wide range of multiagent simulation tasks ranging from swarm robotics to machine learning to social complexity environments. MASON carefully delineates between model and visualization, allowing models to be dynamically detached from or attached to visualizers, and to change platforms mid-run. We describe the MASON system, its motivation, and its basic architectural design. We then discuss five applications of MASON we have built over the past year to suggest its breadth of utility.",458
Ontology-based web agents,"Sean Luke, Lee Spector, David Rager, James Hendler",1997/2/8,Book Proceedings of the first international conference on Autonomous agents,"This paper describes SHOE, a set of Simple HTML Ontology Extensions which allow World-Wide Web authors to annotate their pages with semantic knowledge such as “I am a graduate student” or “This person is my graduate advisor”. These annotations are expressed in terms of ontological knowledge which can be generated by using or extending standard ontologies available on the Web. This makes it possible to ask Web agent queries such as “Find me all graduate students in Maryland who are working on a project funded by DoD initiative 123-4567"", instead of simplistickeyword searches enabled by current search engines. We have also developed a web-crawling agent, Exposé, which interns SHOE knowledge from web documents, making these kinds queries a reality.",351
SHOE: A knowledge representation language for internet applications,"Jeff Heflin, James Hendler, Sean Luke",1999/10/28,"Description It is our contention that the World Wide Web poses challenges to knowledge representation systems that fundamentally change the way we should design KR languages.  In this paper, we describe the Simple HTML Ontology Extensions (SHOE), a KR language which allows web pages to be annotated with semantics. We present a formalism for the language and discuss the features which make it well suited for the Web. We describe the syntax and semantics of this language, and discuss the differences from traditional KR systems that make it more suited to modern web applications. We also describe some generic tools for using the language and demonstrate its capabilities by describing two prototype systems that use it.  We also discuss some future tools currently being developed for the language.  The language, tools, and details of the applications are all available on the World Wide Web at http://www.cs.umd.edu/projects/plus/SHOE. (Also cross-referenced as UMIACS-TR-99-71)","It is our contention that the World Wide Web poses challenges to knowledge representation systems that fundamentally change the way we should design KR languages.  In this paper, we describe the Simple HTML Ontology Extensions (SHOE), a KR language which allows web pages to be annotated with semantics. We present a formalism for the language and discuss the features which make it well suited for the Web. We describe the syntax and semantics of this language, and discuss the differences from traditional KR systems that make it more suited to modern web applications. We also describe some generic tools for using the language and demonstrate its capabilities by describing two prototype systems that use it.  We also discuss some future tools currently being developed for the language.  The language, tools, and details of the applications are all available on the World Wide Web at http://www.cs.umd.edu/projects/plus/SHOE. (Also cross-referenced as UMIACS-TR-99-71)",341
Lexicographic parsimony pressure,"Sean Luke, Liviu Panait",2002/7/9,Book Proceedings of the 4th Annual Conference on Genetic and Evolutionary Computation,"We introduce a technique called lexicographic parsimony pressure, for controlling the significant growth of genetic programming trees during the course of an evolutionary computation run. Lexicographic parsimony pressure modifies selection to prefer smaller trees only when fitnesses are equal (or equal in rank). This technique is simple to implement and is not affected by specific differences in fitness values, but only by their relative ranking. In two experiments we show that lexicographic parsimony pressure reduces tree size while maintaining good fitness values, particularly when coupled with Kozastyle maximum tree depth limits.",303
Genetic programming needs better benchmarks,"James McDermott, David R White, Sean Luke, Luca Manzoni, Mauro Castelli, Leonardo Vanneschi, Wojciech Jaskowski, Krzysztof Krawiec, Robin Harper, Kenneth De Jong, Una-May O'Reilly",2012/7/7,Book Proceedings of the 14th annual conference on Genetic and evolutionary computation,"Genetic programming (GP) is not a field noted for the rigor of its benchmarking. Some of its benchmark problems are popular purely through historical contingency, and they can be criticized as too easy or as providing misleading information concerning real-world performance, but they persist largely because of inertia and the lack of good alternatives. Even where the problems themselves are impeccable, comparisons between studies are made more difficult by the lack of standardization. We argue that the definition of standard benchmarks is an essential step in the maturation of the field. We make several contributions towards this goal. We motivate the development of a benchmark suite and define its goals; we survey existing practice; we enumerate many candidate benchmarks; we report progress on reference implementations; and we set out a concrete plan for gathering feedback from the GP community that …",280
Evolving teamwork and coordination with genetic programming,"Sean Luke, Lee Spector",1996/7/28,Journal Genetic Programming,"Some problems can be solved only by multi–agent teams. In using genetic programming to produce such teams, one faces several design decisions. First, there are questions of team diversity and of breeding strategy. In one commonly used scheme, teams consist of clones of single individuals; these individuals breed in the normal way and are cloned to form teams during fitness evaluation. In contrast, teams could also consist of distinct individuals. In this case one can either allow free interbreeding between members of different teams, or one can restrict interbreeding in various ways. A second design decision concerns the types of coordination–facilitating mechanisms provided to individual team members; these range from sensors of various sorts to complex communication systems. This paper examines three breeding strategies (clones, free, and restricted) and three coordination mechanisms (none, deictic sensing, and name–based sensing) for evolving teams of agents in the Serengeti world, a simple predator/prey environment. Among the conclusions are the fact that a simple form of restricted interbreeding outperforms free interbreeding in all teams with distinct individuals, and the fact that name–based sensing consistently outperforms deictic sensing.",271
Ecj: A java-based evolutionary computation research system,"Sean Luke, Liviu Panait, Gabriel Balan, Sean Paus, Zbigniew Skolicki, Jeff Bassett, Robert Hubley, A Chircop",2006/2,Journal Downloadable versions and documentation can be found at the following url: http://cs. gmu. edu/eclab/projects/ecj,,266
A comparison of bloat control methods for genetic programming,"Sean Luke, Liviu Panait",2006/9,Journal Evolutionary computation,"Genetic programming has highlighted the problem of bloat, the uncontrolled growth of the average size of an individual in the population. The most common approach to dealing with bloat in tree-based genetic programming individuals is to limit their maximal allowed depth. An alternative to depth limiting is to punish individuals in some way based on excess size, and our experiments have shown that the combination of depth limiting with such a punitive method is generally more effective than either alone. Which such combinations are most effective at reducing bloat? In this article we augment depth limiting with nine bloat control methods and compare them with one another. These methods are chosen from past literature and from techniques of our own devising. esting with four genetic programming problems, we identify where each bloat control method performs well on a per-problem basis, and under what …",256
Co-evolving soccer softbot team coordination with genetic programming,"Sean Luke, Charles Hohn, Jonathan Farris, Gary Jackson, James Hendler",1998,Conference RoboCup-97: Robot Soccer World Cup I 1,"In this paper we explain how we applied genetic programming to behavior-based team coordination in the RoboCup Soccer Server domain. Genetic programming is a promising new method for automatically generating functions and algorithms through natural selection. In contrast to other learning methods, genetic programming's automatic programming makes it a natural approach for developing algorithmic robot behaviors. The RoboCup Soccer Server was a very challenging domain for genetic programming, but we were pleased with the results. At the end, genetic programming had produced teams of soccer softbots which had learned to cooperate to play a good game of simulator soccer.",245
Better GP benchmarks: community survey results and proposals,"David R White, James McDermott, Mauro Castelli, Luca Manzoni, Brian W Goldman, Gabriel Kronberger, Wojciech Jaśkowski, Una-May O’Reilly, Sean Luke",2013/3,Journal Genetic Programming and Evolvable Machines,"We present the results of a community survey regarding genetic programming benchmark practices. Analysis shows broad consensus that improvement is needed in problem selection and experimental rigor. While views expressed in the survey dissuade us from proposing a large-scale benchmark suite, we find community support for creating a “blacklist” of problems which are in common use but have important flaws, and whose use should therefore be discouraged. We propose a set of possible replacement problems.",236
Genetic programming produced competitive soccer softbot teams for robocup97,Sean Luke,1998/7/22,Journal Genetic Programming,"At RoboCup, teams of autonomous robots or software softbots compete in simulated soccer matches to demonstrate cooperative robotics techniques in a very difficult, real-time, noisy environment. At the IJCAI/RoboCup97 softbot competition, all entries but ours used human-crafted cooperative decision-making behaviors. We instead entered a softbot team whose high-level decision making behaviors had been entirely evolved using genetic programming. Our team won its first two games against human-crafted opponent teams, and received the RoboCup Scientific Challenge Award. This report discusses the issues we faced and the approach we took to use GP to evolve our robot soccer team for this difficult environment.",194
Two fast tree-creation algorithms for genetic programming,Sean Luke,2000/9,Journal IEEE Transactions on Evolutionary Computation,"Genetic programming is an evolutionary optimization method that produces functional programs to solve a given task. These programs commonly take the form of trees representing LISP s-expressions, and a typical evolutionary run produces a great many of these trees. For this reason, a good tree-generation algorithm is very important to genetic programming. This paper presents two new tree-generation algorithms for genetic programming and for ""strongly typed"" genetic programming, a common variant. These algorithms are fast, allow the user to request specific tree sizes, and guarantee probabilities of certain nodes appearing in trees. The paper analyzes these two algorithms, and compares them with traditional and recently proposed approaches.",191
A comparison of crossover and mutation in genetic programming,"Sean Luke, Lee Spector",1997/7/13,Journal Genetic Programming,"This paper presents a large and systematic body of data on the relative effectiveness of mutation, crossover, and combinations of mutation and crossover in genetic programming (GP). The literature of traditional genetic algorithms contains related studies, but mutation and crossover in GP differ from their traditional counterparts in significant ways. In this paper we present the results from a very large experimental data set, the equivalent of approximately 12,000 typical runs of a GP system, systematically exploring a range of parameter settings. The resulting data may be useful not only for practitioners seeking to optimize parameters for GP runs, but also for theorists exploring issues such as the role of “building blocks” in GP.",168
A revised comparison of crossover and mutation in genetic programming,"Sean Luke, Lee Spector",1998/7/22,Journal Genetic Programming,"In [Luke and Spector 1997] we presented a comprehensive suite of data comparing GP crossover and point mutation over four domains and a wide range of parameter settings. Unfortunately, the results were marred by statistical flaws. This revision of the study eliminates these flaws, with three times as much the data as the original experiments had. Our results again show that crossover does have some advantage over mutation given the right parameter settings (primarily larger population sizes), though the difference between the two surprisingly small. Further, the results are complex, suggesting that the big picture is more complicated than is commonly believed.",164
A pheromone-based utility model for collaborative foraging,"Liviu Panait, Sean Luke",2004/7/23,"Conference Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems, 2004. AAMAS 2004.","Multi-agent research often borrows from biology, where remarkable examples of collective intelligence may be found. One interesting example is ant colonies’ use of pheromones as a joint communication mechanism. In this paper we propose two pheromone-based algorithms for artificial agent foraging, trail-creation, and other tasks. Whereas practically all previous work in this area has focused on biologically-plausible but ad-hoc single pheromone models, we have developed a formalism which uses multiple pheromones to guide cooperative tasks. This model bears some similarity to reinforcement learning. However, our model takes advantage of symmetries common to foraging environments which enables it to achieve much faster reward propagation than reinforcement learning does. Using this approach we demonstrate cooperative behaviors well beyond the previous ant-foraging work, including the ability to …",160
MASON: A Java multi-agent simulation library,"Sean Luke, Gabriel Catalin Balan, Liviu Panait, Claudio Cioffi-Revilla, Sean Paus",2003/10,Journal Proceedings of Agent 2003 Conference on Challenges in Social Simulation,"We present MASON, a new multiagent simulation library written for Java. MASON is a general-purpose, single-process, discrete-event simulation library intended to support diverse multiagent experiments ranging from 3D continuous robotics to social complexity networks to discretized ant foraging algorithms. MASON is of special interest to the social insect algorithm community because its primary design goal is to support very large numbers of agents efficiently. As such, MASON is faster than scripted systems such as StarLogo1 or Breve2, while still remaining portable and producing guaranteed replicable results. In other papers submitted to this workshop, we have successfully used the system to develop by hand, and to apply evolutionary computation to search for, ant foraging behaviors involving thousands of ants and multiple pheremones.",150
Ontology-based knowledge discovery on the world-wide web,"Sean Luke, Lee Spector, David Rager",1996/8/4,Journal Working Notes of the Workshop on Internet-Based Information Systems at the 13th National Conference on Artificial Intelligence (AAAI96),"This paper describes SHOE, a set of Simple HTML Ontology Extensions. SHOE allows World-Wide Web authors to annotate their pages with ontology-based knowledge about page contents. We present examples showing how the use of SHOE can support a new generation of knowledge-based search and knowledge discovery tools that operate on the WorM-Wide Web.",146
Evolving graphs and networks with edge encoding: Preliminary report,"Sean Luke, Lee Spector",1996/7/28,Journal Late breaking papers at the genetic programming 1996 conference,"We present an alternative to the cellular encoding technique [Gruau 1992] for evolving graph and network structures via genetic programming. The new technique, called edge encoding, uses edge operators rather than the node operators of cellular encoding. While both cellular encoding and edge encoding can produce all possible graphs, the two encodings bias the genetic search process in different ways; each may therefore be most useful for a different set of problems. The problems for which these techniques may be used, and for which we think edge encoding may be particularly useful, include the evolution of recurrent neural networks, finite automata, and graph-based queries to symbolic knowledge bases. In this preliminary report we present a technical description of edge encoding and an initial comparison to cellular encoding. Experimental investigation of the relative merits of these encoding schemes is currently in progress.",142
SHOE 1.01. Proposed specification,"Sean Luke, Jeff Heflin",2000/2,Journal Shoe Project,,125
Fighting bloat with nonparametric parsimony pressure,"Sean Luke, Liviu Panait",2002,"Conference Parallel Problem Solving from Nature—PPSN VII: 7th International Conference Granada, Spain, September 7–11, 2002 Proceedings 7","Many forms of parsimony pressure are parametric, that is final fitness is a parametric model of the actual size and raw fitness values. The problem with parametric techniques is that they are hard to tune to prevent size from dominating fitness late in the evolutionary run, or to compensate for problem-dependent nonlinearities in the raw fitness function. In this paper we briefly discuss existing bloat-control techniques, then introduce two new kinds of non-parametric parsimony pressure, Direct and Proportional Tournament. As their names suggest, these techniques are based on simple modifications of tournament selection to consider both size and fitness, but not together as a combined parametric equation. We compare the techniques against, and in combination with, the most popular genetic programming bloat-control technique, Koza-style depth limiting, and show that they are effective in limiting size while …",119
Theoretical advantages of lenient q-learners: An evolutionary game theoretic perspective,"Liviu Panait, Karl Tuyls",2007/5/14,Book Proceedings of the 6th international joint conference on Autonomous agents and multiagent systems,"This paper presents the dynamics of multiple reinforcement learning agents from an Evolutionary Game Theoretic (EGT) perspective. We provide a Replicator Dynamics model for traditional multiagent Q-learning, and we extend these differential equations to account for lenient learners: agents that forgive possible mistakes of their teammates that resulted in lower rewards. We use this extended formal model to visualize the basins of attraction of both traditional and lenient multiagent Q-learners in two benchmark coordination problems. The results indicate that lenience provides learners with more accurate estimates for the utility of their actions, resulting in higher likelihood of convergence to the globally optimal solution. In addition, our research supports the strength of EGT as a backbone for multiagent reinforcement learning.",113
SHOE: A blueprint for the semantic web,"Jeff Heflin, James A Hendler, Sean Luke",2003/2/21,Journal Spinning the Semantic Web,"The World Wide Web is a vast repository of information, but its utility is restricted by limited facilities for searching and integrating this information. The problem of making sense of the Web has engaged the minds of numerous researchers from fields such as databases, artificial intelligence, and library science, and these researchers have applied numerous approaches in an attempt to solve it. Tim Berners-Lee, inventor of the Web, has coined the term"" Semantic Web"" to describe a vision of the future in which the"" web of links"" is replaced with a"" web of meaning."" In this chapter, we examine the thesis that the"" the Semantic Web can be achieved if we describe web resources in a language that makes their meaning explicit."" Any language for the Semantic Web must take into account the nature of the Web. Let's consider some of the issues that arise: 1. The Web is distributed. One of the driving factors in the proliferation of the Web is the freedom from a centralized authority. However, since the Web is the product of many individuals, the lack of central control presents many challenges for reasoning with the information it presents. First, different communities will use different vocabularies, resulting in problems of synonymy (when two different words have the same meaning) and polysemy (when the same word is used with different meanings). Second, the",109
"Issues in scaling genetic programming: breeding strategies, tree generation, and code bloat",Sean Luke,2000,"Institution University of Maryland, College Park",,108
An overview of cooperative and competitive multiagent learning,"Pieter Jan ’t Hoen, Karl Tuyls, Liviu Panait, Sean Luke, Johannes A La Poutre",2006,"Source Learning and Adaption in Multi-Agent Systems: First International Workshop, LAMAS 2005, Utrecht, The Netherlands, July 25, 2005, Revised Selected Papers"," Multi-agent systems (MASs) is an area of distributed artificial intelligence that emphasizes the joint behaviors of agents with some degree of autonomy and the complexities arising from their interactions. The research on MASs is intensifying, as supported by a growing number of conferences, workshops, and journal papers. In this survey we give an overview of multi-agent learning research in a spectrum of areas, including reinforcement learning, evolutionary computation, game theory, complex systems, agent modeling, and robotics.",105
Biasing coevolutionary search for optimal multiagent behaviors,"Liviu Panait, Sean Luke, R Paul Wiegand",2006/11/30,Journal IEEE Transactions on Evolutionary Computation,"Cooperative coevolutionary algorithms (CEAs) offer great potential for concurrent multiagent learning domains and are of special utility to domains involving teams of multiple agents. Unfortunately, they also exhibit pathologies resulting from their game-theoretic nature, and these pathologies interfere with finding solutions that correspond to optimal collaborations of interacting agents. We address this problem by biasing a cooperative CEA in such a way that the fitness of an individual is based partly on the result of interactions with other individuals (as is usual), and partly on an estimate of the best possible reward for that individual if partnered with its optimal collaborator. We justify this idea using existing theoretical models of a relevant subclass of CEAs, demonstrate how to apply biasing in a way that is robust with respect to parameterization, and provide some experimental evidence to validate the biasing …",95
Coping with changing ontologies in a distributed environment,"Jeff Heflin, James Hendler, Sean Luke",1999/7/18,Journal AAAI-99 Workshop on Ontology Management,"We discuss the problems associated with versioning ontologies in distributed environments. This is an important issue because ontologies can be of great use in structuring and querying intemet information, but many of the Intemet’s characteristics, such as distributed ownership, rapid evolution, and heterogeneity, make ontology management difficult. We present SHOE, a web-based knowledge representation language that supports multiple versions of ontologies. We then discuss the features of SHOE that address ontology versioning, the affects of ontology revision on SHOE web pages, and methods for implementing ontology integration using SHOE’s extension and version mechanisms.",95
A survey and comparison of tree generation algorithms,"Sean Luke, Liviu Panait",2001/7/7,Book Proceedings of the 3rd Annual Conference on Genetic and Evolutionary Computation,"This paper discusses and compares five major tree-generation algorithms for genetic programming, and their effects on fitness: RAMPED HALF-AND-HALF, PTC1, PTC2, RANDOMBRANCH, and UNIFORM. The paper compares the performance of these algorithms on three genetic programming problems (11-Boolean Multiplexer, Artificial Ant, and Symbolic Regression), and discovers that the algorithms do not have a significant impact on fitness. Additional experimentation shows that tree size does have an important impact on fitness, and further that the ideal initial tree size is very different from that used in traditional GP.",94
Reading between the lines: Using shoe to discover implicit knowledge from the web,"Jeff Heflin, James Hendler, Sean Luke",1998,Journal AAAI-98 Workshop on AI and Information Integration,"This paper describes how SHOE, a set of Simple HTML Ontological Extensions, can be used to discover implicit knowledge from the World-Wide Web (WWW). SHOE allows authors to annotate their pages with ontology-based knowledge about page contents. In previous papers, we discussed how the semantic knowledge provided by SHOE allows users to issue queries that are much more sophisticated than keyword search techniques, including queries that require retrieval of information from many sources. Here, we expand upon this idea by describing how SHOE’s ontologies allow agents to understand more than what is explicitly stated in Web pages through the use of context, inheritance and inference. We use examples to illustrate the usefulness of these features to Web agents and query engines.",92
Code growth is not caused by introns,Sean Luke,2000/7/8,Journal Late Breaking Papers at the 2000 Genetic and Evolutionary Computation Conference,"Genetic programming trees have a strong tendency to grow rapidly and relatively independent of fitness, a serious flaw which has received considerable attention in the genetic programming literature. Much of this literature has implicated introns, subtree structures with no effect on the an individual’s fitness assessment. The propagation of inviable code, a certain kind of intron, has been especially linked to tree growth. However this paper presents evidence which shows that denying inviable code the opportunity to propagate actually increases tree growth. The paper argues that rather than causing tree growth, a rise in inviable code is in fact an expected result of tree growth. Lastly, this paper proposes a more general theory of growth for which introns are merely a symptom.",89
Ant foraging revisited,"Liviu Panait, Sean Luke",2004/9,Journal proceedings of the Ninth International Conference on the Simulation and Synthesis of Living Systems (ALIFE9),"Most previous artificial ant foraging algorithms have to date relied to some degree on a priori knowledge of the environment, in the form of explicit gradients generated by the nest, by hard-coding the nest location in an easily-discoverable place, or by imbuing the artificial ants with the knowledge of the nest direction. In contrast, the work presented solves ant foraging problems using two pheromones, one applied when searching for food and the other when returning food items to the nest. This replaces the need to use complicated nest-discovery devices with simpler mechanisms based on pheromone information, which in turn reduces the ant system complexity. The resulting algorithm is orthogonal and simple, yet ants are able to establish increasingly efficient trails from the nest to the food in the presence of obstacles. The algorithm replaces the blind addition of new amounts of pheromones with an adjustment mechanism that resembles dynamic programming.",88
Evolving kernels for support vector machine classification,"Keith M Sullivan, Sean Luke",2007/7/7,Book Proceedings of the 9th annual conference on Genetic and evolutionary computation,"While support vector machines (SVMs) have shown great promise in supervised classification problems, researchers have had to rely on expert domain knowledge when choosing the SVM's kernel function. This project seeks to replace this expert with a genetic programming (GP) system. Using strongly typed genetic programming and principled kernel closure properties, we introduce a new algorithm, called KGP, which finds near-optimal kernels. The algorithm shows wide applicability, but the combined computational overhead of GP and SVMs remains a major unresolved issue.",84
Multiagent soft q-learning,"Ermo Wei, Drew Wicke, David Freelan, Sean Luke",2018/4/25,Journal arXiv preprint arXiv:1804.09817,"Policy gradient methods are often applied to reinforcement learning in continuous multiagent games. These methods perform local search in the joint-action space, and as we show, they are susceptable to a game-theoretic pathology known as relative overgeneralization. To resolve this issue, we propose Multiagent Soft Q-learning, which can be seen as the analogue of applying Q-learning to continuous controls. We compare our method to MADDPG, a state-of-the-art approach, and show that our method achieves better coordination in multiagent cooperative tasks, converging to better local optima in the joint action space.",79
Three RoboCup simulation league commentator systems,"Elisabeth André, Kim Binsted, Kumiko Tanaka-Ishii, Sean Luke, Gerd Herzog, Thomas Rist",2000/3/15,Journal AI Magazine,"Three systems that generate real-time natural language commentary on the RoboCup simulation league are presented, and their similarities, differences, and directions for the future discussed. Although they emphasize different aspects of the commentary problem, all three systems take simulator data as input and generate appropriate, expressive, spoken commentary in real time.",78
Multiagent simulation and the MASON library,Sean Luke,2011/8,Journal George Mason University,"MASON is a multiagent simulation toolkit designed to support large numbers of agents relatively efficiently on a single machine. MASON has no domain-specific features: it is not a robotics simulator like TeamBots or Player/Stage, nor is it a game library. Instead it belongs in the class of domain-independent simulators which might be unfairly described as “dots on a screen” simulators, such as Repast, Ascape, StarLogo, NetLogo, and of course, the venerable SWARM. I call these simulators “ultra-lightweight” multiagent simulation toolkits. They’re popular for problems which involve many relatively simple agents and arbitrary problems, and are common in areas like artificial life, population biology, computational social sciences, complexity science, artificial intelligence, and (in my case) swarm robotics and mulitrobotics.",77
Cultural transmission of information in genetic programming,"Lee Spector, Sean Luke",1996/7/28,Journal Genetic Programming 1996: Proceedings of the First Annual Conference,"This paper shows how the performance of a genetic programming system can be improved through the addition of mechanisms for nongenetic transmission of information between individuals (culture). Teller has previously shown how genetic programming systems can be enhanced through the addition of memory mechanisms for individual programs [Teller 1994]; in this paper we show how Teller’s memory mechanism can be changed to allow for communication between individuals within and across generations. We show the effects of indexed memory and culture on the performance of a genetic programming system on a symbolic regression problem, on Koza’s Lawnmower problem, and on Wumpus world agent problems. We show that culture can reduce the computational effort required to solve all of these problems. We conclude with a discussion of possible improvements to the technique.",77
Lenient learning in independent-learner stochastic cooperative games,"Ermo Wei, Sean Luke",2016/1/1,Journal The Journal of Machine Learning Research,"We introduce the Lenient Multiagent Reinforcement Learning 2 (LMRL2) algorithm for independent-learner stochastic cooperative games. LMRL2 is designed to overcome a pathology called relative overgeneralization, and to do so while still performing well in games with stochastic transitions, stochastic rewards, and miscoordination. We discuss the existing literature, then compare LMRL2 against other algorithms drawn from the literature which can be used for games of this kind: traditional (“Distributed”) Q-learning, Hysteretic Q-learning, WoLF-PHC, SOoN, and (for repeated games only) FMQ. The results show that LMRL2 is very effective in both of our measures (complete and correct policies), and is found in the top rank more often than any other technique. LMRL2 is also easy to tune: though it has many available parameters, almost all of them stay at default settings. Generally the algorithm is optimally tuned with a single parameter, if any. We then examine and discuss a number of side-issues and options for LMRL2.",76
When short runs beat long runs,Sean Luke,2001/7/7,Book Proceedings of the 3rd Annual Conference on Genetic and Evolutionary Computation,"What will yield the best results: doing one run n generations long or doing m runs n/m generations long each? This paper presents a techniqueindependent analysis which answers this question, and has direct applicability to scheduling and restart theory in evolutionary computation and other stochastic methods. The paper then applies this technique to three problem domains in genetic programming. It discovers that in two of these domains there is a maximal number of generations beyond which it is irrational to plan a run; instead it makes more sense to do multiple shorter runs.",72
Archive-based cooperative coevolutionary algorithms,"Liviu Panait, Sean Luke, Joseph F Harrison",2006/7/8,Book Proceedings of the 8th annual conference on Genetic and evolutionary computation,"Archive-based cooperative coevolutionary algorithms attempt to retain a set of individuals which act as good collaborators for other coevolved individuals in the evolutionary system. We introduce a new archive-based algorithm, called iCCEA, which compares favorably with other cooperative coevolutionary algorithms. We explain the current problems with cooperative coevolution which have given rise to archive methods, detail the iCCEA algorithm, compare it against other traditional and archive-based methods on basic problem domains, and discuss the reasons behind the performance of various algorithms.",65
History-based traffic control,"Gabriel Balan, Sean Luke",2006/5/8,Book Proceedings of the fifth international joint conference on Autonomous agents and multiagent systems,"What if traffic lights gave you a break after you've spent a long time waiting in traffic elsewhere? In this paper we examine a variety of multi-agent traffic light controllers which consider vehicles' past stopped-at-red histories. For example, a controller might distribute credits to cars as they wait and award the green light to lanes with the most credits, allowing cars to keep the credits they accumulate during travel. Such history-based controllers are intended to provide a kind of global fairness, reducing the variance in mean time spent waiting at lights during trips. We compare these controllers against other multi-agent controllers which only consider present information, and discover, among other things, that while the history-based controllers are among the most robust, they often unexpectedly provide more efficiency than fairness.",65
Tunably decentralized algorithms for cooperative target observation,"Sean Luke, Keith Sullivan, Liviu Panait, Gabriel Balan",2005/7/25,Book Proceedings of the fourth international joint conference on Autonomous agents and multiagent systems,"Multi-agent problem domains may require distributed algorithms for a variety of reasons: local sensors, limitations of communication, and availability of distributed computational resources. In the absence of these constraints, centralized algorithms are often more efficient, simply because they are able to take advantage of more information. We introduce a variant of the cooperative target observation domain which is free of such constraints. We propose two algorithms, inspired by K-means clustering and hill-climbing respectively, which are scalable in degree of decentralization. Neither algorithm consistently outperforms the other across over all problem domain settings. Surprisingly, we find that hill-climbing is sensitive to degree of decentralization, while K-means is not. We also experiment with a combination of the two algorithms which draws strength from each.",62
A comparison of two competitive fitness functions,"Liviu Panait, Sean Luke",2002/7/9,Book Proceedings of the 4th Annual Conference on Genetic and Evolutionary Computation,"Competitive fitness is the assessment of an individual’s fitness in the context of competition with other individuals in the evolutionary system. This commonly takes one of two forms: one-population competitive fitness, where competition is solely between individuals in the same population; and N-population competitive fitness, often termed competitive coevolution. In this paper we discuss common topologies for one-population competitive fitness functions, then test the performance of two such topologies, Single-Elimination Tournament and K-Random Opponents, on four problem domains. We show that neither of the extremes of K-Random Opponents (Round Robin and Random-Pairing) gives the best results when using limited computational resources. We also show that while Single-Elimination Tournament usually outperforms variations of K-Random Opponents in noise-free problems, it can suffer from premature convergence in noisy domains.",61
Character design for soccer commentary,"Kim Binsted, Sean Luke",1999,Conference RoboCup-98: Robot Soccer World Cup II 2,"In this paper we present early work on an animated talking head commentary system called Byrne. The goal of this project is to develop a system which can take the output from the RoboCup soccer simulator, and generate appropriate affective speech and facial expressions, based on the character’s personality, emotional state, and the state of play. Here we describe a system which takes pre-analysed simulator output as input, and which generates text marked-up for use by a speech generator and a face animation system. We make heavy use of inter-system standards, so that future versions of Byrne will be able to take advantage of advances in the technologies that it incorporates.",61
GeoMason: Geospatial support for MASON,"Keith Sullivan, Mark Coletti, Sean Luke",2010,"Publisher Department of Computer Science, George Mason University","MASON is a free, open-source Java-based discrete event multi-agent simulation toolkit that has been used to model network intrusions, unmanned aerial vehicles, nomadic migrations, and farmer/herder conflicts, among others. Many multi-agent models use georeferenced data which represent such things as road networks, rivers, vegetation coverage, population, and topology. However, MASON does not directly support georeferenced data. Therefore practitioners using MASON must hand craft such support, which may be difficult and error prone. In this paper we describe newly added geospatial functionality in MASON that addresses this problem. We discuss the design of this functionality, called GeoMASON, and its use and limitations. Finally, we give examples on how to import and manipulate georeferenced data.",59
Lenient learners in cooperative multiagent systems,"Liviu Panait, Keith Sullivan, Sean Luke",2006/5/8,Book Proceedings of the fifth international joint conference on Autonomous agents and multiagent systems,"In concurrent learning algorithms, an agent's perception of the joint search space depends on the actions currently chosen by the other agents. These perceptions change as each agent's action selection is influenced by its learning. We observe that agents that show lenience to their teammates achieve more accurate perceptions of the overall learning task. Additionally, lenience appears more beneficial at early stages of learning, when the agent's teammates are merely exploring their actions, and less helpful as the agents start to converge. We propose two multiagent learning algorithms where agents exhibit a variable degree of lenience, and we demonstrate their advantages in several coordination problems.",59
Alternative bloat control methods,"Liviu Panait, Sean Luke",2004,"Conference Genetic and Evolutionary Computation–GECCO 2004: Genetic and Evolutionary Computation Conference, Seattle, WA, USA, June 26-30, 2004. Proceedings, Part II","Bloat control is an important aspect of evolutionary computation methods, such as genetic programming, which must deal with genomes of arbitrary size. We introduce three new methods for bloat control: Biased Multi-Objective Parsimony Pressure (BMOPP), the Waiting Room, and Death by Size. These methods are unusual approaches to bloat control, and are not only useful in various circumstances, but two of them suggest novel approaches to attack the problem. BMOPP is a more traditional parsimony-pressure style bloat control method, while the other two methods do not consider parsimony as part of the selection process at all, but instead penalize for parsimony at other stages in the evolutionary process. We find parameter settings for BMOPP and the Waiting Room which are effective across all tested problem domains. Death by Size does not appear to have this consistency, but we find it a useful …",58
Applying ontology to the web: A case study,"Jeff Heflin, James Hendler, Sean Luke",1999,"Conference Engineering Applications of Bio-Inspired Artificial Neural Networks: International Work-Conference on Artificial and Natural Neural Networks, IWANN'99 Alicante, Spain, June 2–4, 1999 Proceedings, Volume II 5","This paper describes the use of Simle HTML Ontology Extensions (SHOE) in a real world internet application. SHOE allows authors to add semantic content to web pages and to relate this content to common ontologies that provide contextual information about the domain. Using this information, query systems can provide more accurate responses than are possible with the search engines available on the Web. We have applied these techniques to the domain of Transmissible Spongiform Encephalopathies (TSEs), a class of diseases that include “Mad Cow Disease”. We discuss our experiences and provides lessons learned from the process.",56
"Essentials of metaheuristics. Lulu, 2009",Sean Luke,2011,Journal Available for free at http://cs. gmu. edu/sean/book/metaheuristics/. There is no corresponding record for this reference,,55
Modification point depth and genome growth in genetic programming,Sean Luke,2003/3,Journal Evolutionary Computation,"The evolutionary computation community has shown increasing interest in arbitrary-length representations, particularly in the field of genetic programming. A serious stumbling block to the scalability of such representations has been  bloat : uncontrolled genome growth during an evolutionary run. Bloat appears across the evolutionary computation spectrum, but genetic programming has given it by far the most attention. Most genetic programming models explain this phenomenon as a result of the growth of  introns , areas in an individual which serve no functional purpose. This paper presents evidence which directly contradicts intron theories as applied to tree-based genetic programming. The paper then uses data drawn from this evidence to propose a new model of genome growth. In this model, bloat in genetic programming is a function of the mean depth of the modification (crossover or mutation) point. Points …",55
"""Genetic” programming","Sean Luke, Shugo Hamahashi, Hiroaki Kitano",1999,Journal Proceedings of the Genetic and Evolutionary Computation Conference,"Much of evolutionary computation was inspired by Mendelian genetics. But modern genetics has since advanced considerably, revealing that genes are not simply parameter settings, but interactive cogs in a complex chemical machine. At the same time, an increasing number of evolutionary computation domains are evolving non-parameterized mechanisms such as neural networks or symbolic computer programs. As such, we think modern biological genetics offers much in helping us understand how to evolve such things. In this paper, we present a gene regulation model for Drosophila melanogaster. We then apply gene regulation to evolve deterministic finite-state automata, and show that our approach does well compared to past examples from the literature.",55
ECJ: a java-based evolutionary computation and genetic programming research system,"Sean Luke, Liviu Panait, J Bassett, R Hubley, C Balan, A Chircop",2009,"Journal Disponıvel em http://www. cs. umd. edu/projetc/plus/ec/ecj/, última visita em",,54
Replication of Sugarscape using MASON,"Anthony Bigbee, Claudio Cioffi-Revilla, Sean Luke",2007,Conference Agent-Based Approaches in Economic and Social Complex Systems IV: Post-Proceedings of The AESCS International Workshop 2005,"The purpose of this research was to replicate the Sugarscape model (Eptstein and Axtell 1996) and simulation outcomes as described in Growing Artificial Societies (GAS). Sugarscape is a classic agent-based model and contemporary simulation toolkits usually only have a very simple replication of a few core rules. There is scant evidence of significant replication of the rules and simulation outcomes; code supplied with Repast, Swarm, and NetLogo implement a minority of the rules in Sugarscape. In particular, the standard Repast distribution only implements Growback, Movement, and Replacement. Sugarscape implementations in these toolkits are clearly provided only as basic demonstrations of how wellknown social models might be implemented, rather than complete achievements of scientific replication.",52
ECJ then and now,Sean Luke,2017/7/15,Book Proceedings of the genetic and evolutionary computation conference companion,"ECJ is a mature and widely used evolutionary computation library with particular strengths in genetic programming, massive distributed computation, and coevolution. In Fall of 2016 we received a three-year NSF grant to expand ECJ into a toolkit with wide-ranging facilities designed to serve the broader metaheuristics community. This report discusses ECJ's history, capabilities, and architecture, then details our planned extensions and expansions.",51
Essentials of metaheuristics: a set of undergraduate lecture notes,Sean Luke,2015,Publisher editor no identificat,,51
Population implosion in genetic programming,"Sean Luke, Gabriel Catalin Balan, Liviu Panait",2003,"Conference Genetic and Evolutionary Computation—GECCO 2003: Genetic and Evolutionary Computation Conference Chicago, IL, USA, July 12–16, 2003 Proceedings, Part II","With the exception of a small body of adaptive-parameter literature, evolutionary computation has traditionally favored keeping the population size constant through the course of the run. Unfortunately, genetic programming has an aging problem: for various reasons, late in the run the technique become less effective at optimization. Given a fixed number of evaluations, allocating many of them late in the run may thus not be a good strategy. In this paper we experiment with gradually decreasing the population size throughout a genetic programming run, in order to reallocate more evaluations to early generations. Our results show that over four problem domains and three different numbers of evaluations, decreasing the population size is always as good as, and frequently better than, various fixed-sized population strategies.",49
Improving coevolutionary search for optimal multiagent behaviors,"Liviu Panait, R Paul Wiegand, Sean Luke",2003/8/9,Conference IJCAI,"Evolutionary computation is a useful technique for learning behaviors in multiagent systems. Among the several types of evolutionary computation, one natural and popular method is to coevolve multiagent behaviors in multiple, cooperating populations. Recent research has suggested that coevolutionary systems may favor stability rather than performance in some domains. In order to improve upon existing methods, this paper examines the idea of modifying traditional coevolution, biasing it to search for maximal rewards. We introduce a theoretical justification of the improved method and present experiments in three problem domains. We conclude that biasing can help coevolution find better results in some multiagent problem domains.",48
Is the perfect the enemy of the good?,"Sean Luke, Liviu Panait",2002/7/9,Book Proceedings of the 4th Annual Conference on Genetic and Evolutionary Computation,"Much of the genetic programming literature compares techniques using counts of ideal solutions found. These counts in turn form common comparison measures such as Koza’s Computational Effort or Cumulative Probability of Success. The use of these measures continues despite past warnings that they are not statistically valid. In this paper we too criticize the measures for serious statistical problems, and also argue that their motivational justification is faulty. We then present evidence suggesting that idealsolution counts are not necessarily positively related to best-fitness-of-run statistics: in fact they are often inversely correlated. Thus claims based on ideal-solution counts can mislead readers into thinking techniques will provide superior final results, when in fact the opposite is true.",48
When coevolutionary algorithms exhibit evolutionary dynamics,"Sean Luke, R Paul Wiegand",2002/9/3,Journal 2002 Genetic and Evolutionary Computation Conference Workshop Program,"The task of understanding the dynamics of coevolutionary algorithms or comparing performance between such algorithms is complicated by the fact the internal fitness measures are subjective. Though a variety of techniques have been proposed to use external or objective measures to help in analysis, there are clearly properties of fitness payoff (eg, intransitivity) which call such methods into question in certain contexts. We present a model of competitive fitness assessment with a single population and non-parametric selection (such as tournament selection), and show minimum conditions and examples under which an objective measure exists, and when the dynamics of the coevolutionary algorithm are identical to those of a traditional EA. We also discuss terminological difficulties in the coevolution literature, and present a detailed description of external measures presently in use in the literature.",43
ECJ at 20: toward a general metaheuristics toolkit,"Eric O Scott, Sean Luke",2019/7/13,Book Proceedings of the genetic and evolutionary computation conference companion,"ECJ is now 20 years old. Begun as a genetic programming and evolutionary computation library in Java, it has since established itself as historically one of the most popular EC toolkits worldwide. In 2016 we received a National Science Foundation grant to improve ECJ in many ways with an eye toward making it a useful toolkit not just for EC but for the broader metaheuristics community. This paper is a report on our efforts to this end. We discuss new metaheuristics frameworks and representations added to ECJ and the design challenges that they raise for a general-purpose framework, as well as testing facilities and other support tools. We conclude with our future directions for the library.",42
Agent-based modeling simulation of social adaptation and long-term change in inner Asia,"Claudio Cioffi-Revilla, Sean Luke, Dawn C Parker, J Daniel Rogers, William W Fitzhugh, William Honeychurch, Bruno Fröhlich, Paula De Priest, Chunag Amartuvshin",2007,Journal Advancing social simulation: the first world congress,"We present a new international project to develop temporally and spatially calibrated agent-based models of the rise and fall of polities in Inner Asia (Central Eurasia) in the past 5,000 years. Gaps in theory, data, and computational models for explaining long-term sociopolitical change—both growth and decay—motivate this project. We expect three contributions: (1) new theoreticallygrounded simulation models validated and calibrated by the best available data; (2) a new long-term cross-cultural database with several data sets; and (3) new conceptual, theoretical, and methodological contributions for understanding social complexity and long-term change and adaptation in real and artificial societies. Our theoretical framework is based on explaining sociopolitical evolution by the process of “canonical variation”.",42
Culture enhances the evolvability of cognition,"Lee Spector, Sean Luke",2019/2/21,Book Proceedings of the Eighteenth Annual Conference of the Cognitive Science Society,"This paper discusses the role of culture in the evolution of cognitive systems. We define ""culture"" as any information transmitted between individuals and between generations by non-genetic means. Experiments are presented that use genetic programming systems that include special mechanisms for cultural transmission of information. These systems evolve computer programs that perform cognitive tasks including mathematical function mapping and action selection in a virtual world. The data show that the presence of culture-supporting mechanisms can have a clear beneficial impact on the evolvability of correct programs. The implications that these results may have for cognitive science are briefly discussed.",39
A sensitivity analysis of a cooperative coevolutionary algorithm biased for optimization,"Liviu Panait, R Paul Wiegand, Sean Luke",2004,"Conference Genetic and Evolutionary Computation–GECCO 2004: Genetic and Evolutionary Computation Conference, Seattle, WA, USA, June 26-30, 2004. Proceedings, Part I","Recent theoretical work helped explain certain optimization-related pathologies in cooperative coevolutionary algorithms (CCEAs). Such explanations have led to adopting specific and constructive strategies for improving CCEA optimization performance by biasing the algorithm toward ideal collaboration. This paper investigates how sensitivity to the degree of bias (set in advance) is affected by certain algorithmic and problem properties. We discover that the previous static biasing approach is quite sensitive to a number of problem properties, and we propose a stochastic alternative which alleviates this problem. We believe that finding appropriate biasing rates is more feasible with this new biasing technique.",36
Collaborative foraging using beacons,"Brian Hrolenok, Sean Luke, Keith Sullivan, Christopher Vo",2010/5/10,Book Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems: volume 3-Volume 3,"A classic example of multiagent coordination in a shared environment involves the use of pheromone deposits as a communication mechanism. Due to physical limitations in deploying actual pheromones, we propose a sparse representation of the pheromones using movable beacons. There is no communication between the beacons to propagate pheromones; instead, robots make movement and update decisions based entirely on local pheromone values. Robots deploy the beacons throughout the environment, and subsequently move them and update them using a variation of value iteration. Simulation results show that our approach is effective at finding good trails, locally improving them, and adapting to dynamic changes in the environments.",35
Bounty hunters and multiagent task allocation,"Drew Wicke, David Freelan, Sean Luke",2015/5/4,Book Proceedings of the 2015 international conference on autonomous agents and multiagent systems,"We propose a system for multiagent task allocation inspired by the model used by bounty hunters and bail bondsmen. A bondsman posts tasks for agents to complete, along with bounties to be collected by an agent on completion. Multiple agents, taking the role of the bounty hunters, compete to finish tasks and collect their bounties. While a task remains uncompleted, its bounty gradually rises, making it more and more desirable to pursue. Unlike auctions, this model does not assume rationality in agents’ bids (as there are none), and since tasks are not exclusive to given agents, the system is robust to highly noisy environments. We examine how agents may locally develop rational task valuations in such an environment, gradually adapting to dividing tasks according to the agents best suited to them. We compare different methods for building these valuations against approaches which are more “auction-like” in that they permit exclusivity, and we do so under both static environments and ones in which agents, and task details, change dynamically.",34
The Perfect C. ELEGANS Project: An Initial Report,"Hiroaki Kitano, Shugo Hamahashi, Sean Luke",1998/4,Journal Artificial Life,"The soil nematode  Caenorhabditis Elegans (C. elegans)  is the most investigated of all multicellular organisms. Since the proposal to use it as a model organism, a series of research projects have been undertaken, investigating various aspects of this organism. As a result, the complete cell lineage, neural circuitry, and various genes and their functions have been identified. The complete  C. elegans  DNA sequencing and gene expression mapping for each cell at different times during embryogenesis will be identified in a few years. Given the abundance of collected data, we believe that the time is ripe to introduce synthetic models of  C. elegans  to further enhance our understanding of the underlying principles of its development and behavior. For this reason, we have started the Perfect  C. elegans  Project, which aims to produce ultimately a complete synthetic model of  C. elegans ' cellular structure and function …",34
A visual demonstration of convergence properties of cooperative coevolution,"Liviu Panait, R Paul Wiegand, Sean Luke",2004,"Conference Parallel Problem Solving from Nature-PPSN VIII: 8th International Conference, Birmingham, UK, September 18-22, 2004. Proceedings 8","We introduce a model for cooperative coevolutionary algorithms (CCEAs) using partial mixing, which allows us to compute the expected long-run convergence of such algorithms when individuals’ fitness is based on the maximum payoff of some N evaluations with partners chosen at random from the other population. Using this model, we devise novel visualization mechanisms to attempt to qualitatively explain a difficult-to-conceptualize pathology in CCEAs: the tendency for them to converge to suboptimal Nash equilibria. We further demonstrate visually how increasing the size of N, or biasing the fitness to include an ideal-collaboration factor, both improve the likelihood of optimal convergence, and under which initial population configurations they are not much help.",32
Time-dependent Collaboration Schemes for Cooperative Coevolutionary Algorithms.,"Liviu Panait, Sean Luke",2005/11,Conference AAAI Fall Symposium: Coevolutionary and Coadaptive Systems,Cooperative coevolutionary algorithms are a popular approach to learning via problem decomposition. One important aspect of cooperative coevolutionary algorithms concerns how to select collaborators for computing the fitness of individuals in different populations. We argue that using a fixed number of collaborators during the entire search may be suboptimal. We experiment with a simple ad-hoc scheme that varies the numbers of collaborators over time. Empirical comparisons in a series of problem domains indicate that decreasing the numbers of collaborators over time fares better than keeping the number fixed. We conclude with a brief discussion of our findings and suggest directions for future research.,31
Shoe: A prototype language for the semantic web,"Jeff Heflin, James Hendler, Sean Luke",2001,Publisher Linköping University Electronic Press,"The term Semantic Web was coined by Tim Berners-Lee to describe his proposal for\a web of meaning,"" as opposed to the\web of links"" that currently exists on the Internet. To achieve this vision, we need to develop languages and tools that enable machine understandable web pages. The SHOE project, begun in 1995, was one of the first to begin exploring these issues. In this paper, we describe our experiences developing and using the SHOE language. We begin by describing the unique features of the World Wide Web and how they must influence potential Semantic Web languages. We then discuss why web standards such as XML and RDF are currently insufficient for the Semantic Web. We present SHOE, a language which allows web pages to be annotated with semantics, describe its syntax and semantics, and discuss our approaches to handling characteristics of the Web such as distributed authority and rapid evolution. We discuss the implementation issues of such a language, and describe some generic tools that we have built to aid in its use. Finally, we demonstrate the language and tools by applying them to two different domains. The language, tools, and details of the applications are all available on the World Wide Web at http://www. cs. umd. edu/projects/plus/SHOE/.",28
Mnemonic structure and sociality: A computational agent-based simulation model,"Claudio Cioffi-Revilla, Sean Paus, Sean Luke, James L Olds, Jason Thomas",2004,Journal Proceedings of the Conference on Collective Intentionality IV,"How does group memory affect sociality? Most computational multi-agent social simulation models are designed with agents lacking explicit internal information-processing structure in terms of basic cognitive elements. In particular, memory is usually not explicitly modeled. We present initial results from a new prototype called “Wetlands”, designed to investigate the effect of group memory structures and interaction situations on emergent patterns of sociality or collective intentionality. Specifically, we report on initial computational experiments conducted on culturally-differentiated agents endowed with finite and degradable memory that simulate bounded mnemonic function and forgetfulness. Our main initial findings are that memory capacity and engram retention both promote sociality among groups, probably as nonlinear (inverse) functions. Wetlands 1.1 is implemented in the new MASON 3 (Multi-Agent Simulator of Networks and Neighborhoods) computational environment developed at George Mason University.",26
"The MASON simulation toolkit: past, present, and future","Sean Luke, Robert Simon, Andrew Crooks, Haoliang Wang, Ermo Wei, David Freelan, Carmine Spagnuolo, Vittorio Scarano, Gennaro Cordasco, Claudio Cioffi-Revilla",2019,"Conference Multi-Agent-Based Simulation XIX: 19th International Workshop, MABS 2018, Stockholm, Sweden, July 14, 2018, Revised Selected Papers 19","MASON is a widely-used open-source agent-based simulation toolkit that has been in constant development since 2002. MASON’s architecture was cutting-edge for its time, but advances in computer technology now offer new opportunities for the ABM community to scale models and apply new modeling techniques. We are extending MASON to provide these opportunities in response to community feedback. In this paper we discuss MASON, its history and design, and how we plan to improve and extend it over the next several years. Based on user feedback will add distributed simulation, distributed GIS, optimization and sensitivity analysis tools, external language and development environment support, statistics facilities, collaborative archives, and educational tools.",25
Evolving soccerbots: A retrospective,Sean Luke,1998/6/16,Journal Proceedings of the 12th Annual Conference of the Japanese Society for Artificial Intelligence,"In the RoboCup97 robot soccer tournament, we entered a team of softbot programs whose player strategies had been entirely learned by computer. Our team beat other human-coded competitors and received the RoboCup97 Scientific Challenge award. This paper discusses our approach, and details various ways that, in retrospect, it could have been improved.",24
Learning from demonstration with swarm hierarchies,"Keith Sullivan, Sean Luke",2012/6/4,Book Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems-Volume 1,"We present a supervised learning from demonstration system capable of training stateful and recurrent collective behaviors for multiple agents or robots. A model space of this kind is often high-dimensional and consequently may require a large number of samples to learn. Furthermore, the inverse problem posed by emergent macrophenomena among multiple agents presents major challenges to supervised learning methods. Our approach reduces the size of the state space, and shortens the gap between individual behaviors and macrophenomena, by manually decomposing individual behaviors and arranging the agents into a tree hierarchy. This makes it possible to train potentially large numbers of agents using a small number of samples. We demonstrate our system using hundreds of agents in a simulated foraging task, and on real robots performing a collective patrolling task.",23
Hierarchical approaches for reinforcement learning in parameterized action space,"Ermo Wei, Drew Wicke, Sean Luke",2018/10/23,Journal arXiv preprint arXiv:1810.09656,"We explore Deep Reinforcement Learning in a parameterized action space. Specifically, we investigate how to achieve sample-efficient end-to-end training in these tasks. We propose a new compact architecture for the tasks where the parameter policy is conditioned on the output of the discrete action policy. We also propose two new methods based on the state-of-the-art algorithms Trust Region Policy Optimization (TRPO) and Stochastic Value Gradient (SVG) to train such an architecture. We demonstrate that these methods outperform the state of the art method, Parameterized Action DDPG, on test domains.",22
Selecting informative actions improves cooperative multiagent learning,"Liviu Panait, Sean Luke",2006/5/8,Book Proceedings of the fifth international joint conference on Autonomous agents and multiagent systems,"In concurrent cooperative multiagent learning, each agent simultaneously learns to improve the overall performance of the team, with no direct control over the actions chosen by its teammates. An agent's action selection directly influences the rewards received by all the agents, resulting in a co-adaptation among the concurrent learning processes. Co-adaptation can drive the team towards suboptimal solutions because agents tend to select those actions that are rewarded better, without any consideration for how such actions may affect the search of their teammates. We argue that to counter this tendency, agents should also prefer actions that inform their teammates about the structure of the joint search space in order to help them choose from among various action options. We analyze this approach in a cooperative coevolutionary framework, and we propose a new algorithm, iCCEA, that highlights the …",22
Methods for evolving robust programs,"Liviu Panait, Sean Luke",2003,"Conference Genetic and Evolutionary Computation—GECCO 2003: Genetic and Evolutionary Computation Conference Chicago, IL, USA, July 12–16, 2003 Proceedings, Part II","Many evolutionary computation search spaces require fitness assessment through the sampling of and generalization over a large set of possible cases as input. Such spaces seem particularly apropos to Genetic Programming, which notionally searches for computer algorithms and functions. Most existing research in this area uses ad-hoc approaches to the sampling task, guided more by intuition than understanding. In this initial investigation, we compare six approaches to sampling large training case sets in the context of genetic programming representations. These approaches include fixed and random samples, and adaptive methods such as coevolution or fitness sharing. Our results suggest that certain domain features may lead to the preference of one approach to generalization over others. In particular, coevolution methods are strongly domain-dependent. We conclude the paper with suggestions …",22
Towards rapid multi-robot learning from demonstration at the robocup competition,"David Freelan, Drew Wicke, Keith Sullivan, Sean Luke",2015,Conference RoboCup 2014: Robot World Cup XVIII 18,"We describe our previous and current efforts towards achieving an unusual personal RoboCup goal: to train a full team of robots directly through demonstration, on the field of play at the RoboCup venue, how to collaboratively play soccer, and then use this trained team in the competition itself. Using our method, HiTAB, we can train teams of collaborative agents via demonstration to perform nontrivial joint behaviors in the form of hierarchical finite-state automata. We discuss HiTAB, our previous efforts in using it in RoboCup 2011 and 2012, recent experimental work, and our current efforts for 2014, then suggest a new RoboCup Technical Challenge problem in learning from demonstration.",21
Lenience towards teammates helps in cooperative multiagent learning,"Liviu Panait, Keith Sullivan, Sean Luke",2006/5,Journal Proceedings of the Fifth International Joint Conference on Autonomous Agents and Multi Agent Systems–AAMAS-2006,"Concurrent learning is a form of cooperative multiagent learning in which each agent has an independent learning process and little or no control over its teammates’ actions. In such learning algorithms, an agent’s perception of the joint search space depends on the reward received by both agents, which in turn depends on the actions currently chosen by the other agents. The agents will tend to converge towards certain areas of the space because of their learning processes. As a result, an agent’s perception of the search space may benefit if computed over multiple rewards at early stages of learning, but additional rewards have little impact towards the end. We thus suggest that agents should be lenient with their teammates: ignore many of the low rewards initially, and fewer rewards as learning progresses. We demonstrate the benefit of lenience in a cooperative coevolution algorithm and in a new reinforcement learning algorithm.",21
Hierarchical learning from demonstration on humanoid robots,"Keith Sullivan, Sean Luke, Vittoria Amos Ziparo",2010,Journal Proceedings of Humanoid Robots Learning from Human Interaction Workshop,"Developing behaviors for humanoid robots is difficult due to the high complexity of programming these robots, which includes repeated trial and error cycles. We have recently developed a learning from demonstration system capable of training agent behaviors from a small number of training examples. Our system represents a complex behavior as a hierarchical finite automaton, permitting decomposition of the behavior into simple, easier-to-train sub-behaviors. The system was originally designed for swarms of virtual agents, but based on recent Robocup experience, we have ported the system to our humanoid robot platform. We discuss the system and the platform, and preliminary experiments involving both novice and expert users in a stateful visual servoing task.",18
Web agents that work,"Sean Luke, James Hendler",1997/7,Journal IEEE multimedia,"Intelligent search applications are the future direction for the World Wide Web and for the Internet in general, but without the ability to gather and understand exact information about multimedia data and documents, making these applications a reality will be difficult. In the future, we may have the technology necessary to read human-oriented multimedia documents. Making the Web less agent-hostile takes great strides toward that goal today.",18
Swarm robot foraging with wireless sensor motes,"Katherine Russell, Michael Schader, Kevin Andrea, Sean Luke",2015/5/4,Book Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems,"We investigate the use of wireless sensor motes as mobile deployable waypoints for swarm robot navigation in a foraging scenario. Each robot can deploy, retrieve, and optimize the location of the sensor motes. After deployment, the robots treat the sensor motes as nodes in a sparse graph, and store and retrieve multiple pheromones and flags locally in each of them. Pheromone information stored in the sensor motes allows the robots to build up gradients to different targets of interest, and to determine which sensor motes are good candidates to optimize location, or to harvest for reuse elsewhere. Unlike many earlier pheromone-based foraging techniques, our method must deal with the physical reality of deploying and manipulating sensor motes, including a limited mote supply both onboard and in total, robustly dealing with occlusion and interference from other robots, and handling noise and robot or mote failure. We demonstrate the effectiveness of the technique both on differential drive robots of our own design, and in simulation, to examine its ability to robustly deal with various failure modes and changes in environment.",15
Large scale empirical analysis of cooperative coevolution,"Sean Luke, Keith Sullivan, Faisal Abidi",2011/7/12,Book Proceedings of the 13th annual conference companion on Genetic and evolutionary computation,"We present a study of cooperative coevolution applied to moderately complex optimization problems in large-population environments. The study asks three questions. First: what collaboration methods perform best, and when? Second: how many subpopulations are desirable? Third: is it worthwhile to do more than one trial per fitness evaluation? We discovered that parallel methods tended to work better than sequential ones, that ""shuffling"" (a collaboration method) predominated in performance in more complex problems, that more subpopulations generally did better, and that more trials performed marginally better.",14
Learn to behave! rapid training of behavior automata,"Sean Luke, Vittorio Amos Ziparo",2010/5/10,Journal Proceedings of adaptive and learning agents workshop at aamas,"Programming robot or virtual agent behaviors can be a challenging task, and makes attractive the prospect of automatically learning the behaviors from the actions of a human demonstrator. However, learning complex behaviors rapidly from a demonstrator may be difficult if they demand a large number of training samples. We describe an architecture for rapid learning of recurrent behaviors from demonstration. The architecture is based on deterministic hierarchical finitestate automata (HFAs) with classification algorithms taking the place of the state transition function. This architecture allows for task decomposition, statefulness, parameterized features and behaviors, per-behavior feature set customization, and storage of learned behaviors in libraries to be used later on as elements in more complex behaviors. We describe the system, then illustrate its application in a simple, but nontrivial, foraging task involving multiple behaviors.",14
Guaranteeing Coevolutionary Objective Measures.,"Sean Luke, R Paul Wiegand",2002,Conference FOGA,"The task of understanding the dynamics of coevolutionary algorithms or comparing performance between such algorithms is complicated by the fact the internal fitness measures are subjective. Though several techniques have been proposed to use external or objective measures to help in analysis, there are clearly properties of fitness payoff, like intransitivity, for which these techniques are ineffective. We feel that a principled approach to this problem is to first establish the theoretical bounds to guarantee objective measures in one CEA model; from there one can later examine the effects of deviating from the assumptions made by these bounds. To this end, we present a model of competitive fitness assessment with a single population and non-parametric selection (such as tournament selection), and show minimum conditions and examples under which an objective measure exists, and when the dynamics of the coevolutionary algorithm are identical to those of a traditional EA.",14
Is the meta-EA a viable optimization method?,"Sean Luke, AKM Khaled Ahsan Talukder",2013/7/6,Book Proceedings of the 15th annual conference on Genetic and evolutionary computation,"Meta-evolutionary algorithms have long been proposed as an approach to automatically discover good parameter settings to use in later optimization runs. In this paper we instead ask whether a meta-evolutionary algorithm makes sense as an optimizer in its own right. That is, we're not interested in the resulting parameter settings, but only in the final result. As it so happens, this use of meta-EAs make sense in the context of large numbers of parallel runs, particularly in massive distributed scenarios. A primary issue facing meta-EAs is the stochastic nature of the meta-level fitness function. We consider whether this poses a challenge to establishing a gradient in the meta-level search space, and to what degree multiple tests are helpful in smoothing the noise. We discuss the nature of the meta-level search space and its impact on local optima, then examine the degree to which exploitation can be applied. We find …",13
Real-time training of team soccer behaviors,"Keith Sullivan, Sean Luke",2013,Conference RoboCup 2012: Robot Soccer World Cup XVI 16,"Training robot or agent behaviors by example is an attractive alternative to directly coding them. However training complex behaviors can be challenging, particularly when it involves interactive behaviors involving multiple agents. We present a novel hierarchical learning from demonstration system which can be used to train both single-agent and scalable cooperative multiagent behaviors. The methodology applies manual task decomposition to break the complex training problem into simpler parts, then solves the problem by iteratively training each part. We discuss our application of this method to multiagent problems in the humanoid RoboCup competition, and apply the technique to the keepaway soccer problem in the RoboCup Soccer Simulator.",12
MASON NorthLands: A geospatial agent-based model of coupled human-artificial-natural systems in boreal and arctic regions,"Claudio Cioffi-Revilla, J Daniel Rogers, Paul Schopf, Sean Luke, Jeff Bassett, Atesmachew Hailegiorgis, William Kennedy, Peter Froncek, Meghan Mulkerin, Madeline Shaffer, Ermo Wei",2015,Journal European Social Simulation Association (ESSA),"Current climate change causes significant biophysical effects in the Northern Hemisphere, especially in the Boreal and Arctic regions. Rising and more variable temperatures, permafrost thawing, and snow loading are major hazards affecting human societies on multiple spatial, temporal, and risk-related scales. The MASON NorthLands computational simulation model is motivated by fundamental science and policy research questions. Preliminary results demonstrate causal processes relating ambient and soil temperature increases to measurable social impacts, mediated by biophysical effects of climate change on the built environment, as in a coupled human-artificial-natural system (CHANS).",11
Opportunistic evolution: efficient evolutionary computation on large-scale computational grids,"Keith Sullivan, Sean Luke, Curt Larock, Sean Cier, Steven Armentrout",2008/7/12,Book Proceedings of the 10th annual conference companion on Genetic and evolutionary computation,"We examine opportunistic evolution, a variation of master-slave distributed evaluation designed for deployment of evolutionary computation to very large grid computing architectures with limited communications, severe evaluation overhead, and wide variance in evaluation node speed. In opportunistic evolution, slaves receive some N individuals at a time, evaluate them, and then run those individuals through their own mini evolutionary loop until some fixed wall clock time has been exceeded. Our implementation of opportunistic evolution may be used in conjunction with either a generational or, for maximum throughput, an asynchronous steady-state evolutionary model in the master. Opportunistic evolution is strongly exploitative. We perform initial experiments comparing the technique with a traditional master/slave model, and suggest possible classes of problems for which it might be apropos.",11
Mason,"Sean Luke, Gabriel Catalin Balan, Keith Sullivan, Liviu Panait",2003,"Journal Evolutionary Computation Lab and Center for Social Complexity, George Mason University, Fairfax, VA, USA, http://cs. gmu. edu/eclab/projects/mason","It’s time to make your plans for attending the 160th Annual Grand Lodge Communication, back in the Twin Cities area again for 2013. Open to ALL Masons, as is the annual Grand Lodge banquet on Friday, April 12th, the 2013 session promises to be a very worthwhile event. All Lodge officers and members are urged to bring their wives, who are invited to attend the banquet and the breakout sessions and to take part in other ladies’ activities. Grand Master Brian E. Beermann urges all Minnesota Lodges to send their full quota of delegates to the 2013 meeting. While the Masters and Wardens are the voting delegates, any Master Mason in good standing is welcome to attend any and all events. Anyone wishing to attend meal events should contact the Grand Lodge office to receive the event registration form; phone 952-948-6700 or 800-245-6050 or by e-mail grandlodge@ qwest. net. Invitations and personalized …",11
Multiobjective optimization of co-clustering ensembles,"Francesco Gullo, AKM Khaled Talukder, Sean Luke, Carlotta Domeniconi, Andrea Tagarelli",2012/7/7,Book Proceedings of the 14th annual conference companion on Genetic and evolutionary computation,"Co-clustering is a machine learning task where the goal is to simultaneously develop clusters of the data and of their respective features. We address the use of co-clustering ensembles to establish a consensus co-clustering over the data. In this paper we develop a new preference-based multiobjective optimization algorithm to compete with a previous gradient ascent approach in finding optimal co-clustering ensembles. Unlike the gradient ascent algorithm, our approach once tackles the co-clustering problem with multiple heuristics, then applies the gradient ascent algorithm's joint heuristic as a preference selection procedure. We are able to significantly outperform the gradient ascent algorithm on feature clustering and on problems with smaller datasets.",10
Empirical study on the effects of synthetic social structures on teams of autonomous vehicles,"Adam Campbell, Annie S Wu, Keith Garfield, Randall Shumaker, Sean Luke, Kenneth A De Jong",2006/4/23,"Conference 2006 IEEE International Conference on Networking, Sensing and Control",The goal of this research is to explore the effects of social interactions between individual autonomous vehicles (AVs) in various problem scenarios. We take a look at one way to construct the social relationships and generate data from computer simulations to compare the behaviors of each. A difference can be noticed when synthetic social structures (SSS) are used to control the interactions between neighboring AVs. Our experiments show that SSSs can be used to improve team performance on a problem in which a team of AVs must maneuver through a narrow corridor to reach a goal,10
Training heterogeneous teams of robots,"Keith Sullivan, Ermo Wei, Bill Squires, Drew Wicke, Sean Luke",2015,Journal Autonomous Robots and Multirobot Systems (ARMS),"Heterogeneous multi-robot teams are common solutions to complex tasks, especially those that are inherently cooperative. Training robots, rather than coding them, to work together in these teams is an attractive prospect, but is very difficult due to the extremely large state space and the inherent inverse problem which separates the agents’ micro-level behaviors and the desired macro-level emergent phenomenon. We approach this problem with HiTAB, a learning from demonstration system which uses behavior decomposition to allow rapid training of teams with minimal samples. This paper presents and compares two approaches to training teams of heterogenous robots: first, forming a multiagent control hierarchy which scales to large numbers of robots but requires the training of additional virtual controller agents; and second, modifying each robot’s feature space to include information about other robots’ current behaviors or limited internal state.",9
Evolutionary computation and the C-value paradox,Sean Luke,2005/6/25,Book Proceedings of the 7th annual conference on Genetic and evolutionary computation,"The C-value Paradox is the name given in biology to the wide variance in and often very large amount of DNA in eukaryotic genomes and the poor correlation between DNA length and perceived organism complexity. Several hypotheses exist which purport to explain the Paradox. Surprisingly there is a related phenomenon in evolutionary computation, known as code bloat, for which a different set of hypotheses has arisen. This paper describes a new hypothesis for the C-value Paradox derived from models of code bloat. The new explanation is that there is a selective bias in preference of genetic events which increase DNA material over those which decrease it. The paper suggests one possible concrete mechanism by which this may occur: deleting strands of DNA is more likely to damage genomic material than migrating or copying strands. The paper also discusses other hypotheses in biology and in …",9
Assisted parameter and behavior calibration in agent-based models with distributed optimization,"Matteo D’Auria, Eric O Scott, Rajdeep Singh Lather, Javier Hilty, Sean Luke",2020,"Conference Advances in Practical Applications of Agents, Multi-Agent Systems, and Trustworthiness. The PAAMS Collection: 18th International Conference, PAAMS 2020, L'Aquila, Italy, October 7–9, 2020, Proceedings 18","Agent-based modeling (ABM) has many applications in the social sciences, biology, computer science, and robotics. One of the most important and challenging phases in agent-based model development is the calibration of model parameters and agent behaviors. Unfortunately, for many models this step is done by hand in an ad-hoc manner or is ignored entirely, due to the complexity inherent in ABM dynamics. In this paper we present a general-purpose, automated optimization system to assist the model developer in the calibration of ABM parameters and agent behaviors. This system combines two popular tools: the MASON agent-based modeling toolkit and the ECJ evolutionary optimization library. Our system distributes the model calibration task over very many processors and provides a wide range of stochastic optimization algorithms well suited to the calibration needs of agent-based models.",8
Cooperative coevolution and univariate estimation of distribution algorithms,"Christopher Vo, Liviu Panait, Sean Luke",2009/1/9,Book Proceedings of the tenth ACM SIGEVO workshop on Foundations of genetic algorithms,"In this paper, we discuss a curious relationship between Cooperative Coevolutionary Algorithms (CCEAs) and univariate Estimation of Distribution Algorithms (EDAs). Specifically, the distribution model for univariate EDAs is equivalent to the infinite population EGT model common in the analysis of CCEAs. This relationship may permit cross-pollination between these two disparate fields. As an example, we derive a new EDA based on a known CCEA from the literature, and provide some preliminary experimental analysis of the algorithm.",8
Collaborative multi-agent learning: A survey,"L Panait, Sean Luke",2003,"Journal Department of Computer Science, George Mason University, Tech. Rep","The field of Multiagent Systems is concerned with domains where several agents interact while solving competitive or cooperative tasks. Increasingly complex problem domains involving non-trivial numbers of agents revealed inherent difficulties with creating such systems. As such, the field witnessed a recent increased interest in Machine Learning techniques, capable of easing the programming efforts for approaching more challenging domains.",8
RoboPatriots: George Mason University 2010 RoboCup Team,"Keith Sullivan, Christopher Vo, Sean Luke, Jyh-Ming Lien",2010,Journal Workshop Robocup Singapore,"The RoboPatriots from George Mason University are a team of three humanoid robots. As we are interested in embodied AI, our robots are based on commercially available equipment. We use the three on-board computers for research into learning from demonstration, a supervised machine learning technique for training robot behavior. RoboCup 2012 marks the fourth year of participation for the RoboPatriots: in 2009 and 2010, we advanced to the second round, and in 2011 we were eliminated in the first round.",6
Replicating the classic Sugarscape in MASON,"Tony Bigbee, Claudio Cioffi-Revilla, Sean Luke",2006/5/16,"Journal Complex Behavior in Economics: Modeling, Computing and Mastering Complexity. Third Aix en Provence Complexity Workshop (COMPLEXITY2006), Aix-en-Provence, France","Replication is essential in science and agent-based computational social science is no exception. We present results from a replication of the Sugarscape model (Eptstein and Axtell, 1996) as initially presented in Growing Artificial Societies (GAS). Sugarscape is a classic agent-based model and contemporary simulation toolkits usually only have a partial replication consisting of a few core model rules without documenting simulation outcomes; code supplied with Repast, Swarm, and NetLogo, for example implement very few of the rules in Sugarscape. By contrast, we demonstrate a detailed replication of Sugarscape in the MASON (Multi-Agent Simulator of Neighborhoods and Networks) environment, and describe various outcomes such migration waves. For major outcomes documenteed in GAS, we describe the degree to which we replicated those results and conclude by outlining major challenges in replication activities and the young field of agent-based modeling in general.",6
Unlearning from demonstration,"Keith Sullivan, Ahmed ElMolla, Bill Squires, Sean Luke",2013/6/30,Conference Twenty-Third International Joint Conference on Artificial Intelligence,"When doing learning from demonstration, it is often the case that the demonstrator provides corrective examples to fix errant behavior by the agent or robot. We present a set of algorithms which use this corrective data to identify and remove noisy examples in datasets which caused errant classifications, and ultimately errant behavior. The objective is to actually modify the source datasets rather than solely rely on the noise-insensitivity of the classification algorithm. This is particularly useful in the sparse datasets often found in learning from demonstration experiments. Our approach tries to distinguish between noisy misclassification and mere undersampling of the learning space. If errors are a result of misclassification, we potentially remove the responsible points and update the classifier. We demonstrate our method on UCI Machine Learning datasets at different levels of sparsity and noise, using decision trees, K-Nearest-Neighbor, and support vector machines.",5
Long-term fairness with bounded worst-case losses,"Gabriel Balan, Dana Richards, Sean Luke",2011/1,Journal Autonomous Agents and Multi-Agent Systems,"How does one repeatedly choose actions so as to be fairest to the multiple beneficiaries of those actions? We examine approaches to discovering sequences of actions for which the worst-off beneficiaries are treated maximally well, then secondarily the second-worst-off, and so on. We formulate the problem for the situation where the sequence of action choices continues forever; this problem may be reduced to a set of linear programs. We then extend the problem to situations where the game ends at some unknown finite time in the future. We demonstrate that an optimal solution is intractable, and present two good approximation algorithms.",5
Finding interesting things,"Sean Luke, Deepankar Sharma, Gabriel Catalin Balan",2007/7/7,Book Proceedings of the 9th annual conference on genetic and evolutionary computation,"Model- and simulation-designers are often interested not in the optimum output of their system, but in understanding how the output is sensitive to different parameters. This can require an inefficient sweep of a multidimensional parameter space, with many samples tested in regions of the space where the output is essentially all the same, or a sparse sweep which misses crucial ""interesting"" regions where the output is strongly sensitive. In this paper we introduce a novel population-oriented approach to adaptive parameter sweeping which focuses its samples on these sensitive areas. The method is easy to implement and model-free, and does not require any previous knowledge about the space. In a weakened form the method can operate in non-metric spaces such as the space of genetic program trees. We demonstrate the method on three test problems, showing that it identifies regions of the space where the …",5
Planner-guided robot swarms,"Michael Schader, Sean Luke",2020,"Conference Advances in Practical Applications of Agents, Multi-Agent Systems, and Trustworthiness. The PAAMS Collection: 18th International Conference, PAAMS 2020, L'Aquila, Italy, October 7–9, 2020, Proceedings 18","Robot swarms have many virtues for large-scale task execution: this includes redundancy, a high degree of parallel task implementation, and the potential to jointly complete jobs that a single agent could not do. But because of their distributed nature, robot swarms face challenges in large-scale coordination, task serialization or ordering, and synchronization. We investigate the use of a central automated planner to guide a robot swarm to perform complicated, multistep operations normally beyond the capabilities of purely decentralized swarms. The planner orchestrates the actions of task groups of agents, while preserving swarm virtues, and can operate over a variety of swarm communication and coordination modalities. We demonstrate the effectiveness of the technique in simulation with three swarm robotics scenarios.",4
Stochastic synthesizer patch exploration in edisyn,Sean Luke,2019,"Conference Computational Intelligence in Music, Sound, Art and Design: 8th International Conference, EvoMUSART 2019, Held as Part of EvoStar 2019, Leipzig, Germany, April 24–26, 2019, Proceedings 8","Edisyn is a music synthesizer program (or “patch”) editor library which enables musicians to easily edit and manipulate a variety of difficult-to-program synthesizers. Edisyn sports a first-in-class set of tools designed to help explore the parameterized space of synthesizer patches without needing to directly edit the parameters. This paper discusses the most sophisticated of these tools, Edisyn’s Hill-Climber and Constrictor methods, which are based on interactive evolutionary computation techniques. The paper discusses the special difficulties encountered in programming synthesizers, the motivation behind these techniques, and their design. It then evaluates them in an experiment with novice synthesizer users, and concludes with additional observations regarding utility and efficacy.",4
RoboCup 2015: Robot World Cup XIX,"Luis Almeida, Jianmin Ji, Gerald Steinbauer, Sean Luke",2016/1/29,Volume 9513,"This book is the Proceedings of the 19th Annual RoboCup International Symposium, held in Hefei, China, in July 2015. The book contains 20 papers presented at the Symposium, carefully selected from 39 submissions. Additionally the book contains 11 champion team papers and one paper from the Workshop on Benchmarking Service Robots. The papers present current research in robotics, artificial intelligence, computer vision, multiagent systems, simulation, and other areas.",4
Throwing in the towel: Faithless bounty hunters as a task allocation mechanism,"Drew Wicke, Ermo Wei, Sean Luke",2016,Journal IJCAI workshop on Interactions with Mixed Agent Types,"Bounty hunting has been shown to solve the multiagent task allocation problem robustly in noisy and dynamic scenarios with multiple other agents of unknown quality. This bounty hunting model does not require task exclusivity, but does require task commitment. We examine eliminating this second requirement, thus allowing bounty hunters to commit to tasks but abandon them later (to jump ship) for more promising tasks, without telling other agents of their intent. Bounty hunting agents must use an adaptive valuation mechanism in order to avoid too much redundancy in working on tasks. We examine how one might revise this mechanism in the face of task abandonment. We compare jumping ship favorably against other bounty hunting methods and against methods which are more “auction-like” in that they permit exclusivity, and we do so under both static environments and ones in which agents, and task scenarios, change dynamically.",4
Scalability in the MASON multi-agent simulation system,"Haoliang Wang, Ermo Wei, Robert Simon, Sean Luke, Andrew Crooks, David Freelan, Carmine Spagnuolo",2018/10/15,Conference 2018 IEEE/ACM 22nd International Symposium on Distributed Simulation and Real Time Applications (DS-RT),"This paper describes Distributed MASON, a distributed version of the MASON agent-based simulation tool. Distributed MASON is architected to take advantage of well known principles from Parallel and Discrete Event Simulation, such as the use of Logical Processes (LP) as a method for obtaining scalable and high performing simulation systems. We first explain data management and sharing between LPs and describe our approach to load balancing. We then present both a local greedy approach and a global hierarchical approach. Finally, we present the results of our implementation of Distributed MASON on an instance in the Amazon Cloud, using several standard multi-agent models. The results indicate that our design is highly scalable and achieves our expected levels of speed-up.",3
Bounty Hunting and Human-Agent Group Task Allocation.,"Drew Wicke, Sean Luke",2017/10/9,Conference AAAI Fall Symposia,"Much research has been done to apply auctions, markets, and negotiation mechanisms to solve the multiagent task allocation problem. However, there has been very little work on human-agent group task allocation. We believe that the notion of bounty hunting has good properties for human-agent group interaction in dynamic task allocation problems. We use previous experimental results comparing bounty hunting with auction-like methods to argue why it would be particularly adept at handling scenarios with unreliable collaborators and unexpectedly hard tasks: scenarios we believe highlight difficulties involved in working with humans collaborators.",3
Can good learners always compensate for poor learners?,"Keith Sullivan, Liviu Panait, Gabriel Balan, Sean Luke",2006/5/8,Book Proceedings of the fifth international joint conference on Autonomous agents and multiagent systems,"Can a good learner compensate for a poor learner when paired in a coordination game? Previous work presented an example where a special learning algorithm (FMQ) is capable of doing just that when paired with a specific less capable algorithm even in games which stump the poorer algorithm when paired with itself. We argue that this result is not general. We give a straightforward extension to the coordination game in which FMQ cannot compensate for the lesser algorithm. We also provide other problematic pairings, and argue that another high-quality algorithm cannot do so either.",3
Autonomous uuv control via tunably decentralized algorithms,"Keith M Sullivan, Sean Luke",2004/6/17,Conference 2004 IEEE/OES Autonomous Underwater Vehicles (IEEE Cat. No. 04CH37578),"We apply previous studied control algorithms to the cooperative target observation (CTO) task for multiple UUVs. The algorithms are based on k-means clustering and hill climbing, and each are scalable in the degree of decentralization. In the underwater formulation of the CTO problem, k-means is not sensitive to the degree of decentralization, while the hill climber is sensitive. Unlike in previous work, K-means outperformed hill-climbing across all environmental parameters.",3
Evolving foraging behaviors,"Liviu Panait, Sean Luke",2003/12/15,"Journal Proc. of the Ninth Int. Conf. on the Simulation and Synthesis of Living Systems, ALIFE-9","Insects are particularly good at cooperatively solving multiple complex tasks. For example, foraging for food far away from the nest can be solved through relatively simple behaviors in combination with communication through pheromones. As task complexity increases, however, it may become difficult to determine the proper simple rules which yield the desired emergent cooperative behavior, or to know if any such rules exist at all. For such tasks, machine learning techniques like evolutionary computation (EC) may prove a valuable approach to searching the space of possible rule combinations. The paper shows that by allowing simultaneous learning of both the pheromone-depositing and pheromone-using policies, good performing foraging behaviors can be obtained. Additionally, the learned foraging behaviors use only pheromone information to find the path to the nest and to the food source, not requiring compasses or other complex mechanisms to return back to the nest.",3
Biology: see it again-for the first time,"Sean Luke, Shugo Hamahashi, Koji Kyoda, Hiroki Ueda",1998/9,Journal IEEE Intelligent Systems and Their Applications,"Computer science owes a huge debt to biological systems. The field came about largely as an attempt to understand and replicate the function and abilities of the brain. From this early lineage have sprung many subfields derived largely from biological metaphors: computer vision, neural networks, evolutionary computation, robotics, multiagent studies, and much of artificial intelligence. In some areas, the computer has bested its biological counterparts in efficiency and simplicity. But for many domains the biological ""real thing"" remains superior to the artificial algorithms that it inspired. While computer science has been simplifying its inspirations from biology, biologists have been catching up. Soon it will be possible to model entire neurosystems, gene-regulation mechanisms, evolutionary processes and even whole organisms on a computer. Given how much biological metaphors have inspired AI and computer …",3
"Distributed, automated calibration of agent-based model parameters and agent behaviors","Matteo D'Auria, Eric O Scott, Rajdeep Singh Lather, Javier Hilty, Sean Luke",2020/7,Journal Autonomous Agents and Multiagent Systems (AAMAS),"Agent-based models can present special challenges to model calibration due in part to their high parameter count, tunable agent behaviors, complex emergent macrophenomena, and potentially long runtimes. However, due to this difficulty, these models are most often calibrated by hand, or with hand-coded optimization tools customized per-problem if at all. As simulations increase in complexity, we will require general-purpose, distributed model calibration tools tailored for the needs of agent-based models. In this paper, we present the results of a system we have developed which combines two popular tools, the MASON agent-based modeling toolkit, and the ECJ evolutionary optimization library. This system distributes the model calibration task over many processors, provides many stochastic optimization algorithms well suited to the calibration needs of agent-based models, and offers the ability to optimize not just model parameters but agent behaviors.",2
Multiagent Adversarial Inverse Reinforcement Learning.,"Ermo Wei, Drew Wicke, Sean Luke",2019/5/8,Conference AAMAS,"Learning to coordinate is a hard task for reinforcement learning due to a game-theoretic pathology known as relative overgeneralization. To help deal with this issue, we propose two methods which apply forms of imitation learning to the problem of learning coordinated behaviors. The proposed methods have a close connection to multiagent actor-critic models, and will avoid relative overgeneralization if the right demonstrations are given. We compare our algorithms with MADDPG, a state-ofthe-art approach, and show that our methods achieve better coordination in multiagent cooperative tasks.",2
Do multiple trials help Univariate methods?,"Daniel Rothman, Sean Luke, Keith Sullivan",2011/6/5,Conference 2011 IEEE Congress of Evolutionary Computation (CEC),"Cooperative Coevolutionary Algorithms (CCEAs) and Univariate Estimation of Distribution Algorithms (Univariate ED As) are closely related algorithms in that both update marginal distributions/populations, and test samples of those distributions/populations by grouping them with collaborators drawn from elsewhere to form a complete solution. Thus the quality of these samples is context-sensitive and the algorithms assume low linkage among their variables. This results in well-known difficulties with these methods. While EDAs have commonly overcome these difficulties by examining multivariate linkage, CCEAs have instead examined basing the fitness of each marginal sample on the maximum of several trials. In this study we examine whether multiple-trial CCEA approach is really effective for difficult problems and large numbers of subpopulations; and whether this approach can be used to improve Univariate …",2
Multiagent supervised training with agent hierarchies and manual behavior decomposition,"Keith Sullivan, Sean Luke",2011,Journal Proceedings of Agents Learning Interactively from Human Teachers Workshop,"We present a supervised learning from demonstration system capable of training stateful and recurrent behaviors, both in the single agent and multiagent case. Furthermore, behavior complexity due to statefulness and multiple agents can result in a high dimensional learning space, which can require many samples to learn properly. Our approach, which relies heavily on both per-agent behavior decomposition and structuring agents into a tree hierarchy, can significantly reduce the number of samples and make such training feasible. We demonstrate our system in a simulated collective foraging task where all the agents execute the same behavior set. We also discuss how to extend our approach to a heterogeneous case, where different subgroups of agents perform different behaviors.",2
Hierarchical multi-robot learning from demonstration,"Keith Sullivan, Sean Luke",2011,Journal Proceedings of the Robotics: Science and Systems Conference,"Developing robot behaviors is a tedious task requiring multiple coding, trial, and debugging cycles. This makes attractive the notion of learning from demonstration, whereby a robot learns behaviors in real time from the examples of a demonstrator. Learning from demonstration can be problematic, however, because of the number of trials necessary to gather sufficient samples to learn correctly. The problem is compounded in a multi-robot setting due to the potentially much larger design space arising from the number of and interactions between the robots. In this paper, we propose a learning from demonstration system capable of rapidly training multiple robots to perform a collaborative task. Our supervised learning method applies user domain knowledge to decompose complex behaviors into a hierarchy of simpler behaviors, which are easier to train and learn, and require many fewer samples to do so. The system further reduces the state space by only considering environmental features and actions pertinent to each decomposed simple behavior. Decomposition occurs not only within individual robot behaviors but also at the hierarchical group behavior level. Experiments using Pioneer robots in a patrol scenario illustrate our system.",2
Can you do me a favor?,"Keith Sullivan, Sean Luke, Brian Hrolenok",2010/5/10,Journal The Thirteenth International Workshop on Trust in Agent Societies TRUST-2010,"Multiagent systems often require coordination among the agents to maximize system utility. Using the notion of favors, we propose a technique, flexible reciprocal altruism, which determines when one agent should grant a favor to another agent based on past interactions. The desired rate of altruism is controllable, and as a result the loss associated with granting unmatched favors is bounded and amortized over all past interactions. In flexible reciprocal altruism the desired acceptable loss is independent of the cost and value of the favors. Experiments show that our technique performs well with different cost/value tradeoffs, numbers of agents, and load.",2
Evolving the goal priorities of autonomous agents,"Adam Campbell, Annie S Wu, Randall Shumaker, Keith Garfield, Sean Luke, Kenneth A De Jong",2006,"Journal Proc. IEEE International Conference on Networking, Sensing, and Control, Technical Report# CS-TR-06-04, School of EECS, University of Central Florida","Designing a robot control system that is able to intelligently decide how to handle prioritizing and combining the actions from multiple, conflicting goals is necessary for effective autonomous behavior. The method proposed in this paper uses a Genetic Algorithm (GA) to evolve the relative goal weights that enable agents to combine outputs from conflicting goals. Two problem scenarios are constructed to test the system, and the evolved parameters are examined in detail. We find that the GA is able to find parameter sets that allow the agents to perform well in both scenarios. Parameter sets are evolved by the GA that are difficult to hand code, indicating that evolution is a good possible solution to this problem.",2
A demonstration of neural programming applied to non-Markovian problems,"Gabriel Catalin Balan, Sean Luke",2004,"Conference Genetic and Evolutionary Computation–GECCO 2004: Genetic and Evolutionary Computation Conference, Seattle, WA, USA, June 26-30, 2004. Proceedings, Part II","Genetic programming may be seen as a recent incarnation of a long-held goal in evolutionary computation: to develop actual computational devices through evolutionary search. Genetic programming is particularly attractive because of the generality of its application, but it has rarely been used in environments requiring iteration, recursion, or internal state. In this paper we investigate a version of genetic programming developed originally by Astro Teller called neural programming. Neural programming has a cyclic graph representation which lends itself naturally to implicit internal state and recurrence, but previously has been used primarily for problems which do not need these features. In this paper we show a successful application of neural programming to various partially observable Markov decision processes, originally developed for the learning classifier system community, and which require the use of internal state and iteration.",2
Using the parka parallel knowledge representation system (version 3.2),"Brian Kettler, William Andersen, James Hendler, Sean Luke",1998/10/15,"Description Parka is a symbolic, semantic network knowledge representation system that takes advantage of the massive parallelism of supercomputers such as the Connection Machine.  The Parka language has many of the features of traditional semantic net/frame-based knowledge representation languages but also supports several kinds of rapid parallel inference mechanisms that scale to large knowledge-bases of hundreds of thousands of frames or more.  Parka is intended for general-purpose use and has been used thus far to support A.I. systems for case-based reasoning and data mining.  This document is a user manual for the current version of Parka, version 3.2.  It describes the Parka language and presents some examples of knowledge representation using Parka. Details about the parallel algorithms, implementation, and empirical results are presented elsewhere. (Also cross-referenced as UMIACS-TR-95-68)","Parka is a symbolic, semantic network knowledge representation system that takes advantage of the massive parallelism of supercomputers such as the Connection Machine.  The Parka language has many of the features of traditional semantic net/frame-based knowledge representation languages but also supports several kinds of rapid parallel inference mechanisms that scale to large knowledge-bases of hundreds of thousands of frames or more.  Parka is intended for general-purpose use and has been used thus far to support A.I. systems for case-based reasoning and data mining.  This document is a user manual for the current version of Parka, version 3.2.  It describes the Parka language and presents some examples of knowledge representation using Parka. Details about the parallel algorithms, implementation, and empirical results are presented elsewhere. (Also cross-referenced as UMIACS-TR-95-68)",2
Fully decentralized planner-guided robot swarms,"Michael Schader, Sean Luke",2021,"Conference Advances in Practical Applications of Agents, Multi-Agent Systems, and Social Good. The PAAMS Collection: 19th International Conference, PAAMS 2021, Salamanca, Spain, October 6–8, 2021, Proceedings 19","Robot swarms hold great potential for accomplishing missions in a robust, scalable, and flexible manner. However, determining what low-level agent behavior to implement in order to meet high-level objectives is an unsolved inverse problem. Building on previous work on partially-centralized planner-guided robot swarms, we present an approach that achieves total decentralization of executive and deliberator functions, adds robustness and performance optimization through dynamic task switching, and employs agent-initiated superrational planning to coordinate agent activity while responding to changes in the environment. We demonstrate the effectiveness of the technique with three swarm robotics scenarios.",1
Scalable heterogeneous multiagent learning from demonstration,"William Squires, Sean Luke",2020,"Conference Advances in Practical Applications of Agents, Multi-Agent Systems, and Trustworthiness. The PAAMS Collection: 18th International Conference, PAAMS 2020, L'Aquila, Italy, October 7–9, 2020, Proceedings 18","We present a method of supervised learning from demonstration for real-time, online training of complex heterogenous multiagent behaviors which scale to large numbers of agents in operation. Our learning method is applicable in domains where coordinated behaviors must be created quickly in unexplored environments. Examples of such problem domains includes disaster relief, search and rescue, and gaming environments. We demonstrate this training method in an adversarial mining scenario which coordinates four types of individual agents to perform six distinct roles in a mining task.",1
Dynamic traveling repairmen bounty hunters,"Drew Wicke, Ermo Wei, Sean Luke",2018/7/9,Book Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems,"Vehicle routing problems such as the multiagent dynamic traveling repariman problem (DTRP) are of interest to many fields and of increasing practical importance in light of advances in autonomous vehicles. DTRP is NP-hard, making approximation methods attractive. However, current approaches do not adequately consider issues special to DTRP, such as discontiguous-space scenarios or alternatives to equitably partitioning the task space. We tackle this problem in a novel way, using a multiagent task allocation technique called bounty hunting. In bounty hunting, agents compete to perform tasks non-exclusively in return for reward, and rapidly learn which agents are more adept at various tasks, implicitly splitting up the task space. We demonstrate that bounty hunting can perform efficiently in discontiguous environments, and Pareto-dominates the state-of-the-art heuristic technique, and is particularly good in large-scale scenarios.",1
LfD training of heterogeneous formation behaviors,"William G Squires, Sean Luke",2018/3/15,Conference 2018 AAAI Spring Symposium Series,"Problem domains such as disaster relief, search and rescue, and games can benefit from having a human quickly train coordinated behaviors for a diverse set of agents. Hierarchical Training of Agent Behaviors (HiTAB) is a Learning from Demonstration (LfD) approach that addresses some inherent complexities in multiagent learning, making it possible to train complex heterogeneous behaviors from a small set of training samples. In this paper, we successfully demonstrate LfD training of formation behaviors using a small set of agents that, without retraining, continue to operate correctly when additional agents are available. We selected training of formations for the experiments because formations: require a great deal of coordination between agents, are heterogenous due to the differing roles of participating agents, and can scale as the number of agents grows. We also introduce some extensions to HiTAB that facilitate this type of training.",1
Bounty Hunters as Dynamic Traveling Repairmen,"Drew Wicke, Ermo Wei, Sean Luke",2018,"Publisher Technical Report GMU-CS-TR-2018-2. Department of Computer Science, George Mason University, 4400 University Drive MSN 4A5, Fairfax, VA 22030-4444 USA","Vehicle routing problems such as the multiagent Dynamic Traveling Repariman Problem (DTRP) are of interest to many fields and of increasing practical importance in light of advances in autonomous vehicles. DTRP is NP-hard, making approximation methods attractive. However current heuristic approaches do not adequately consider issues special to DTRP, such as fairness and variance, discontiguous-space scenarios, or approaches to equitably partitioning the task space. We tackle this problem in a novel way, using a multiagent task allocation technique called bounty hunting. In bounty hunting, agents compete to perform tasks non-exclusively in return for reward, and rapidly learn which agents are more adept at various tasks than others, divvying up the task space. We demonstrate that bounty hunting can perform efficiently in discontiguous environments, and can improve the bias and variance of the system while minimally affecting average waiting time. We show that Bounty Hunting Pareto dominates the current state-ofthe-art heuristic, and is particularly good in large-scale scenarios.",1
RoboCup 2015: robot world cup XIX,Sean Luke,2016,Publisher Springer,,1
Future MASON Directions: Community Recommendations,"Nicolas Payette, Marius Bujorianu, Glen Ropella, Ken Cline, Jeffrey Schank, Matt Miller, Sara Jonsson, Laszlo Gulyas, Richard Legendi, Olaf Bochmann, Luıs de Sousa, Vlasios Voudouris, Daniil Kiose, Przemyslaw Szufel, Steve Saul, John McManus, Vittorio Scarano, Gennaro Cordasco, Chris Hollander, Paul Wiegand, Vera Kazakova, Brian Hrolenok, J Daniel Rogers, Michael Schader, Sean Luke, Kenneth De Jong, Mark Coletti, Paul Schopf, Claudio Cioffi-Revilla, Keith Sullivan, Khaled Talukder, Ahmed Elmolla, Ermo Wei",2013,"Journal Report of the 2013 MASON NSF Workshop, George Mason University Computer Science Technical Report","MASON is an open source multiagent simulation library geared towards simulating very large numbers of relatively lightweight interacting agents. MASON has been used for a wide variety of simulation tasks in robotics, the social sciences, biology, and animation. On June 15 and 16, 2013, approximately two dozen invitees convened at George Mason University to discuss future directions for MASON and needs of the MASON community. This meeting formed the 2013 MASON NSF Workshop, sponsored by the National Science Foundation under CRI CI-P grant 1205626. The invitees responded to a call for participation on the MASON community mailing list, among others, and those selected for participation came from a broad spectrum of fields, organizations, and countries.",1
Algorithms for leximin-optimal fair policies in repeated games,"Gabriel Balan, Dana Richards, Sean Luke",2008,"Publisher Technical Report GMU-CS-TR-2008-1, George Mason University","Solutions to non-cooperative multiagent systems often require achieving a joint policy which is as fair to all parties as possible. There are a variety of methods for determining the fairest such joint policy. One approach, min fairness, finds the policy which maximizes the minimum average reward given to any agent. We focus on an extension, leximin fairness, which breaks ties among candidate policies by choosing the one which maximizes the second-to-minimum average reward, then the thirdto-minimum average reward, and so on. This method has a number of advantages over others in the literature, but has so far been little-used because of the computational cost in employing it to find the fairest policy. In this paper we propose a linear programming based algorithm for computing leximin fairness in repeated games which has a polynomial time complexity given certain reasonable assumptions.",1
SHOE: A blueprint for the semantic web,"Jeff Heflin, James A Hendler, Sean Luke",2003/2/21,Journal Spinning the Semantic Web,"The World Wide Web is a vast repository of information, but its utility is restricted by limited facilities for searching and integrating this information. The problem of making sense of the Web has engaged the minds of numerous researchers from fields such as databases, artificial intelligence, and library science, and these researchers have applied numerous approaches in an attempt to solve it. Tim Berners-Lee, inventor of the Web, has coined the term"" Semantic Web"" to describe a vision of the future in which the"" web of links"" is replaced with a"" web of meaning."" In this chapter, we examine the thesis that the"" the Semantic Web can be achieved if we describe web resources in a language that makes their meaning explicit."" Any language for the Semantic Web must take into account the nature of the Web. Let's consider some of the issues that arise: 1. The Web is distributed. One of the driving factors in the proliferation of the Web is the freedom from a centralized authority. However, since the Web is the product of many individuals, the lack of central control presents many challenges for reasoning with the information it presents. First, different communities will use different vocabularies, resulting in problems of synonymy (when two different words have the same meaning) and polysemy (when the same word is used with different meanings). Second, the",109
SHOE: A Prototype Language for the Semantic Web,"James Hendler, Sean Luke",2001/7/16,Journal in Linköping Electronic Articles in Computer and Information Science,"The term Semantic Web was coined by Tim Berners-Lee to describe his proposal for\a web of meaning,"" as opposed to the\web of links"" that currently exists on the Internet. To achieve this vision, we need to develop languages and tools that enable machine understandable web pages. The SHOE project, begun in 1995, was one of the rst to begin exploring these issues. In this paper, we describe our experiences developing and using the SHOE language. We begin by describing the unique features of the World Wide Web and how they must in uence potential Semantic Web languages. We then discuss why web standards such as XML and RDF are currently insu cient for the Semantic Web. We present SHOE, a language which allows web pages to be annotated with semantics, describe its syntax and semantics, and discuss our approaches to handling characteristics of the Web such as distributed authority and rapid evolution. We discuss the implementation issues of such a language, and describe some generic tools that we have built to aid in its use. Finally, we demonstrate the language and tools by applying them to two di erent domains. The language, tools, and details of the applications are all available on the World Wide Web at http://www. cs. umd. edu/projects/plus/SHOE/.",1
Coevolving soccer softbots,Sean Luke,1998/9/15,Journal AI Magazine,"1. Author (s) agree to transfer their copyrights in their article/paper to the Association for the Advancement of Artificial Intelligence (AAAI), in order to deal with future requests for reprints, translations, anthologies, reproductions, excerpts, and other publications. This grant will include, without limitation, the entire copyright in the article/paper in all countries of the world, including all renewals, extensions, and reversions thereof, whether such rights current exist or hereafter come into effect, and also the exclusive right to create electronic versions of the article/paper, to the extent that such right is not subsumed under copyright.",1
Parka Parallel Knowledge Representation System,"Brian Kettler, William Andersen, James Hendler, Sean Luke",1995/5,"Publisher Technical Report CS-TR-3485, Department of Computer Science, Institute for Systems Research. and Institute for Advanced Computer Studies, University of Maryland","Parka is a symbolic, semantic network knowledge representation system that takes advantage of the massive parallelism of supercomputers such as the Connection Machine. The Parka language has many of the features of traditional semantic net frame-based knowledge representation languages but also supports several kinds of rapid parallel inference mechanisms that scale to large knowledgebases of hundreds of thousands of frames or more. Parka is intended for general-purpose use and has been used thus far to support AI systems for case-based reasoning and data mining. This document is a user manual for the current version of Parka, version 3.2. It describes the Parka language and presents some examples of knowledge representation using Parka. Details about the parallel algorithms, implementation, and empirical results are presented elsewhere.",1
"Simulate Less, Expect More: Bringing Robot Swarms to Life via Low-Fidelity Simulations","Ricardo Vega, Kevin Zhu, Sean Luke, Maryam Parsa, Cameron Nowzari",2023/1/21,Journal arXiv preprint arXiv:2301.09018,"This paper proposes a novel methodology for addressing the simulation-reality gap for multi-robot swarm systems. Rather than immediately try to shrink or `bridge the gap' anytime a real-world experiment failed that worked in simulation, we characterize conditions under which this is actually necessary. When these conditions are not satisfied, we show how very simple simulators can still be used to both (i) design new multi-robot systems, and (ii) guide real-world swarming experiments towards certain emergent behaviors when the gap is very large. The key ideas are an iterative simulator-in-the-design-loop in which real-world experiments, simulator modifications, and simulated experiments are intimately coupled in a way that minds the gap without needing to shrink it, as well as the use of minimally viable phase diagrams to guide real world experiments. We demonstrate the usefulness of our methods on deploying a real multi-robot swarm system to successfully exhibit an emergent milling behavior.",
Retrograde Behavior Mitigation in Planner-Guided Robot Swarms,"Michael Schader, Sean Luke",2022/10/13,"Book Advances in Practical Applications of Agents, Multi-Agent Systems, and Complex Systems Simulation. The PAAMS Collection: 20th International Conference, PAAMS 2022, L'Aquila, Italy, July 13–15, 2022, Proceedings","Using an automated planner to guide the behavior of a robot swarm is an effective way to control a decentralized multi-robotic system so that it can accomplish complex tasks. Although classical planning assumes that the actors are unitary agents performing atomic actions, the virtual agents in a planner-guided swarm are groups of individuals. When those individuals have differing beliefs about what step of the plan they are on, so-called retrograde behavior can occur, slowing or stopping progress and potentially causing catastrophic failure. We formally define this issue, explain several approaches to mitigate it, and report the results of experiments in simulation across three different swarm robotics scenarios. We determine that this problem can be solved by combining a plan analyzer with either offline programming changes or some form of additional online coordination, and present a decision tree for choosing …",
Mitigation of Optimized Pharmaceutical Supply Chain Disruptions by Criminal Agents,"Abhisekh Rana, Hamdi Kavak, Andrew Crooks, Sean Luke, Carlotta Domeniconi, Jim Jones",2022/9/18,"Book Social, Cultural, and Behavioral Modeling: 15th International Conference, SBP-BRiMS 2022, Pittsburgh, PA, USA, September 20–23, 2022, Proceedings","Disruption to supply chains can significantly influence the operation of the world economy and this has been shown to permeate and affect a large majority of countries and their citizens. We present initial results from a model that explores the disruptions to supply chains by a criminal agent and possible mitigation strategies. We construct a model of a typical pharmaceutical manufacturing supply chain, which is implemented via discrete event simulation. The criminal agent optimizes its resource allocation to maximize disruption to the supply chain. Our findings show criminal agents can cause cascading damage and exploit vulnerabilities, which inherently exist within the supply chain itself. We also demonstrate how basic mitigation strategies can efficaciously alleviate this potential damage.",
Fully Decentralized Planner-Guided Robot Swarm Demonstration,"Michael Schader, Sean Luke",2021,"Conference Advances in Practical Applications of Agents, Multi-Agent Systems, and Social Good. The PAAMS Collection: 19th International Conference, PAAMS 2021, Salamanca, Spain, October 6–8, 2021, Proceedings 19","Robot swarms hold great potential for accomplishing missions in a robust, scalable, and flexible manner. However, determining what low-level agent behavior to implement in order to meet high-level objectives is an unsolved inverse problem. Building on previous work on partially-centralized planner-guided robot swarms, we present an approach that achieves total decentralization of executive and deliberator functions, adds robustness and performance optimization through dynamic task switching, and employs agent-initiated superrational planning to coordinate agent activity while responding to changes in the environment. We demonstrate the effectiveness of the technique with three swarm robotics scenarios.",
Design of a multi-agent classification system,Mauro Giampieri,2020/2/18,"Description In the era of information, emergent paradigms such as the Internet of Things with billions of devices constantly connected to the Internet exchanging heterogeneous data, demand new computing approaches for intelligent big data processing. Given this technological scenario, a suitable approach leverages on many computational entities, each of which performs tasks with low computational burden, conceived to be executed on multi-core and many-core architectures. To this aim, in this thesis, we propose Evolutive Agent Based Clustering (E-ABC) as promising framing reference. E-ABC is conceived to orchestrate a swarm of intelligent agents acting as individuals of an evolving population, each performing a random walk on a different subset of patterns. Each agent is in charge of discovering well-formed (compact and populated) clusters and, at the same time, a suitable subset of features corresponding to the subspace where such clusters lie, following a local metric learning approach, where each cluster is characterized by its own subset of relevant features. E-ABC is able to process data belonging to structured and possibly non-metric spaces, relying on custom parametric dissimilarity measures. Specifically, two variants are investigated. A first variant, namely E-ABC, aims at solving unsupervised problems, where agents’ task is to find well-formed clusters lying in suitable subspaces. A second variant, E-ABC^ 2, aims at solving classification problems by synthesizing a classification system on the top of the clusters discovered by the swarm. In particular, as a practical and real-world application, this novel classification system has been …","In the era of information, emergent paradigms such as the Internet of Things with billions of devices constantly connected to the Internet exchanging heterogeneous data, demand new computing approaches for intelligent big data processing. Given this technological scenario, a suitable approach leverages on many computational entities, each of which performs tasks with low computational burden, conceived to be executed on multi-core and many-core architectures. To this aim, in this thesis, we propose Evolutive Agent Based Clustering (E-ABC) as promising framing reference. E-ABC is conceived to orchestrate a swarm of intelligent agents acting as individuals of an evolving population, each performing a random walk on a different subset of patterns. Each agent is in charge of discovering well-formed (compact and populated) clusters and, at the same time, a suitable subset of features corresponding to the subspace where such clusters lie, following a local metric learning approach, where each cluster is characterized by its own subset of relevant features. E-ABC is able to process data belonging to structured and possibly non-metric spaces, relying on custom parametric dissimilarity measures. Specifically, two variants are investigated. A first variant, namely E-ABC, aims at solving unsupervised problems, where agents’ task is to find well-formed clusters lying in suitable subspaces. A second variant, E-ABC^ 2, aims at solving classification problems by synthesizing a classification system on the top of the clusters discovered by the swarm. In particular, as a practical and real-world application, this novel classification system has been …",
Ant Geometers,"Bryan Hoyle, Katherine Russell, Sean Luke",2016/7/1,"Conference ALIFE 2016, the Fifteenth International Conference on the Synthesis and Simulation of Living Systems","Just how much can a pheromone-enabled swarm do? Motivated by robotic construction, we set out to show that a swarm of computationally simple ants, communicating only via pheromones, can in fact perform classic compass-straightedge geometry, and thus can make many shapes and perform many nontrivial geometric tasks. The ants do not need specially-designed stigmergic building materials, a prepared environment, local or global direct communication facilities (such as radio or line-of-sight signaling), or any localization beyond initial starting points for drawing. We describe the proof of concept in replicable detail. We then note that its accuracy and efficiency can be greatly improved through augmentation with a simple embeddable broadcast mechanism.",
GECCO’14: Proceedings of the 2014 conference on Genetic and evolutionary computation,"C Igel, DV Arnold, C Gagne, E Popovici, A Auger, J Bacardit, D Brockhoff, S Cagnoni, K Deb, B Doerr, J Foster, T Glasmachers, E Hart, MI Heywood, H Iba, C Jacob, T Jansen, Y Jin, M Kessentini, JD Knowles, WB Langdon, P Larranaga, S Luke, G Luque, JAW McCall, MAMD Oca, A Motsinger-Reif, YS Ong, M Palmer, KE Parsopoulos, G Raidl, S Risi, G Ruhe, T Schaul, T Schmickl, B Sendhoff, KO Stanley, T Stuetzle, D Thierens, J Togelius, C Witt, C Zarges",2014,"Description (2014) GECCO’14: Proceedings of the 2014 conference on Genetic and evolutionary computation. In: Igel, C and Arnold, DV and Gagne, C and Popovici, E and Auger, A and Bacardit, J and Brockhoff, D and Cagnoni, S and Deb, K and Doerr, B and Foster, J and Glasmachers, T and Hart, E and Heywood, MI and Iba, H and Jacob, C and Jansen, T and Jin, Y and Kessentini, M and Knowles, JD and Langdon, WB and Larranaga, P and Luke, S and Luque, G and McCall, JAW and Oca, MAMD and Motsinger-Reif, A and Ong, YS and Palmer, M and Parsopoulos, KE and Raidl, G and Risi, S and Ruhe, G and Schaul, T and Schmickl, T and Sendhoff, B and Stanley, KO and Stuetzle, T and Thierens, D and Togelius, J and Witt, C and Zarges, C,(eds.)","(2014) GECCO’14: Proceedings of the 2014 conference on Genetic and evolutionary computation. In: Igel, C and Arnold, DV and Gagne, C and Popovici, E and Auger, A and Bacardit, J and Brockhoff, D and Cagnoni, S and Deb, K and Doerr, B and Foster, J and Glasmachers, T and Hart, E and Heywood, MI and Iba, H and Jacob, C and Jansen, T and Jin, Y and Kessentini, M and Knowles, JD and Langdon, WB and Larranaga, P and Luke, S and Luque, G and McCall, JAW and Oca, MAMD and Motsinger-Reif, A and Ong, YS and Palmer, M and Parsopoulos, KE and Raidl, G and Risi, S and Ruhe, G and Schaul, T and Schmickl, T and Sendhoff, B and Stanley, KO and Stuetzle, T and Thierens, D and Togelius, J and Witt, C and Zarges, C,(eds.)",
Better GP benchmarks: community survey results and GPBench2012,"DR White, J McDermott, M Castelli, L Manzoni, BW Goldman, G Kronberger, W Jaskowski, UM O'Reilly, S Luke",2013,Journal Genetic Programming and Evolvable Machines,,
Adaptive and Robust Multi-Agent Systems,"Sean Luke, Jeffrey K Bassett",2008/7/3,Publisher GEORGE MASON UNIV FAIRFAX VA,"We applied tools based on quantitative genetic theory in order to improve Evolutionary Algorithms for use with team learning tasks. We reviewed the quantitative genetics literature more widely, and developed a theoretical analysis applying genetic theory to the team learning problem. We then constructed and analyzed a neural network structure and new genetic operators which more effectively divide the feature space for the Evolutionary Algorithm. We performed experiments and discovered that the new operators and structure produced more parsimonious results. We plan to publish these results in an upcoming conference following more rigorous experiments.",
"The following reviewers have helped us to judge papers submitted for ‘‘Volume 8, 2007’’of Genetic Programming and Evolvable Machines: A. Abraham R. Adams","M Affenzeller, F Archetti, L Ballerini, A Bankhead, A Barton, D Basanta, P Bentley, V Bevilacqua, A Blouza, L Bocchi, J Bongard, M Brameier, J Branke, K Browder, L Bull, A Cangelosi, D Chesmore, E Claridge, T Clarke, J Clegg, L Dipietro, K Downing, L Dumas, G Eiben, M Engoren, M Eppstein, M Fairhust, U Feldkamp, D Floreano, J Foster, B Frachet, S Freeland, I Garibay, S Gotshall, A Greensted, H Guo, P Haddow, D Halliday, G Hamarneh, S Harding, M Heywood, D Hope, G Hornby, D Howard, G Howells, C Jacob, R Keller, S Kelly, J Kline, S Kumar, S Lanzeni, P Larranaga, P Legrand, R Lehn, A Leier, J Levy-Vehel, M Lones, S Luke, E Lutton, I Mbaye",2008,"Description Acknowledgment Page 1 Acknowledgment Published online: 31 January 2008 © Springer 
Science+Business Media, LLC 2008 The following reviewers have helped us to judge papers 
submitted for ‘‘Volume 8, 2007’’ of Genetic Programming and Evolvable Machines: A. 
Abraham R. Adams M. Affenzeller F. Archetti L. Ballerini A. Bankhead A. Barton D. Basanta P. 
Bentley V. Bevilacqua A. Blouza L. Bocchi J. Bongard C. Bourgeois-Republique M. Brameier J. 
Branke K. Browder L. Bull A. Cangelosi D. Chesmore E. Claridge T. Clarke J. Clegg P. Collet 
S. Conant-Pablos F. Deravi L. Dipietro K. Downing L. Dumas G. Eiben M. Engoren M. Eppstein 
M. Fairhust U. Feldkamp D. Floreano J. Foster B. Frachet S. Freeland I. Garibay S. Gotshall A. 
Greensted H. Guo P. Haddow D. Halliday G. Hamarneh S. Harding I. Harvey R. Heckendorn 
R. Hernandez-Cisneros M. Heywood D. Hope G. Hornby D. Howard G. Howells C. Jacob R…",,
Can Good Learners Always Compensate for Poor Learners?,"Keith Sullivan Liviu Panait Gabriel Balan, Sean Luke",2006,"Description Can a good learner compensate for a poor learner when paired in a coordination game? Previous work has given an example where a special learning algorithm (FMQ) is capable of doing just that when paired with a specific less capable algorithm even in games which stump the poorer algorithm when paired with itself. In this paper, we argue that this result is not general. We give a straightforward extension to the coordination game in which FMQ cannot compensate for the lesser algorithm. We also provide other problematic pairings, and argue that another high-quality algorithm cannot do so either.","Can a good learner compensate for a poor learner when paired in a coordination game? Previous work has given an example where a special learning algorithm (FMQ) is capable of doing just that when paired with a specific less capable algorithm even in games which stump the poorer algorithm when paired with itself. In this paper, we argue that this result is not general. We give a straightforward extension to the coordination game in which FMQ cannot compensate for the lesser algorithm. We also provide other problematic pairings, and argue that another high-quality algorithm cannot do so either.",
Reports on the 2004 AAAI fall symposia,"Nick Cassimatis, Sean Luke, Simon D Levy, Ross Gayler, Pentti Kanerva, Chris Eliasmith, Timothy Bickmore, Alan C Schultz, Randall Davis, James Landay, Rob Miller, Eric Saund, Tom Stahovich, Michael Littman, Satinder Singh, Shlomo Argamon, Shlomo Dubnov",2005/3/15,Journal AI Magazine,"The Association for the Advancement of Artificial Intelligence presented its 2004 Fall Symposium Series Friday through Sunday, October 22-24 at the Hyatt Regency Crystal City in Arlington, Virginia, adjacent to Washington, DC. The symposium series was preceded by a one-day AI funding seminar. The topics of the eight symposia in the 2004 Fall Symposia Series were:(1) Achieving Human-Level Intelligence through Integrated Systems and Research;(2) Artificial Multiagent Learning;(3) Compositional Connectionism in Cognitive Science;(4) Dialogue Systems for Health Communications;(5) The Intersection of Cognitive Science and Robotics: From Interfaces to Intelligence;(6) Making Pen-Based Interaction Intelligent and Natural;(7) Real-Life Reinforcement Learning; and (8) Style and Meaning in Language, Art, Music, and Design.",
Evolving Optimal Submunition Design for Attacking Relocatable Targets,"Keith Sullivan, Sean Luke",2004/11/15,Publisher SYSTEMS PLANNING AND ANALYSIS INC ALEXANDRIA VA,"Relocatable targets are mobile targets that will stay in a discrete location for an unknown, random length of time before moving to another location. Such targets include mobile missile launchers, air defense units, fuel trucks and other high value targets eg maneuver forces. Using a combination of multiagent simulation and a multiobjective evolutionary algorithm, we evolve optimal submunition design characteristics for attacking relocatable target examined three types of target concealment, and discovered that high probability of detection, short delay times, and multiple submunitions are required for successful engagement.",
The following reviewers have helped us to judge papers and reviews submitted for Volume 3 of Genetic Programming and Evolvable Machines,"L Altenberg, H Hemmi, M Pelikan, B Bollig, H Iba, B Punch, E Cantu Paz, C Jacob, R Reynolds, M Conrads, H Kargupta, J Rosca, K Deb, M Keijzer, C Ryan, P Dittrich, R Keller, M Schoenauer, M Dorigo, P Kennedy, B Shackleford, G Eiben, S Kumar, M Sipper, U Feldkamp, B Langdon, J Smith, D Floreano, G Lamont, P Smith, T Fogarty, S Luke, T Soule, J Foster, B Manderick, L Spector, F Francone, B McKay, D Thierens, B Freisleben, N McPhee, L Todorowski, M Garzon, L Merkle, A Totonchi, P Haddow, J Mittenthal, P Whigham, D Haig, D Montana, B Zhang, R Hartl, P Nordin, J Ziegler, R Heckendorn, U O’Reilly, E Zitzler, W Banzhaf",2002,Journal Genetic Programming and Evolvable Machines,,
The following reviewers have helped us to judge papers and reviews submitted for Volume 2 of Genetic Programming and Evolvable Machines,"FH Bennett, M Brameier, S Cagnoni, S Chen, J Davila, P Dittrich, G Eiben, K Ezawa, D Fogel, F Francone, N Gershenfeld, P Haddow, SE Haupt, M Herdy, L Huelsbergen, H Iba, T Kalganova, R Keller, P Kennedy, D Keymeulen, S Luke, B Manderick, B McMullin, N McPhee, D Montana, J Niehaus, P Nordin, M O’Neill, R Poli, J Rosca, G Roth, C Ryan, K Saitou, E Sanchez, M Sebag, M Sipper, T Soule, C Stephens, A Tettamanzi, A Uritani, V Vassilev, P Whigham, A Wu, R Zebulum, B Zhang, W Banzhaf",2001,Journal Genetic Programming and Evolvable Machines,,
Competitive Soccer Softbot Teams for RoboCup97,Sean Luke,1998,"Journal Genetic Programming: Proceedings of the Third Annual Conference, July 22-25, 1998, University of Wisconsin, Madison","At RoboCup, teams of autonomous robots or software softbots compete in simulated soccer matches to demonstrate cooperative robotics techniques in a very difficult, real-time, noisy environment. At the IJCAVRoboCup97 softbot competition, all entries but ours used human-crafted cooperative decision-making behaviors. We instead entered a softbot team whose high-level decision making behaviors had been entirely evolved using genetic programming. Our team won its first two games against human-crafted opponent teams, and re-ceived the RoboCup Scientific Challenge Award. This report discusses the issues we faced and the approach we took to use GP to evolve our robot soccer team for this difficult environment.",
CDI Type II: Cyber-Enabled Understanding of Complexity in Socio-Ecological Systems Using Computational Thinking,"Claudio Cioffi-Revilla PI, Sean Luke, J Daniel Rogers, Paul Schopf","Our CDI objectives are:(1) to apply computational thinking in the form of advanced multiagent systems and evolutionary computation to understanding the complexity of nonlinear dynamics in socio-ecological systems subject to climate change; and (2) promote the transformative computational paradigm in anthropology, political science—social sciences in general—and Earth system science via tightly integrated multiagent systems (MAS; agent-based models, ABMs), general circulation climate models","Scholar articles CDI Type II: Cyber-Enabled Understanding of Complexity in Socio-Ecological Systems Using Computational ThinkingCCR PI, S Luke, JD Rogers, P SchopfRelated articles All 2 versions ","Our CDI objectives are:(1) to apply computational thinking in the form of advanced multiagent systems and evolutionary computation to understanding the complexity of nonlinear dynamics in socio-ecological systems subject to climate change; and (2) promote the transformative computational paradigm in anthropology, political science—social sciences in general—and Earth system science via tightly integrated multiagent systems (MAS; agent-based models, ABMs), general circulation climate models",
Evolving Graphs and Networks with Edge Encoding,Sean Luke,"We present an alternative to the cellular encoding technique [Gruau 1992] for evolving graph and network structures via genetic programming. The new technique, called edge encoding, uses edge operators rather than the node operators of cellular encoding. While both cellular encoding and edge encoding can produce all possible graphs, the two encodings bias the genetic search process in different ways; each may therefore be most useful for a different set of problems. The problems for which these techniques may be used, and for which we think edge encoding may be particularly useful, include the evolution of recurrent neural networks, finite automata, and graph-based queries to symbolic knowledge bases. In this preliminary report we present a technical description of edge encoding and an initial comparison to cellular encoding. Experimental investigation of the relative merits of these encoding schemes …",Scholar articles Evolving Graphs and Networks with Edge EncodingS LukeRelated articles ,"We present an alternative to the cellular encoding technique [Gruau 1992] for evolving graph and network structures via genetic programming. The new technique, called edge encoding, uses edge operators rather than the node operators of cellular encoding. While both cellular encoding and edge encoding can produce all possible graphs, the two encodings bias the genetic search process in different ways; each may therefore be most useful for a different set of problems. The problems for which these techniques may be used, and for which we think edge encoding may be particularly useful, include the evolution of recurrent neural networks, finite automata, and graph-based queries to symbolic knowledge bases. In this preliminary report we present a technical description of edge encoding and an initial comparison to cellular encoding. Experimental investigation of the relative merits of these encoding schemes …",
Supporting Mobile Swarm Robotics in Low Power and Lossy Sensor Networks,"Kevin Andrea, Robert Simon, Sean Luke","Wireless low-power and lossy networks (LLNs) are a key enabling technology for the deployment of massively scaled self-organizing sensor swarm systems. Supporting applications such as providing human users situational awareness across large areas requires that swarm-friendly LLNs effectively support communication between embedded and mobile devices, such as autonomous robots. The reason for this is that large scale embedded sensor applications such as unattended ground sensing systems typically do not have full end-to-end connectivity, but suffer frequent communication partitions. Further, it is desirable for many tactical applications to offload tasks to mobile robots. Despite the importance of support this communication pattern, there has been relatively little work in designing and evaluating LLN-friendly protocols capable of supporting such interactions.This paper addresses the above problem by describing the design, implementation, and evaluation of the MoRoMi system. MoRoMi stands for Mobile Robotic MultI-sink. It is intended to support autonomous mobile robots that interact with embedded sensor swarms engaged in activities such as cooperative target observation, collective map building, and ant foraging. These activities benefit if the swarm can dynamically interact with embedded sensing and actuator systems that provide both local environmental or positional information and an ad-hoc communication system. Our paper quantifies the performance levels that can be expected using current swarm and LLN technologies.","Scholar articles Supporting Mobile Swarm Robotics in Low Power and Lossy Sensor NetworksK Andrea, R Simon, S LukeRelated articles All 2 versions ","Wireless low-power and lossy networks (LLNs) are a key enabling technology for the deployment of massively scaled self-organizing sensor swarm systems. Supporting applications such as providing human users situational awareness across large areas requires that swarm-friendly LLNs effectively support communication between embedded and mobile devices, such as autonomous robots. The reason for this is that large scale embedded sensor applications such as unattended ground sensing systems typically do not have full end-to-end connectivity, but suffer frequent communication partitions. Further, it is desirable for many tactical applications to offload tasks to mobile robots. Despite the importance of support this communication pattern, there has been relatively little work in designing and evaluating LLN-friendly protocols capable of supporting such interactions.",
Portable Sensor Motes as a Distributed Communication Medium for Large Groups of Mobile Robots,"Sean Luke, Katherine Russell","We argue for the use of swarms of distributed portable sensors as a support medium for a large number of autonomous mobile robots. Because of the scaling issues inherent in their multiplicity, and because they may operate in broadcast-denied environments, swarm robot architectures often focus on local and “indirect” communication methods such as breadcrumbs, pheromones, or messages left in the environment. We are interested in how far we can go with these models in real robots. To this end, our research investigates robots capable of deploying, retrieving, moving, and locally communicating with many embedded sensor motes. The mobile agents deploy and optimize the location of the motes, read historic and current sensor data from them, and store useful local information in them for other mobile agents to discover later. We have demonstrated the ability to do robot foraging in environments with significant noise and physical disruption, such as might occur in any deployment of a large sensor network. We have also demonstrated experiments using swarms and sensor motes to collectively build sophisticated, non-trivial swarm behaviors, such as laying out complex shapes using compass/straightedge geometry. In this paper we discuss these results and their limitations, and indicate where we think wireless sensor mote technology can help advance swarm robotics going forward.","Scholar articles Portable Sensor Motes as a Distributed Communication Medium for Large Groups of Mobile RobotsS Luke, K RussellRelated articles All 2 versions ","We argue for the use of swarms of distributed portable sensors as a support medium for a large number of autonomous mobile robots. Because of the scaling issues inherent in their multiplicity, and because they may operate in broadcast-denied environments, swarm robot architectures often focus on local and “indirect” communication methods such as breadcrumbs, pheromones, or messages left in the environment. We are interested in how far we can go with these models in real robots. To this end, our research investigates robots capable of deploying, retrieving, moving, and locally communicating with many embedded sensor motes. The mobile agents deploy and optimize the location of the motes, read historic and current sensor data from them, and store useful local information in them for other mobile agents to discover later. We have demonstrated the ability to do robot foraging in environments with significant noise and physical disruption, such as might occur in any deployment of a large sensor network. We have also demonstrated experiments using swarms and sensor motes to collectively build sophisticated, non-trivial swarm behaviors, such as laying out complex shapes using compass/straightedge geometry. In this paper we discuss these results and their limitations, and indicate where we think wireless sensor mote technology can help advance swarm robotics going forward.",
SHOE: A Knowledge Representation Language for Internet Applications,Sean Luke,"It is our contention that the World Wide Web poses challenges to knowledge representation systems that fundamentally change the way we should design KR languages. In this paper, we describe the Simple HTML Ontology Extensions (SHOE), a KR language which allows web pages to be annotated with semantics. We present a formalism for the language and discuss the features which make it well suited for the Web. We describe the syntax and semantics of this language, and discuss the di erences from traditional KR systems that make it more suited to modern web applications. We also describe some generic tools for using the language and demonstrate its capabilities by describing two prototype systems that use it. We also discuss some future tools currently being developed for the language. The language, tools, and details of the applications are all available on the World Wide Web at http://www. cs. umd. edu/projects/plus/SHOE.",Scholar articles SHOE: A Knowledge Representation Language for Internet ApplicationsS LukeRelated articles All 11 versions ,"It is our contention that the World Wide Web poses challenges to knowledge representation systems that fundamentally change the way we should design KR languages. In this paper, we describe the Simple HTML Ontology Extensions (SHOE), a KR language which allows web pages to be annotated with semantics. We present a formalism for the language and discuss the features which make it well suited for the Web. We describe the syntax and semantics of this language, and discuss the di erences from traditional KR systems that make it more suited to modern web applications. We also describe some generic tools for using the language and demonstrate its capabilities by describing two prototype systems that use it. We also discuss some future tools currently being developed for the language. The language, tools, and details of the applications are all available on the World Wide Web at http://www. cs. umd. edu/projects/plus/SHOE.",
RoboPatriots: George Mason University 2014 RoboCup Team,"David Freelan, Drew Wicke, Chau Thai, Josh Snider, Anna Papadogiannakis, Sean Luke","The RoboPatriots are a team of four DARwIn-OP robots from George Mason University which participate in the Kid-Size Humanoid League. RoboCup 2015 marks the sixth year of participation for the RoboPatriots. Our approach is very unusual in that our goal is to train our robots how to play cooperative soccer, rather than program them. We do this not at our laboratory, but at the RoboCup venue during the preparatory period. Then, we enter the learned robot behaviors into the competition. In 2014 we trained all three attackers, pairing them with a hard-coded goalie. This year we intend to train a full team of all four robots.","Scholar articles RoboPatriots: George Mason University 2014 RoboCup TeamD Freelan, D Wicke, C Thai, J Snider…Related articles All 9 versions ","The RoboPatriots are a team of four DARwIn-OP robots from George Mason University which participate in the Kid-Size Humanoid League. RoboCup 2015 marks the sixth year of participation for the RoboPatriots. Our approach is very unusual in that our goal is to train our robots how to play cooperative soccer, rather than program them. We do this not at our laboratory, but at the RoboCup venue during the preparatory period. Then, we enter the learned robot behaviors into the competition. In 2014 we trained all three attackers, pairing them with a hard-coded goalie. This year we intend to train a full team of all four robots.",
George Mason University Technical Reports,Sean Luke,"Students are often confused by what constitutes plagiarism in academia and the seriousness with which the offense is treated. The objective of this essay is to explain the issue and provide examples to explain what is plagiarism, and hopefully act as a useful guide. 1",Scholar articles George Mason University Technical ReportsS LukeRelated articles All 2 versions ,"Students are often confused by what constitutes plagiarism in academia and the seriousness with which the offense is treated. The objective of this essay is to explain the issue and provide examples to explain what is plagiarism, and hopefully act as a useful guide. 1",
Adaptive Search for Interesting Things,"William Squires, Sean Luke","The results of a parameter sweep over a multidimensional parameter space are often used to gain an understanding of the space beyond simply identifying optima. But sweeps are costly, and so it is highly desirable to adaptively sample the space in such a way as to concentrate precious samples on the more “interesting” areas of the space. In this paper we analyze and expand on a previous work which defined such areas as those in which the slope of some quality function was high. We develop a performance metric in terms of generalizability of the resulting sampled model, examine the existing method in terms of scalability and accuracy, and then propose and examine two population-based approaches which address some of its shortcomings.","Scholar articles Adaptive Search for Interesting ThingsW Squires, S LukeRelated articles All 3 versions ","The results of a parameter sweep over a multidimensional parameter space are often used to gain an understanding of the space beyond simply identifying optima. But sweeps are costly, and so it is highly desirable to adaptively sample the space in such a way as to concentrate precious samples on the more “interesting” areas of the space. In this paper we analyze and expand on a previous work which defined such areas as those in which the slope of some quality function was high. We develop a performance metric in terms of generalizability of the resulting sampled model, examine the existing method in terms of scalability and accuracy, and then propose and examine two population-based approaches which address some of its shortcomings.",
An Application of Evolutionary Algorithms to Study the Extent of SLHF Anomaly Associated with Coastal Earthquakes,"Guido Cervone, Liviu Panait, Ramesh Singh, Sean Luke","Multi sensor remote sensing provides real time high resolution data that can be used to study anomalous changes on land, in the ocean, and in the atmosphere associated with an impending earthquake. Anomalous behaviour in Surface Latent Heat Flux (SLHF) prior to large coastal earthquakes has been recently found. However, an SLHF time series usually contains several sharp peaks that may be associated either with earthquakes or with atmospheric perturbations. In this paper we have used evolutionary algorithms to perform a search in a large space bounded by longitude, latitude and time, to distinguish between signals associated with earthquakes and those associated with atmospheric phenomena. The algorithm finds paths which delimit the extent of the detected anomalies by optimizing an objective function that takes into consideration several aspects, such as spatial and time continuity, the magnitude of the anomalies, and the distance to the continental boundary. This search strategy is crucial for the development of a fully automated early warning system for providing information about impending earthquakes in a seismically active coastal region. Experiments have been performed over a 2000 km2 area comprising a part of the continental boundary between the African and Eurasian plate, roughly corresponding to Italy and Greece, one of the most seismically active regions. Using a 365-days-long time series, we identified three signals associated with seismic events. Additionally, it was possible to establish that the extent of the signal does not propagate further than 600 km from the epicenter of the earthquake.","Scholar articles An Application of Evolutionary Algorithms to Study the Extent of SLHF Anomaly Associated with Coastal EarthquakesG Cervone, L Panait, R Singh, S LukeRelated articles All 7 versions ","Multi sensor remote sensing provides real time high resolution data that can be used to study anomalous changes on land, in the ocean, and in the atmosphere associated with an impending earthquake. Anomalous behaviour in Surface Latent Heat Flux (SLHF) prior to large coastal earthquakes has been recently found. However, an SLHF time series usually contains several sharp peaks that may be associated either with earthquakes or with atmospheric perturbations. In this paper we have used evolutionary algorithms to perform a search in a large space bounded by longitude, latitude and time, to distinguish between signals associated with earthquakes and those associated with atmospheric phenomena. The algorithm finds paths which delimit the extent of the detected anomalies by optimizing an objective function that takes into consideration several aspects, such as spatial and time continuity, the magnitude of the anomalies, and the distance to the continental boundary. This search strategy is crucial for the development of a fully automated early warning system for providing information about impending earthquakes in a seismically active coastal region. Experiments have been performed over a 2000 km2 area comprising a part of the continental boundary between the African and Eurasian plate, roughly corresponding to Italy and Greece, one of the most seismically active regions. Using a 365-days-long time series, we identified three signals associated with seismic events. Additionally, it was possible to establish that the extent of the signal does not propagate further than 600 km from the epicenter of the earthquake.",
Creating Ontologies Using SHOE,Sean Luke,"Suppose we're trying to let our knowledge-robot system be able to gather information about the UMCP Computer Science Department web site. Before we can annotate our web pages with this information, we need to first establish one or more ontologies (or much better, use already-established ones) that will define how we can classify our documents. These ontologies will describe categories which our web pages can fall into, and relationship rules between categories or other data which we can use later to describe relationships between our web pages and other web pages (or other data like numbers or dates).An example works best to explain this idea. Imagine that the Association for Computing Machinery (the ACM, an"" official"" Computer Science group) has asked us create an ontology for computer science department web pages. It's rare that an ontology will simply be created to stand on its own--more often …",Scholar articles Creating Ontologies Using SHOES LukeRelated articles ,"Suppose we're trying to let our knowledge-robot system be able to gather information about the UMCP Computer Science Department web site. Before we can annotate our web pages with this information, we need to first establish one or more ontologies (or much better, use already-established ones) that will define how we can classify our documents. These ontologies will describe categories which our web pages can fall into, and relationship rules between categories or other data which we can use later to describe relationships between our web pages and other web pages (or other data like numbers or dates).",
AGENT-BASED DYNAMICS OF SOCIAL COMPLEXITY,"C Cioffi-Revilla, S Luke, DC Parker, JD Rogers, WW Fitzhugh, W Honeychurch, B Frohlich, P DePriest, Naran Bazarsad","Inner Asia is the heartland of the Old World, a “bridge” and large-scale social network linking Asia and Europe across an expansive steppe land, and a unique laboratory for understanding long-term social and political adaptations in the face of great challenges. Depending on the epoch, Inner Asia has fluctuated from being an active center or core with significant influence on neighboring regions (China, Russia, South Asia, Eastern Europe, and the Middle East), to being a passive-reactive periphery of these same regions. The mobile populations, long-distance contacts and exchange, rapid transport technologies, and macro-scale complex polities of Inner Asia offer an opportunity to develop and test a new approach to understanding the emergence of complex horizontal and vertical forms of social organization as dynamic adaptive responses to social and environmental changes. In this project we do so using diachronic data from written sources and from three archaeological projects located along a north-south transect spanning the Mongolian steppe zone; and developing object-oriented agent-based simulation models that build upon and extend extant computational social science models to generate the emergence of multi-scale networks over space and time. This project is aimed at producing new knowledge for better understanding social dynamic responses and collective behavior to change.","Scholar articles AGENT-BASED DYNAMICS OF SOCIAL COMPLEXITYC Cioffi-Revilla, S Luke, DC Parker, JD Rogers…Related articles All 4 versions ","Inner Asia is the heartland of the Old World, a “bridge” and large-scale social network linking Asia and Europe across an expansive steppe land, and a unique laboratory for understanding long-term social and political adaptations in the face of great challenges. Depending on the epoch, Inner Asia has fluctuated from being an active center or core with significant influence on neighboring regions (China, Russia, South Asia, Eastern Europe, and the Middle East), to being a passive-reactive periphery of these same regions. The mobile populations, long-distance contacts and exchange, rapid transport technologies, and macro-scale complex polities of Inner Asia offer an opportunity to develop and test a new approach to understanding the emergence of complex horizontal and vertical forms of social organization as dynamic adaptive responses to social and environmental changes. In this project we do so using diachronic data from written sources and from three archaeological projects located along a north-south transect spanning the Mongolian steppe zone; and developing object-oriented agent-based simulation models that build upon and extend extant computational social science models to generate the emergence of multi-scale networks over space and time. This project is aimed at producing new knowledge for better understanding social dynamic responses and collective behavior to change.",
Analysis of Coevolutionary Algorithm Progress Measures,"Sean Luke, R Paul Wiegand","The task of understanding the dynamics of coevolutionary algorithms or comparing performance between such algorithms is complicated by the fact the internal fitness measures are subjective. Though a variety of techniques for employing various kinds of external or objective measures exist to help with analysis, there are clearly properties of fitness payoff (eg: intransitivity) which call certain methods into question in certain contexts. Moreover, the terminology which describe these measures is often unclear and inconsistent. We present a detailed description of what kinds of measures exist, when they should or should not be used, and what relationship properties of external measures have with respect to properties of fitness payoff. Additionally we are able to identify when certain classes of payoff methods imply that particular kinds of coevolutionary algorithms to behave precisely as a traditional EA, in terms of its dynamics","Scholar articles Analysis of Coevolutionary Algorithm Progress MeasuresS Luke, RP WiegandRelated articles All 3 versions ","The task of understanding the dynamics of coevolutionary algorithms or comparing performance between such algorithms is complicated by the fact the internal fitness measures are subjective. Though a variety of techniques for employing various kinds of external or objective measures exist to help with analysis, there are clearly properties of fitness payoff (eg: intransitivity) which call certain methods into question in certain contexts. Moreover, the terminology which describe these measures is often unclear and inconsistent. We present a detailed description of what kinds of measures exist, when they should or should not be used, and what relationship properties of external measures have with respect to properties of fitness payoff. Additionally we are able to identify when certain classes of payoff methods imply that particular kinds of coevolutionary algorithms to behave precisely as a traditional EA, in terms of its dynamics",
Position Name Affiliation Country Email Address,"Berna Dengiz, Gerry Dozier, Hitoshi Iba, Pier Luca Lanzi, JJ Merelo, Risto Miikkulainen, Simon Lucas, Sean Luke, Graham Kendall, Marc Schoenauer, Eric Fraga, KC Tan, Philip Hingston, Dan Ashlock, Jennie Si, Special Sessions Chairs Julian Togelius, Kay Wiese","CEC 2011 Organizing Committee Page 1 CEC 2011ORGANIZING COMMITTEE Position 
Name Affiliation Country Email Address Co-General Chairs Alice E. Smith Auburn University 
USA smithae@auburn.edu Ian Parmee University of the West of England UK Ian.Parmee@uwe.ac.uk 
Advisory Chairs Kenneth De Jong George Mason University USA kdejong@gmu.edu 
Kalyanmoy Deb Indian Institute of Technology Kanpur India deb@iitk.ac.in Marco Dorigo 
Université Libre de Bruxelles Belgium mdorigo@ulb.ac.be Zbyszek Michalewicz University of 
Adelaide Australia zbyszek@cs.adelaide.edu.au Hans-Paul Schwefel Dortmund University of 
Technology Germany hps@uDo.edu Finance Chair David Fogel Natural Selection Inc. USA 
dfogel@natural-selection.com Program Chair Larry Bull University of the West of England 
UK larry.bull@uwe.ac.uk Technical Program Chairs Berna Dengiz Baskent University Turkey …","Scholar articles Position Name Affiliation Country Email AddressB Dengiz, G Dozier, H Iba, PL Lanzi, JJ Merelo…",,
"Agent-based Modeling of Climate Change, Ecosystems, and Security: A Research Programme1","C Cioffi-Revilla, S Luke, JD Rogers, P Schopf, J Trimble","The goal of this project is to advance understanding of the effects of environmental uncertainty, specifically climate variability, on polity and security conditions on multiple scales. Climate uncertainty is investigated by developing, validating, and analyzing new computational agent-based models (ABM) as tools for simulating human societies that are spatially situated in regions with diverse ecosystems, including climate with changing patterns. The new models focus on two regions selected for the impact of climate change on security and ecosystems: Sub-Saharan Africa (over a billion people at high risk for displacement, disease, and starvation) and the Arctic Circumboreal region (where the fastest ecological changes are already occurring with major strategic consequences). The project responds directly to the need to understand natural-social linkages as well as governmental and NGO recommendations. The …","Scholar articles Agent-based Modeling of Climate Change, Ecosystems, and Security: A Research Programme1C Cioffi-Revilla, S Luke, JD Rogers, P Schopf…Related articles ","The goal of this project is to advance understanding of the effects of environmental uncertainty, specifically climate variability, on polity and security conditions on multiple scales. Climate uncertainty is investigated by developing, validating, and analyzing new computational agent-based models (ABM) as tools for simulating human societies that are spatially situated in regions with diverse ecosystems, including climate with changing patterns. The new models focus on two regions selected for the impact of climate change on security and ecosystems: Sub-Saharan Africa (over a billion people at high risk for displacement, disease, and starvation) and the Arctic Circumboreal region (where the fastest ecological changes are already occurring with major strategic consequences). The project responds directly to the need to understand natural-social linkages as well as governmental and NGO recommendations. The …",
