titles,authors,date,source,descriptions,citations
Experimental evaluation of an educational game for improved learning in introductory computing,"Michael Eagle, Tiffany Barnes",2009/3/4,Journal ACM SIGCSE Bulletin,"We are developing games to increase student learning and attitudes in introductory CS courses. Wu's Castle is a game where students program changes in loops and arrays in an interactive, visual way. The game provides immediate feedback and helps students visualize code execution in a safe environment. We compared the game to a traditional programming assignment in an introductory CS course. In our study, half of the students were randomly selected to play the learning game first and half to write a program first. Our results show that students who play our learning game first outperform those who write a program before playing the game. Students in the game-first group felt they spent less time on the assignments, and all students preferred the learning game over the program. These results suggest that games like Wu's Castle can help prepare students to create deeper, more robust understanding of …",175
Experimental Evaluation of Automatic Hint Generation for a Logic Tutor,"John Stamper, Michael Eagle, Tiffany Barnes, Marvin Croy",2013,Journal International Journal of Artificial Intelligence in Education,"We have augmented the Deep Thought logic tutor with a Hint Factory that generates data-driven, context-specific hints for an existing computer aided instructional tool. We investigate the impact of the Hint Factory's automatically generated hints on educational outcomes in a switching replications experiment that shows that hints help students persist in a deductive logic proofs tutor. Three instructors taught two semester-long courses, each teaching one semester using a logic tutor with hints, and one semester using the tutor without hints, controlling for the impact of different instructors on course outcomes. Our results show that students in the courses using a logic tutor augmented with automatically generated hints attempted and completed significantly more logic proof problems, were less likely to abandon the tutor, performed significantly better on a post-test implemented within the tutor, and achieved higher …",121
A framework for using hypothesis-driven approaches to support data-driven learning analytics in measuring computational thinking in block-based programming environments,"Shuchi Grover, Satabdi Basu, Marie Bienkowski, Michael Eagle, Nicholas Diana, John Stamper",2017/8/28,Journal ACM Transactions on Computing Education (TOCE),"Systematic endeavors to take computer science (CS) and computational thinking (CT) to scale in middle and high school classrooms are underway with curricula that emphasize the enactment of authentic CT skills, especially in the context of programming in block-based programming environments. There is, therefore, a growing need to measure students’ learning of CT in the context of programming and also support all learners through this process of learning computational problem solving. The goal of this research is to explore hypothesis-driven approaches that can be combined with data-driven ones to better interpret student actions and processes in log data captured from block-based programming environments with the goal of measuring and assessing students’ CT skills. Informed by past literature and based on our empirical work examining a dataset from the use of the Fairy Assessment in the Alice …",90
Wu's castle: teaching arrays and loops in a game,"Michael Eagle, Tiffany Barnes",2008/6/30,Book Proceedings of the 13th annual conference on Innovation and technology in computer science education,"We are developing games to teach introductory computer science concepts to increase student motivation and engagement in learning to program. Wu's Castle is a two-dimensional role playing game that teaches loops and arrays in an interactive, visual way. In this game, the player interactively programs magical creatures to create armies of snowmen. The game provides immediate feedback and helps students visualize the execution of their code in a safe environment. We tested the game in a CS1 course, where students could earn extra credit to play Wu's Castle. Our results show learning gains for game players, compared both through pre- and post-tests differences and improved performance on relevant final exam questions when compared to students who did not play the game. The results of this study suggest that Wu's Castle implements good practices for teaching programming within a game.",79
An instructor dashboard for real-time analytics in interactive programming assignments,"Nicholas Diana, Michael Eagle, John Stamper, Shuchi Grover, Marie Bienkowski, Satabdi Basu",2017/3/13,Book Proceedings of the seventh international learning analytics & knowledge conference,"Many introductory programming environments generate a large amount of log data, but making insights from these data accessible to instructors remains a challenge. This research demonstrates that student outcomes can be accurately predicted from student program states at various time points throughout the course, and integrates the resulting predictive models into an instructor dashboard. The effectiveness of the dashboard is evaluated by measuring how well the dashboard analytics correctly suggest that the instructor help students classified as most in need. Finally, we describe a method of matching low-performing students with high-performing peer tutors, and show that the inclusion of peer tutors not only increases the amount of help given, but the consistency of help availability as well.",74
Audience participation games: Blurring the line between player and spectator,"Joseph Seering, Saiph Savage, Michael Eagle, Joshua Churchin, Rachel Moeller, Jeffrey P Bigham, Jessica Hammer",2017/6/10,Book Proceedings of the 2017 Conference on Designing Interactive Systems,"Audience Participation Games challenge traditional assumptions about gameplay by blurring the line between audience and player, allowing audience members to impact gameplay in a meaningful way. Their recent rise in popularity has created new opportunities for game research and development. To better understand this design space, we developed several versions of two prototype games as design probes. We livestreamed them to an online audience in order to develop a framework for audience motivations and participation styles, to explore ways in which mechanics can affect audience members' sense of agency, and to identify promising design spaces. Our results show the breadth of opportunities and challenges that designers face in creating engaging Audience Participation Games.",67
Assessing implicit science learning in digital games,"Elizabeth Rowe, Jodi Asbell-Clarke, Ryan S Baker, Michael Eagle, Andrew G Hicks, Tiffany M Barnes, Rebecca A Brown, Teon Edwards",2017/11/1,Journal Computers in Human Behavior,"Building on the promise shown in game-based learning research, this paper explores methods for Game-Based Learning Assessments (GBLA) using a variety of educational data mining techniques (EDM). GBLA research examines patterns of behaviors evident in game data logs for the measurement of implicit learning—the development of unarticulated knowledge that is not yet expressible on a test or formal assessment. This paper reports on the study of two digital games showing how the combination of human coding with EDM has enabled researchers to measure implicit learning of Physics. In the game Impulse, researchers combined human coding of video with educational data mining to create a set of automated detectors of students' implicit understanding of Newtonian mechanics. For Quantum Spectre, an optics puzzle game, human coding of Interaction Networks was used to identify common student …",66
Program representation for automatic hint generation for a data-driven novice programming tutor,"Wei Jin, Tiffany Barnes, John Stamper, Michael John Eagle, Matthew W Johnson, Lorrie Lehmann",2012,"Conference Intelligent Tutoring Systems: 11th International Conference, ITS 2012, Chania, Crete, Greece, June 14-18, 2012. Proceedings 11","We describe a new technique to represent, classify, and use programs written by novices as a base for automatic hint generation for programming tutors. The proposed linkage graph representation is used to record and reuse student work as a domain model, and we use an overlay comparison to compare in-progress work with complete solutions in a twist on the classic approach to hint generation. Hint annotation is a time consuming component of developing intelligent tutoring systems. Our approach uses educational data mining and machine learning techniques to automate the creation of a domain model and hints from student problem-solving data. We evaluate the approach with a sample of partial and complete, novice programs and show that our algorithms can be used to generate hints over 80 percent of the time. This promising rate shows that the approach has potential to be a source for …",63
Interaction Networks: Generating High Level Hints Based on Network Community Clustering.,"Michael Eagle, Matthew Johnson, Tiffany Barnes",2012/6,Journal International Educational Data Mining Society,"We introduce a novel data structure, the Interaction Network, for representing interaction-data from open problem solving environment tutors. We show how using network community detecting techniques are used to identify sub-goals in problems in a logic tutor. We then use those community structures to generate high level hints between sub-goals. The preliminary results show that using network analysis techniques are promising for exploring and understanding user data from open problem solving environments. (Contains 3 figures.) [For the complete proceedings,",48
Communities of Performance & Communities of Preference.,"Rebecca Brown, Collin F Lynch, Yuan Wang, Michael Eagle, Jennifer L Albert, Tiffany Barnes, Ryan Shaun Baker, Yoav Bergner, Danielle S McNamara",2015/6,Conference EDM (Workshops),"The current generation of Massive Open Online Courses (MOOCs) operate under the assumption that good students will help poor students, thus alleviating the burden on instructors and Teaching Assistants (TAs) of having thousands of students to teach. In practice, this may not be the case. In this paper, we examine social network graphs drawn from forum interactions in a MOOC to identify natural student communities and characterize them based on student performance and stated preferences. We examine the community structure of the entire course, students only, and students minus low performers and hubs. The presence of these communities and the fact that they are homogeneous with respect to grade but not motivations has important implications for planning in MOOCs.",31
Exploring networks of problem-solving interactions,"Michael Eagle, Drew Hicks, B Perrycord, T. Barnes",2015,Journal Proceedings of the Fifth International Conference on Learning Analytics and Knowledge (LAK 15),"Intelligent tutoring systems and other computer-aided learning environments produce large amounts of transactional data on student problem-solving behavior, in previous work we modeled the student-tutor interaction data as a complex network, and successfully generated automated next-step hints as well as visualizations for educators. In this work we discuss the types of tutoring environments that are best modeled by interaction networks, and how the empirical observations of problem-solving result in common network features. We find that interaction networks exhibit the properties of scale-free networks such as vertex degree distributions that follow power law. We compare data from two versions of a propositional logic tutor, as well as two different representations of data from an educational game on programming. We find that statistics such as degree assortativity and the scale-free metric allow comparison of …",31
Exploring Differences in Problem Solving with Data-Driven Approach Maps,"Michael Eagle, Tiffany Barnes",2014,Journal The 7th International Conference on Educational Data Mining,"Understanding the differences in problem solving behavior between groups of students is quite challenging. We have mined the structure of interaction traces to discover different approaches to solving logic problems. In a prior study, significant differences in performance and tutor retention were found between two groups of students, one group with access to hints, and one without. The Approach Maps we have derived help us discover differences in how students in each group explore the possible solution space for each problem. We summarize our findings across several logic problems, and present in-depth Approach analyses for two logic problems that seem to influence future performance in the tutor for each group. Our results show that the students in the hint group approach the two problems in statistically and practically different ways, when compared to the control group. Our data-driven approach maps offer a novel way to compare behaviors between groups, while providing insight into the ways students solve problems.",31
Using game analytics to evaluate puzzle design and level progression in a serious game,"Drew Hicks, Michael Eagle, Elizabeth Rowe, Jodi Asbell-Clarke, Teon Edwards, Tiffany Barnes",2016/4/25,Conference Proceedings of the Sixth International Conference on Learning Analytics & Knowledge,"Our previous work has demonstrated that players who perceive a game as more challenging are likely to perceive greater learning from that game [8]. However, this may not be the case for all sources of challenge. In this study of a Science learning game called Quantum Spectre, we found that students' progress through the first zone of the game seemed to encounter a ""roadblock"" during gameplay, dropping out when they cannot (or do not want to) progress further. Previously we had identified two primary types of errors in the learning game, Quantum Spectre: Science Errors related to the game's core educational content; and Puzzle Errors related to rules of the game but not to science knowledge. Using this prior analysis, alongside Survival Analysis techniques for analyzing time-series data and drop-out rates, we explored players' gameplay patterns to help us understand player dropout in Quantum Spectre …",30
Estimating individual differences for student modeling in intelligent tutors from reading and pretest data,"Michael Eagle, Albert Corbett, John Stamper, Bruce M McLaren, Angela Wagner, Benjamin MacLaren, Aaron Mitchell",2016,"Conference Intelligent Tutoring Systems: 13th International Conference, ITS 2016, Zagreb, Croatia, June 7-10, 2016. Proceedings 13","Past studies have shown that Bayesian Knowledge Tracing (BKT) can predict student performance and implement Cognitive Mastery successfully. Standard BKT individualizes parameter estimates for skills, also referred to as knowledge components (KCs), but not for students. Studies deriving individual student parameters from the data logs of student tutor performance have shown improvements to the standard BKT model fits, and result in different practice recommendations for students. This study investigates whether individual student parameters, specifically individual difference weights (IDWs) [1], can be derived from student activities prior to tutor use. We find that student performance measures in reading instructional text and in a conceptual knowledge pretest can be employed to predict IDWs. Further, we find that a model incorporating these predicted IDWs performs well, in terms of model fit and …",21
Level up: a frame work for the design and evaluation of educational games,Michael Eagle,2009/4/26,Book Proceedings of the 4th International Conference on Foundations of Digital Games,"Games have the potential to transform the educational system in the United States. However, the study of games has lacked a coherent research paradigm. In order for games to research their full positional, there is a need to have a scientific way to evaluate the effectiveness of games and interactive environments for learning. In this paper, we discuss current research into the empirical evaluation of games; we use methods from the Intelligent Tutoring System literature to evaluate an educational computer science game. We do this by mapping empirical learning curves on student game-log data. We believe the results of this type of analysis can help evaluate and improve educational video game research.",21
Evaluation of a game-based lab assignment,"Michael Eagle, Tiffany Barnes",2009/4/26,Book Proceedings of the 4th International Conference on Foundations of Digital Games,"We have developed a learning game to teach loops, nested loops, and arrays using scaffolding and interactive visualization. We compare the game to a traditional programming assignment in an introductory computing laboratory. In our study, 17 Introduction to Computer Science labs were randomly assigned to play the learning game first and half to write a program first. Our results show that students playing the learning game first learn more, and that students prefer the game assignment to the traditional assignment. These results suggest that incorporation of game-based assignments is beneficial to student learning.",21
Invis: An interactive visualization tool for exploring interaction networks,"Matthew Johnson, Michael Eagle, Tiffany Barnes",2013/7/6,Conference Educational Data Mining 2013,"We introduce InVis, a novel visualization technique and tool for exploring, navigating, and understanding user interaction data. In-Vis creates a interaction network from student-interaction data extracted from large numbers of students using educational systems, and enables instructors to make new insights and discoveries about student learning. Here we present our novel interaction network model and InVis tool. We also demonstrate that InVis is an effective tool for providing instructors with useful and meaningful insights to how students solve problems.",20
The EDM Vis Tool.,"Matthew W Johnson, Michael Eagle, Leena Joseph, Tiffany Barnes",2011/7/6,Conference EDM,"We introduce EDM Vis, an information visualization software tool for exploring, navigating and understanding student data logs. EDM Vis loads student logs, entire classes, hundreds of students, at a time, and displays the student behavior of those students as they solved problems using a software tutor. The visualization uses a tree structure to provide an overview of class performance, and interface elements to allow easy navigation and exploration of student behavior.",20
Good communities and bad communities: Does membership affect performance?,"Rebecca Brown, Collin F Lynch, Michael Eagle, Jennifer L Albert, Tiffany Barnes, Ryan S Baker, Yoav Bergner, Danielle S McNamara",2015/6/26,Conference EDM,"The current generation of Massive Open Online Courses (MOOCs) are designed to leverage student knowledge to augment instructor guidance. Activity in these courses is typically centered on a threaded forum that, while curated by the instructors, is largely student driven. When planning MOOCs, it is commonly hoped that open forums will allow students to interact freely and that better students will help the poorer performers. It has not yet been shown, however, that this occurs in practice.",19
Survival analysis on duration data in intelligent tutors,"Michael Eagle, Tiffany Barnes",2014,"Conference Intelligent Tutoring Systems: 12th International Conference, ITS 2014, Honolulu, HI, USA, June 5-9, 2014. Proceedings 12","Effects such as student dropout and the non-normal distribution of duration data confound the exploration of tutor efficiency, time-in-tutor vs. tutor performance, in intelligent tutors. We use an accelerated failure time (AFT) model to analyze the effects of using automatically generated hints in Deep Thought, a propositional logic tutor. AFT is a branch of survival analysis, a statistical technique designed for measuring time-to-event data and account for participant attrition. We found that students provided with automatically generated hints were able to complete the tutor in about half the time taken by students who were not provided hints. We compare the results of survival analysis with a standard between-groups mean comparison and show how failing to take student dropout into account could lead to incorrect conclusions. We demonstrate that survival analysis is applicable to duration data collected from …",18
Towards data-driven mastery learning,"Behrooz Mostafavi, Michael Eagle, Tiffany Barnes",2015/3/16,Book Proceedings of the Fifth International Conference on Learning Analytics And Knowledge,"We have developed a novel data-driven mastery learning system to improve learning in complex procedural problem solving domains. This new system was integrated into an existing logic proof tool, and assigned as homework in a deductive logic course. Student performance and dropout were compared across three systems: The Deep Thought logic tutor, Deep Thought with integrated hints, and Deep Thought with our data-driven mastery learning system. Results show that the data-driven mastery learning system increases mastery of target tutor-actions, improves tutor scores, and lowers the rate of tutor dropout over Deep Thought, with or without provided hints.",15
A learning objective focused methodology for the design and evaluation of game-based tutors,"Michael John Eagle, Tiffany Barnes",2012/2/29,Book Proceedings of the 43rd ACM technical symposium on Computer Science Education,"We present the Game2Learn methodology for the design and evaluation of educational games with a focus on well-defined learning objectives and empirical verification. This integrative process adapts ideas from educational design, intelligent tutoring systems, classical test-theory, and interaction and game design, and agile software development. The methodology guides researchers through the steps of the design process, including identification of specific learning objectives, translation of learning activities to game mechanics, and the empirical evaluation of the final product. This methodology is particularly useful for ensuring successful student research experiences or software engineering courses.",15
A framework for hypothesis-driven approaches to support data-driven learning analytics in measuring computational thinking in block-based programming,"Shuchi Grover, Marie Bienkowski, Satabdi Basu, Michael Eagle, Nicholas Diana, John Stamper",2017/3/13,Book Proceedings of the seventh international learning analytics & knowledge conference,"K-12 classrooms use block-based programming environments (BBPEs) for teaching computer science and computational thinking (CT). To support assessment of student learning in BBPEs, we propose a learning analytics framework that combines hypothesis- and data-driven approaches to discern students' programming strategies from BBPE log data. We use a principled approach to design assessment tasks to elicit evidence of specific CT skills. Piloting these tasks in high school classrooms enabled us to analyze student programs and video recordings of students as they built their programs. We discuss a priori patterns derived from this analysis to support data-driven analysis of log data in order to better assess understanding and use of CT in BBPEs.",14
Evaluation of automatically generated hint feedback,"Michael Eagle, Tiffany Barnes",2013/7/6,Conference Educational Data Mining 2013,"This work explores the effects of using automatically generated hints in problem solving tutor environments. Generating hints automatically removes a large amount of development time for new tutors, and it also useful for already existing computer-aided instruction systems that lack intelligent feedback. We focus on a series of problems, after which, previous analysis showed the control group is to be 3.5 times more likely to cease logging onto an online tutor when compared to the group who were given hints. We found a consistent trend in which students without hints spent more time on problems when compared to students that were provided hints.",14
"Intelligent Tutoring Systems, Educational Data Mining, and the Design and Evaluation of Video Games.","Michael Eagle, Tiffany Barnes",2010/6/14,Conference Intelligent Tutoring Systems (2),"Technological support for personalized learning has the potential to transform the educational system in the United States. There is a growing interest in educational games and their potential for motivating learners. Techniques from the educational data mining and intelligent tutoring systems communities can be leveraged to better understand, design, and evaluate educational games for both learning effectiveness and learner engagement. This work explores the use of intelligent feedback in games as well as the potential pitfalls; it concludes with a proposed study designed to explore the differences between intelligent tutoring systems and educational video games.",12
Towards automatic hint generation for a data-driven novice programming tutor,"Wei Jin, Lorrie Lehmann, Matthew Johnson, Michael Eagle, Behrooz Mostafavi, Tiffany Barnes, J Stamper",2011/8,"Journal Workshop on knowledge discovery in educational data, 17th ACM conference on knowledge discovery and data mining","________________________________________________________________________ Hint annotation is one of the most time consuming components of developing intelligent tutoring systems. One approach is to use educational data mining and machine learning techniques to automate the creation of hints from student problem-solving data. This paper describes a new technique to represent, classify, and use programs written by novices as a base for automatic hint generation for programming tutors. Our preliminary evaluation shows that this approach can effectively cluster programs and therefore has potential to be a source for automatically generated hints for novice programmers.",11
Data-driven generation of rubric criteria from an educational programming environment,"Nicholas Diana, Michael Eagle, John Stamper, Shuchi Grover, Marie Bienkowski, Satabdi Basu",2018/3/7,Book Proceedings of the 8th International Conference on Learning Analytics and Knowledge,"We demonstrate that, by using a small set of hand-graded student work, we can automatically generate rubric criteria with a high degree of validity, and that a predictive model incorporating these rubric criteria is more accurate than a previously reported model. We present this method as one approach to addressing the often challenging problem of grading assignments in programming environments. A classic solution is creating unit-tests that the student-generated program must pass, but the rigid, structured nature of unit-tests is suboptimal for assessing the more open-ended assignments students encounter in introductory programming environments like Alice. Furthermore, the creation of unit-tests requires predicting the various ways a student might correctly solve a problem - a challenging and time-intensive process. The current study proposes an alternative, semi-automated method for generating rubric criteria …",10
Predicting individual differences for learner modeling in intelligent tutors from previous learner activities,"Michael Eagle, Albert Corbett, John Stamper, Bruce M McLaren, Ryan Baker, Angela Wagner, Benjamin MacLaren, Aaron Mitchell",2016/7/13,Book Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization,"This study examines how accurately individual student differences in learning can be predicted from prior student learning activities. Bayesian Knowledge Tracing (BKT) predicts learner performance well and has often been employed to implement cognitive mastery. Standard BKT individualizes parameter estimates for knowledge components, but not for learners. Studies have shown that individualizing parameters for learners improves the quality of BKT fits and can lead to very different (and potentially better) practice recommendations. These studies typically derive best-fitting individualized learner parameters from learner performance in existing data logs, making the methods difficult to deploy in actual tutor use. In this work, we examine how well BKT parameters in a tutor lesson can be individualized based on learners' prior performance in reading instructional text, taking a pretest, and completing an earlier …",9
Measuring Gameplay Affordances of User-Generated Content in an Educational Game.,"Drew Hicks, Zhongxiu Liu, Michael Eagle, Tiffany Barnes",2016,Journal International Educational Data Mining Society,"Level creation is a creative game-play exercise that resembles problem-posing, and has shown to be engaging and helpful for players to learn about the game's core mechanic. However, in user-authoring environments, users often create levels without considering the game's objective, or with entirely different objectives in mind, resulting in levels which fail to afford the core gameplay mechanic. This poses a bigger threat to educational games, because the core gameplay is aligned with the learning objectives. Therefore, such levels fail to provide any opportunity for players to practice the skills the game is designed to teach. To address this problem, we designed and compared three versions of level creators in a programming game -- Freeform, Programming, and Building-Block. Our results show that a simple-to-use building-block editor can guarantee levels that contain some affordances, but an editor designed to use the same core mechanic as gameplay results in the highest-quality",9
An algorithm for reducing the complexity of interaction networks,"Matthew Johnson, Michael Eagle, John Stamper, Tiffany Barnes",2013/7/6,Conference Educational Data Mining 2013,"We present an algorithm for reducing the size and complexity of the Interaction Network, a data structure used for storing solution paths explored by students in open-ended multi-step problem solving environments. Our method reduces the number of edges and nodes of an Interaction Network by an average of 90% while still accounting for 40% of actions performed by students, and preserves the most frequent half of solution paths. We compare our method to two other approaches and demonstrate why it is more effective at reducing the size of large Interaction Networks.",9
Exploring player behavior with visual analytics.,"Michael Eagle, Matthew W Johnson, Tiffany Barnes, Acey Kreisler Boyce",2013/5,Conference FDG,"In designing puzzle and educational games, it is critical to be able to understand player behavior, in order to provide feedback when a player needs help, or redesign a game to keep players on-task. However, building a system that can react to all possible player behaviors can be very time intensive, and if a redesign is needed, can be a wasted effort. We propose a novel visual analytic approach to analyzing playtest data to help the game design process, and demonstrate its application to BeadLoom Game. The approach helped the game developers identify uninterested players, and refine the game so players could get a better sense of how close they were to the puzzle’s solution.",9
Extracting Measures of Active Learning and Student Self-Regulated Learning Strategies from MOOC Data,"Nicholas Diana, Michael Eagle, John Stamper, Kenneth R Koedinger",2016,Conference Proceedings of the Eighth International Conference on Educational Data Mining,"Previous work has demonstrated that in the context of Massively Open Online Courses (MOOCs), doing activities is more predictive of learning than reading text or watching videos (Koedinger et al., 2015). This paper breaks down the general behaviors of reading and watching into finer behaviors, and considers how these finer behaviors may provide evidence for active learning as well. By characterizing learner strategies through patterns in their data, we can evaluate which strategies (or measures of them) are predictive of learning outcomes. We investigated strategies such as page re-reading (active reading) and video watching in response to an incorrect attempt (active watching) and found that they add predictive power beyond mere counts of the amount of doing, reading, and watching.",8
Measuring implicit science learning with networks of player-game interactions,"Michael Eagle, Elizabeth Rowe, Drew Hicks, Rebecca Brown, Tiffany Barnes, Jodi Asbell-Clarke, Teon Edwards",2015/10/5,Book Proceedings of the 2015 Annual Symposium on Computer-Human Interaction in Play,"Visualizing player behavior in complex problem solving tasks such as games is important for both assessing learning and for the design of content. We collected data from 195 high school students playing an optics puzzle game, Quantum Spectre, and modeled their game play as an interaction network, examining errors hypothesized to be related to a lack of implicit understanding of the science concepts embedded in the game. We found that the networks were useful for visualization of student behavior, identifying areas of student misconceptions and locating regions of the network where students become stuck. Preliminary regression analyses show a negative relationship between the science misconceptions identified during gameplay and implicit science learning.",8
Data-driven domain models for problem solving,"Tiffany Barnes, Behrooz Mostafavi, Michael J Eagle",2016,Journal Design Recommendations for Intelligent Tutoring Systems,"Problem solving is integral to learning in science, technology, engineering, math, and computer science (STEM+ C) fields. Computer-aided instruction environments allow students to work open-ended problems, but often fall short on providing students with individualized feedback. Intelligent tutoring systems and cognitive tutors provide student feedback that approaches that of human tutors. We have created a data-driven method of producing problem-specific domain models as well as tutor-specific student models. We model each problem as an interaction network, a graph-based, problem-specific domain model that represents data collected during interactive problem solving. These domain models are naturally constrained by the specific problem-solving environment and the biases of students using it to solve problems. We use the interaction networks to mark problem steps as correct or incorrect by tracking each student’s ability to recognize when to use specific tutor-actions and assign problems appropriate to each student’s level. The combination of these methods allows tutor developers to individualize problem selection and provide next-step hints and worked examples that can improve student learning. In this chapter, we describe how we use interaction networks in place of formal domain models to provide intelligent support for learning, enabling the creation of intelligent tutors from existing problem-solving environments and their data. We also highlight how the process of constructing data-driven support for intelligent tutors can lead to understanding the problem-solving domains themselves.",6
Peer tutor matching for introductory programming: Data-driven methods to enable new opportunities for help,"Nicholas Diana, Michael Eagle, John Stamper, Shuchi Grover, Marie Bienkowski, Satabdi Basu",2018,"Publisher International Society of the Learning Sciences, Inc.[ISLS].","The number of students that can be helped in a given class period is limited by the time constraints of the class and the number of agents available for providing help. We use a classroom-replay of previously collected data to evaluate a data-driven method for increasing the number of students that can be helped. We use a machine learning model to identify students who need help in real-time, and an interaction network to group students who need similar help together using approach maps. By assigning these groups of struggling students to peer tutors (as well the instructor), we were able to more than double the number of students helped.",5
Data-driven generation of rubric parameters from an educational programming environment,"Nicholas Diana, Michael Eagle, John Stamper, Shuchi Grover, Marie Bienkowski, Satabdi Basu",2017,"Conference Artificial Intelligence in Education: 18th International Conference, AIED 2017, Wuhan, China, June 28–July 1, 2017, Proceedings 18","We demonstrate that, by using a small set of hand-graded students, we can automatically generate rubric parameters with a high degree of validity, and that a predictive model incorporating these rubric parameters is more accurate than a previously reported model. We present this method as one approach to addressing the often challenging problem of grading assignments in programming environments. A classic solution is creating unit-tests that the student-generated program must pass, but the rigid, structured nature of unit-tests is suboptimal for assessing more open-ended assignments. Furthermore, the creation of unit-tests requires predicting the various ways a student might correctly solve a problem – a challenging and time-intensive process. The current study proposes an alternative, semi-automated method for generating rubric parameters using low-level data from the Alice programming …",5
Validating Game-Based Measures of Implicit Science Learning.,"Elizabeth Rowe, Michael Eagle, Drew Hicks",2016,Journal International Educational Data Mining Society,"Building on prior work visualizing player behavior using interaction networks [1], we examined whether measures of implicit science learning collected during gameplay were significantly related to changes in external pre-post assessments of the same constructs. As part of a national implementation study, we collected data from 329 high school students playing an optics puzzle game, ""Quantum Spectre,"" and modeled their gameplay as an interaction network, examining errors hypothesized to be related to a lack of implicit understanding of the science concepts embedded in the game. Hierarchical linear modeling (HLM) showed a negative relationship between the science errors identified during gameplay and implicit science learning. These results suggest ""Quantum Spectre"" gameplay behaviors are valid assessments of implicit science learning. Implications for how gameplay data might inform classroom teaching in-game scaffolding is discussed. [For the full proceedings, see",5
Data-Driven Method for Assessing Skill-Opportunity Recognition in Open Procedural Problem Solving Environments.,"Michael John Eagle, Tiffany Barnes",2012/6/14,Conference ITS,"Our research goal is to use data-driven methods to generate the basic functionalities of intelligent tutoring systems. In open procedural problem solving environments, the tutor gives users a goal with little to no restrictions on how to reach it. Knowledge components refer to not only skill application, but also applicable skill-opportunity recognition. Syntax and logic errors further confound the results with ambiguity in error detection. In this work, we present a domain independent method of assessing skill-opportunity recognition. The results of this method can be used to provide automatic feedback to users as well as to assess users problem solving abilities.",5
Data-Driven Methods for Deriving Insight from Educational Problem Solving Environments,Michael John Eagle,2015,Institution North Carolina State University,"Intelligent tutoring systems provide personalized feedback to students and improve learning at effect sizes approaching that of human tutors. However, the design and development of these systems is expensive and requires the collaboration of experts across multiple fields. An additional benefit of these educational systems is that they allow collection of detailed records of student actions. However, the complex nature of this interaction rich data makes it difficult to analyze. In previous work, researchers were able to use a past corpus of student data to generate one of the basic features of intelligent tutoring systems, a personalized hint about the next step in a problem. We have used a variety of methods to discover the effectiveness of these automatically generated hints in terms of tutor performance, student motivation, and student problem solving strategies.",4
Interaction Network Estimation: Predicting Problem-Solving Diversity in Interactive Environments.,"Michael Eagle, Drew Hicks, Tiffany Barnes",2015,Conference 8th International Conference on Educational Data Mining,"Intelligent tutoring systems and computer aided learning environments aimed at developing problem solving produce large amounts of transactional data which make it a challenge for both researchers and educators to understand how students work within the environment. Researchers have modeled student-tutor interactions using complex networks in order to automatically derive next step hints. However, there are no clear thresholds for the amount of student data required before the hints can be produced. We introduce a novel method of estimating the size of the unobserved interaction network from a sample by leveraging Good-Turing frequency estimation. We use this estimation to predict size, growth, and overlap of interaction networks using a small sample of student data. Our estimate is accurate in as few as 10{30 students and is a good predictor for the growth of the observed state space for the full network, as well as the subset of the network which is usable for automatic hint",4
Exploring Problem-Solving Behavior in an Optics Game.,"Michael Eagle, Rebecca Brown, Elizabeth Rowe, Tiffany Barnes, Jodi Asbell-Clarke, Teon Edwards",2015,Conference EDM,"Understanding player behavior in complex problem solving tasks is important for both assessing learning and for the design of content. Previous research has modeled studenttutor interactions as a complex network; researchers were able to use these networks to provide visualizations and automatically generated feedback. We collected data from 195 high school students playing an optics puzzle game, Quantum Spectre, and modeled their game play as an interaction network. We found that the networks were useful for visualization of student behavior, identifying areas of student misconceptions, and locating regions of the network where students become stuck.",4
Predictive Student Modeling for Interventions in Online Classes.,"Michael Eagle, Ted Carmichael, Jessica Stokes, Mary Jean Blink, John C Stamper, Jason Levin",2018/7,Conference EDM,"As large-scale online classes become more prevalent there is great interest in finding ways to model students at scale in these classes in order to predict outcomes. Student models, if successful, would help determine strong predictors of student success, which would highlight potential causal factors for such success, allowing schools to focus on refinements and interventions that positively impact their student outcomes. In this research, TutorGen has partnered with Western Governors University (WGU), a large online university, and gathered data at scale in order to build exploratory models to predict student outcomes. This paper presents our results so far in successfully identifying students who will pass (or even take) the final exam. We have examined the order in which students take courses, as well as the timing of starting and completing work; our initial analysis reveals that these are strong predictors of course outcomes.",3
Automatic Peer Tutor Matching: Data-Driven Methods to Enable New Opportunities for Help.,"Nicholas Diana, Michael Eagle, John C Stamper, Shuchi Grover, Marie A Bienkowski, Satabdi Basu",2017/6,Conference EDM,"The number of students that can be helped in a given class period is limited by the time constraints of the class and the number of agents available for providing help. We use a classroom-replay of previously collected data to evaluate a data-driven method for increasing the number of students that can be helped. We use a machine learning model to identify students who need help in real-time, and an interaction network to group students who need similar help together using approach maps. By assigning these groups of struggling students to peer tutors (as well the instructor), we were able to more than double the number of students helped.",3
Exploring learner model differences between students,"Michael Eagle, Albert Corbett, John Stamper, Bruce M McLaren, Ryan Baker, Angela Wagner, Benjamin MacLaren, Aaron Mitchell",2017,"Conference Artificial Intelligence in Education: 18th International Conference, AIED 2017, Wuhan, China, June 28–July 1, 2017, Proceedings 18"," Bayesian Knowledge Tracing (BKT) has been employed successfully in intelligent learning environments to individualize curriculum sequencing and help messages. Standard BKT employs four parameters, which are estimated separately for individual knowledge components, but not for individual students. Studies have shown that individualizing the parameter estimates for students based on existing data logs improves goodness of fit and leads to substantially different practice recommendations. This study investigates how well BKT parameters in a tutor lesson can be individualized ahead of time, based on learners’ prior activities, including reading text and completing prior tutor lessons. We find that directly applying best-fitting individualized parameter estimates from prior tutor lessons does not appreciably improve BKT goodness of fit for a later tutor lesson, but that individual differences in the later …",3
Data-driven feedback beyond next-step hints,"Michael Eagle, Tiffany Barnes",2014/7/4,Conference Educational Data Mining 2014,"Intelligent tutors have been shown to be as effective as human tutors in supporting learning in many domains. Although they can be very effective, the construction of intelligent tutors can be costly. One way to address this problem is to use previously collected data to generate domain models to provide intelligent feedback to otherwise non-personalized tutors. These data-driven methods for providing next-step hints have been successful in providing feedback to students in procedural problem solving tutors. We seek to expand on next-step hints with other data-driven methods. We outline three different interventions, all of which can be generated using previously collected student data.",3
Modeling student dropout in tutoring systems,"Michael Eagle, Tiffany Barnes",2014,"Conference Intelligent Tutoring Systems: 12th International Conference, ITS 2014, Honolulu, HI, USA, June 5-9, 2014. Proceedings 12","Intelligent tutors have been shown to be almost as effective as human tutors in supporting learning in many domains. However, the construction of intelligent tutors can be costly. One way to address this problem is to use previously collected data to generate models to provide intelligent feedback to otherwise non-personalized tutors. In this work, we explore how we can use previously collected data to build models of student dropout over time; we define dropout as ceasing to interact with the tutor before the completion of all required tasks. We use survival analysis, a statistical method of measuring time to event data, to model how long we can expect students to interact with a tutor. Future work will explore ways to use these models to to provide personalized feedback, with the goal of preventing students from dropping out.",3
Predicting Individualized Learner Models across Tutor Lessons.,"Michael Eagle, Albert Corbett, John Stamper, Bruce Mclaren",2018/7,Journal International Educational Data Mining Society,"In this work we use prior to tutor-session data to generate an individualized student knowledge model. Intelligent learning environments use student models to individualize curriculum sequencing and help messages. Researchers decompose the learning tasks into sets of Knowledge Components (KCs) that represent individual units of knowledge; the student model estimates a parameters for each KC, but not for each student. Using existing performance data to adjust parameters for each individual student improves model fit, and leads to different practice recommendations. However, in order to be implemented in a live system we need to have a method to estimate the student parameters using only the student's prior activities. In this work, we use data collected from student reading, prior tutor lessons, to predict individualized difference weights for parameters of a Bayesian Knowledge Tracing (BKT) variant. We find that best-fitting student parameters trained on previous lessons do not",2
Measuring transfer of data-driven code features across tasks in alice,"Nicholas Diana, Michael Eagle, John Stamper, Shuchi Grover, Marie Bienkowski, Satabdi Basu",2018,Journal Proceedings of SPLICE 2018 workshop Computing Science Education Infrastructure,"Previous research has demonstrated that low-level log data from introductory programming environments like Alice can be used to predict student outcomes and generate datadriven rubric criteria. The success of these methods suggests that the features used in these predictive models may be crude representations of more fundamental introductory programming skills. In this experiment we first replicated previously reported methods using a novel dataset. Then, we tested whether or not the features predictive of success on one task are also predictive of other tasks. We found that we could, with reasonable accuracy, use a model trained on data from one task to predict a separate task. Our results suggest that the features of successful predictive models contain some amount of information that transfers across tasks.",2
Towards Understanding the Impact of Real-Time AI-Powered Educational Dashboards (RAED) on Providing Guidance to Instructors,Ajay Kulkarni,2021/7/30,Journal arXiv preprint arXiv:2107.14414,"The objectives of this ongoing research are to build Real-Time AI-Powered Educational Dashboard (RAED) as a decision support tool for instructors, and to measure its impact on them while making decisions. Current developments in AI can be combined with the educational dashboards to make them AI-Powered. Thus, AI can help in providing recommendations based on the students' performances. AI-Powered educational dashboards can also assist instructors in tracking real-time student activities. In this ongoing research, our aim is to develop the AI component as well as improve the existing design component of the RAED. Further, we will conduct experiments to study its impact on instructors, and understand how much they trust RAED to guide them while making decisions. This paper elaborates on the ongoing research and future direction.",1
Estimating effects of the decision support system on educational agents with simulations,"Ajay Kulkarni, Michael Eagle",2020/5/18,Conference 2020 Spring Simulation Conference (SpringSim),"This paper presents the simulated results of four different scenarios from an ABM to understand the effect of utilization of Alert and Recommender systems on graduation rate. Academic advising help students to enhance their academic performance, and it is also one of the critical aspects of judging institutional effectiveness. For evaluating the effectiveness, college graduation rates are calculated for every scenario, and then they are compared with the baseline scenario. This objective is achieved by using details of SAT scores and core courses of the Department of Physics and Astronomy at a large public university. The prime focus of the paper is to model the impact of the system, which, in reality, helps to save time and cost. The preliminary results show that the Alert and Recommender system could have a positive impact on graduation rates.",1
Predictive models of user performance for marksmanship training,"Mary Jean Blink, Ted Carmichael, Jennifer Murphy, Michael Eagle",2018/5/10,Conference The Thirty-First International Flairs Conference,"How the Army conducts rifle marksmanship training is undergo-ing a number of positive changes. Despite this, challenges to con-ducting and coordinating this critical training remain. One chal-lenge to assessing training effectiveness is a lack of persistent records of soldier performance; too often soldier data are purged shortly after training events for convenience and in order to en-sure privacy. This paper reports on our efforts to research the fea-sibility of collecting, analyzing, and storing data from multiple training systems, in order to accelerate and improve marksman-ship training. We do this through the use of cognitive, psychomo-tor, and affective constructs; and the use of predictive modeling techniques in order to forecast marksmanship qualification scores. These models successfully predicted scores on a 40-point scalewith a root mean square error (RMSE) of less than three, using models that are robust to changing input variables. Future im-provements and directions for this research are also discussed.",1
Teaching informal logical fallacy identification with a cognitive tutor,"Nicholas Diana, Michael Eagle, John Stamper, Kenneth R Koedinger",2017,"Conference Artificial Intelligence in Education: 18th International Conference, AIED 2017, Wuhan, China, June 28–July 1, 2017, Proceedings 18","In this age of fake news and alternative facts, the need for a citizenry capable of critical thinking has never been greater. While teaching critical thinking skills in the classroom remains an enduring challenge, research on an ill-defined domain like critical thinking in the educational technology space is even more scarce. We propose a difficulty factors assessment (DFA) to explore two factors that may make learning to identify fallacies more difficult: type of instruction and belief bias. This study will allow us to make two key contributions. First, we will better understand the relationship between sense-making and induction when learning to identify informal fallacies. Second, we will contribute to the limited work examining the impact of belief bias on informal (rather than formal) reasoning. The results of this DFA will also be used to improve the next iteration of our fallacy tutor, which may ultimately contribute to a …",1
Exploring Missing Behaviors with Region-Level Interaction Network Coverage,"Michael Eagle, Tiffany Barnes",2015,"Conference Artificial Intelligence in Education: 17th International Conference, AIED 2015, Madrid, Spain, June 22-26, 2015. Proceedings 17","We have used a complex network model of student-tutor interactions to derive high-level approaches to problem solving. We also have used interaction networks to evaluate between-group differences in student approaches, as well as for automatically producing both next-step and high-level hints. Students do not visit vertices within the networks uniformly; students from different experimental groups are expected to have different patterns of network exploration. In this work we explore the possibility of using frequency estimation to uncover locations in the network with differing amounts of student-saturation. Identification of these regions can be used to locate specific problem approaches and strategies that would be most improved by additional student-data, as well as provide a measure of confidence when comparing across networks or between groups.",1
Exploration of Student's Use of Rule Application References in a Propositional Logic Tutor,"Michael Eagle, Vinaya Polamreddi, Behrooz Mostafavi, Tiffany Barnes",2014/7/4,Conference Educational Data Mining 2014,"Many tutors offer students reference material or tips that they can access as needed. We have logged data about student use of references with Deep Thought logic tutor which to understand why and how references are used. We find evidence that students use these references in systematic ways that change over the course of the tutor, and can be predictive of rule application errors. We can use this information to increase our understanding of which concepts students find similar, what times during the tutor students feel the need to use references. Our goal is to eventually incorporate data-driven feedback based on when and how the references are accessed.",1
Using sequential pattern mining to increase graph comprehension in intelligent tutoring system student data,"Aaron Springer, Matthew Johnson, Michael Eagle, Tiffany Barnes",2013/3/6,Book Proceeding of the 44th ACM technical symposium on Computer science education,"Examining student interactions in multi-step problems from Intelligent Tutoring Systems currently involves examining thousands of interactions from hundreds of students. We designed and implemented a sequential pattern mining algorithm and a sequence rating algorithm that together recognize interesting student action sequences and display them to the user in the context of the larger graph system. With the added feature of our algorithms in the InVis system, we hope to allow teachers and tutoring system designers to better understand student action patterns and thus cater better to their learning.",1
Wu's castle: teaching for loops and arrays using games,Michael Eagle,2007/10/14,Book Proceedings of the 2007 conference on Diversity in computing,"The Game2Learn project seeks to recruit and retain novice computing students by presenting programming concepts in a less intimidating setting, while leveraging the interactivity and motivation of games. We present Wu’s Castle, a two-dimensional role-playing game that teaches loops and arrays in an interactive, visual way. In Wu’s Castle, players program magical creatures called machina to create armies of snowmen. Players can practice programming and easily identify mistakes in a safe environment. The results of our pilot pre-test post-test study suggest that Wu’s Castle implements good practices for teaching programming within a game.",1
Using Interaction Networks to Identify Unproductive Solution Steps in Multistep Problems,"Drew Hicks, Michael Eagle",2017/1,"Description Interaction networks are a complex graph structure for transactional student data. They enable developers to use common graph analysis algorithms to uncover insights into both student behavior and system behavior. The data contained in these networks can be used to supplement expert understanding of those domains, allowing student, task, and evidence models to be derived from observed behavior in the systems. However, even for simple problems, these networks can be large and dense, making it difficult for domain experts and educators to gain insights from them and hard to draw conclusions about groups of student paths. This is especially true for systems that are not simple rule-using systems, for example, systems where code is written and then run. To address this issue, we use an abstract state representation to create clusters. This state representation is built for each domain by generalizing multiple …","Interaction networks are a complex graph structure for transactional student data. They enable developers to use common graph analysis algorithms to uncover insights into both student behavior and system behavior. The data contained in these networks can be used to supplement expert understanding of those domains, allowing student, task, and evidence models to be derived from observed behavior in the systems. However, even for simple problems, these networks can be large and dense, making it difficult for domain experts and educators to gain insights from them and hard to draw conclusions about groups of student paths. This is especially true for systems that are not simple rule-using systems, for example, systems where code is written and then run. To address this issue, we use an abstract state representation to create clusters. This state representation is built for each domain by generalizing multiple …",
Estimating the Local Size and Coverage of Interaction Network Regions.,"Michael Eagle, Tiffany Barnes",2015/6,Journal International Educational Data Mining Society,"Interactive problem solving environments, such as intelligent tutoring systems and educational video games, produce large amounts of transactional data which make it a challenge for both researchers and educators to understand how students work within the environment. Researchers have modeled the student-tutor interactions using complex network representations to automatically derive next-step hints, derive high-level approaches, and create visualizations of student behavior. However, students do not explore the complete problem space. The nonuniform exploration of the problem results in smaller networks and less next-step hints. In this work we explore the possibility of using frequency estimation to uncover locations in the network with differing amounts of student-saturation. Identification of these regions can be used to locate specific problem approaches and strategies that would be most improved by additional student-data. [For complete proceedings, see ED560503.]",
Experimental evaluation of automatic hint generation for a logic tutor.,"John Stamper, Michael Eagle, Tiffany Barnes, Marvin Croy",2011,Conference Proceeding of the 15th International Conference on Artificial Intelligence in Education (AIED2011).,,
Experimental Evaluation of Automatic Hint Generation for a Logic Tutor,"John Stamper, Michael Eagle, Tiffany Barnes, Marvin Croy",2013,Journal International Journal of Artificial Intelligence in Education,"We have augmented the Deep Thought logic tutor with a Hint Factory that generates data-driven, context-specific hints for an existing computer aided instructional tool. We investigate the impact of the Hint Factory's automatically generated hints on educational outcomes in a switching replications experiment that shows that hints help students persist in a deductive logic proofs tutor. Three instructors taught two semester-long courses, each teaching one semester using a logic tutor with hints, and one semester using the tutor without hints, controlling for the impact of different instructors on course outcomes. Our results show that students in the courses using a logic tutor augmented with automatically generated hints attempted and completed significantly more logic proof problems, were less likely to abandon the tutor, performed significantly better on a post-test implemented within the tutor, and achieved higher …",121
