titles,authors,date,source,descriptions,citations
Modnn: Local distributed mobile computing system for deep neural network,"Jiachen Mao, Xiang Chen, Kent W Nixon, Christopher Krieger, Yiran Chen",2017/3/27,"Conference Design, Automation & Test in Europe Conference & Exhibition (DATE), 2017","Although Deep Neural Networks (DNN) are ubiquitously utilized in many applications, it is generally difficult to deploy DNNs on resource-constrained devices, e.g., mobile platforms. Some existing attempts mainly focus on client-server computing paradigm or DNN model compression, which require either infrastructure supports or special training phases, respectively. In this work, we propose MoDNN - a local distributed mobile computing system for DNN applications. MoDNN can partition already trained DNN models onto several mobile devices to accelerate DNN computations by alleviating device-level computing cost and memory usage. TWo model partition schemes are also designed to minimize non-parallel data delivery time, including both wakeup time and transmission time. Experimental results show that when the number of worker nodes increases from 2 to 4, MoDNN can accelerate the DNN …",220
How convolutional neural network see the world-A survey of convolutional neural network visualization methods,"Zhuwei Qin, Fuxun Yu, Chenchen Liu, Xiang Chen",2018/4/30,Journal arXiv preprint arXiv:1804.11191,"Nowadays, the Convolutional Neural Networks (CNNs) have achieved impressive performance on many computer vision related tasks, such as object detection, image recognition, image retrieval, etc. These achievements benefit from the CNNs outstanding capability to learn the input features with deep layers of neuron structures and iterative training process. However, these learned features are hard to identify and interpret from a human vision perspective, causing a lack of understanding of the CNNs internal working mechanism. To improve the CNN interpretability, the CNN visualization is well utilized as a qualitative analysis method, which translates the internal features into visually perceptible patterns. And many CNN visualization works have been proposed in the literature to interpret the CNN in perspectives of network structure, operation, and semantic concept. In this paper, we expect to provide a comprehensive survey of several representative CNN visualization methods, including Activation Maximization, Network Inversion, Deconvolutional Neural Networks (DeconvNet), and Network Dissection based visualization. These methods are presented in terms of motivations, algorithms, and experiment results. Based on these visualization methods, we also discuss their practical applications to demonstrate the significance of the CNN interpretability in areas of network design, optimization, security enhancement, etc.",214
How is energy consumed in smartphone display applications?,"Xiang Chen, Yiran Chen, Zhan Ma, Felix CA Fernandes",2013/2/26,Book Proceedings of the 14th Workshop on Mobile Computing Systems and Applications,"Smartphones have emerged as a popular and frequently used platform for the consumption of multimedia. New display technologies, such as AMOLED, have been recently introduced to smartphones to fulfill the requirements of these multimedia applications. However, as an AMOLED screen's power consumption is determined by the display content, such applications are often limited by the battery life of the device they are running on, inspiring many researches to develop new power management schemes. In this work, we evaluate the power consumption of several applications on a series of Samsung smartphones and take a deep look into AMOLED's power consumption and its relative contributions for multimedia apps. We improve AMOLED power analysis by considering the dynamic factors in displaying, and analyze the individual factors affecting power consumption when streaming video, playing a video …",186
Elfish: Resource-aware federated learning on heterogeneous edge devices,"Zirui Xu, Zhao Yang, Jinjun Xiong, Janlei Yang, Xiang Chen",2019,Journal Ratio,"Leveraging scalable data parallelism and effective model parameter aggregation, Federated Learning has been widely used to unite resource-constrained devices for neural network training-on-edge. However, when federated learning deploys identical neural network models to heterogeneous edge devices, the ones with weak computation capacities may significantly delay the synchronized parameter aggregation, causing severe computational straggler issues. Although stragglers can be accelerated by training model optimization, the optimized models usually result-in diverged structures due to heterogeneous devices’ resource constraints and significantly defect the collaborative convergence. Therefore, most solutions can only be compromised with asynchronous edge collaboration, without fundamentally eliminating computational stragglers. In this work, we propose ELFISH—a resource-aware federated learning framework to tackle these challenges. In ELFISH, neural network models’ training consumption will be firstly profiled in terms of different computation resources. Guided by profiling, a “softtraining” method is proposed for straggler acceleration, which partially trains the model by masking a particular number of resourceintensive neurons. Rather than generating a deterministically optimized model with diverged structure, different sets of neurons will be dynamically masked every training cycle and will be recovered and updated during parameter aggregation, ensuring comprehensive model updates overtime. The corresponding parameter aggregation scheme is also proposed to balance the contribution from soft-trained models and …",70
Mednn: A distributed mobile system with enhanced partition and deployment for large-scale dnns,"Jiachen Mao, Zhongda Yang, Wei Wen, Chunpeng Wu, Linghao Song, Kent W Nixon, Xiang Chen, Hai Li, Yiran Chen",2017/11/13,Conference 2017 IEEE/ACM International Conference on Computer-Aided Design (ICCAD),"Deep Neural Networks (DNNs) are pervasively used in a significant number of applications and platforms. To enhance the execution efficiency of large-scale DNNs, previous attempts focus mainly on client-server paradigms, relying on powerful external infrastructure, or model compression, with complicated pre-processing phases. Though effective, these methods overlook the optimization of DNNs on distributed mobile devices. In this work, we design and implement MeDNN, a local distributed mobile computing system with enhanced partitioning and deployment tailored for large-scale DNNs. In MeDNN, we first propose Greedy Two Dimensional Partition (GTDP), which can adaptively partition DNN models onto several mobile devices w.r.t. individual resource constraints. We also propose Structured Model Compact Deployment (SMCD), a mobile-friendly compression scheme which utilizes a structured sparsity …",69
Quality-retaining OLED dynamic voltage scaling for video streaming applications on mobile devices,"Xiang Chen, Jian Zheng, Yiran Chen, Mengying Zhao, Chun Jason Xue",2012/6/3,Book Proceedings of the 49th Annual Design Automation Conference,"This paper developed a dynamic voltage scaling (DVS) technique for the power management of the OLED display on mobile devices in video streaming applications. An optimal voltage control scheme is proposed under input constraints. Fine-grained DVS technique is applied to maximize the power saving by leveraging the locality of the display content. The display quality is retained by monitoring structural-similarity-index (SSIM) during the optimization, subject to the hardware constraints like voltage regulator response time. Simulation results on four typical video test benchmarks show that the proposed technique saves 19.05%~49.05% OLED power on average while maintaining a high display quality (SSIM > 0.98) all the time. The power saving efficiency of the proposed technique varies at different display resolutions, refresh rates, and display contents.",62
Progressive weight pruning of deep neural networks using ADMM,"Shaokai Ye, Tianyun Zhang, Kaiqi Zhang, Jiayu Li, Kaidi Xu, Yunfei Yang, Fuxun Yu, Jian Tang, Makan Fardad, Sijia Liu, Xiang Chen, Xue Lin, Yanzhi Wang",2018/10/17,Journal arXiv preprint arXiv:1810.07378,"Deep neural networks (DNNs) although achieving human-level performance in many domains, have very large model size that hinders their broader applications on edge computing devices. Extensive research work have been conducted on DNN model compression or pruning. However, most of the previous work took heuristic approaches. This work proposes a progressive weight pruning approach based on ADMM (Alternating Direction Method of Multipliers), a powerful technique to deal with non-convex optimization problems with potentially combinatorial constraints. Motivated by dynamic programming, the proposed method reaches extremely high pruning rate by using partial prunings with moderate pruning rates. Therefore, it resolves the accuracy degradation and long convergence time problems when pursuing extremely high pruning ratios. It achieves up to 34 times pruning rate for ImageNet dataset and 167 times pruning rate for MNIST dataset, significantly higher than those reached by the literature work. Under the same number of epochs, the proposed method also achieves faster convergence and higher compression rates. The codes and pruned DNN models are released in the link bit.ly/2zxdlss",44
Admm for efficient deep learning with global convergence,"Junxiang Wang, Fuxun Yu, Xiang Chen, Liang Zhao",2019/7/25,Book Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining,"Alternating Direction Method of Multipliers (ADMM) has been used successfully in many conventional machine learning applications and is considered to be a useful alternative to Stochastic Gradient Descent (SGD) as a deep learning optimizer. However, as an emerging domain, several challenges remain, including 1) The lack of global convergence guarantees, 2) Slow convergence towards solutions, and 3) Cubic time complexity with regard to feature dimensions. In this paper, we propose a novel optimization framework for deep learning via ADMM (dlADMM) to address these challenges simultaneously. The parameters in each layer are updated backward and then forward so that the parameter information in each layer is exchanged efficiently. The time complexity is reduced from cubic to quadratic in (latent) feature dimensions via a dedicated algorithm design for subproblems that enhances them utilizing …",43
Fingershadow: An {OLED} power optimization based on smartphone touch interactions,"Xiang Chen, Kent W Nixon, Hucheng Zhou, Yunxin Liu, Yiran Chen",2014,Conference 6th Workshop on Power-Aware Computing and Systems (HotPower 14),"Despite that OLED screen has been increasingly adopt-ed in smartphones to save power; screen is still one of the most energy-consuming modules in smartphones. Techniques such as local dimming are proposed to fur-ther reduce the power consumption of OLED screen, but it is hard to decide which part of the screen could be dimmed, and it often results in compromised user expe-rience. Intuitively, when a user interacts with a smartphone via the touch screen, the screen areas are covered by the user’s fingers and even some of the neighboring areas could be safely dimmed. Thus, in this paper, we propose FingerShadow, a new technique which does local dimming for the screen areas covered by user fingers to save more power, without compro-mising the user visual experience. We have studied 10 users’ touch interaction behaviors and found that on average 11.14% of the screen were covered by fingers. For these 10 users, we estimate that FingerShadow can achieve 5.07%~ 22.32% power saving, averaging 12.96%, with negligible overhead. We discuss the chal-lenges and future research work to implement Finger-Shadow in existing smartphone systems.",43
Fine-grained dynamic voltage scaling on OLED display,"Xiang Chen, Jian Zeng, Yiran Chen, Wei Zhang, Hai Li",2012/1/12,Conference 17th Asia and South Pacific Design Automation Conference,"Organic Light Emitting Diode (OLED) has emerged as the new generation display technique for mobile multimedia devices. Compared to existing technologies OLEDs are thinner, brighter, lighter, and cheaper. However, OLED panels are still the biggest contributor to the total power consumption of mobile devices. In this work, we proposed a fine-grained dynamic voltage scaling (FDVS) technique to reduce the OLED power. An OLED panel is partitioned into multiple display areas of which the supply voltage is adaptively adjusted based on the displayed content. A DVS-friendly OLED driver design is also proposed to enhance the color accuracy of the OLED pixels at the scaled supply voltage. Our experimental results show that compared to the existing global DVS technique, FDVS technique can achieve 25.9%~43.1% more OLED power saving while maintaining a high image quality measured by Structural …",43
"Tiny but accurate: A pruned, quantized and optimized memristor crossbar framework for ultra efficient dnn implementation","Xiaolong Ma, Geng Yuan, Sheng Lin, Caiwen Ding, Fuxun Yu, Tao Liu, Wujie Wen, Xiang Chen, Yanzhi Wang",2020/1/13,Conference 2020 25th Asia and South Pacific design automation conference (ASP-DAC),"The memristor crossbar array has emerged as an intrinsically suitable matrix computation and low-power acceleration framework for DNN applications. Many techniques such as memristor-based weight pruning and memristor-based quantization have been studied. However, the high accuracy solution for the above techniques is still waiting for unraveling. In this paper, we propose a memristor-based DNN framework which combines both structured weight pruning and quantization by incorporating ADMM algorithm for better pruning and quantization performance. We also discover the non-optimality of the ADMM solution in weight pruning and the unused data path in a structured pruned model. We design a software-hardware co-optimization framework which contains the first proposed Network Purification and Unused Path Removal algorithms targeting on post-processing a structured pruned model after ADMM …",41
Interpreting and evaluating neural network robustness,"Fuxun Yu, Zhuwei Qin, Chenchen Liu, Liang Zhao, Yanzhi Wang, Xiang Chen",2019/5/10,Journal arXiv preprint arXiv:1905.04270,"Recently, adversarial deception becomes one of the most considerable threats to deep neural networks. However, compared to extensive research in new designs of various adversarial attacks and defenses, the neural networks' intrinsic robustness property is still lack of thorough investigation. This work aims to qualitatively interpret the adversarial attack and defense mechanism through loss visualization, and establish a quantitative metric to evaluate the neural network model's intrinsic robustness. The proposed robustness metric identifies the upper bound of a model's prediction divergence in the given domain and thus indicates whether the model can maintain a stable prediction. With extensive experiments, our metric demonstrates several advantages over conventional adversarial testing accuracy based robustness estimation: (1) it provides a uniformed evaluation to models with different structures and parameter scales; (2) it over-performs conventional accuracy based robustness estimation and provides a more reliable evaluation that is invariant to different test settings; (3) it can be fast generated without considerable testing cost.",41
Mobile {GPU} power consumption reduction via dynamic resolution and frame rate scaling,"Kent W Nixon, Xiang Chen, Hucheng Zhou, Yunxin Liu, Yiran Chen",2014,Conference 6th Workshop on Power-Aware Computing and Systems (HotPower 14),"The emerging industry trend of ever-increasing display density on mobile devices has dramatically increased workload placed on a mobile GPU’s. Because mobile GPU power consumption increases almost linearly with workload, increasing the display density directly de-creases battery life of a device. While this tradeoff is ac-ceptable if user experience is improved, display densities beyond that which the human eye can perceive would re-sult in decreased device battery life for no perceptible gain. Further, the workload imposed by such high den-sity displays may invalidate the previous requirement that the interface always run at high frame rates.",39
DaTuM: Dynamic tone mapping technique for OLED display power saving based on video classification,"Xiang Chen, Yiran Chen, Chun Jason Xue",2015/6/7,Book Proceedings of the 52nd Annual Design Automation Conference,"The adoption of the latest OLED (organic light emitting diode) technology does not change the fact that screen is still one of the most energy-consuming modules in modern smartphones. In this work, we found that video streams from the same video category share many common power consumption features on OLED screens. Therefore, we are able to build a Hidden Markov Model (HMM) classifier to categorize videos based on OLED screen power characteristics. Using this HMM classifier, we propose a video classification based dynamic tone mapping (DTM) scheme, namely, DaTuM, to remap output color range and minimize the power-hungry color compositions on OLED screens for power saving. Experiment shows that DaTuM scheme averagely reduces OLED screen power by 17.8% with minimum display quality degradation. Compared to DTM scheme based on official category info provided by the video …",30
Demystifying energy usage in smartphones,"Xiang Chen, Yiran Chen, Mian Dong, Charlie Zhang",2014/6/1,Book Proceedings of the 51st Annual Design Automation Conference,"In this paper, we presented our recent characterization and analysis on the power consumption of smartphone radio components, including Wi-Fi, GPS and cellular (3G/4G) modules. Different from previous research that focused on the properties of single module under a limited number of usage scenarios, our works are performed on the statistically selected representative Apps with four generations of Samsung Galaxy series smartphones. We found that over the four characterized generations, the average power consumption of the smartphones with a connected Wi-Fi network on the selected Apps increases about 38.20%, indicating more and more energy-hungry designs. However, the raising of the power consumption is not mainly from the radio modules as the power efficiency of the Wi-Fi module indeed improves by about 21%. The 4G module consumes about 15.13% more power compared to the latest 3G …",27
An image enhancing pattern-based sparsity for real-time inference on mobile devices,"Xiaolong Ma, Wei Niu, Tianyun Zhang, Sijia Liu, Sheng Lin, Hongjia Li, Wujie Wen, Xiang Chen, Jian Tang, Kaisheng Ma, Bin Ren, Yanzhi Wang",2020,"Conference Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XIII 16","Weight pruning has been widely acknowledged as a straightforward and effective method to eliminate redundancy in Deep Neural Networks (DNN), thereby achieving acceleration on various platforms. However, most of the pruning techniques are essentially trade-offs between model accuracy and regularity which lead to impaired inference accuracy and limited on-device acceleration performance. To solve the problem, we introduce a new sparsity dimension, namely pattern-based sparsity that comprises pattern and connectivity sparsity, and becoming both highly accurate and hardware friendly. With carefully designed patterns, the proposed pruning unprecedentedly and consistently achieves accuracy enhancement and better feature extraction ability on different DNN structures and datasets, and our pattern-aware pruning framework also achieves pattern library extraction, pattern selection, pattern and …",23
Unsupervised domain adaptation for object detection via cross-domain semi-supervised learning,"Fuxun Yu, Di Wang, Yinpeng Chen, Nikolaos Karianakis, Tong Shen, Pei Yu, Dimitrios Lymberopoulos, Sidi Lu, Weisong Shi, Xiang Chen",2019/11/17,Journal arXiv preprint arXiv:1911.07158,"Current state-of-the-art object detectors can have significant performance drop when deployed in the wild due to domain gaps with training data. Unsupervised Domain Adaptation (UDA) is a promising approach to adapt models for new domains/environments without any expensive label cost. However, without ground truth labels, most prior works on UDA for object detection tasks can only perform coarse image-level and/or feature-level adaptation by using adversarial learning methods. In this work, we show that such adversarial-based methods can only reduce the domain style gap, but cannot address the domain content distribution gap that is shown to be important for object detectors. To overcome this limitation, we propose the Cross-Domain Semi-Supervised Learning (CDSSL) framework by leveraging high-quality pseudo labels to learn better representations from the target domain directly. To enable SSL for cross-domain object detection, we propose fine-grained domain transfer, progressive-confidence-based label sharpening and imbalanced sampling strategy to address two challenges: (i) non-identical distribution between source and target domain data, (ii) error amplification/accumulation due to noisy pseudo labeling on the target domain. Experiment results show that our proposed approach consistently achieves new state-of-the-art performance (2.2% - 9.5% better than prior best work on mAP) under various domain gap scenarios. The code will be released.",23
Online OLED dynamic voltage scaling for video streaming applications on mobile devices,"Mengying Zhao, Yiran Chen, Xiang Chen, Chun Jason Xue",2013/7/1,Journal ACM SIGBED Review,"This work proposes an online DVS approach for OLED-based mobile video applications to reduce display power consumption. A time-efficient representative-region based DVS scheme is developed and applied in MPEG video streaming. Based on the proposed scheme, flexible DVS solutions can be adaptively derived according to timing constraints. Experimental results show a 26.9% power reduction while keeping 99.3% frames displayed in high quality.",22
COKE: Communication-censored decentralized kernel learning,"Ping Xu, Yue Wang, Xiang Chen, Zhi Tian",2021/1/1,Journal The Journal of Machine Learning Research,"This paper studies the decentralized optimization and learning problem where multiple interconnected agents aim to learn an optimal decision function defined over a reproducing kernel Hilbert space by jointly minimizing a global objective function, with access to their own locally observed dataset. As a non-parametric approach, kernel learning faces a major challenge in distributed implementation: the decision variables of local objective functions are data-dependent and thus cannot be optimized under the decentralized consensus framework without any raw data exchange among agents. To circumvent this major challenge, we leverage the random feature (RF) approximation approach to enable consensus on the function modeled in the RF space by data-independent parameters across different agents. We then design an iterative algorithm, termed DKLA, for fast-convergent implementation via ADMM. Based …",21
Interpreting adversarial robustness: A view from decision surface in input space,"Fuxun Yu, Chenchen Liu, Yanzhi Wang, Liang Zhao, Xiang Chen",2018/9/29,Journal arXiv preprint arXiv:1810.00144,"One popular hypothesis of neural network generalization is that the flat local minima of loss surface in parameter space leads to good generalization. However, we demonstrate that loss surface in parameter space has no obvious relationship with generalization, especially under adversarial settings. Through visualizing decision surfaces in both parameter space and input space, we instead show that the geometry property of decision surface in input space correlates well with the adversarial robustness. We then propose an adversarial robustness indicator, which can evaluate a neural network's intrinsic robustness property without testing its accuracy under adversarial attacks. Guided by it, we further propose our robust training method. Without involving adversarial training, our method could enhance network's intrinsic adversarial robustness against various adversarial attacks.",21
A 1.0 V 45nm nonvolatile magnetic latch design and its robustness analysis,"Peiyuan Wang, Xiang Chen, Yiran Chen, Hai Li, Seung Kang, Xiaochun Zhu, Wenqing Wu",2011/9/19,Conference 2011 IEEE Custom Integrated Circuits Conference (CICC),"A new nonvolatile latch design is proposed based on the magnetic tunneling junction (MTJ) devices. In the standby mode, the latched data can be retained in the MTJs without consuming any power. Two types of operation errors, namely, persistent and non-persistent errors, are quantitatively analyzed by including the process variations and thermal fluctuations during the read and write operations. A design at 45nm technology node is used as the example to discuss the design tradeoffs.",21
Fed2: Feature-aligned federated learning,"Fuxun Yu, Weishan Zhang, Zhuwei Qin, Zirui Xu, Di Wang, Chenchen Liu, Zhi Tian, Xiang Chen",2021/8/14,Book Proceedings of the 27th ACM SIGKDD conference on knowledge discovery & data mining,"Federated learning learns from scattered data by fusing collaborative models from local nodes. However, conventional coordinate-based model averaging by FedAvg ignored the random information encoded per parameter and may suffer from structural feature misalignment. In this work, we propose Fed2, a feature-aligned federated learning framework to resolve this issue by establishing a firm structure-feature alignment across the collaborative models. Fed2 is composed of two major designs: First, we design a feature-oriented model structure adaptation method to ensure explicit feature allocation in different neural network structures. Applying the structure adaptation to collaborative models, matchable structures with similar feature information can be initialized at the very early training stage. During the federated learning process, we then propose a feature paired averaging scheme to guarantee aligned feature …",20
MORPh: Mobile OLED-friendly recording and playback system for low power video streaming,"Xiang Chen, Jiachen Mao, Jiafei Gao, Kent W Nixon, Yiran Chen",2016/6/5,Book Proceedings of the 53rd Annual Design Automation Conference,"Even with the adoption of the latest OLED technology, the display panel remains one of the most power-hungry components in smartphones. Existing attempts for OLED power optimization have mainly focused on modifying the content that is shown on the display during the playback phase, requiring significant overhead in terms of image analysis and modification. While such methods are effective, they overlook opportunities present during the camera recording phase, where utilization of already determined camera parameters could reduce or eliminate the image processing overhead. Hence, we proposed MORPh, a cross-layer optimization system for OLED. We first analyze three fundamental parameters extracted from the smartphone camera and their impact on OLED power consumption and visual quality. We then define corresponding metrics to assess power optimization potentials, and propose a set of …",19
Reform: Static and dynamic resource-aware dnn reconfiguration framework for mobile device,"Zirui Xu, Fuxun Yu, Chenchen Liu, Xiang Chen",2019/6/2,Book Proceedings of the 56th Annual Design Automation Conference 2019,"Although the Deep Neural Network (DNN) technique has been widely applied in various applications, the DNN-based applications are still too computationally intensive for the resource-constrained mobile devices. Many works have been proposed to optimize the DNN computation performance, but most of them are limited in an algorithmic perspective, ignoring certain computing issues in practical deployment. To achieve the comprehensive DNN performance enhancement in practice, the expected DNN optimization works should closely cooperate with specific hardware and system constraints (i.e. computation capacity, energy cost, memory occupancy, and inference latency). Therefore, in this work, we propose ReForm -- a resource-aware DNN optimization framework. Through thorough mobile DNN computing analysis and innovative model reconfiguration schemes (i.e. ADMM based static model fine-tuning …",18
Direct: Resource-aware dynamic model reconfiguration for convolutional neural network in mobile systems,"Zirui Xu, Zhuwei Qin, Fuxun Yu, Chenchen Liu, Xiang Chen",2018/7/23,Book Proceedings of the International Symposium on Low Power Electronics and Design,"Although Convolutional Neural Networks (CNNs) have been widely applied in various applications, their deployment in resource-constrained mobile systems remains a significant concern. To overcome the computation resource constraints, such as limited memory and energy capacity, many works are proposed for mobile CNN optimization. However, most of them lack a comprehensive modeling analysis of the CNN computation consumption and merely focus on static optimization schemes regardless of different mobile computation scenarios. In this work, we proposed DiReCt -- a resource-aware CNN reconfiguration system. Leveraging accurate CNN computation consumption modeling and mobile resource constraint analysis, DiReCt can reconfigure a CNN with different accuracy and resource consumption levels to adapt to various mobile computation scenarios. The experiment results show that: the proposed …",17
Heterogeneous federated learning,"Fuxun Yu, Weishan Zhang, Zhuwei Qin, Zirui Xu, Di Wang, Chenchen Liu, Zhi Tian, Xiang Chen",2020/8/15,Journal arXiv preprint arXiv:2008.06767,"Federated learning learns from scattered data by fusing collaborative models from local nodes. However, due to chaotic information distribution, the model fusion may suffer from structural misalignment with regard to unmatched parameters. In this work, we propose a novel federated learning framework to resolve this issue by establishing a firm structure-information alignment across collaborative models. Specifically, we design a feature-oriented regulation method ({-Net}) to ensure explicit feature information allocation in different neural network structures. Applying this regulating method to collaborative models, matchable structures with similar feature information can be initialized at the very early training stage. During the federated learning process under either IID or non-IID scenarios, dedicated collaboration schemes further guarantee ordered information distribution with definite structure matching, so as the comprehensive model alignment. Eventually, this framework effectively enhances the federated learning applicability to extensive heterogeneous settings, while providing excellent convergence speed, accuracy, and computation/communication efficiency.",16
Distilling critical paths in convolutional neural networks,"Fuxun Yu, Zhuwei Qin, Xiang Chen",2018/10/28,Journal arXiv preprint arXiv:1811.02643,"Neural network compression and acceleration are widely demanded currently due to the resource constraints on most deployment targets. In this paper, through analyzing the filter activation, gradients, and visualizing the filters' functionality in convolutional neural networks, we show that the filters in higher layers learn extremely task-specific features, which are exclusive for only a small subset of the overall tasks, or even a single class. Based on such findings, we reveal the critical paths of information flow for different classes. And by their intrinsic property of exclusiveness, we propose a critical path distillation method, which can effectively customize the convolutional neural networks to small ones with much smaller model size and less computation.",16
LanCe: A comprehensive and lightweight CNN defense methodology against physical adversarial attacks on embedded multimedia applications,"Zirui Xu, Fuxun Yu, Xiang Chen",2020/1/13,Conference 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC),"Recently, adversarial attacks can be applied to the physical world, causing practical issues to various Convolutional Neural Networks (CNNs) powered applications. Most existing physical adversarial attack defense works only focus on eliminating explicit perturbation patterns from inputs, ignoring interpretation to CNN's intrinsic vulnerability. Therefore, they lack expected versatility to different attacks and thereby depend on considerable data processing costs. In this paper, we propose LanCe - a comprehensive and lightweight CNN defense methodology against different physical adversarial attacks. By interpreting CNN's vulnerability, we find that non-semantic adversarial perturbations can activate CNN with significantly abnormal activations and even overwhelm other semantic input patterns' activations. We improve the CNN recognition process by adding a self-verification stage to detect the potential adversarial …",15
Adalearner: An adaptive distributed mobile learning system for neural networks,"Jiachen Mao, Zhuwei Qin, Zirui Xu, Kent W Nixon, Xiang Chen, Hai Li, Yiran Chen",2017/11/13,Conference 2017 IEEE/ACM International Conference on Computer-Aided Design (ICCAD),"Neural networks hold a critical domain in machine learning algorithms because of their self-adaptiveness and state-of-the-art performance. Before the testing (inference) phases in practical use, sophisticated training (learning) phases are required, calling for efficient training methods with higher accuracy and shorter converging time. Many existing studies focus on the training optimization on high-performance servers or computing clusters, e.g. GPU clusters. However, training neural networks on resource-constrained devices, e.g. mobile platforms, is an important research topic barely touched. In this paper, we implement AdaLearner-an adaptive distributed mobile learning system for neural networks that trains a single network with heterogenous mobile resources under the same local network in parallel. To exploit the potential of our system, we adapt neural networks training phase to mobile device-wise …",15
Functionality-oriented convolutional filter pruning,"Zhuwei Qin, Fuxun Yu, Chenchen Liu, Xiang Chen",2018/10/12,Journal arXiv preprint arXiv:1810.07322,"The sophisticated structure of Convolutional Neural Network (CNN) allows for outstanding performance, but at the cost of intensive computation. As significant redundancies inevitably present in such a structure, many works have been proposed to prune the convolutional filters for computation cost reduction. Although extremely effective, most works are based only on quantitative characteristics of the convolutional filters, and highly overlook the qualitative interpretation of individual filter's specific functionality. In this work, we interpreted the functionality and redundancy of the convolutional filters from different perspectives, and proposed a functionality-oriented filter pruning method. With extensive experiment results, we proved the convolutional filters' qualitative significance regardless of magnitude, demonstrated significant neural network redundancy due to repetitive filter functions, and analyzed the filter functionality defection under inappropriate retraining process. Such an interpretable pruning approach not only offers outstanding computation cost optimization over previous filter pruning methods, but also interprets filter pruning process.",14
Towards robust training of neural networks by regularizing adversarial gradients,"Fuxun Yu, Zirui Xu, Yanzhi Wang, Chenchen Liu, Xiang Chen",2018/5/23,Journal arXiv preprint arXiv:1805.09370,"In recent years, neural networks have demonstrated outstanding effectiveness in a large amount of applications.However, recent works have shown that neural networks are susceptible to adversarial examples, indicating possible flaws intrinsic to the network structures. To address this problem and improve the robustness of neural networks, we investigate the fundamental mechanisms behind adversarial examples and propose a novel robust training method via regulating adversarial gradients. The regulation effectively squeezes the adversarial gradients of neural networks and significantly increases the difficulty of adversarial example generation.Without any adversarial example involved, the robust training method could generate naturally robust networks, which are near-immune to various types of adversarial examples. Experiments show the naturally robust networks can achieve optimal accuracy against Fast Gradient Sign Method (FGSM) and C\&W attacks on MNIST, Cifar10, and Google Speech Command dataset. Moreover, our proposed method also provides neural networks with consistent robustness against transferable attacks.",13
Multi-stage deep classifier cascades for open world recognition,"Xiaojie Guo, Amir Alipour-Fanid, Lingfei Wu, Hemant Purohit, Xiang Chen, Kai Zeng, Liang Zhao",2019/11/3,Book Proceedings of the 28th ACM International Conference on Information and Knowledge Management,"At present, object recognition studies are mostly conducted in a closed lab setting with classes in test phase typically in training phase. However, real-world problem are far more challenging because: i)~new classes unseen in the training phase can appear when predicting; ii)~discriminative features need to evolve when new classes emerge in real time; and iii)~instances in new classes may not follow the ""independent and identically distributed"" (iid) assumption. Most existing work only aims to detect the unknown classes and is incapable of continuing to learn newer classes. Although a few methods consider both detecting and including new classes, all are based on the predefined handcrafted features that cannot evolve and are out-of-date for characterizing emerging classes. Thus, to address the above challenges, we propose a novel generic end-to-end framework consisting of a dynamic cascade of classifiers …",12
SC-UDA: Style and content gaps aware unsupervised domain adaptation for object detection,"Fuxun Yu, Di Wang, Yinpeng Chen, Nikolaos Karianakis, Tong Shen, Pei Yu, Dimitrios Lymberopoulos, Sidi Lu, Weisong Shi, Xiang Chen",2022,Conference Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision,"Current state-of-the-art object detectors can have a significant performance drop when deployed in the wild due to domain gaps with training data. Unsupervised Domain Adaptation (UDA) is a promising approach to adapt detectors for new domains/environments without any expensive label cost. Previous mainstream UDA works for object detection usually focused on image-level and/or feature-level adaptation by using adversarial learning methods. In this work, we show that such adversarial-based methods can only reduce the domain style gap, but cannot address the domain content gap that is also important for object detectors. To overcome this limitation, we propose the SC-UDA framework to concurrently reduce both gaps: We propose fine-grained domain style transfer to reduce the style gaps with finer image details preserved for detecting small objects; Then we leverage the pseudo-label-based self-training to reduce content gaps; To address pseudo label error accumulation during self-training, novel optimizations are proposed, including uncertainty-based pseudo labeling and imbalanced mini-batch sampling strategy. Experiment results show that our approach consistently outperforms prior stat-of-the-art methods (up to 8.6%, 2.7%, and 2.5% mAP on three UDA benchmarks).",11
REIN the RobuTS: Robust DNN-based image recognition in autonomous driving systems,"Fuxun Yu, Zhuwei Qin, Chenchen Liu, Di Wang, Xiang Chen",2020/10/23,Journal IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,"In recent years, the neural network (NN) has shown its great potential in image recognition tasks of autonomous driving systems, such as traffic sign recognition, pedestrian detection, etc. However, theoretically well-trained NNs usually fail their performance when facing real-world scenarios. For example, adverse real-world conditions, e.g., bad weather and lighting conditions, can introduce different physical variations and cause considerable accuracy degradation. As for now, the generalization capability of NNs is still one of the most critical challenges for the autonomous driving system. To facilitate the robust image recognition tasks, in this work, we build the RobuTS dataset: a comprehensive Robust Traffic Sign Recognition dataset, which includes images with different environmental variations, e.g., rain, fog, darkening, and blurring. Then to enhance the NN's generalization capability, we propose two …",11
Practical power consumption analysis with current smartphones,"Xiang Chen, Kent W Nixon, Yiran Chen",2016/9/6,Conference 2016 29th IEEE International System-on-Chip Conference (SOCC),"In this paper, we analyzed the power consumption of all Samsung Galaxy smartphones to explore modern smartphones' power consumption characters. With dedicated measurement and analysis, we found that, some previously emphasized power hungry consumers, like Wi-Fi and multimedia codec, consume very trivial power in the modern smartphones; and video adaptation don't achieve significant power saving impact any more. Meanwhile, some other hardware component like cellular network module, GPU and camera emerge as considerable power consumers, and these might be the most efficient optimization objects for designing future power-efficient smartphones.",11
Directx: Dynamic resource-aware cnn reconfiguration framework for real-time mobile applications,"Zirui Xu, Fuxun Yu, Zhuwei Qin, Chenchen Liu, Xiang Chen",2020/5/20,Journal IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,"Although convolutional neural networks (CNNs) have been widely applied in various cognitive applications, they are still very computationally intensive for resource-constrained mobile systems. To reduce the resource consumption of CNN computation, many optimization works have been proposed for mobile CNN deployment. However, most works are merely targeting CNN model compression from the perspective of parameter size or model structure, ignoring different resource constraints in mobile systems with respect to memory, energy, and real-time requirement. Moreover, previous works take accuracy as their primary consideration, requiring a time-costing retraining process to compensate the inference accuracy loss after compression. To address these issues, we propose DiReCtX-a dynamic resource-aware CNN model reconfiguration framework. DiReCtX is based on a set of accurate CNN profiling …",10
Automated runtime-aware scheduling for multi-tenant dnn inference on gpu,"Fuxun Yu, Shawn Bray, Di Wang, Longfei Shangguan, Xulong Tang, Chenchen Liu, Xiang Chen",2021/11/1,Conference 2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD),"With the fast development of deep neural networks (DNNs), many real-world applications are adopting multiple models to conduct compound tasks, such as co-running classification, detection, and segmentation models on autonomous vehicles. Such multi-tenant DNN inference cases greatly exacerbate the computational complexity and call for comprehensive collaboration for graph-level operator scheduling, runtime-level resource awareness, as well as hardware scheduler support. However, the current scheduling support for such multi-tenant inference is still relatively backward. In this work, we propose a resource-aware scheduling framework for efficient multi-tenant DNN inference on GPU, which automatically coordinates DNN computing in different execution levels. Leveraging the unified scheduling intermediate representation and the automated ML-based searching algorithm, optimal schedules could be …",9
CAPTOR: A class adaptive filter pruning framework for convolutional neural networks in mobile applications,"Zhuwei Qin, Fuxun Yu, Chenchen Liu, Xiang Chen",2019/1/21,Book Proceedings of the 24th Asia and South Pacific Design Automation Conference,"Nowadays, the evolution of deep learning and cloud service significantly promotes neural network based mobile applications. Although intelligent and prolific, those applications still lack certain flexibility: For classification tasks, neural networks are generally trained online with vast classification targets to cover various utilization contexts. However, only partial classes are practically tested due to individual mobile user preference and application specificity. Thus the unneeded classes cause considerable computation and communication cost. In this work, we propose CAPTOR - a class-level reconfiguration framework for Convolutional Neural Networks (CNNs). By identifying the class activation preference of convolutional filters through feature interest visualization and gradient analysis, CAPTOR can effectively cluster and adaptively prune the filters associated with unneeded classes. Therefore, CAPTOR enables …",9
Scope-quality retaining display rendering workload scaling based on user-smartphone distance,"Kent W Nixon, Xiang Chen, Yiran Chen",2016/11/7,Book 2016 IEEE/ACM International Conference on Computer-Aided Design (ICCAD),"Modern smartphone display system come equipped with powerful GPU's capable of rendering advanced 2D and 3D graphics. These GPU's make up a significant portion of the system power profile due to the high resolution and framerate of smartphone display. These display features are selected during the design phase of a smartphone and correspond to the capabilities of the human visual system (HVS). However, the level of detail observable by the HVS is not static and changes with user-smartphone distance. In this paper we propose Scope, a system which alters the rendering resolution and framerate on a smartphone to scale display rendering workload in response to real time changes in user-smartphone distance. We demonstrate a new method of measuring this distance in real-time which is able to minimize front-facing camera sampling through the use of sensor fusion techniques. The result is that …",9
AntiDoteX: Attention-Based Dynamic Optimization for Neural Network Runtime Efficiency,"Fuxun Yu, Zirui Xu, Chenchen Liu, Dimitrios Stamoulis, Di Wang, Yanzhi Wang, Xiang Chen",2022/1/19,Journal IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,"Deep neural networks (DNNs) achieved great cognitive performance at the expense of a considerable computation workload. To relieve the computational burden, many optimization works are developed to reduce the model redundancy by identifying and removing insignificant model components, such as weight sparsity and filter pruning methods. However, these works only evaluate model components’ static significance with parameter information, ignoring their dynamic interaction with external inputs. Specifically, due to the difference in per-input features, the model components’ significance can dynamically change and, thus, the static methods can only achieve suboptimal performance. Focusing on this aspect, we propose a dynamic DNN optimization framework in this work. Based on the neural network attention mechanism, we propose a comprehensive dynamic optimization framework, including 1) testing …",8
Demystifying neural network filter pruning,"Zhuwei Qin, Fuxun Yu, Chenchen Liu, Xiang Chen",2018/10/29,Journal arXiv preprint arXiv:1811.02639,"Based on filter magnitude ranking (e.g. L1 norm), conventional filter pruning methods for Convolutional Neural Networks (CNNs) have been proved with great effectiveness in computation load reduction. Although effective, these methods are rarely analyzed in a perspective of filter functionality. In this work, we explore the filter pruning and the retraining through qualitative filter functionality interpretation. We find that the filter magnitude based method fails to eliminate the filters with repetitive functionality. And the retraining phase is actually used to reconstruct the remained filters for functionality compensation for the wrongly-pruned critical filters. With a proposed functionality-oriented pruning method, we further testify that, by precisely addressing the filter functionality redundancy, a CNN can be pruned without considerable accuracy drop, and the retraining phase is unnecessary.",7
Slowmo-enhancing mobile gesture-based authentication schemes via sampling rate optimization,"Kent W Nixon, Xiang Chen, Zhi-Hong Mao, Yiran Chen",2016/1/25,Conference 2016 21st Asia and South Pacific Design Automation Conference (ASP-DAC),"In the era of network service, the user authentication becomes more indispensable but also vulnerable. Traditional user verification approaches such as PIN or pattern lock suffer from easy hacking and replica, motivating the research on many new approaches like gesture-based security. Compare to traditional authentications, the gesture-based security utilizes the user interacts with the device as a dynamic authentication pattern in real-time, offering higher complexity and better reliability. However, gesture-based security still lacks sufficient research on data sampling and preprocessing techniques on classification accuracy. In this work, we develop SlowMo, a novel gesture security technique for user classification in low sampling-rate environments. The proposed algorithm provides maximum classification accuracy at a sampling rate of 4Hz with extreme low power consumption suggesting a more capable …",7
Footfall-GPS polling scheduler for power saving on wearable devices,"Kent W Nixon, Xiang Chen, Yiran Chen",2016/1/25,Conference 2016 21st Asia and South Pacific Design Automation Conference (ASP-DAC),"Wrist-worn wearable fitness devices, such as FitBit and Apple Watch, have become popular in recent years. Runners can use the GPS embedded in these wearable devices to log the route taken during their exercise, providing vital feedback on pace and distance traveled. Unfortunately, continuous polling for GPS data results in a significant adverse impact on device battery life, e.g., many flagship wearables need to be charged as frequently as every two days or even less. In this work, we propose Footfall - an intelligent GPS scheduler that can utilize data from alternative sensors on a device to greatly reduce GPS utilization while still maintaining minimum location accuracy. Compared to existing implementations, Footfall system can achieve on average 97% reduction in total power consumption, while only inducing 7% discrepancy in location accuracy, which is sufficient for the targeted applications.",7
Mobile user classification and authorization based on gesture usage recognition,"Kent W Nixon, Xiang Chen, Zhi-Hong Mao, Yiran Chen, Kang Li",2013/1/22,Conference 2013 18th Asia and South Pacific Design Automation Conference (ASP-DAC),"Intelligent mobile devices have been widely serving in almost all aspects of everyday life, spanning from communication, web surfing, entertainment, to daily organizer. A large amount of sensitive and private information is stored on the mobile device, leading to severe data security concern. In this work, we propose a novel mobile user classification and authorization scheme based on the recognition of user's gesture. Compared to other security solutions like password, track pattern and finger print etc., our scheme can continuously evolve for better protection during the usage cycle of the mobile device. Besides the regular interactive screen and sensors of modern mobile devices, our scheme does not require any additional hardware supports.",7
Nonvolatile memories as the data storage system for implantable ECG recorder,"Zhenyu Sun, Xiang Chen, Yaojun Zhang, Hai Li, Yiran Chen",2012/6/1,Journal ACM Journal on Emerging Technologies in Computing Systems (JETC),"In this article, we propose a data storage system with the emerging nonvolatile memory technologies used for the implantable electrocardiography (ECG) recorder. The proposed storage system can record the digitalized real-time ECG waveforms continuously inside the implantable device and export the stored data to external reader periodically to obtain a long-term backup. Spin transfer torque random access memory (STT-RAM) and spintronic memristor are selected as the storage elements for their nonvolatility, high density, high reliability, low power consumption, good scalability, and CMOS technology compatibility. The new read and write schemes of STT-RAM and spintronic memristors are presented and optimized to fit the specific application scenario. The tradeoffs among data accuracy, chip area, and read/write energy for the different technologies are thoroughly analyzed and compared. Our simulation …",7
A survey of multi-tenant deep learning inference on GPU,"Fuxun Yu, Di Wang, Longfei Shangguan, Minjia Zhang, Chenchen Liu, Xiang Chen",2022/3/17,Journal arXiv preprint arXiv:2203.09040,"Deep Learning (DL) models have achieved superior performance. Meanwhile, computing hardware like NVIDIA GPUs also demonstrated strong computing scaling trends with 2x throughput and memory bandwidth for each generation. With such strong computing scaling of GPUs, multi-tenant deep learning inference by co-locating multiple DL models onto the same GPU becomes widely deployed to improve resource utilization, enhance serving throughput, reduce energy cost, etc. However, achieving efficient multi-tenant DL inference is challenging which requires thorough full-stack system optimization. This survey aims to summarize and categorize the emerging challenges and optimization opportunities for multi-tenant DL inference on GPU. By overviewing the entire optimization stack, summarizing the multi-tenant computing innovations, and elaborating the recent technological advances, we hope that this survey could shed light on new optimization perspectives and motivate novel works in future large-scale DL system optimization.",6
HAMPER: high-performance adaptive mobile security enhancement against malicious speech and image recognition,"Zirui Xu, Fuxun Yu, Chenchen Liu, Xiang Chen",2019/1/21,Book Proceedings of the 24th Asia and South Pacific Design Automation Conference,"Recently, the machine learning technologies have been widely used in cognitive applications such as Automatic Speech Recognition (ASR) and Image Recognition (IR). Unfortunately, these techniques have been massively used in unauthorized audio/image data analysis, causing serious privacy leakage. To address this issue, we propose HAMPER in this work, which is a data encryption framework that protects the audio/image data from unauthorized ASR/IR analysis. Leveraging machine learning models' vulnerability to adversarial examples, HAMPER encrypt the audio/image data with adversarial noises to perturb the recognition results of ASR/IR systems. To deploy the proposed framework in extensive platforms (e.g. mobile devices), HAMPER also take into consideration of computation efficiency, perturbation transferability, as well as data attribute configuration. Therefore, rather than focusing on the high …",6
MobiCore: An adaptive hybrid approach for power-efficient CPU management on Android devices,"Lucie Broyde, Kent Nixon, Xiang Chen, Hai Li, Yiran Chen",2017/9/5,Conference 2017 30th IEEE International System-on-Chip Conference (SOCC),"Smartphones are becoming essential devices used for various types of applications in our daily life. To satisfy the ever-increasing performance requirement, the number of CPU cores in a phone keeps growing, which imposes a great impact on its power consumption. This work presents a series of analysis to understand how the current Android resource management policy adjusts CPU features. Our results indicate a significant improvement margin for CPU power efficiency in modern Android smartphones. We then propose MobiCore — a power-efficient CPU management scheme that can optimize the use of Dynamic and Frequency Voltage Scaling (DVFS) and the Dynamic Core Scaling (DCS) techniques with a sensitive control on CPU bandwidth. The measurements on the real systems prove that MobiCore can achieve substantial CPU power reduction compared to state-of-the-art architectures.",6
Smartphone power consumption characterization and dynamic optimization techniques for OLED display,Xiang Chen,2016,Institution University of Pittsburgh,"Smartphones have emerged as the most popular and frequently used platform for the consumption of multimedia. Following the rapid growth of application number and the explosion of cellular network bandwidth, high power consumption, and limited battery capacity remain as the major challenges in smartphone designs. Therefore, lots of research is made to characterize and optimize the smartphone power performance.",6
Mobile devices user: the subscriber and also the publisher of real-time OLED display power management plan,"Yiran Chen, Xiang Chen, Mengying Zhao, Chun Jason Xue",2012/11/5,Book Proceedings of the International Conference on Computer-Aided Design,"OLED (Organic Light Emitting Diode) technology has already been adopted in many modern smart mobile devices, including cellphones, tablets, laptop etc. However, the power dissipation of displays in some applications like real-time video streaming, significantly limits the smart mobile devices' battery life and influences user experience. In this work, we applied a set of power management techniques that based on the dynamic voltage scaling (DVS) to minimize the power consumption of OLED display. Circuit inventions are also introduced to enable the local voltage scaling of AMOLED display panel while the human vision reception criteria can still be met. We then apply the DVS-based power management techniques to online video streaming, which is the most energy-hungry application of mobile devices: For any known type of mobile devices with AMOLED displays, the DVS power management scheme of a …",6
Towards latency-aware dnn optimization with gpu runtime analysis and tail effect elimination,"Fuxun Yu, Zirui Xu, Tong Shen, Dimitrios Stamoulis, Longfei Shangguan, Di Wang, Rishi Madhok, Chunshui Zhao, Xin Li, Nikolaos Karianakis, Dimitrios Lymberopoulos, Ang Li, ChenChen Liu, Yiran Chen, Xiang Chen",2020/11/8,Journal arXiv preprint arXiv:2011.03897,"Despite the superb performance of State-Of-The-Art (SOTA) DNNs, the increasing computational cost makes them very challenging to meet real-time latency and accuracy requirements. Although DNN runtime latency is dictated by model property (e.g., architecture, operations), hardware property (e.g., utilization, throughput), and more importantly, the effective mapping between these two, many existing approaches focus only on optimizing model property such as FLOPS reduction and overlook the mismatch between DNN model and hardware properties. In this work, we show that the mismatch between the varied DNN computation workloads and GPU capacity can cause the idle GPU tail effect, leading to GPU under-utilization and low throughput. As a result, the FLOPs reduction cannot bring effective latency reduction, which causes sub-optimal accuracy versus latency trade-offs. Motivated by this, we propose a GPU runtime-aware DNN optimization methodology to eliminate such GPU tail effect adaptively on GPU platforms. Our methodology can be applied on top of existing SOTA DNN optimization approaches to achieve better latency and accuracy trade-offs. Experiments show 11%-27% latency reduction and 2.5%-4.0% accuracy improvement over several SOTA DNN pruning and NAS methods, respectively",5
Dc-cnn: computational flow redefinition for efficient cnn through structural decoupling,"Fuxun Yu, Zhuwei Qin, Di Wang, Ping Xu, Chenchen Liu, Zhi Tian, Xiang Chen",2020/3/9,"Conference 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE)","Recently Convolutional Neural Networks (CNNs) are widely applied into novel intelligent applications and systems. However, the CNN computation performance is significantly hindered by its computation flow, which computes the model structure sequentially by layers with massive convolution operations. Such a layer-wise sequential computation flow can cause certain performance issues, such as resource under-utilization, huge memory overhead, etc. To solve these problems, we propose a novel CNN structural decoupling method, which could decouple CNN models into ""critical paths"" and eliminate the inter-layer data dependency. Based on this method, we redefine the CNN computation flow into parallel and cascade computing paradigms, which can significantly enhance the CNN computation performance with both multi-core and single-core CPU processors. Experiments show that, our DC-CNN framework …",5
Masker: Adaptive mobile security enhancement against automatic speech recognition in eavesdropping,"Fuxun Yu, Zirui Xu, Chenchen Liu, Xiang Chen",2019/6/2,Book Proceedings of the 56th Annual Design Automation Conference 2019,"Benefited from recent artificial intelligence evolution, Automatic Speech Recognition (ASR) technology has achieved enormous performance improvement and wider application. Unfortunately, ASR is also heavily leveraged by speech eavesdropping, where ASR is used to translate large volume of intercepted vocal speech into text content, causing considerable information leakage. In this work, we propose MASKER -- a mobile security enhancement solution to protect the mobile speech data from ASR in eavesdropping. By identifying ASR models' ubiquitous vulnerability, MASKER is designed to generate human imperceptible adversarial noises into the real-time speech on the mobile device (e.g. phone call and voice message). Even the speech data is exposed to eavesdropping during data transmission, the adversarial noises can effectively perturb the ASR process with significant Word Error Rate (WER …",5
Enabling efficient ReRAM-based neural network computing via crossbar structure adaptive optimization,"Chenchen Liu, Fuxun Yu, Zhuwei Qin, Xiang Chen",2020/8/10,Book Proceedings of the ACM/IEEE International Symposium on Low Power Electronics and Design,"Resistive random-access memory (ReRAM) based accelerators have been widely studied to achieve efficient neural network computing in speed and energy. Neural network optimization algorithms such as sparsity are developed to achieve efficient neural network computing on traditional computer architectures such as CPU and GPU. However, such computing efficiency improvement is hindered when deploying these algorithms on the ReRAM-based accelerator because of its unique crossbar-structural computations. And a specific algorithm and hardware co-optimization for the ReRAM-based architecture is still in a lack. In this work, we propose an efficient neural network computing framework that is specialized for the crossbar-structural computations on the ReRAM-based accelerators. The proposed framework includes a crossbar specific feature map pruning and an adaptive neural network deployment …",4
A hybrid neural network framework and application to radar automatic target recognition,"Zhe Zhang, Xiang Chen, Zhi Tian",2018/11/26,Conference 2018 IEEE Global Conference on Signal and Information Processing (GlobalSIP),"Deep neural networks (DNNs) have found applications in diverse signal processing (SP) problems. Most efforts either directly adopt the DNN as a black-box approach to perform certain SP tasks without taking into account of any known properties of the signal models, or insert a pre-defined SP operator into a DNN as an add-on data processing stage. This paper presents a novel hybrid-NN framework in which one or more SP layers are inserted into the DNN architecture in a coherent manner to enhance the network capability and efficiency in feature extraction. These SP layers are properly designed to make good use of the available models and properties of the data. The network training algorithm of hybrid-NN is designed to actively involve the SP layers in the learning goal, by simultaneously optimizing both the weights of the DNN and the unknown tuning parameters of the SP operators. The proposed hybrid …",4
ASP: a fast adversarial attack example generation framework based on adversarial saliency prediction,"Fuxun Yu, Qide Dong, Xiang Chen",2018/2/15,Journal arXiv preprint arXiv:1802.05763,"With the excellent accuracy and feasibility, the Neural Networks have been widely applied into the novel intelligent applications and systems. However, with the appearance of the Adversarial Attack, the NN based system performance becomes extremely vulnerable:the image classification results can be arbitrarily misled by the adversarial examples, which are crafted images with human unperceivable pixel-level perturbation. As this raised a significant system security issue, we implemented a series of investigations on the adversarial attack in this work: We first identify an image's pixel vulnerability to the adversarial attack based on the adversarial saliency analysis. By comparing the analyzed saliency map and the adversarial perturbation distribution, we proposed a new evaluation scheme to comprehensively assess the adversarial attack precision and efficiency. Then, with a novel adversarial saliency prediction method, a fast adversarial example generation framework, namely ""ASP"", is proposed with significant attack efficiency improvement and dramatic computation cost reduction. Compared to the previous methods, experiments show that ASP has at most 12 times speed-up for adversarial example generation, 2 times lower perturbation rate, and high attack success rate of 87% on both MNIST and Cifar10. ASP can be also well utilized to support the data-hungry NN adversarial training. By reducing the attack success rate as much as 90%, ASP can quickly and effectively enhance the defense capability of NN based system to the adversarial attacks.",4
Active compensation technique for the thin-film transistor variations and OLED aging of mobile device displays,"Xiang Chen, Beiye Liu, Yiran Chen, Mengying Zhao, Chun Jason Xue, Xiaojun Guo",2012/11/5,Book Proceedings of the International Conference on Computer-Aided Design,"OLED is becoming the main stream display for mobile devices. The process variations of thin-film transistors (TFT) and the aging degradation of OLED devices severely impact the display quality and the user experience on mobile devices throughout lifetime. In this paper, we quantitatively study the nonuniformity of OLED display panels incurred by the TFT variations and OLED cell aging effect. Furthermore, we develop a pixel level sensing circuit that detects and quantifies the nonuniformity condition and corresponding compensating technique. This proposed technique can be actively invoked based on various conditions with flexible configuration and minimal extra overhead, which is suitable to be integrated with mobile displays. The proposed technique's performance is simulated with different display contents. Experiments show that: for the proposed sensing circuit, the error rate for TFT process variation …",4
FalCon: Fine-grained feature map sparsity computing with decomposed convolutions for inference optimization,"Zirui Xu, Fuxun Yu, Chenxi Liu, Zhe Wu, Hongcheng Wang, Xiang Chen",2022,Conference Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision,"Many works focus on the model's static parameter optimization (eg, filters and weights) for CNN inference acceleration. Compared to parameter sparsity, feature map sparsity is per-input related which has better adaptability. The practical sparsity patterns are non-structural and randomly located on feature maps with non-identical shapes. However, the existing feature map sparsity works take computing efficiency as the primary goal, thereby they can only remove structural sparsity and fail to match the above characteristics. In this paper, we develop a novel sparsity computing scheme called FalCon, which can well adapt to the practical sparsity patterns while still maintaining efficient computing. Specifically, we first propose a decomposed convolution design that enables a fine-grained computing unit for sparsity. Additionally, a decomposed convolution computing optimization paradigm is proposed to convert the sparse computing units to practical acceleration. Extensive experiments show that FalCon achieves at most 67.30% theoretical computation reduction with a neglected accuracy drop while accelerating CNN inference by 37%.",3
HASP: A high-performance adaptive mobile security enhancement against malicious speech recognition,"Zirui Xu, Fuxun Yu, Chenchen Liu, Xiang Chen",2018/9/4,Journal arXiv preprint arXiv:1809.01697,"Nowadays, machine learning based Automatic Speech Recognition (ASR) technique has widely spread in smartphones, home devices, and public facilities. As convenient as this technology can be, a considerable security issue also raises -- the users' speech content might be exposed to malicious ASR monitoring and cause severe privacy leakage. In this work, we propose HASP -- a high-performance security enhancement approach to solve this security issue on mobile devices. Leveraging ASR systems' vulnerability to the adversarial examples, HASP is designed to cast human imperceptible adversarial noises to real-time speech and effectively perturb malicious ASR monitoring by increasing the Word Error Rate (WER). To enhance the practical performance on mobile devices, HASP is also optimized for effective adaptation to the human speech characteristics, environmental noises, and mobile computation scenarios. The experiments show that HASP can achieve optimal real-time security enhancement: it can lead an average WER of 84.55% for perturbing the malicious ASR monitoring, and the data processing speed is 15x to 40x faster compared to the state-of-the-art methods. Moreover, HASP can effectively perturb various ASR systems, demonstrating a strong transferability.",3
A Survey of Large-Scale Deep Learning Serving System Optimization: Challenges and Opportunities,"Fuxun Yu, Di Wang, Longfei Shangguan, Minjia Zhang, Xulong Tang, Chenchen Liu, Xiang Chen",2021/11/28,Source arXiv preprint arXiv:2111.14247,"Deep Learning (DL) models have achieved superior performance in many application domains, including vision, language, medical, commercial ads, entertainment, etc. With the fast development, both DL applications and the underlying serving hardware have demonstrated strong scaling trends, i.e., Model Scaling and Compute Scaling, for example, the recent pre-trained model with hundreds of billions of parameters with ~TB level memory consumption, as well as the newest GPU accelerators providing hundreds of TFLOPS. With both scaling trends, new problems and challenges emerge in DL inference serving systems, which gradually trends towards Large-scale Deep learning Serving systems (LDS). This survey aims to summarize and categorize the emerging challenges and optimization opportunities for large-scale deep learning serving systems. By providing a novel taxonomy, summarizing the computing paradigms, and elaborating the recent technique advances, we hope that this survey could shed light on new optimization perspectives and motivate novel works in large-scale deep learning system optimization.",2
CaptorX: A Class-Adaptive Convolutional Neural Network Reconfiguration Framework,"Zhuwei Qin, Fuxun Yu, Zirui Xu, Chenchen Liu, Xiang Chen",2021/2/23,Journal IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,"Nowadays, the evolution of deep learning and cloud service significantly promotes neural network-based mobile applications. Although intelligent and prolific, those applications still lack certain flexibility: for classification tasks, neural networks are generally trained with vast classification targets to cover various utilization contexts. However, only partial classes are practically inferred due to individual mobile user preference and application specificity, which causes unnecessary computation consumption. Thus, we proposed  CaptorX —a class-adaptive convolutional neural network (CNN) reconfiguration framework to adaptively prune convolutional filters associated with unneeded classes.  CaptorX  can reconfigure a pretrained full-class CNN model into class-specific lightweight models based on the visualization analysis of convolutional filters’ exclusive functionality for a single class. These lightweight models can …",2
Exploring the design space of efficient deep neural networks,"Fuxun Yu, Dimitrios Stamoulis, Di Wang, Dimitrios Lymberopoulos, Xiang Chen",2020/11/12,Conference 2020 IEEE/ACM Symposium on Edge Computing (SEC),"This paper gives an overview of our ongoing work on the design space exploration of efficient deep neural networks (DNNs), specifically on the novel optimization perspectives that past work have mainly overlooked. We cover two complementary aspects of efficient DNN design: (1) static architecture design efficiency and (2) dynamic model execution efficiency. In the static architecture design, one of the major challenges of NAS is the low search efficiency. Different with current mainstream efficient search algorithm optimization, we identify the new perspective in efficient search space design. In the dynamic model execution, current major optimization methods still target at the model structure redundancy, e.g., weight/filter pruning, connection pruning, etc. We instead identify the new dimension of DNN feature map redundancy. By showcasing such new perspectives, further advantages could be potentially attained …",2
Exploring decentralized collaboration in heterogeneous edge training,"Xiang Chen, Zhuwei Qin",2020/11/12,Conference 2020 IEEE/ACM Symposium on Edge Computing (SEC),"Recent progress in deep learning techniques enabled collaborative edge training, which usually deploys identical neural network models globally on multiple devices for aggregating parameter updates over distributed data collection. However, as more and more heterogeneous edge devices are involved in practical training, the identical model deployment over collaborative edge devices cannot be guaranteed: On one hand, the weak edge devices with less computation resources may not catch up stronger ones' training progress, and appropriate local model training customization is necessary to balance the collaboration. On the other hand, a particular local edge device may have specific learning task preference, while the global identical model would exceed the practical local demand and cause unnecessary computation cost. Therefore, we explored the collaborative learning with heterogeneous …",2
Interpretable convolutional filter pruning,"Zhuwei Qin, Fuxun Yu, Chenchen Liu, Liang Zhao, Xiang Chen",2018/10,Journal ArXiv e-prints,"The sophisticated structure of Convolutional Neural Network (CNN) allows for outstanding performance, but at the cost of intensive computation. As significant redundancies inevitably present in such a structure, many works have been proposed to prune the convolutional filters for computation cost reduction. Although extremely effective, most works are based only on quantitative characteristics of the convolutional filters, and highly overlook the qualitative interpretation of individual filter’s specific functionality. In this work, we interpreted the functionality and redundancy of the convolutional filters from different perspectives, and proposed a functionality-oriented filter pruning method. With extensive experiment results, we proved the convolutional filters’ qualitative significance regardless of magnitude, demonstrated significant neural network redundancy due to repetitive filter functions, and analyzed the filter functionality defection under inappropriate retraining process. Such an interpretable pruning approach not only offers outstanding computation cost optimization over previous filter pruning methods, but also interprets filter pruning process.",2
LanCeX: A Versatile and Lightweight Defense Method against Condensed Adversarial Attacks in Image and Audio Recognition,"Zirui Xu, Fuxun Yu, Chenchen Liu, Xiang Chen",2022/10/29,Journal ACM Transactions on Embedded Computing Systems,"Convolutional Neural Networks (CNNs) are widely deployed in various embedded recognition applications. However, they demonstrate a considerable vulnerability to adversarial attacks, which leverage the well-designed perturbations to mislead the recognition results. Recently, for easier perturbation injection and higher attack effectiveness, the adversarial perturbations have been concentrated into a small area with various types and different data modalities. When defending such condensed adversarial attacks on the embedded recognition scenarios, most of the existing defense works highlight two critical issues. First, they are particularly designed for each individual condensed attack scenario, lacking enough versatility to accommodate attacks with different data modalities. Second, they rely on computation-intensive preprocessing techniques, which is impractical for time-sensitive embedded recognition …",1
Wideband spectrum sensing based on collaborative multi-task learning,"Weishan Zhang, Yue Wang, Fuxun Yu, Zhuwei Qin, Xiang Chen, Zhi Tian",2022/5/16,Conference 2022 IEEE International Conference on Communications Workshops (ICC Workshops),"To deal with the complex wireless conditions in cognitive radios, data-driven learning technologies have been advocated for spectrum sensing. While the most existing learning-based methods are designed for basic single-band and narrow-band circumstances, they may not work well in practical wide-band regimes. Due to the limited sensing capability and hardware constraints of practical secondary users (SUs) devices, individual SUs can only observe a portion of the entire wideband spectrum pool. It is also known as the issue of partial observations, which leads to a heterogeneous multi-task learning problem. To overcome these challenges, this work proposes a novel framework of wideband spectrum sensing via collaborative learning among distributed SUs. Capitalizing on the hierarchical nature of feature extraction in deep neural networks (DNN), we design a novel multi-task DNN architecture to detect …",1
Powering Multi-Task Federated Learning with Competitive GPU Resource Sharing,"Yongbo Yu, Fuxun Yu, Zirui Xu, Di Wang, Minjia Zhang, Ang Li, Shawn Bray, Chenchen Liu, Xiang Chen",2022/4/25,Book Companion Proceedings of the Web Conference 2022," Federated learning (FL) nowadays involves compound learning tasks as cognitive applications’ complexity increases. For example, a self-driving system hosts multiple tasks simultaneously (e.g., detection, classification, etc.) and expects FL to retain life-long intelligence involvement. However, our analysis demonstrates that, when deploying compound FL models for multiple training tasks on a GPU, certain issues arise: (1) As different tasks’ skewed data distributions and corresponding models cause highly imbalanced learning workloads, current GPU scheduling methods lack effective resource allocations; (2) Therefore, existing FL schemes, only focusing on heterogeneous data distribution but runtime computing, cannot practically achieve optimally synchronized federation. To address these issues, we propose a full-stack FL optimization scheme to address both intra-device GPU scheduling and inter-device FL …",1
Third ArchEdge workshop: Exploring the design space of efficient deep neural networks,"Fuxun Yu, Dimitrios Stamoulis, Di Wang, Dimitrios Lymberopoulos, Xiang Chen",2020/11/22,Journal arXiv preprint arXiv:2011.10912,"This paper gives an overview of our ongoing work on the design space exploration of efficient deep neural networks (DNNs). Specifically, we cover two aspects: (1) static architecture design efficiency and (2) dynamic model execution efficiency. For static architecture design, different from existing end-to-end hardware modeling assumptions, we conduct full-stack profiling at the GPU core level to identify better accuracy-latency trade-offs for DNN designs. For dynamic model execution, different from prior work that tackles model redundancy at the DNN-channels level, we explore a new dimension of DNN feature map redundancy to be dynamically traversed at runtime. Last, we highlight several open questions that are poised to draw research attention in the next few years.",1
Task-adaptive incremental learning for intelligent edge devices,"Zhuwei Qin, Fuxun Yu, Xiang Chen",2019/10/7,Journal arXiv preprint arXiv:1910.03122,"Convolutional Neural Networks (CNNs) are used for a wide range of image-related tasks such as image classification and object detection. However, a large pre-trained CNN model contains a lot of redundancy considering the task-specific edge applications. Also, the statically pre-trained model could not efficiently handle the dynamic data in the real-world application. The CNN training data and their labels are collected in an incremental manner. To tackle the above two challenges, we proposed TeAM a task-adaptive incremental learning framework for CNNs in intelligent edge devices. Given a pre-trained large model, TeAM can configure it into any specialized model for dedicated edge applications. The specialized model can be quickly fine-tuned with local data to achieve very high accuracy. Also, with our global aggregation and incremental learning scheme, the specialized CNN models can be collaboratively aggregated to an enhanced global model with new training data.",1
Dopa: A comprehensive cnn detection methodology against physical adversarial attacks,"Zirui Xu, Fuxun Yu, Xiang Chen",2019/5/21,Journal arXiv preprint arXiv:1905.08790,"Recently, Convolutional Neural Networks (CNNs) demonstrate a considerable vulnerability to adversarial attacks, which can be easily misled by adversarial perturbations. With more aggressive methods proposed, adversarial attacks can be also applied to the physical world, causing practical issues to various CNN powered applications. To secure CNNs, adversarial attack detection is considered as the most critical approach. However, most existing works focus on superficial patterns and merely search a particular method to differentiate the adversarial inputs and natural inputs, ignoring the analysis of CNN inner vulnerability. Therefore, they can only target to specific physical adversarial attacks, lacking expected versatility to different attacks. To address this issue, we propose DoPa -- a comprehensive CNN detection methodology for various physical adversarial attacks. By interpreting the CNN's vulnerability, we find that non-semantic adversarial perturbations can activate CNN with significantly abnormal activations and even overwhelm other semantic input patterns' activations. Therefore, we add a self-verification stage to analyze the semantics of distinguished activation patterns, which improves the CNN recognition process. We apply such a detection methodology into both image and audio CNN recognition scenarios. Experiments show that DoPa can achieve an average rate of 90% success for image attack detection and 92% success for audio attack detection. Announcement:[The original DoPa draft on arXiv was modified and submitted to a conference already, while this short abstract was submitted only for a presentation at the KDD …",1
REIN: A robust training method for enhancing generalization ability of neural networks in autonomous driving systems,"Fuxun Yu, Chenchen Liu, Xiang Chen",2019/1/21,Book Proceedings of the 24th Asia and South Pacific Design Automation Conference,"In recent years, neural network has shown its great potential in autonomous driving systems. However, the theoretically well-train neural networks usually fail their performance when facing real-world examples with unexpected physical variations. As the current neural networks still suffer from limited generalization ability, those unexpected variations would cause considerable accuracy degradation and critical safety issues. Therefore, the generalization ability of neural networks becomes one of the most critical challenges for autonomous driving system design. In this work, we propose a robust training method to enhance neural network's generalization ability in various practical autonomous driving scenarios. Based on detailed practical variation modeling and neural network generation ability analysis, the proposed training method could consistently improve model classification accuracy by at most 25% in …",1
Rerise: An adversarial example restoration system for neuromorphic computing security,"Chenchen Liu, Qide Dong, Fuxun Yu, Xiang Chen",2018/7/8,Conference 2018 IEEE Computer Society Annual Symposium on VLSI (ISVLSI),"While the Deep Neural Network (DNN) has achieved remarkable success in advanced intelligent applications, the security issue becomes a significant concern due to the emerged adversarial attacks. State-of-the-art defense against adversarial attacks involves adversarial example detection via multi-model cross verification, followed by adversarial example filtration. Although this has proven effective, the high computational overhead and considerable input data loss make this solution unsuitable for use. To overcome the above drawbacks, we propose a novel adversarial example restoration system to restore the adversarially perturbed input to its original state. It includes a restoration network based on a residual learning and a hardware implementation by leveraging neuromorphic technique to achieve an effective and efficient defense. Our proposed restoration system demonstrates a high restoration rate that …",1
The Global Convergence of the Alternating Minimization Algorithm for Deep Neural Network Problems,"Junxiang Wang, Fuxun Yu, Xiang Chen& Liang Zhao",2018,Journal arXiv preprint arXiv:1811.04187,"In recent years, stochastic gradient descent (SGD) is a dominant optimization method for training deep neural networks. But the SGD suffers from several limitations including lack of theoretical guarantees, gradient vanishing, poor conditioning and the non-differentiability of activation functions, which motives the development of alternating minimization methods. However, there are still two challenges needed to overcome: difficulty in obtaining global minimum in subproblems, and expensive cost of matrix inversion between layers. In this paper, we propose a novel deep learning alternating minimization (DLAM) algorithm to deal with those two challenges. Furthermore, detail proofs are provided to validate the global convergence of our DLAM algorithm under mild conditions. Experiments on real-world datasets demonstrate the effectiveness of our DLAM algorithm.",1
VoCaM: Visualization oriented convolutional neural network acceleration on mobile system,"Zhuwei Qin, Zirui Xu, Qide Dong, Yiran Chen, Xiang Chen",2017/11/13,Conference 2017 IEEE/ACM International Conference on Computer-Aided Design (ICCAD),"Convolutional Neural Networks (CNNs) have been widely investigated as some of the most promising solution for various computer vision tasks. However, CNNs introduce massive computing overhead due to their complex network computing flow, resulting in significantly reduced applicability and performance, especially in the mobile devices. Various optimization schemes have been proposed mainly based on both model compression and stacked external computing resources. While these schemes have been proven effective, methods which take into account mobile-specific context-aware optimization approaches have been largely overlooked. One such opportunity is the feasible CNN computing flow simplification to the under-test objects with distinguish features, which can be efficiently pre-analyzed inside the mobile sensor system. Hence, we propose VoCaM, a visualization oriented CNN acceleration …",1
Privacy-preserving federated learning for transportation mode prediction based on personal mobility data,"Fuxun Yu, Zirui Xu, Zhuwei Qin, Xiang Chen",2022/12/1,Journal High-Confidence Computing,"Personal daily mobility trajectories/traces like Google Location Service integrates many valuable information from individuals and could benefit a lot of application scenarios, such as pandemic control and precaution, product recommendation, customized user profile analysis, traffic management in smart cities, etc. However, utilizing such personal mobility data faces many challenges since users’ private information, such as home/work addresses, can be unintentionally leaked. In this work, we build an FL system for transportation mode prediction based on personal mobility data. Utilizing FL-based training scheme, all user’s data are kept in local without uploading to central nodes, providing high privacy preserving capability. At the same time, we could train accurate DNN models that is close to the centralized training performance. The resulted transportation mode prediction system serves as a prototype on user’s …",
QuadraLib: A Performant Quadratic Neural Network Library for Architecture Optimization and Design Exploration,"Zirui Xu, Fuxun Yu, Jinjun Xiong, Xiang Chen",2022/4/22,Journal Proceedings of Machine Learning and Systems,"The significant success of Deep Neural Networks (DNNs) is highly promoted by the multiple sophisticated DNN libraries. On the contrary, although some work have proved that Quadratic Deep Neuron Networks (QDNNs) show better non-linearity and learning capability than the traditional first-order DNNs, their neuron design suffers certain drawbacks from theoretical performance to practical deployment. In this paper, we first proposed a new QDNN neuron architecture design, and further developed QuadraLib, a QDNN library to provide architecture optimization and design exploration for QDNNs. Extensive experiments show that our design has better performance regarding prediction accuracy and computation consumption on multiple learning tasks.",
Efficient Neural Network Implementation with Quadratic Neuron,"Zirui Xu, Jinjun Xiong, Fuxun Yu, Xiang Chen",2020/11/21,Journal arXiv preprint arXiv:2011.10813,"Previous works proved that the combination of the linear neuron network with nonlinear activation functions (e.g. ReLu) can achieve nonlinear function approximation. However, simply widening or deepening the network structure will introduce some training problems. In this work, we are aiming to build a comprehensive second-order CNN implementation framework that includes neuron/network design and system deployment optimization.",
Interpretable Deep Learning for Efficient Mobile Computing,Zhuwei Qin,2020,Institution George Mason University,"Promoted by the evolution of artificial intelligence and deep learning, more and more intelligent applications have emerged on mobile devices. As one of the most representative deep learning technologies, deep neural networks (DNNs) have been considered as a primary tool in computer vision fields. However, the heavy computation, memory, and energy demands of the DNN model restrict their deployment on resource-constrained mobile devices. Therefore, lots of research works have been proposed to optimize the computational efficiency of DNNs.",
CAPTURE: An End-to-End Mobile Implementation for a Computationally Optimized Deep Learning Framework,"Rayan Yu, Lekha Punya Punya, Kenneth Wang, Zhuwei Qin, Xiang Chen",2019/11/19,Journal Journal of Student-Scientists' Research,"Through modern artificial intelligence techniques, Convolutional Neural Networks (CNNs) are one of the most effective methods for computer vision tasks such as image classification. However, the computation of CNN models remains extremely costly, highly limiting applications in areas such as mobile devices with limited computation resources. To resolve this issue, we investigate local optimization and propose CAPTURE, a fully offline CNN computing framework for mobile deployment, with significant reductions in model size and computation load while maintaining optimal accuracy. Since most CNN-based mobile applications classify only a specific subset of images, this project’s objective includes compressing pre-trained CNN models into specialized models. Techniques include distilling critical pathways with mean activation and gradient calculations of convolutional filters as well as reconstructing and …",
DoPa: A Fast and Comprehensive CNN Defense Methodology against Physical Adversarial Attacks.,"Zirui Xu, Fuxun Yu, Xiang Chen",2019,Journal CoRR,"Recently, Convolutional Neural Networks (CNNs) demonstrate a considerable vulnerability to adversarial attacks, which can be easily mislead by adversarial perturbations. With more aggressive methods proposed, adversarial attacks can be also applied to the physical world, causing practical issues to various CNN powered applications. Most existing defense works for physical adversarial attacks only focus on eliminating explicit perturbation patterns from inputs, ignoring interpretation and solution to CNN’s intrinsic vulnerability. Therefore, most of them depend on considerable data processing costs and lack expected versatility to different attacks. In this paper, we propose DoPa–a fast and comprehensive CNN defense methodology against physical adversarial attacks. By interpreting the CNN’s vulnerability, we find that non-semantic adversarial perturbations can activate CNN with significantly abnormal activations and even overwhelm other semantic input patterns’ activations. We improve the CNN recognition process by adding a self-verification stage to analyze the semantics of distinguished activation patterns with only one CNN inference involved. Based on the detection result, we further propose a data recovery methodology to defend the physical adversarial attacks. We apply such detection and data recovery methodology into both image and audio CNN recognition process. Experiments show that our methodology can achieve an average rate of 90% success for attack detection and 81% accuracy recovery for image physical adversarial attacks. Also, the proposed defense method can achieve a 92% detection successful rate and 77.5 …",
MORPh: mobile OLED power friendly camera system,"Xiang Chen, Jiachen Mao, Kent W Nixon, Yiran Chen",2016/10/1,Book Proceedings of the 27th International Symposium on Rapid System Prototyping: Shortening the Path from Specification to Prototype,"With superior advantages of better display quality and power efficiency, the latest OLED technology has achieved unprecedented popularity in the display screen market. However, the OLED remains one of the most power-hungry components in mobile devices. Various optimization schemes have been proposed based on the color-dependent power consumption feature of OLED pixels. These schemes mainly focus on color modification during the playback phase and require significant overhead in terms of frame analysis and real-time modification. While such schemes are effective, the power saving opportunities during the camera recording phase are overlooked. To further enhance the power optimization, the camera parameters during the recording phase could be effectively utilized to reduce or eliminate the optimization overhead. Hence, we proposed MORPh, a cross-layer optimization system for OLED …",
A Real-Time Driving Fatigue Monitoring DSP Device Based on Computing Complexity of Binarized Image,"Xiang Chen, Zhifei Zhang, Yang Song, Renyi Chen",2009/10/28,Conference 2009 Second International Workshop on Computer Science and Engineering,"This paper presents a driving fatigue monitoring method with machine vision algorithm, which is based on computing complexity. And a DSP system based on this method is also introduced. In this method, we firstly binarizated image which contains driver's facial information, to distinguish face area from background.. Then the binarizated luminance components is horizontally and vertically accumulated for collecting face pixel to draw out a face and eyes' location block. Thus, with accumulated index, analyze the relative location ratio between eyes and index of other facial parts, face width, and eyes horizontal position. Compare these ratios to PERCLOS based thresholds, we can ensure whether the driver's eyes are open or not , and infer drivers fatigue state. Finally, this method has been fulfilled with an intact device based on DSP system. Series of experiments indicate this contactless device has advantages of …",
IEEE SOCC Technical Program Committee,"Ali Ahmadinia, Md Tanvir Arafin, Magdy Bayoumi, Andrew Marshall, Jürgen Becker, Thomas Büchner, Unni Chandran, Ke-Horng Chen, Kun-Chih Chen, Xiang Chen, Aijiao Cui, Sri Navaneeth Easwaran, Esam El-Araby, Tanja Harbaum, Klaus Hofmann, Po-Tsang Huang, Tianyu Jia, Hailong Jiao, Phil Knag, Raghavan Kumar, Bo-Cheng Lai, Jinmei Lai, He Li, Chenchen Liu, Arnab Neelim Mazumder, Kieran McLaughlin, Venkatesan Muthukumar, Alberto Nannarelli, Erika Neumann","IEEE SOCC Technical Program Committee Page 1 xiv IEEE SOCC Technical Program 
Committee Ali Ahmadinia California State University San Marcos, USA Md Tanvir Arafin George 
Mason University, USA Magdy Bayoumi University of Louisiana at Lafayette, USA Andrew 
Marshall University of Texas at Dallas, USA Jürgen Becker Karlsruhe Institute of Technology, 
Germany Thomas Büchner IBM Germany Research & Development, Germany Unni Chandran 
Intel Corporation, USA Ke-Horng Chen NCTU, Taiwan Kun-Chih Chen National Sun Yat-Sen 
University, Taiwan Xiang Chen George Mason University, USA Aijiao Cui HIT Shenzhen, China 
Sri Navaneeth Easwaran Texas Instruments, USA Esam El-Araby University of Kansas, USA 
Tanja Harbaum Karlsruhe Institute of Technology, Germany Klaus Hofmann TU Darmstadt, 
Germany Po-Tsang Huang National Chiao Tung University, Taiwan Tianyu Jia Peking …","Scholar articles IEEE SOCC Technical Program CommitteeA Ahmadinia, MT Arafin, M Bayoumi, A Marshall…",,
Massimo Alioto Alberto Nannarelli,"Arindam Basu, Mahdi Nikdast, Magdy Bayoumi, Maurizio Palesi, Thomas Büchner, Davide Patti, Wang Chao, Darshika G Perera, Ke-Horng Chen, Fakhrul Zaman Rokhani, Kun-Chih Jimmy Chen, Radu Secareanu, Xiang Chen, Sakir Sezer, Malgorzata Chrzanowska-Jeske, Hongjiang Song, Masoud Daneshtalab, Tolga Soyata, Esam El-Araby, Ramalingam Sridhar, Magdy Ali El-Moursy, Mircea Stan, Kamal El-Sankary, Huseyin Sumbul","SOCC 2019 Technical Program Committee Page 1 2019 TECHNICAL PROGRAM 
COMMITTEE Massimo Alioto Alberto Nannarelli National University of Singapore, 
Singapore Technical University of Denmark, Denmark Arindam Basu Mahdi Nikdast 
Nanyang Technological University, Singapore Colorado State University Fort Collins, USA 
Magdy Bayoumi Maurizio Palesi University of Louisiana at Lafayette, USA University of 
Catania, Italy Thomas Büchner Davide Patti IBM, Germany University of Catania, Italy Wang 
Chao Darshika G. Perera Huazhong University of Science and Technology, China 
University of Colorado at Colorado Springs, USA Ke-Horng Chen Fakhrul Zaman Rokhani 
National Chiao Tung University, Taiwan University Putra, Malaysia Kun-Chih (Jimmy) Chen 
Radu Secareanu National Sun Yat-Sen University, Taiwan NXP, USA Xiang Chen Sakir 
Sezer George Mason University, USA Queen's …","Scholar articles Massimo Alioto Alberto NannarelliA Basu, M Nikdast, M Bayoumi, M Palesi, T Büchner…",,
Fatma Abdelkefi High School of Communications of Tunis (SUPCOM) Tunisia Chadi Abou-Rjeily Lebanese American University (LAU) Lebanon Syed Hassan Ahmed University of Central …,"Marcelo Alencar, Giuseppa Alfano, Masoud Alghoniemy, Mohamad Yusoff Alias, Saud Althunibat, Gayan Amarasuriya, Beongku An, Kamran Arshad, United Arab, Takuya Asaka, Koichi Asatani, Chaodit Aswakul, Bigomokero Bagula, Dariusz Barbucha, Paolo Bellavista, Jalel Ben-Othman, Roc Berenguer TECNUN Spain, Kaigui Bian, Rajendra Boppana, Zied Bouida, Loc Bui, Nicola Bui, Lin Cai, Berk Canberk, Maria-Dolores Cano, Luis Castedo, Calvin CK Chan, Ben-Jye Chang, Zheng Chang, Cheng Chen, Jieqiong Chen, Lin Chen, Xiang Chen, Yuanfang Chen","Technical program committee Page 1 xii Technical Program Committee Fatma Abdelkefi High 
School of Communications of Tunis (SUPCOM) Tunisia Chadi Abou-Rjeily Lebanese 
American University (LAU) Lebanon Syed Hassan Ahmed University of Central Florida USA 
Ozgur Akan University of Cambridge United Kingdom Michele Albano CISTER/INESC-TEC, 
ISEP, Polytechnic Institute of Porto Portugal Marcelo Alencar Federal University of Campina 
Grande Brazil George Alexandropoulos Huawei Technologies France France Giuseppa Alfano 
Politecnico di Torino Italy Masoud Alghoniemy University of Alexandria Egypt Mohamad Yusoff 
Alias Multimedia University Malaysia Saud Althunibat Al-Hussein Bin Talal University Jordan 
Gayan Amarasuriya Southern Illinois University USA Beongku An Hongik University Korea 
Kamran Arshad Ajman University United Arab Emirates Takuya Asaka Tokyo Metropolitan …","Scholar articles Fatma Abdelkefi High School of Communications of Tunis (SUPCOM) Tunisia Chadi Abou-Rjeily Lebanese American University (LAU) Lebanon Syed Hassan Ahmed University of Central Florida USA Ozgur Akan University of Cambridge UnitedM Alencar, G Alfano, M Alghoniemy, MY Alias…",,
Gradient-free Neural Network Training by Multi-convex Alternating Optimization,"Junxiang Wang, Fuxun Yu, Xiang Chen, Liang Zhao","In recent years, stochastic gradient descent (SGD) and its variants have been the dominant optimization methods for training deep neural networks. However, SGD suffers from limitations such as the lack of theoretical guarantees, vanishing gradients, excessive sensitivity to input, and difficulties solving highly non-smooth constraints and functions. To overcome these drawbacks, alternating minimization-based methods for deep neural network optimization have attracted fast-increasing attention recently. As an emerging and open domain, however, several new challenges need to be addressed, including 1) Convergence depending on the choice of hyperparameters, and 2) Lack of unified theoretical frameworks with general conditions. We, therefore, propose a novel Deep Learning Alternating Minimization (DLAM) algorithm to deal with these two challenges. Our innovative inequality-constrained formulation infinitely approximates the original problem with non-convex equality constraints, enabling our proof of global convergence of the DLAM algorithm under mild, practical conditions, regardless of the choice of hyperparameters and wide range of various activation functions. Experiments on benchmark datasets demonstrate the effectiveness of DLAM.","Scholar articles Gradient-free Neural Network Training by Multi-convex Alternating OptimizationJ Wang, F Yu, X Chen, L ZhaoRelated articles ","In recent years, stochastic gradient descent (SGD) and its variants have been the dominant optimization methods for training deep neural networks. However, SGD suffers from limitations such as the lack of theoretical guarantees, vanishing gradients, excessive sensitivity to input, and difficulties solving highly non-smooth constraints and functions. To overcome these drawbacks, alternating minimization-based methods for deep neural network optimization have attracted fast-increasing attention recently. As an emerging and open domain, however, several new challenges need to be addressed, including 1) Convergence depending on the choice of hyperparameters, and 2) Lack of unified theoretical frameworks with general conditions. We, therefore, propose a novel Deep Learning Alternating Minimization (DLAM) algorithm to deal with these two challenges. Our innovative inequality-constrained formulation infinitely approximates the original problem with non-convex equality constraints, enabling our proof of global convergence of the DLAM algorithm under mild, practical conditions, regardless of the choice of hyperparameters and wide range of various activation functions. Experiments on benchmark datasets demonstrate the effectiveness of DLAM.",
