titles,authors,date,source,descriptions,citations
Spectre Returns! Speculation Attacks using the Return Stack Buffer.,"Esmaeil Mohammadian Koruyeh, Khaled N Khasawneh, Chengyu Song, Nael B Abu-Ghazaleh",2018/8/13,Conference WOOT@ USENIX Security Symposium,"The recent Spectre attacks exploit speculative execution, a pervasively used feature of modern microprocessors, to allow the exfiltration of sensitive data across protection boundaries. In this paper, we introduce a new Spectreclass attack that we call SpectreRSB. In particular, rather than exploiting the branch predictor unit, SpectreRSB exploits the return stack buffer (RSB), a common predictor structure in modern CPUs used to predict return addresses. We show that both local attacks (within the same process such as Spectre 1) and attacks on SGX are possible by constructing proof of concept attacks. We also analyze additional types of the attack on the kernel or across address spaces and show that under some practical and widely used conditions they are possible. Importantly, none of the known defenses including Retpoline and Intel’s microcode patches stop all SpectreRSB attacks. We believe that future system developers should be aware of this vulnerability and consider it in developing defenses against speculation attacks. In particular, on Core-i7 Skylake and newer processors (but not on Intel’s Xeon processor line), a patch called RSB refilling is used to address a vulnerability when the RSB underfills; this defense interferes with SpectreRSB’s ability to launch attacks that switch into the kernel. We recommend that this patch should be used on all machines to protect against SpectreRSB.",290
Safespec: Banishing the spectre of a meltdown with leakage-free speculation,"Khaled N Khasawneh, Esmaeil Mohammadian Koruyeh, Chengyu Song, Dmitry Evtyushkin, Dmitry Ponomarev, Nael Abu-Ghazaleh",2019/6/2,Conference 2019 56th ACM/IEEE Design Automation Conference (DAC),"Speculative attacks, such as Spectre and Meltdown, target speculative execution to access privileged data and leak it through a side-channel. In this paper, we introduce (SafeSpec), a new model for supporting speculation in a way that is immune to the side-channel leakage by storing side effects of speculative instructions in separate structures until they commit. Additionally, we address the possibility of a covert channel from speculative instructions to committed instructions before these instructions are committed. We develop a cycle accurate model of modified design of an x86-64 processor and show that the performance impact is negligible.",173
Ensemble learning for low-level hardware-supported malware detection,"Khaled N Khasawneh, Meltem Ozsoy, Caleb Donovick, Nael Abu-Ghazaleh, Dmitry Ponomarev",2015/11/2,"Conference International Symposium on Research in Attacks, Intrusions and Defenses (RAID)","Recent work demonstrated hardware-based online malware detection using only low-level features. This detector is envisioned as a first line of defense that prioritizes the application of more expensive and more accurate software detectors. Critical to such a framework is the detection performance of the hardware detector. In this paper, we explore the use of both specialized detectors and ensemble learning techniques to improve performance of the hardware detector. The proposed detectors reduce the false positive rate by more than half compared to a single detector, while increasing the detection rate. We also contribute approximate metrics to quantify the detection overhead, and show that the proposed detectors achieve more than 11x reduction in overhead compared to a software only detector (1.87x compared to prior work), while improving detection time. Finally, we characterize the hardware …",110
Hardware-based malware detection using low-level architectural features,"Meltem Ozsoy, Khaled N Khasawneh, Caleb Donovick, Iakov Gorelik, Nael Abu-Ghazaleh, Dmitry Ponomarev",2016/3/10,Journal IEEE Transactions on Computers,"Security exploits and ensuant malware pose an increasing challenge to computing systems as the variety and complexity of attacks continue to increase. In response, software-based malware detection tools have grown in complexity, thus making it computationally difficult to use them to protect systems in real-time. Therefore, software detectors are applied selectively and at a low frequency, creating opportunities for malware to remain undetected. In this paper, we propose Malware-Aware Processors (MAP) - processors augmented with a hardware-based online malware detector to serve as the first line of defense to differentiate malware from legitimate programs. The output of this detector helps the system prioritize how to apply more expensive software-based solutions. The always-on nature of MAP detector helps protect against intermittently operating malware. We explore the use of different features for …",84
Ric: Relaxed inclusion caches for mitigating llc side-channel attacks,"Mehmet Kayaalp, Khaled N Khasawneh, Hodjat Asghari Esfeden, Jesse Elwell, Nael Abu-Ghazaleh, Dmitry Ponomarev, Aamer Jaleel",2017/6/18,Book Proceedings of the 54th Annual Design Automation Conference 2017,"Recently, side-channel attacks on Last Level Caches (LLCs) were demonstrated. The attacks require the ability to evict critical data from the cache hierarchy, making future accesses visible. We propose Relaxed Inclusion Caches (RIC), a low-complexity cache design protecting against LLC side channel attacks. RIC relaxes inclusion when it is not needed, preventing the attacker from replacing the victim's data from the local core caches thus protecting critical data from leakage. RIC improves performance (by about 10%) and retains snoop filtering capabilities of inclusive cache hierarchies, while requiring only minimal changes to the cache.",76
Constructing and characterizing covert channels on gpgpus,"Hoda Naghibijouybari, Khaled N Khasawneh, Nael Abu-Ghazaleh",2017/10/14,Book Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture,"General Purpose Graphics Processing Units (GPGPUs) are present in most modern computing platforms. They are also increasingly integrated as a computational resource on clusters, data centers, and cloud infrastructure, making them possible targets for attacks. We present a first study of covert channel attacks on GPGPUs. GPGPU attacks offer a number of attractive properties relative to CPU covert channels. These channels also have characteristics different from their counterparts on CPUs. To enable the attack, we first reverse engineer the hardware block scheduler as well as the warp to warp scheduler to characterize how co-location is established. We exploit this information to manipulate the scheduling algorithms to create co-residency between the trojan and the spy. We study contention on different resources including caches, functional units and memory, and construct operational covert channels on all …",61
Speccfi: Mitigating spectre attacks using cfi informed speculation,"Esmaeil Mohammadian Koruyeh, Shirin Haji Amin Shirazi, Khaled N Khasawneh, Chengyu Song, Nael Abu-Ghazaleh",2020/5/18,Conference 2020 IEEE Symposium on Security and Privacy (SP),"Spectre attacks and their many subsequent variants are a new vulnerability class affecting modern CPUs. The attacks rely on the ability to misguide speculative execution, generally by exploiting the branch prediction structures, to execute a vulnerable code sequence speculatively. In this paper, we propose to use Control-Flow Integrity (CFI), a security technique used to stop control-flow hijacking attacks, on the committed path, to prevent speculative control-flow from being hijacked to launch the most dangerous variants of the Spectre attacks (Spectre-BTB and Spectre-RSB). Specifically, CFI attempts to constrain the possible targets of an indirect branch to a set of legal targets defined by a pre-calculated control-flow graph (CFG). As CFI is being adopted by commodity software (e.g., Windows and Android) and commodity hardware (e.g., Intel's CET and ARM's BTI), the CFI information becomes readily available …",59
RHMD: Evasion-resilient hardware malware detectors,"Khaled N Khasawneh, Nael Abu-Ghazaleh, Dmitry Ponomarev, Lei Yu",2017/10/14,Book Proceedings of the 50th Annual IEEE/ACM international symposium on microarchitecture,"Hardware Malware Detectors (HMDs) have recently been proposed as a defense against the proliferation of malware. These detectors use low-level features, that can be collected by the hardware performance monitoring units on modern CPUs to detect malware as a computational anomaly. Several aspects of the detector construction have been explored, leading to detectors with high accuracy. In this paper, we explore the question of how well evasive malware can avoid detection by HMDs. We show that existing HMDs can be effectively reverse-engineered and subsequently evaded, allowing malware to hide from detection without substantially slowing it down (which is important for certain types of malware). This result demonstrates that the current generation of HMDs can be easily defeated by evasive malware. Next, we explore how well a detector can evolve if it is exposed to this evasive malware during …",59
EnsembleHMD: Accurate hardware malware detectors with specialized ensemble classifiers,"Khaled N Khasawneh, Meltem Ozsoy, Caleb Donovick, Nael Abu-Ghazaleh, Dmitry Ponomarev",2018/2/5,Journal IEEE Transactions on Dependable and Secure Computing,"Hardware-based malware detectors (HMDs) are a promising new approach to defend against malware. HMDs collect low-level architectural features and use them to classify malware from normal programs. With simple hardware support, HMDs can be always on, operating as a first line of defense that prioritizes the application of more expensive and more accurate software-detector. In this paper, our goal is to increase the accuracy of HMDs, to improve detection, and reduce overhead. We use specialized detectors targeted towards a specific type of malware to improve the detection of each type. Next, we use ensemble learning techniques to improve the overall accuracy by combining detectors. We explore detectors based on logistic regression (LR) and neural networks (NN). The proposed detectors reduce the false-positive rate by more than half compared to using a single detector, while increasing their …",41
A review of in-memory computing architectures for machine learning applications,"Sathwika Bavikadi, Purab Ranjan Sutradhar, Khaled N Khasawneh, Amlan Ganguly, Sai Manoj Pudukotai Dinakarrao",2020/9/7,Source Proceedings of the 2020 on Great Lakes Symposium on VLSI,"to meet the extensive computational load presented by the rapidly growing Machine Learning (ML) and Artificial Intelligence (AI) algorithms such as Deep Neural Networks (DNNs) and Convolutional Neural Networks (CNNs). In order to obtain hardware solutions to meet the low-latency and high-throughput computational demands from these algorithms, Non-Von Neumann computing architectures such as In-memory Computing (IMC)/ Processing-in-memory (PIM) are being extensively researched and experimented with. In this survey paper, we analyze and review pioneer IMC/PIM works designed to accelerate ML algorithms such as DNNs and CNNs. We investigate different architectural aspects and dimensions of these works and provide our comparative evaluations. Furthermore, we discuss challenges and limitations in IMC research and also present feasible directions based on our observations and insight.",30
Defensive approximation: securing cnns using approximate computing,"Amira Guesmi, Ihsen Alouani, Khaled N Khasawneh, Mouna Baklouti, Tarek Frikha, Mohamed Abid, Nael Abu-Ghazaleh",2021/4/19,Book Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems,"In the past few years, an increasing number of machine-learning and deep learning structures, such as Convolutional Neural Networks (CNNs), have been applied to solving a wide range of real-life problems. However, these architectures are vulnerable to adversarial attacks: inputs crafted carefully to force the system output to a wrong label. Since machine-learning is being deployed in safety-critical and security-sensitive domains, such attacks may have catastrophic security and safety consequences. In this paper, we propose for the first time to use hardware-supported approximate computing to improve the robustness of machine learning classifiers. We show that our approximate computing implementation achieves robustness across a wide range of attack scenarios. Specifically, we show that successful adversarial attacks against the exact classifier have poor transferability to the approximate implementation …",22
Evolution of defenses against transient-execution attacks,"Claudio Canella, Sai Manoj Pudukotai Dinakarrao, Daniel Gruss, Khaled N Khasawneh",2020/9/7,Book Proceedings of the 2020 on Great Lakes Symposium on VLSI,"Transient-execution attacks, such as Meltdown and Spectre, exploit performance optimizations in modern CPUs to enable unauthorized access to data across protection boundaries. Against these attacks, we have noticed a rapid growth of deployed and proposed countermeasures. In this paper, we show the evolution of countermeasures against transient-execution attacks by both industry and academia since the initial discoveries of the attacks. We show that despite the advances in the understanding and systematic view of the field, the proposed and deployed defenses are limited.",22
Lightweight implementation of the lowmc block cipher protected against side-channel attacks,"Javad Bahrami, Viet B Dang, Abubakr Abdulgadir, Khaled N Khasawneh, Jens-Peter Kaps, Kris Gaj",2020/11/13,Book Proceedings of the 4th ACM Workshop on Attacks and Solutions in Hardware Security,"LowMC is a parameterizable block cipher developed for use in Multi-Party Computation (MPC) and Fully Homomorphic Encryption (FHE). In these applications, linear operations are much less expensive in terms of resource utilization compared to the non-linear operations due to their low multiplicative complexity. In this work, we implemented two versions of LowMC -- unrolled and lightweight. Both implementations are realized using RTL VHDL. To the best of our knowledge, we report the first lightweight implementation of LowMC and the first implementation protected against side-channel analysis (SCA). For the SCA protection, we used a hybrid 2/3 shares Threshold Implementation (TI) approach, and for the evaluation, the Test Vector Leakage Assessment (TVLA) method, also known as the T-test. Our unprotected implementations show information leakage at 10K traces, and after protection, they could …",20
The evolution of transient-execution attacks,"Claudio Canella, Khaled N Khasawneh, Daniel Gruss",2020/9/7,Book Proceedings of the 2020 on Great Lakes Symposium on VLSI,"Historically, non-architectural state was considered non-observable. Side-channel attacks, in particular on caches, already showed that this is not entirely correct and meta-information, such as the cache state, can be extracted. Transient-execution attacks emerged when multiple groups discovered the exploitability of speculative execution and, simultaneously, the exploitability of deferred permission checks in modern out-of-order processors. These attacks are called transient as they exploit that the processor first executes operations that are then reverted as if they were never executed. However, on the microarchitectural level, these operations and their effects can be observed. While side-channel attacks enable and exploit direct access to meta-data from other security domains, transient-execution attacks enable and exploit direct access to actual data from other security domains. In this paper, we show how the …",20
Code-bridged classifier (cbc): A low or negative overhead defense for making a cnn classifier robust against adversarial attacks,"Farnaz Behnia, Ali Mirzaeian, Mohammad Sabokrou, Saj Manoj, Tinoosh Mohsenin, Khaled N Khasawneh, Liang Zhao, Houman Homayoun, Avesta Sasan",2020/3/25,Conference 2020 21st International Symposium on Quality Electronic Design (ISQED),"In this paper, we propose Code-Bridged Classifier (CBC), a framework for making a Convolutional Neural Network (CNNs) robust against adversarial attacks without increasing or even by decreasing the overall models' computational complexity. More specifically, we propose a stacked encoder-convolutional model, in which the input image is first encoded by the encoder module of a denoising auto-encoder, and then the resulting latent representation (without being decoded) is fed to a reduced complexity CNN for image classification. We illustrate that this network not only is more robust to adversarial examples but also has a significantly lower computational complexity when compared to the prior art defenses.",12
Imitating functional operations for mitigating side-channel leakage,"Abhijitt Dhavlle, Setareh Rafatirad, Khaled Khasawneh, Houman Homayoun, Sai Manoj Pudukotai Dinakarrao",2021/3/31,Journal IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,"Inspired by the idiom, “Mitigation (prevention) is better than cure!”, this work presents a random yet cognitive side-channel mitigation technique that is independent of underlying architecture and/or operating system. Unlike malware and other cyber-attacks, side-channel attacks (SCAs) exploit the architectural and design vulnerabilities and obtain sensitive information through the side channels. In contrast to the existing randomization-based side-channel defenses, we introduce a cognitive perturbation-based defense, Covert-Enigma, where the introduced perturbations look legit, but lead to an incorrect observation when interpreted by the attacker. To achieve this, the perturbations are injected at appropriate time instances to introduce additional operations, thereby misleading the attacker making the extracted data futile. To further make the attack more intricate for the attacker, proposed Covert-Enigma offers two modes …",8
Nd-hmds: Non-differentiable hardware malware detectors against evasive transient execution attacks,"Md Shohidul Islam, Abraham Peedikayil Kuruvila, Kanad Basu, Khaled N Khasawneh",2020/10/18,Conference 2020 IEEE 38th International Conference on Computer Design (ICCD),"Transient execution attacks exploit performance optimizations, built into modern CPU designs, to leak sensitive data through side channels. Preventing such attacks is limited: (1) Software solutions engender high performance overhead, and (2) Hardware solutions require new CPU designs and intensive formal analysis, which is impractical due to the tremendous complexity of modern CPUs and lack of public documentation. To address these challenges, Hardware-Malware Detectors (HMDs), which utilize Hardware Performance Counters (HPCs), have been proposed to detect transient execution attacks as a computational anomaly, with a low impact on performance. Unfortunately, some recent studies show that HMDs detection can be easily evaded by obfuscating the HPC traces. Upon observing that two main methods mostly generate evasive transient execution attacks, namely gradient-based and sleep based …",8
LATCH: A locality-aware taint CHecker,"Daniel Townley, Khaled N Khasawneh, Dmitry Ponomarev, Nael Abu-Ghazaleh, Lei Yu",2019/10/12,Book Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture,"We present LATCH (short for Locality-Aware Taint CHecker), a generalizable architecture for optimizing dynamic information flow tracking (DIFT). LATCH exploits the observation that information flows under DIFT exhibit strong temporal locality, with typical applications manipulating sensitive data during limited phases of computation. This property allows LATCH to monitor significant spans of execution using lightweight, coarse-grained checks, invoking precise, computationally intensive tracking logic only during periods of execution that involve sensitive data. LATCH implements this policy without sacrificing the accuracy of DIFT.",8
Adversarial evasion-resilient hardware malware detectors,"Khaled N Khasawneh, Nael B Abu-Ghazaleh, Dmitry Ponomarev, Lei Yu",2018/11/5,Conference 2018 IEEE/ACM International Conference on Computer-Aided Design (ICCAD),"Machine learning offers tantalizing possibilities in computing and autonomous systems: data driven components and systems are trained to learn their environment and offer decisions comparable or surpassing those of humans. However, adversaries can learn the behavior of classifiers and construct adversarial examples that cause them to make wrong decisions, with potentially disastrous consequences. We explore this space in the context of Hardware Malware Detectors (HMDs), which have recently been proposed as a defense against the proliferation of malware. These detectors use low-level features, that can be collected by the hardware performance monitoring units on modern CPUs to detect malware as a computational anomaly. An adversary can reverse engineer existing HMDs effectively and use the reverse engineered model to create malware that evades detection. To address this critical problem …",8
Cloak & co-locate: Adversarial railroading of resource sharing-based attacks on the cloud,"Hosein Mohammadi Makrani, Hossein Sayadi, Najmeh Nazari, Khaled N Khasawneh, Avesta Sasan, Setareh Rafatirad, Houman Homayoun",2021/9/20,Conference 2021 International Symposium on Secure and Private Execution Environment Design (SEED),"The heterogeneity of resources and the diversity of applications on the cloud motivated the need for resource provisioning systems (RPSs) to meet the users’ performance requirements while maximizing the resource utilization to achieve cost-efficiency. On the other hand, resource sharing-based attacks, such as side-channel, transient execution, rowhammer, and denial of service attacks, exploit shared resources to leak sensitive data or hurt the performance of a victim. Although mounting resource sharing-based attacks on the cloud is trivial once the attacker virtual machine (VM) is co-located with the victim VM, the co-location requirement with the victim limit the practicality of resource sharing-based attacks on the cloud. In this paper, we show that RPSs can be exploited to solve the co-location challenge of resource sharing-based attacks in the cloud. In particular, we propose a new attack, called Cloak & Co …",6
Efficient hardware malware detectors that are resilient to adversarial evasion,"Md Shohidul Islam, Khaled N Khasawneh, Nael Abu-Ghazaleh, Dmitry Ponomarev, Lei Yu",2021/3/29,Journal IEEE Transactions on Computers,"Hardware Malware Detectors (HMDs) have recently been proposed to make systems more malware-resistant. HMDs use hardware features to detect malware as a computational anomaly. Several aspects of the detector construction have been explored, leading to detectors with high accuracy. In this article, we explore whether malware developers can modify malware to avoid HMDs detection. We show that existing HMDs can be effectively reverse-engineered and subsequently evaded. Next, we explore whether retraining using evasive malware would help and show that retraining is limited. To address these limitations, we propose a new type of Resilient HMDs (RHMDs) that stochastically switch between different detectors. These detectors can be shown to be provably more difficult to reverse engineer based on recent results in probably approximately correct (PAC) learnability theory. We show that indeed such …",5
Defensive approximation: Enhancing cnns security through approximate computing,"Amira Guesmi, Ihsen Alouani, Khaled Khasawneh, Mouna Baklouti, Tarek Frikha, Mohamed Abid, Nael Abu-Ghazaleh",2020,Journal arXiv preprint arXiv:2006.07700,"In the past few years, an increasing number of machine-learning and deep learning structures, such as Convolutional Neural Networks (CNNs), have been applied to solving a wide range of real-life problems. However, these architectures are vulnerable to adversarial attacks: inputs crafted carefully to force the system output to a wrong label. Since machinelearning is being deployed in safety-critical and security-sensitive domains, such attacks may have catastrophic security and safety consequences. In this paper, we propose for the first time to use hardware-supported approximate computing to improve the robustness of machine learning classifiers. We show that our approximate computing implementation achieves robustness across a wide range of attack scenarios. Specifically, for black-box and grey-box attack scenarios, we show that successful adversarial attacks against the exact classifier have poor transferability to the approximate implementation. Surprisingly, the robustness advantages also apply to white-box attacks where the attacker has access to the internal implementation of the approximate classifier: in this case, we show that substantially higher levels of adversarial noise are needed to produce adversarial examples. We explain some of the possible reasons for this robustness through analysis of the internal operation of the approximate implementation. Furthermore, our approximate computing model maintains the same level in terms of classification accuracy, does not require retraining, and reduces resource utilization and energy consumption of the CNN. We conducted extensive experiments on a set of strong adversarial …",4
Repttack: Exploiting cloud schedulers to guide co-location attacks,"Chongzhou Fang, Han Wang, Najmeh Nazari, Behnam Omidi, Avesta Sasan, Khaled N Khasawneh, Setareh Rafatirad, Houman Homayoun",2021/10/2,Journal arXiv preprint arXiv:2110.00846,"Cloud computing paradigms have emerged as a major facility to store and process the massive data produced by various business units, public organizations, Internet-of-Things, and cyber-physical systems. To meet users' performance requirements while maximizing resource utilization to achieve cost-efficiency, cloud administrators leverage schedulers to orchestrate tasks to different physical nodes and allow applications from different users to share the same physical node. On the other hand, micro-architectural attacks can exploit the shared resources to compromise the confidentiality/integrity of a co-located victim application. Since co-location is an essential requirement for micro-architectural attacks, in this work, we investigate whether attackers can exploit the cloud schedulers to satisfy the co-location requirement. Our analysis shows that for cloud schedulers that allow users to submit application requirements, an attacker can carefully select the attacker's application requirements to influence the scheduler to co-locate it with a targeted victim application. We call such attack Replication Attack (Repttack). Our experimental results, in both a simulated cluster environment and a real cluster, show similar trends; a single attack instance can reach up to 50% co-location rate and with only 5 instances the co-location rate can reach up to 80%. Furthermore, we propose and evaluate a mitigation strategy that can help defend against Repttack. We believe that our results highlight the fact that schedulers in multi-user clusters need to be more carefully designed with security in mind, and the process of making scheduling decisions should involve as little …",3
Monotonic-hmds: Exploiting monotonic features to defend against evasive malware,"Md Shohidul Islam, Behnam Omidi, Khaled N Khasawneh",2021/4/7,Conference 2021 22nd International Symposium on Quality Electronic Design (ISQED),"Machine learning-based hardware malware detectors (HMDs) offer a potential game-changing advantage in defending systems against malware. However, HMDs suffer from adversarial attacks; they can be effectively reverse-engineered and subsequently be evaded, allowing malware to hide from detection. Adversarial evasion attacks requires adding benign features to the program execution to be able to evade detection. Against these attacks, in this paper, we propose Monotonic-HMDs, which are HMDs built using monotonic features to defend against adversarial evasion attacks. Specifically, Monotonic-HMDs are build using monotonic malicious features only. Thus, Monotonic-HMDs ensures that an adversary cannot evade the detection by simply adding benign features to the malware programs since they are not used in the Monotonic-HMD model. In addition, adding malicious features will only increase the …",1
Stochastic-hmds: Adversarial resilient hardware malware detectors through voltage over-scaling,"Md Shohidul Islam, Ihsen Alouani, Khaled N Khasawneh",2021/3/11,Journal arXiv preprint arXiv:2103.06936,"Machine learning-based hardware malware detectors (HMDs) offer a potential game changing advantage in defending systems against malware. However, HMDs suffer from adversarial attacks, can be effectively reverse-engineered and subsequently be evaded, allowing malware to hide from detection. We address this issue by proposing a novel HMDs (Stochastic-HMDs) through approximate computing, which makes HMDs' inference computation-stochastic, thereby making HMDs resilient against adversarial evasion attacks. Specifically, we propose to leverage voltage overscaling to induce stochastic computation in the HMDs model. We show that such a technique makes HMDs more resilient to both black-box adversarial attack scenarios, i.e., reverse-engineering and transferability. Our experimental results demonstrate that Stochastic-HMDs offer effective defense against adversarial attacks along with by-product power savings, without requiring any changes to the hardware/software nor to the HMDs' model, i.e., no retraining or fine tuning is needed. Moreover, based on recent results in probably approximately correct (PAC) learnability theory, we show that Stochastic-HMDs are provably more difficult to reverse engineer.",1
Malware detectors learn to work together,Michael Lee,2018/4,Journal Nature Electronics,"Software designed with malicious intent is termed malware. These programs are typically used to intercept sensitive data or to gain unauthorized control of a system and its resources. The detection of malware using software approaches is very effective but computationally expensive due to the complex algorithms employed. Khaled Khasawneh and Nael Abu-Ghazaleh from the University of California, Riverside, with colleagues from Binghamton University, Stanford University, and Intel Corporation have now devised a combined hardware and software approach to reduce the computational overhead by employing hardware detectors with simple machine learning algorithms. Hardware malware detectors (HMDs) operate on the basis that the computational footprint of malware differs from normal software. HMDs are able to sense anomalous low-level features at the hardware level by observing the mix of …",1
Ensemble Learning with an Architectural Sub-semantic Engine for Malware Detection,Khaled Khasawneh,2014,Institution State University of New York at Binghamton,"Malware threat is continuously increasing as attackers grow more motivated and sophisticated. Signature based analysis can no longer reliably find malware. Dynamic detection is also growing in complexity making it difficult to monitor all applications all the time. The work in this thesis builds on recent work that attempts to address the above situation using hardware support detection. This research builds on this basic detector in a number of ways. First, we explore the question of whether specialized detectors by malware family type can more effectively detect malware than a single general detector. Since such detectors are specialized to similar groups of malware, they can more effectively identify them. Second, having established that these specialized detectors are in fact more accurate, we explore how to combine multiple specialized detectors to improve overall malware detection and use it in the online …",1
Enhancing hardware malware detectors' security through voltage over-scaling,"Md Shohidul Islam, Ihsen Alouani, Khaled N Khasawneh",2021 5th ACM SIGARCH Workshop on Cognitive Architectures,"Description Computing systems are under continuous attacks by increasingly motivated and sophisticated adversaries. These attackers exploit vulnerabilities to compromise systems and deploy malware. Although significant effort continues to be directed at making systems more resilient to attacks, the number of exploitable vulnerabilities is overwhelming. While preventing compromise is difficult, signature based static analysis techniques can be easily bypassed using metamorphic/polymorphic malware or zero-day exploits since their signatures have not yet been encountered. On the other hand, dynamic detection techniques can detect unseen signatures since they monitor the behavior of the program. However, the complexity and difficulty of continuous dynamic monitoring have traditionally limited its use due to constrained resources. Against this backdrop, several research studies proposed using Hardware Malware Detectors (HMDs) to make the continuous dynamic monitoring resource-efficient through hardware support. Specifically, HMDs are machine learning classifiers that use low-level hardware features such as instructions traces, memory access patterns, etc. and classify malware as a computational anomaly. HMDs can offer a significant advantage to defend against malware attacks because they can be ‘always on’with small-to-no impact on performance. It appears that the industry started to show interest in using HMDs too; SnapDragon processor from Qualcomm appears to be using hardware features to detect malware, but the technical details are not published [4].As HMDs showed potential defense effectiveness, it is natural to expect that …","Computing systems are under continuous attacks by increasingly motivated and sophisticated adversaries. These attackers exploit vulnerabilities to compromise systems and deploy malware. Although significant effort continues to be directed at making systems more resilient to attacks, the number of exploitable vulnerabilities is overwhelming. While preventing compromise is difficult, signature based static analysis techniques can be easily bypassed using metamorphic/polymorphic malware or zero-day exploits since their signatures have not yet been encountered. On the other hand, dynamic detection techniques can detect unseen signatures since they monitor the behavior of the program. However, the complexity and difficulty of continuous dynamic monitoring have traditionally limited its use due to constrained resources. Against this backdrop, several research studies proposed using Hardware Malware Detectors (HMDs) to make the continuous dynamic monitoring resource-efficient through hardware support. Specifically, HMDs are machine learning classifiers that use low-level hardware features such as instructions traces, memory access patterns, etc. and classify malware as a computational anomaly. HMDs can offer a significant advantage to defend against malware attacks because they can be ‘always on’with small-to-no impact on performance. It appears that the industry started to show interest in using HMDs too; SnapDragon processor from Qualcomm appears to be using hardware features to detect malware, but the technical details are not published [4].",1
Secure and Energy-Efficient Proximity-Based Pairing for IoT Devices,"Yaqi He, Kai Zeng, Brian L Mark, Khaled N Khasawneh",2022/12/4,Conference 2022 IEEE Globecom Workshops (GC Wkshps),"Internet of Things (IoT) devices are largely resource-constrained embedded devices with limited user interface and battery capacity. As a consequence, bootstrapping a secure connection between an IoT device and a wireless network (e.g., WiFi network) becomes a challenging problem since the traditional Pre-Shared Key (PSK) based authentication cannot be directly applied. Proximity-based device authentication is a promising mechanism to enable secure pairing of an IoT device to a wireless network. However, existing solutions do not deliberately consider energy-efficiency nor the tradeoff between energy consumption and security strength in the pairing process. This paper fills this gap by enhancing the energy-efficiency and studying the tradeoff between energy consumption and security strength of an existing proximity-based IoT device authentication protocol, called Move2Auth. An optimization problem is …",
Defending with Errors: Approximate Computing for Robustness of Deep Neural Networks,"Amira Guesmi, Ihsen Alouani, Khaled N Khasawneh, Mouna Baklouti, Tarek Frikha, Mohamed Abid, Nael Abu-Ghazaleh",2022/11/2,Journal arXiv preprint arXiv:2211.01182,"Machine-learning architectures, such as Convolutional Neural Networks (CNNs) are vulnerable to adversarial attacks: inputs crafted carefully to force the system output to a wrong label. Since machine-learning is being deployed in safety-critical and security-sensitive domains, such attacks may have catastrophic security and safety consequences. In this paper, we propose for the first time to use hardware-supported approximate computing to improve the robustness of machine-learning classifiers. We show that successful adversarial attacks against the exact classifier have poor transferability to the approximate implementation. Surprisingly, the robustness advantages also apply to white-box attacks where the attacker has unrestricted access to the approximate classifier implementation: in this case, we show that substantially higher levels of adversarial noise are needed to produce adversarial examples. Furthermore, our approximate computing model maintains the same level in terms of classification accuracy, does not require retraining, and reduces resource utilization and energy consumption of the CNN. We conducted extensive experiments on a set of strong adversarial attacks; We empirically show that the proposed implementation increases the robustness of a LeNet-5, Alexnet and VGG-11 CNNs considerably with up to 50% by-product saving in energy consumption due to the simpler nature of the approximate logic.",
ROOM: Adversarial Machine Learning Attacks Under Real-Time Constraints,"Amira Guesmi, Khaled N Khasawneh, Nael Abu-Ghazaleh, Ihsen Alouani",2022/7/18,Conference 2022 International Joint Conference on Neural Networks (IJCNN),"Advances in deep-learning have enabled a wide range of promising applications. However, these systems are vulnerable to adversarial attacks; adversarially crafted pertur-bations to their inputs could cause them to misclassify. Most state-of-the-art adversarial attack generation algorithms focus primarily on controlling the noise magnitude to make it undetectable. The execution time is a secondary consideration for these attacks and the underlying assumption is that there are no time constraints. However, just-in-time adversarial attacks where an attacker opportunistically generates adversarial examples on-the-fly represent an even more critical threat, especially against real-time applications. Therefore, this paper introduces a new problem: how to systematically generate adversarial noise under real-time constraints? Understanding this problem improves our understanding of the threat these attacks pose to real …",
Characterization of AES Implementations on Microprocessor-based IoT Devices,"Sunanda Roy, Angelos Stavrou, Brian L Mark, Kai Zeng, Sai Manoj PD, Khaled N Khasawneh",2022/4/10,Conference 2022 IEEE Wireless Communications and Networking Conference (WCNC),"The increased proliferation of IoT devices and the emergence of 5G networks have necessitated increased security of data storage and communication in such connected devices. Thus, cryptography is used in IoT environments to provide secrecy and integrity to the data as well as both authentication and anonymity to the communications across the IoT network. However, IoT devices are resource-constrained devices; have limited memory, network bandwidth, power, and compute units. Since most of the existing cryptographic algorithms were designed to run on resource powerful devices (e.g., desktops or servers), many of these algorithms may not fit into resource-constrained devices. Therefore, in this work, we present a practical performance analysis of different implementations of the Advanced Encryption Standard (AES), which is the most widely used symmetric-key cryptosystem in the IoT environment …",
Lower Voltage for Higher Security: Using Voltage Overscaling to Secure Deep Neural Networks,"Shohidul Islam, Ihsen Alouani, Khaled N Khasawneh",2021/11/1,Conference 2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD),"Deep neural networks (DNNs) are shown to be vulnerable to adversarial attacks—carefully crafted additive noise that undermines DNNs integrity. Previously proposed defenses against these attacks require substantial overheads, making it challenging to deploy these solutions in power and computational resource-constrained devices, such as embedded systems and the Edge. In this paper, we explore the use of voltage over-scaling (VOS) as a lightweight defense against adversarial attacks. Specifically, we exploit the stochastic timing violations of VOS to implement a moving-target defense for DNNs. Our experimental results demonstrate that VOS guarantees effective defense against different attack methods, does not require any software/hardware modifications, and offers a by-product reduction in power consumption.",
Energy-Efficient and Adversarially Robust Machine Learning with Selective Dynamic Band Filtering,"Neha Nagarkar, Khaled Khasawneh, Setareh Rafatirad, Avesta Sasan, Houman Homayoun, Sai Manoj Pudukotai Dinakarrao",2021/6/22,Book Proceedings of the 2021 on Great Lakes Symposium on VLSI,"The popularity of neural networks is increasing day by day. Traditional machine learning solutions, such as image recognition, object detection, are being replaced by deep learning solutions because of their vigorous performance in computer vision. Despite their superior performance in these applications, neural networks are prone to adversarial attacks. The adversarial attack is the process of using adversarial samples as an input to the neural network which causes the network to misclassify, eventually degrading overall performance. Thus, it becomes very important to maintain their robustness by identifying, analyzing, and eliminating the cause of their vulnerability. In this paper, we introduce a technique to determine the most sensitive frequency band of input samples and filter the noise from this band to shield the network against adversarial attacks. First, we decompose the input sample into four different …",
Stochastic-HMDs: Adversarial Resilient Hardware Malware Detectors through Voltage Over-scaling,"Md Shohidul Islam, Ihsen Alouani, Khaled N Khasawneh",2021/3,Journal arXiv e-prints,"Machine learning-based hardware malware detectors (HMDs) offer a potential game changing advantage in defending systems against malware. However, HMDs suffer from adversarial attacks, can be effectively reverse-engineered and subsequently be evaded, allowing malware to hide from detection. We address this issue by proposing a novel HMDs (Stochastic-HMDs) through approximate computing, which makes HMDs' inference computation-stochastic, thereby making HMDs resilient against adversarial evasion attacks. Specifically, we propose to leverage voltage overscaling to induce stochastic computation in the HMDs model. We show that such a technique makes HMDs more resilient to both black-box adversarial attack scenarios, ie, reverse-engineering and transferability. Our experimental results demonstrate that Stochastic-HMDs offer effective defense against adversarial attacks along with by …",
SPECCFI: Mitigating Spectre Attacks using CFI Informed Speculation,"Esmaeil Mohammadian Koruyeh, Shirin Haji Amin Shirazi, Khaled N Khasawneh, Chengyu Song, Nael Abu-Ghazaleh",2019/6,Journal arXiv e-prints,"Spectre attacks and their many subsequent variants are a new vulnerability class affecting modern CPUs. The attacks rely on the ability to misguide speculative execution, generally by exploiting the branch prediction structures, to execute a vulnerable code sequence speculatively. In this paper, we propose to use Control-Flow Integrity (CFI), a security technique used to stop control-flow hijacking attacks, on the committed path, to prevent speculative control-flow from being hijacked to launch the most dangerous variants of the Spectre attacks (Spectre-BTB and Spectre-RSB). Specifically, CFI attempts to constrain the possible targets of an indirect branch to a set of legal targets defined by a pre-calculated control-flow graph (CFG). As CFI is being adopted by commodity software (eg, Windows and Android) and commodity hardware (eg, Intel's CET and ARM's BTI), the CFI information becomes readily available …",
Architectural Support for Securing Systems Against Software Vulnerabilities,Khaled Nofan Khasawneh,2019,"Institution University of California, Riverside","Cyberattacks are the fastest growing crime in the US, and they are increasing in size, sophistication, and cost. These attacks use vulnerabilities to compromise systems to leak Information (Yahoo 2016, Marriott 2018, and Facebook 2019), steal identity information (Equifax 2017), or even effecting politics (by attacking the governmental election process). Traditionally, security researchers and practitioners have viewed security as a software problem-originating in software and to be solved by software. Recently, the Spectre and Meltdown attacks have shown that hardware should also be considered when evaluating the system security. Conversely, because many aspects of security are computationally expensive, hardware can play a role in promoting software security through computational support as well as the development of new abstractions that promote security. Under this general umbrella, the research in this …",
Spectre Returns! Speculation Attacks using the Return Stack Buffer,"Esmaeil Mohammadian Koruyeh, Khaled Khasawneh, Chengyu Song, Nael Abu-Ghazaleh",2018/7,Journal arXiv e-prints,"The recent Spectre attacks exploit speculative execution, a pervasively used feature of modern microprocessors, to allow the exfiltration of sensitive data across protection boundaries. In this paper, we introduce a new Spectre-class attack that we call SpectreRSB. In particular, rather than exploiting the branch predictor unit, SpectreRSB exploits the return stack buffer (RSB), a common predictor structure in modern CPUs used to predict return addresses. We show that both local attacks (within the same process such as Spectre 1) and attacks on SGX are possible by constructing proof of concept attacks. We also analyze additional types of the attack on the kernel or across address spaces and show that under some practical and widely used conditions they are possible. Importantly, none of the known defenses including Retpoline and Intel's microcode patches stop all SpectreRSB attacks. We believe that future …",
Connecting the Dots: Privacy Leakage via Write-Access Patterns to the Main Memory,"Khaled N Khasawneh, Meltem Ozsoy, Caleb Donovick, Nael Abu-Ghazaleh, Dmitry Ponomarev",2018,"Description Hardware-based malware detectors (HMDs) are a promising new approach to defend against malware. HMDs collect low-level architectural features and use them to classify malware from normal programs. With simple hardware support, HMDs can be always on, operating as a first line of defense that prioritizes the application of more expensive and more accurate software-detector. In this paper, we explore improving the accuracy of HMDs, to improve detection, and reduce overhead. First, we use specialized detectors targeted towards a specific type of malware. Next, we use ensemble learning techniques to improve accuracy by combining detectors. We explore detectors based on logistic regression (LR) and neural networks (NN). The proposed detectors reduce the false-positive rate by more than half compared to using a single detector, while increasing their sensitivity. We develop metrics to estimate detection overhead; the proposed detectors achieve more than 16.6 x overhead reduction during online detection compared to a software-only detector, with an 8x improvement in relative detection time. NN detectors outperform LR detectors in accuracy, overhead (by 40%), and time-to-detection of the hardware component (by 5x). Finally, we characterize the hardware complexity by extending an open-core and synthesizing it on an FPGA platform, showing that the overhead is minimal.","Hardware-based malware detectors (HMDs) are a promising new approach to defend against malware. HMDs collect low-level architectural features and use them to classify malware from normal programs. With simple hardware support, HMDs can be always on, operating as a first line of defense that prioritizes the application of more expensive and more accurate software-detector. In this paper, we explore improving the accuracy of HMDs, to improve detection, and reduce overhead. First, we use specialized detectors targeted towards a specific type of malware. Next, we use ensemble learning techniques to improve accuracy by combining detectors. We explore detectors based on logistic regression (LR) and neural networks (NN). The proposed detectors reduce the false-positive rate by more than half compared to using a single detector, while increasing their sensitivity. We develop metrics to estimate detection overhead; the proposed detectors achieve more than 16.6 x overhead reduction during online detection compared to a software-only detector, with an 8x improvement in relative detection time. NN detectors outperform LR detectors in accuracy, overhead (by 40%), and time-to-detection of the hardware component (by 5x). Finally, we characterize the hardware complexity by extending an open-core and synthesizing it on an FPGA platform, showing that the overhead is minimal.",
HeteroScore: Evaluating and Mitigating Cloud Security Threats Brought by Heterogeneity,"Chongzhou Fang, Najmeh Nazari, Behnam Omidi, Han Wang, Aditya Puri, Manish Arora, Setareh Rafatirad, Houman Homayoun, Khaled N Khasawneh","Cloud computing has emerged as a critical part of commercial computing infrastructure due to its computing power, data storage capabilities, scalability, software/API integration, and convenient billing features. At the early stage of cloud computing, the majority of clouds are homogeneous, ie, most machines are identical. It has been proven that heterogeneity in the cloud, where a variety of machine configurations exist, provides higher performance and power efficiency for applications. This is because heterogeneity enables applications to run in more suitable hardware/software environments. In recent years, the adoption of heterogeneous cloud has increased with the integration of a variety of hardware into cloud systems to serve the requirements of increasingly diversified user applications.At the same time, the emergence of security threats, such as micro-architectural attacks, is becoming a more critical problem for cloud users and providers. It has been demonstrated (eg, Repttack and Cloak & Co-locate) that the prerequisite of micro-architectural attacks, the co-location of attack and victim instances, is easier to achieve in the heterogeneous cloud. This also means that the ease of attack is not just related to the heterogeneity of the cloud but increases with the degree of heterogeneity. However, there is a lack of numerical metrics to define, quantify or compare the heterogeneity of one cloud environment with another. In this paper, we propose a novel metric called Heterogeneity Score (HeteroScore), which quantitatively evaluates the heterogeneity of a cluster. We demonstrate that HeteroScore is closely connected to security against co-location …","Scholar articles HeteroScore: Evaluating and Mitigating Cloud Security Threats Brought by HeterogeneityC Fang, N Nazari, B Omidi, H Wang, A Puri, M Arora…All 2 versions ","Cloud computing has emerged as a critical part of commercial computing infrastructure due to its computing power, data storage capabilities, scalability, software/API integration, and convenient billing features. At the early stage of cloud computing, the majority of clouds are homogeneous, ie, most machines are identical. It has been proven that heterogeneity in the cloud, where a variety of machine configurations exist, provides higher performance and power efficiency for applications. This is because heterogeneity enables applications to run in more suitable hardware/software environments. In recent years, the adoption of heterogeneous cloud has increased with the integration of a variety of hardware into cloud systems to serve the requirements of increasingly diversified user applications.",
2021 International Symposium on Secure and Private Execution Environment Design (SEED)| 978-1-6654-2025-9/21/$31.00© 2021 IEEE| DOI: 10.1109/SEED51797. 2021.00034,"Arie Aharon, Ismail Akturk, Fitsum Assamnew Andargie, Miguel A Arroyo, Todd Austin, Amro Awad, Lauren Biernacki, Kunbei Cai, Dror Caspi, Baruch Chaikin, Rui Chang, Yuezhi Che, Yueqiang Cheng, Siddhartha Chhabra, Zamshed I Chowdhury, Md Hafizul Islam Chowdhuryy, Husrev Cilasun, Scott Constable, Jasmin Cosic, Jedidiah R Crandall, Brandon D'Agostino, Deeksha Dangwal, Meron Zerihun Demissie, Matthias Drodt, Michael Eckel, Rickard Ewetz, Plato Gebremedhin, Yanan Guo, Zecheng He, Houman Homayoun, Guangyuan Hu, Barry Huntley, Ibn Ziad, Mohamed Tarek, Malith Jayaweera, David Kaeli, Sanjay Kariyappa, Stefan Katzenbeisser, Stefanos Kaxiras, Vasileios P Kemerlis, Omer Khan, Khaled N Khasawneh, Christoph Krauß, Don Kuzhiyelil, Ruby B Lee, Gang Liu, Evgeny Manzhosov, Hosein Mohammadi Makrani, Dominic P Mulligan, Galane Basha Namomsa, Najmeh Nazari, Jason Oberg, Ido Ouziel, Sarp Ozdemir, Thomas Peterson, Gustavo Petri, Jean-Jacques Pitrolle, Dmitry Ponomarev, Aravind Prakash, Moinuddin Qureshi, Setareh Rafatirad, Brandon Reagen, Salonik Resch, Alberto Ros, Ravi Sahita, Gururaj Saileshwar, Christos Sakalis, Sachin S Sapatnekar, Rutvik Saptarshi, Avesta Sasan, Hossein Sayadi, Vincent Scarlata, Simha Sethumadhavan",Presents an index of the authors whose articles are published in the conference proceedings record.,"Scholar articles 2021 International Symposium on Secure and Private Execution Environment Design (SEED)| 978-1-6654-2025-9/21/$31.00© 2021 IEEE| DOI: 10.1109/SEED51797. 2021.00034A Aharon, I Akturk, FA Andargie, MA Arroyo, T Austin…All 2 versions ",Presents an index of the authors whose articles are published in the conference proceedings record.,
Defensive Approximation: Securing CNNs using Approximate Computing Extended Abstract,"Amira Guesmi, Ihsen Alouani, Khaled Khasawneh, Mouna Baklouti, Tarek Frikha, Mohamed Abid, Nael Abu-Ghazaleh","In the past few years, deep learning structures, such as Convolutional Neural Networks (CNNs), have been used in a wide range of real-life problems [4, 3, 2]. While providing breakthrough improvements in classification performance, these architectures are vulnerable to adversarial machine learning (AML) attacks: carefully-crafted humanly-imperceptible perturbations to the inputs that cause the system to output a wrong label to disrupt the system or otherwise provide the attacker with an advantage. In safety-critical domains, AML can have catastrophic consequences. For example, AML attacks threaten intelligent transportation systems where deep neural networks are a critical component of environment perception used in controlling autonomous vehicles leading to potential crashes and loss of life. Several defenses against adversarial attacks have been proposed, but subsequent, more sophisticated attacks continue to evolve and challenge these defenses. Often defenses require expensive retraining and/or substantial overheads, increasing the cost and reducing the performance of CNNs. As attacks keep getting more sophisticated, the cost of defenses also increases. Our proposed defense, Defensive Approximation (DA), leverages for the first time approximate computing (AC) to achieve quantifiable improvement in the resilience of CNNs to AML attacks. We observe this advantage for all adversarial example generation algorithms we study and under a range of attack scenarios, without harming classification performance. The defense does not require retraining, and by rooting the defense in the architecture, we achieve robustness while …","Scholar articles Defensive Approximation: Securing CNNs using Approximate Computing Extended AbstractA Guesmi, I Alouani, K Khasawneh, M Baklouti…Related articles All 3 versions ","In the past few years, deep learning structures, such as Convolutional Neural Networks (CNNs), have been used in a wide range of real-life problems [4, 3, 2]. While providing breakthrough improvements in classification performance, these architectures are vulnerable to adversarial machine learning (AML) attacks: carefully-crafted humanly-imperceptible perturbations to the inputs that cause the system to output a wrong label to disrupt the system or otherwise provide the attacker with an advantage. In safety-critical domains, AML can have catastrophic consequences. For example, AML attacks threaten intelligent transportation systems where deep neural networks are a critical component of environment perception used in controlling autonomous vehicles leading to potential crashes and loss of life. Several defenses against adversarial attacks have been proposed, but subsequent, more sophisticated attacks continue to evolve and challenge these defenses. Often defenses require expensive retraining and/or substantial overheads, increasing the cost and reducing the performance of CNNs. As attacks keep getting more sophisticated, the cost of defenses also increases. Our proposed defense, Defensive Approximation (DA), leverages for the first time approximate computing (AC) to achieve quantifiable improvement in the resilience of CNNs to AML attacks. We observe this advantage for all adversarial example generation algorithms we study and under a range of attack scenarios, without harming classification performance. The defense does not require retraining, and by rooting the defense in the architecture, we achieve robustness while …",
