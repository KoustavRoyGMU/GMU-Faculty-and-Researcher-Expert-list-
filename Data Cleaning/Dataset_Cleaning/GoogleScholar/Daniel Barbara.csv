titles,authors,date,source,descriptions,citations
Sleepers and workaholics: Caching strategies in mobile environments,"Daniel Barbara, Tomasz Imieliński",1994/5/24,Journal ACM Sigmod Record,"In the mobile wireless computing environment of the future a large number of users equipped with low powered palm-top machines will query databases over the wireless communication channels. Palmtop based units will often be disconnected for prolonged periods of time due to the battery power saving measures; palmtops will also frequencly relocate between different cells and connect to different data servers at different times. Caching of frequently accessed data items will be an important technique that will reduce contention on the narrow bandwidth wireless channel. However, cache invalidation strategies will be severely affected by the disconnection and mobility of the clients. The server may no longer know which clients are currently residing under its cell and which of them are   currently on. We propose a taxonomy of different cache invalidation strategies and study the impact of client's disconnection …",909
How to assign votes in a distributed system,"Hector Garcia-Molina, Daniel Barbara",1985/10/1,Journal Journal of the ACM (JACM),"In a distributed system, one strategy for achieving mutual exclusion of groups of nodes without communication is to assign to each node a number of votes. Only a group with a majority of votes can execute the critical operations, and mutual exclusion is achieved because at any given time there is at most one such group. A second strategy, which appears to be similar to votes, is to define a priori a set of groups that intersect each other. Any group of nodes that finds itself in this set can perform the restricted operations. In this paper, both of these strategies are studied in detail and it is shown that they are not equivalent in general (although they are in some cases). In doing so, a number of other interesting properties are proved. These properties will be of use to a system designer who is selecting a vote assignment or a set of groups for a specific application.",822
Mobile computing and databases-a survey,Daniel Barbará,1999/1,Journal IEEE transactions on Knowledge and Data Engineering,"The emergence of powerful portable computers, along with advances in wireless communication technologies, has made mobile computing a reality. Among the applications that are finding their way to the market of mobile computing-those that involve data management-hold a prominent position. In the past few years, there has been a tremendous surge of research in the area of data management in mobile computing. This research has produced interesting results in areas such as data dissemination over limited bandwidth channels, location-dependent querying of data, and advanced interfaces for mobile computers. This paper is an effort to survey these techniques and to classify this research in a few broad areas.",679
The management of probabilistic data,"Daniel Barbará, Hector Garcia-Molina, Daryl Porter",1992/10,Journal IEEE Transactions on knowledge and data engineering,"It is often desirable to represent in a database, entities whose properties cannot be deterministically classified. The authors develop a data model that includes probabilities associated with the values of the attributes. The notion of missing probabilities is introduced for partially specified probability distributions. This model offers a richer descriptive language allowing the database to more accurately reflect the uncertain real world. Probabilistic analogs to the basic relational operators are defined and their correctness is studied. A set of operators that have no counterpart in conventional relational systems is presented.< >",643
On-line lda: Adaptive topic models for mining text streams with applications to topic detection and tracking,"Loulwah AlSumait, Daniel Barbará, Carlotta Domeniconi",2008/12/15,Conference 2008 eighth IEEE international conference on data mining,"This paper presents Online Topic Model (OLDA), a topic model that automatically captures the thematic patterns and identifies emerging topics of text streams and their changes over time. Our approach allows the topic modeling framework, specifically the Latent Dirichlet Allocation (LDA) model, to work in an online fashion such that it incrementally builds an up-to-date model (mixture of topics per document and mixture of words per topic) when a new document (or a set of documents) appears. A solution based on the Empirical Bayes method is proposed. The idea is to incrementally update the current model according to the information inferred from the new stream of data with no need to access previous data. The dynamics of the proposed approach also provide an efficient mean to track the topics over time and detect the emerging topics in real time. Our method is evaluated both qualitatively and quantitatively …",613
COOLCAT: an entropy-based algorithm for categorical clustering,"Daniel Barbará, Yi Li, Julia Couto",2002/11/4,Book Proceedings of the eleventh international conference on Information and knowledge management,"In this paper we explore the connection between clustering categorical data and entropy: clusters of similar poi lower entropy than those of dissimilar ones. We use this connection to design an incremental heuristic algorithm, COOLCAT, which is capable of efficiently clustering large data sets of records with categorical attributes, and data streams. In contrast with other categorical clustering algorithms published in the past, COOLCAT's clustering results are very stable for different sample sizes and parameter settings. Also, the criteria for clustering is a very intuitive one, since it is deeply rooted on the well-known notion of entropy. Most importantly, COOLCAT is well equipped to deal with clustering of data streams(continuously arriving streams of data point) since it is an incremental algorithm capable of clustering new points without having to look at every point that has been clustered so far. We demonstrate the …",533
Data caching issues in an information retrieval system,"Rafael Alonso, Daniel Barbara, Hector Garcia-Molina",1990/9/1,Journal ACM Transactions on Database Systems (TODS),"Currently, a variety of information retrieval systems are available to potential users.… While in many cases these systems are accessed from personal computers, typically no advantage is taken of the computing resources of those machines (such as local processing and storage). In this paper we explore the possibility of using the user's local storage capabilities to cache data at the user's site. This would improve the response time of user queries albeit at the cost of incurring the overhead required in maintaining multiple copies. In order to reduce this overhead it may be appropriate to allow copies to diverge in a controlled fashion.… Thus, we introduce the notion of quasi-copies, which embodies the ideas sketched above. We also define the types of deviations that seem useful, and discuss the available implementation strategies.—From the Authors' Abstract",502
Detecting novel network intrusions using bayes estimators,"Daniel Barbara, Ningning Wu, Sushil Jajodia",2001/4/5,Book Proceedings of the 2001 SIAM International Conference on Data Mining,1 Introduction,479
The New Jersey data reduction report,"Daniel Barbara, William DuMouchel, Christos Faloutsos, Peter J.  Haas, Joseph M.  Hellerstein, Yannis E.  Ioannidis, HV Jagadish, Theodore Johnson, Raymond T.  Ng, Viswanath Poosala, Kenneth A.  Ross, Kenneth C.  Sevcik",1997/12/20,Journal IEEE Data Eng. Bull.,,372
ADAM: a testbed for exploring the use of data mining in intrusion detection,"Daniel Barbará, Julia Couto, Sushil Jajodia, Ningning Wu",2001/12/1,Journal ACM Sigmod Record,"Intrusion detection systems have traditionally been based on the characterization of an attack and the tracking of the activity on the system to see if it matches that characterization. Recently, new intrusion detection systems based on data mining are making their appearance in the field. This paper describes the design and experiences with the ADAM (Audit Data Analysis and Mining) system, which we use as a testbed to study how useful data mining techniques can be in intrusion detection.",331
ADAM: Detecting intrusions by data mining,Daniel Barbara,2001,"Journal Proc. 2001 IEEE Workshop Information Assurance and Security, June",,280
Requirements for clustering data streams,Daniel Barbará,2002/1/1,Journal ACM sIGKDD Explorations Newsletter,"Scientific and industrial examples of data streams abound in astronomy, telecommunication operations, banking and stock-market applications, e-commerce and other fields. A challenge imposed by continuously arriving data streams is to analyze them and to modify the models that explain them as new data arrives. In this paper, we analyze the requirements needed for clustering data streams. We review some of the latest algorithms in the literature and assess if they meet these requirements.",249
Preserving QoS of e-commerce sites through self-tuning: A performance model approach,"Daniel A Menascé, Daniel Barbará, Ronald Dodge",2001/10/14,Book Proceedings of the 3rd ACM conference on Electronic Commerce,"The Quality of Service (QoS) of e-commerce sites plays a crucial role in attracting and retaining customers. The workload experienced by these sites tends to vary in a very dynamic way. The complexity of the sites combined with the large short-terms variations of the workload calls for automated methods for site configuration. This paper describes a method for dynamically monitoring and tuning e-commerce sites so that desired QoS levels are attained. Our approach uses hill climbing techniques combined with analytic queuing models to guide the search for the best combination of configuration parameters. We validate our approach in an experimental setting by comparing the QoS levels of a TPC-W e-commerce site with and without control. We showed that under increasing loads, the controlled system meets its QoS goals, while the uncontrolled site fails to do so.",244
Using the fractal dimension to cluster datasets,"Daniel Barbará, Ping Chen",2000/8/1,Book Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining,"Clustering is a widely used knowledge discovery technique. It helps uncovering structures in data that were not previously known. The clustering of large data sets has received a lot of atten tion in recent years, how ever, clustering is a still a challenging task since many published algorithms fail to do well in scaling with the size of the data set and the number of dimensions that describe the points, or in finding arbitrary shapes of clusters, or dealing effectively with the presence of noise. In this paper, we presen ta new clustering algorithm, based in the fractal properties of the data sets. The new algorithm which we callFractalClustering (FC) places poin tsincrementally in the cluster for whic h the change in the fractal dimension after adding the point is the least. This is a very natural way of clustering points, since points in the same cluster have a great degree of selfsimilarity among them (and m uch lessself-similarity …",234
Topic significance ranking of LDA generative models,"Loulwah AlSumait, Daniel Barbará, James Gentle, Carlotta Domeniconi",2009,"Conference Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2009, Bled, Slovenia, September 7-11, 2009, Proceedings, Part I 20","Topic models, like Latent Dirichlet Allocation (LDA), have been recently used to automatically generate text corpora topics, and to subdivide the corpus words among those topics. However, not all the estimated topics are of equal importance or correspond to genuine themes of the domain. Some of the topics can be a collection of irrelevant words, or represent insignificant themes. Current approaches to topic modeling perform manual examination to find meaningful topics. This paper presents the first automated unsupervised analysis of LDA models to identify junk topics from legitimate ones, and to rank the topic significance. Basically, the distance between a topic distribution and three definitions of “junk distribution” is computed using a variety of measures, from which an expressive figure of the topic significance is implemented using 4-phase Weighted Combination approach. Our experiments on …",215
Trie structure based method and apparatus for indexing and searching handwritten databases with dynamic search sequencing,"Walid Aref, Daniel Barbara",1998/6/16,Patent office US,A method of searching for one of a plurality of objects that matches an input sequence of handwritten objects is provided. The objects are modeled by concatenating members of a set of component objects. A Trie structure representing the plurality of objects is generated. Component objects of each object are assigned to the elements of respective nodes of the Trie structure. A respective hidden Markov model (HMM) is associated with each element of each non-leaf node. The HMMs represent the respective component object of the element. A maximum probability of any HMM accepting any of the set of component objects is estimated. The root node of the Trie structure is selected. A plurality of elements of the selected node are selected. A plurality of segments of the input sequence are applied to respective HMMs associated with the selected elements to generate respective acceptance values.,198
Method and apparatus for similarity matching of handwritten data objects,"Daniel Barbara, Ibrahim Kamel",1998/1/20,Patent office US,"Apparatus for determining a distance between two handwritten strings in a database. A processor extracts global features from each string. The processor divides the string into strokes, and identifies a plurality of bounding boxes. Each box contains a different stroke. The processor extracts global features from the suing, including:(1) a number of points;(2) a maximum angle between a first point in the string and a corner of the tallest bounding box;(3) a number of positive inversions; and (4) a number of negative inversions. The apparatus calculates the distance between the strings based on all of the numbers of points, maximum angles, numbers of positive inversions and numbers of negative inversions. A fixed query tree index may be formed. The tree has leaves and internal nodes belonging to multiple levels. A different key is associated with each level. Each key is a handwritten string. Each string is associated …",185
The reliability of voting mechanisms,"Daniel Barbara, Hector Garcia-Molina",1987/10/1,Journal IEEE Transactions on Computers,"In a faulty distributed system, voting is commonly used to achieve mutual exclusion among groups of isolated nodes. Each node is assigned a number of votes, and any group with a majority of votes can perform the critical operations. Vote assignments can have a significant impact on system reliability. In this paper we address the problem of selecting vote assignments in order to maximize the probability that the critical operations can be performed at a given time by some group of nodes. We suggest simple heuristics to assign votes, and show that they give good results in most cases. We also study three particular homogeneous topologies (fully connected, Ethernet, and ring networks), and derive analytical expressions for system reliability. These expressions provide useful insights into the reliability provided by voting mechanisms.",185
INCAs: Managing dynamic workflows in distributed environments,"Daniel Barbara, Sharad Mehrotra, Marek Rusinkiewicz",1996/1/1,Journal Journal of Database Management (JDM),"A workflow is a long-duration multi-step activity. In this paper we are interested in workflows that execute under the control of various processing stations that may be located at different nodes of a distributed system. The stations may be autonomous and only partially automated. We present the design and a proposed implementation of a new model for workflow management that is based on a concept of an Information Carriers (INCA). Workflow computations are carried out as interactions between INCAs and the processing stations with the locus of control of a computation migrating with the workflow. The model presented is modular in the sense that modification of a sub-activities of the workflow does not necessarily require changes to the workflow specification. Furthermore, the model preserves the autonomy of the processing stations and does not require them to change the means they use to process the …",181
System for maintaining data coherency in cache memory by periodically broadcasting a single invalidation report from server to clients,"Daniel Barbara, Tomasz Imielinski",1998/1/6,Patent office US,"A method and system are provided for maintaining coherency between a server processor and a client processor that has a cache memory. The server may, for example, be a fixed location mobile unit support station. The client may, for example, be a palmtop computer. The server stores a plurality of data values, and the client stores a subset of the plurality of data values in the cache. The server processor periodically broadcasts invalidation reports to the client processor. Each respective invalidation report includes information identifying which, if any, of the plurality of data values have been updated within a predetermined period of time before the server processor broadcasts the respective invalidation report. The client processor determines, based on the invalidation reports, whether a selected data value in the cache memory of the client processor has been updated in the server processor since the selected data …",170
Applications of data mining in computer security,"Daniel Barbará, Sushil Jajodia",2002/5/31,Volume 6,"Data mining is becoming a pervasive technology in activities as diverse as using historical data to predict the success of a marketing campaign, looking for patterns in financial transactions to discover illegal activities or analyzing genome sequences. From this perspective, it was just a matter of time for the discipline to reach the important area of computer security. Applications Of Data Mining In Computer Security presents a collection of research efforts on the use of data mining in computer security. Data mining has been loosely defined as the process of extracting information from large amounts of data. In the context of security, the information we are seeking is the knowledge of whether a security breach has been experienced, and if the answer is yes, who is the perpetrator. This information could be collected in the context of discovering intrusions that aim to breach the privacy of services, data in a computer system or alternatively, in the context of discovering evidence left in a computer system as part of criminal activity. Applications Of Data Mining In Computer Security concentrates heavily on the use of data mining in the area of intrusion detection. The reason for this is twofold. First, the volume of data dealing with both network and host activity is so large that it makes it an ideal candidate for using data mining techniques. Second, intrusion detection is an extremely critical activity. This book also addresses the application of data mining to computer forensics. This is a crucial area that seeks to address the needs of law enforcement in analyzing the digital evidence. Applications Of Data Mining In Computer Security is designed to meet the needs …",167
Quasi-cubes: Exploiting approximations in multidimensional databases,"Daniel Barbará, Mark Sullivan",1997/9/1,Journal ACM SIGMOD Record,"A data cube is a popular organization for summary data. A cube is simply a multidimensional structure that contains at each point an aggregate value, i.e., the result of applying an aggregate function to an underlying relation. In practical situations, cubes can require a large amount of storage. The typical approach to reducing storage cost is to materialize parts of the cube on demand. Unfortunately, this lazy evaluation can be a time-consuming operation.",124
Increasing availability under mutual exclusion constraints with dynamic vote reassignment,"Daniel Barbara, Hector Garcia-Molina, Annemarie Spauster",1989/11/1,Journal ACM Transactions on Computer Systems (TOCS),"Voting is used commonly to enforce mutual exclusion in distributed systems. Each node is assigned a number of votes, and only the group with a majority of votes is allowed to perform a restricted operation. This paper describes techniques for dynamically reassigning votes upon node or link failure, in an attempt to make the system more resilient to future failures. We focus on autonomous methods for achieving this, that is, methods that allow the nodes to make independent choices about changing their votes and picking new vote values, rather than group consensus techniques that require tight coordination among the remaining nodes. Protocols are given which allow nodes to install new vote values while still maintaining mutual exclusion requirements. The lemmas and theorems to validate the protocols are presented. A simple example shows how to apply the method to a database object-locking scheme; the …",123
Mutual exclusion in partitioned distributed systems,"Daniel Barbara, Hector Garcia-Molina",1986/6,Journal Distributed Computing,"A network partition can break a distributed computing system into groups of isolated nodes. When this occurs, a mutual exclusion mechanism may be required to ensure that isolated groups do not concurrently perform conflicting operations. We study and formalize these mechanisms in three basic scenarios: where there is a single conflicting type of action; where there are two conflicting types, but operations of the same type do not conflict; and where there are two conflicting types, but operations of one type do not conflict among themselves. For each scenario, we present applications that require mutual exclusion (e.g., name servers, termination protocols, concurrency control). In each case, we also present mutual exclusion mechanisms that are more general and that may provide higher reliability than the voting mechanisms that have been proposed as solutions to this problem.",116
Detecting outliers using transduction and statistical testing,"Daniel Barbará, Carlotta Domeniconi, James P Rogers",2006/8/20,Book Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining,"Outlier detection can uncover malicious behavior in fields like intrusion detection and fraud analysis. Although there has been a significant amount of work in outlier detection, most of the algorithms proposed in the literature are based on a particular definition of outliers (e.g., density-based), and use ad-hoc thresholds to detect them. In this paper we present a novel technique to detect outliers with respect to an existing clustering model. However, the test can also be successfully utilized to recognize outliers when the clustering information is not available. Our method is based on Transductive Confidence Machines, which have been previously proposed as a mechanism to provide individual confidence measures on classification decisions. The test uses hypothesis testing to prove or disprove whether a point is fit to be in each of the clusters of the model. We experimentally demonstrate that the test is highly robust …",115
Certification reports: supporting transactions in wireless systems,Daniel Barbará,1997/5/27,Conference Proceedings of 17th International Conference on Distributed Computing Systems,"The emergence of small portable computers and the advances in wireless networking have made mobile computing today a reality. Information systems and databases are among the applications that make mobile computing attractive. While the topic of querying data in wireless and mobile systems has received a lot of attention, techniques to efficiently update data in these systems while providing transaction semantics are not fully developed. We present a novel protocol that uses the broadcast facility to help mobile units do some of the work of verifying if the transactions being run by them need to be aborted. Only when the mobile unit cannot detect any conflict is the server involved in completing the verification. Of course, if the transaction can commit, the server will install the valves in the central database and notify the mobile units (again, using the broadcast channel). The protocol uses a modified version of …",111
The Demarcation Protocol: A technique for maintaining linear arithmetic constraints in distributed database systems,"Daniel Barbara, Hector Garcia-Molina",1992/3/23,Journal EDBT,"Traditional protocols for distributed database managcmcnt have high message overhead, lock or restrain access to resources during protocol execution, and may become impractical for some scenarios like real-time systems and very large distributed databases. In this paper WC present the demarcation prutocok it overcomes these problems through the use of explicit linear arithmetic consistency constraints as the correctness criteria. The method establishes safe limits as “lines drawn in the sand” for updates and gives a way of changing these limits dynamically, enforcing the constraints at all times.",111
A probabilistic relational data model,"Daniel Barbará, Hector Garcia-Molina, Daryl Porter",1990,"Conference Advances in Database Technology—EDBT'90: International Conference on Extending Database Technology Venice, Italy, March 26–30, 1990 Proceedings 2",It is often desirable to represent in a database entities whose properties cannot be deterministically classified. We develop a new data model that includes probabilities associated with the values of the attributes. The notion of missing probabilities is introduced for partially specified probability distributions. This new model offers a richer descriptive language allowing the database to reflect more accurately the uncertain real world. Probabilistic analogs to the basic relational operators are defined and their correctness is studied.,95
Quasi-copies: Efficient data sharing for information retrieval systems,"Rafael Alonso, Daniel Barbara, Hector Garcia-Molina, Soraya Abad",1988,"Conference Advances in Database Technology—EDBT'88: International Conference on Extending Database Technology Venice, Italy, March 14–18, 1988 Proceedings 1","Currently, a variety of information retrieval systems are available to potential users. These services are provided by commercial enterprises (such as Dow Jones [Dunn 1984] and The Source [Edelhart 1983]), while others are research efforts (the Boston Community Information System [Gifford1985]). While in many cases these systems are accessed from personal computers, typically no advantage is taken of the computing resources of those machines (such as local processing and storage). In this paper we explore the possibility of using the user's local storage capabilities to cache data at the user's site. This would improve the response time of user queries albeit at the cost of incurring the the overhead required in maintaining multiple copies. In order to reduce this overhead it may be appropriate to allow copies to diverge in a controlled fashion. This would not only make caching less costly, but would also …",94
Protocols for dynamic vote reassignment,"Daniel Barbara, Hector Garcia-Molina, Annemarie Spauster",1986/11/1,Book Proceedings of the fifth annual ACM symposium on Principles of distributed computing,"Voting is used commonly to enforce mutual exclusion in distributed systems. Each node is assigned a number of votes and only the group with a majority of votes is allowed to perform a restricted operation. This paper describes techniques for dynamically reassigning votes upon node or link failure, in an attempt to make the system more resilient. Protocols are given which allow nodes to select new vote values autonomously while still maintaining mutual exclusion requirements. The lemmas and theorems to validate the protocols are presented, along with proof of correctness. A simple example shows how to apply the method to a database object-locking scheme; the protocols, however, are versatile and can be used for any application requiring mutual exclusion. Also included is a brief discussion of simulation results.",92
Method and apparatus for storage and retrieval of handwritten information,"Daniel Barbara, Henry F Korth",1996/6/4,Patent office US,"A method is provided for generating an indexed database stored in a computer system. A database is established. The database includes a plurality of data objects. Each data object is defined by a respective tuple of attributes. The attributes include at least one attribute having a domain of values that includes handwritten objects. Each handwritten object includes a plurality of symbols ordered in an output sequence. An index is established, having a root node and a plurality of leaf nodes. Each leaf node is connected to the root node by a respective path, such that each path from the root node to one of the plurality of leaf nodes corresponds to a respective input sequence of symbols. The input sequence for the respective leaf node includes a set of pointers to a subset of the tuples. A respective Hidden Markov Model (HMM) is executed to analyze the output sequence of each handwritten object and to determine a …",83
The vulnerability of vote assignments,"Daniel Barbara, Hector Garcia-Molina",1986/8/1,Journal ACM Transactions on Computer Systems (TOCS),"In a faulty distributed system, voting is commonly used to achieve mutual exclusion among groups of nodes. Each node is assigned a number of votes, and any group with a majority of votes can perform the critical operations. Vote assignments can have a significant impact on system reliability, and in this paper we study the vote assignment problem. To compare vote assignments we define two deterministic measures, node and edge vulnerability. We present various properties of these measures and discuss how they can be computed. For these measures we discuss the selection of the best assignment and propose heuristics to identify good candidate assignments.",81
"Continuous authentication on mobile devices using power consumption, touch gestures and physical movement of users","Rahul Murmuria, Angelos Stavrou, Daniel Barbará, Dan Fleck",2015,"Conference Research in Attacks, Intrusions, and Defenses: 18th International Symposium, RAID 2015, Kyoto, Japan, November 2-4, 2015. Proceedings 18","Handheld devices today do not continuously verify the identity of the user while sensitive activities are performed. This enables attackers, who can either compromise the initial password or grab the device after login, full access to sensitive data and applications on the device. To mitigate this risk, we propose continuous user monitoring using a machine learning based approach comprising of an ensemble of three distinct modalities: power consumption, touch gestures, and physical movement. Users perform different activities on different applications: we consider application context when we model user behavior. We employ anomaly detection algorithms for each modality and place a bound on the fraction of anomalous events that can be considered “normal” for any given user. We evaluated our system using data collected from 73 volunteer participants. We were able to verify that our system is functional …",78
Bootstrapping a data mining intrusion detection system,"Daniel Barbará, Yi Li, Julia Couto, Jia-Ling Lin, Sushil Jajodia",2003/3/9,Book Proceedings of the 2003 ACM symposium on Applied computing,"The application of data mining techniques in intrusion detection has received a lot of attention lately. Most of the approaches require of a training phase based on the availability of labelled data, where the labels indicate whether the points correspond to normal events or attacks. Unfortunately, this labelled data is not readily available in practice. In this paper we present a novel method based in intersecting segments of unlabelled data and using the intersection as the base data for unsupervised learning (clustering). The clustering algorithm, along with a method to find outliers with respect to the base clusters form the basis for separation of unlabelled data into groups of points that are normal (attack-free) and points that correspond to attacks. We show that the technique is very sucessful in separating points of the data sets of the DARPA, Lincoln Labs evaluation of 1999.",73
Spectrum based fraud detection in social networks,"Xiaowei Ying, Xintao Wu, Daniel Barbar á",2010/10/4,Book Proceedings of the 17th ACM conference on Computer and communications security,"Social networks are vulnerable to various attacks such as spam emails, viral marketing and the such. In this paper we develop a spectrum based detection framework to discover the perpetrators of these attacks. In particular, we focus on Random Link Attacks (RLAs) in which the malicious user creates multiple false identities and interactions among those identities to later proceed to attack the regular members of the network. We show that RLA attackers can be filtered by using their spectral coordinate characteristics, which are hard to hide even after the efforts by the attackers of resembling as much as possible the rest of the network. Experimental results show that our technique is very effective in detecting those attackers and outperforms techniques previously published.",71
Method for proximity searching with range testing and range adjustment,"Daniel Barbara, Stephen Johnson, Sharad Mehrotra, Walid Aref",1996/3/12,Patent office US,"A method of searching a database having a plurality of objects is provided. Each object includes attributes and, for each attribute, a number of values. A query specifies two attributes and a maximum distance. A respective set of ranges is established for each object that has a value for the first attribute. Each set includes a range for each value of the first attribute. Each range is defined by minimum and maximum location values. A test range is established for one of the ranges. The test range has values equal to the minimum and maximum values of one of the ranges. The test range is adjusted, if necessary, so that it includes one of the values of the second attribute of the corresponding object. The test range is added to a group of ranges corresponding to the object if the minimum and maximum test values do not differ from one another by more than the maximum distance. The steps of (1) establishing a test range,(2 …",70
The case for controlled inconsistency in replicated data,"Daniel Barbará, Hector Garcia-Molina",1990/11/8,Conference [1990] Proceedings. Workshop on the Management of Replicated Data,"Although replication is widely accepted as a good technique for increasing reliability and availability of data, it is also known as an expensive proposition, especially when the number of replicas increases. Protocols that keep the copies consistent, such as two-phase commit, require one or more rounds of messages and have a high overhead in the overall performance. There are some applications that can run perfectly using copies that may not be consistent, as long as the application knows how much the copy can differ from the most recent version of the data. Many of the applications would rather tolerate some inconsistencies of the information in order to provide a better, faster service. A scenario is considered in which the database consists of several segments, each one controlled by a single node (or group of nodes). All the updates to a particular segment of the data take place at its controlling node, while the …",68
System for maintaining data coherency in cache memory by periodically broadcasting invalidation reports from server to client,"Daniel Barbara, Tomasz Imielinski",1996/12/3,Patent office US,"A method and system are provided for maintaining coherency between a server processor and a client processor that has a cache memory. The server may, for example, be a fixed location mobile unit support station. The client may, for example, be a palmtop computer. The server stores a plurality of data values, and the client stores a subset of the plurality of data values in the cache. The server processor periodically broadcasts invalidation reports to the client processor. Each respective invalidation report includes information identifying which, if any, of the plurality of data values have been updated within a predetermined period of time before the server processor broadcasts the respective invalidation report. The client processor determines, based on the invalidation reports, whether a selected data value in the cache memory of the client processor has been updated in the server processor since the selected data …",67
A survey of computational methods for protein function prediction,"Amarda Shehu, Daniel Barbará, Kevin Molloy",2016,Journal Big data analytics in genomics,"Rapid advances in high-throughout genome sequencing technologies have resulted in millions of protein-encoding gene sequences with no functional characterization. Automated protein function annotation or prediction is a prime problem for computational methods to tackle in the post-genomic era of big molecular data. While recent community-driven experiments demonstrate that the accuracy of function prediction methods has significantly improved, challenges remain. The latter are related to the different sources of data exploited to predict function, as well as different choices in representing and integrating heterogeneous data. Current methods predict function from a protein’s sequence, often in the context of evolutionary relationships, from a protein’s three-dimensional structure or specific patterns in the structure, from neighbors in a protein–protein interaction network, from microarray data, or a …",65
Using self-similarity to cluster large data sets,"Daniel Barbará, Ping Chen",2003/4,Journal Data Mining and Knowledge Discovery,"Clustering is a widely used knowledge discovery technique. It helps uncovering structures in data that were not previously known. The clustering of large data sets has received a lot of attention in recent years, however, clustering is a still a challenging task since many published algorithms fail to do well in scaling with the size of the data set and the number of dimensions that describe the points, or in finding arbitrary shapes of clusters, or dealing effectively with the presence of noise. In this paper, we present a new clustering algorithm, based in self-similarity properties of the data sets. Self-similarity is the property of being invariant with respect to the scale used to look at the data set. While fractals are self-similar at every scale used to look at them, many data sets exhibit self-similarity over a range of scales. Self-similarity can be measured using the fractal dimension. The new algorithm which we call Fractal …",64
Replicated data management in mobile environments: Anything new under the Sun?,"Daniel Barbara, Hector Garcia-Molina",1993,Publisher Stanford,"The mobile wireless computing environment of the future will contain large numbers of low powered palmtop machines. Replication will be an essential technique in this environment, providing data availability to the system. In a mobile environment it is important to have dynamic replicated data management algorithms that allow for instance copies to migrate from one site to another or for new copies to be generated. In this paper we show that such dynamic algorithms can be obtained simply by letting transaction update the directory that specifies sites holding copies. Thus we argue that no fundamentally new algorithms are needed to cope with mobility. However, exisiting algorithms may have to be ""tuned"" for a mobile environment, and we discuss what this may entail. As an illustration, we present a variation of the primary copy algorithm, Primary By Row, that is well suited for migrating copies 1 . Keywords: Distributed Data Bases, replication, mobility, availability.",62
Using checksums to detect data corruption,"Daniel Barbará, Rajni Goel, Sushil Jajodia",2000/3/8,Journal Lecture notes in computer science,"In this paper, we consider the problem of malicious and intended corruption of data in a database, acting outside of the scope of the database management system. Although detecting an attacker who changes a set of database values at the disk level is a simple task (achievable by attaching signatures to each block of data), a more sophisticated attacker may corrupt the data by replacing the current data with copies of old block images, compromising the integrity of the data. To prevent successful completion of this attack, we provide a defense mechanism that enormously increases the intruders workload, yet maintains a low system cost during an authorized update. Our algorithm calculates and maintains two levels of signatures (checksum values) on blocks of data. The signatures are grouped in a manner that forces an extended series of block copying for any unauthorized update. Using the available information …",61
Mining malicious corruption of data with hidden Markov models,"Daniel Barbará, Rajni Goel, Sushil Jajodia",2003,"Journal Research Directions in Data and Applications Security: IFIP TC11/WG11. 3 Sixteenth Annual Conference on Data and Applications Security July 28–31, 2002, Cambridge, UK","Data mining algorithms have been applied to investigate a wide range of research issues recently. In this paper we describe an alternative technique of profiling databases via time series analysis to detect anomalous changes to a database. We view the history of modifications in the database as a set of time series sequences. We then examine the application of Hidden Markov models (HMMs)as a mining tool to capture the normal trend of a database’s changes in transactions. Rather than examining each record independently, our technique accounts for the existence of relations among groups of records, and validates modifications to the sequence of transactions. The algorithm is adaptive to changes in behavior. Experiments with real data-sets, comparing various options for the initial HMM parameters, demonstrate that the distribution of the change in acceptance probabilities of anomalous values is …",56
Negotiating data access in federated database systems,"Rafael Alonso, Daniel Barbara",1989/2/6,Conference ICDE,"The ever growing need for information is putting pressure on organizations to share data with their partners. However, although the different entities would like to share infonnation, it is clear that each individual system administrator would like to preserve his or her control over the system. This concern with each system's autonomy has led to the notion of federated databases. Previous work in this area has touched upon the topic of negotiating access in a federated database (ie, detennining what local information may be accessed by any particular remote user), but We feel that the topic has not been studied in depth. In this paper we propose a new scheme, based on the notion of quasicopies, which may be used for interaction among autonomous databases. We also provide protocols for access negotiation, as well as simple cost models for estimating the expense involved in allowing remote access to information …",56
Detecting threatening behavior using bayesian networks,"Kathryn Laskey, Ghazi Alghamdi, Xun Wang, Daniel Barbara, Tom Shackelford, Edward Wright, Julie Fitzgerald",2004/5/17,Journal Proceedings of the Conference on Behavioral Representation in Modeling and Simulation,,54
Aggressive transmissions of short messages over redundant paths,"Ben Kao, Hector Garcia-Molina, Daniel Barbara",1994/1,Journal IEEE Transactions on Parallel and Distributed Systems,"Fault-tolerant computer systems have redundant paths connecting their components. Given these paths, it is possible to use aggressive techniques to reduce the average value and variability of the response time for short, critical messages. One technique is to send a copy of a packet over an alternate path before it is known whether the first copy failed or was delayed. A second technique is to split a single stream of packets over multiple paths. The authors analyze both approaches and show that they can provide significant improvements over conventional, conservative mechanisms.< >",54
"SPANNER: A tool for the specification, analysis, and evaluation of protocols","Sudhir Aggarwal, Daniel Barbará, Kalman Z.  Meth",1987/12/1,Journal IEEE Transactions on Software Engineering,"SPANNER, a software package for the specification, analysis, and evaluation of protocols, is based on a mathematical model of coordinating processes called the selection/resolution model. SPANNER is composed of 3 modules: 1. the parser module, which checks a formal specification in the SPANNER specification language for syntactic correctness, 2. the reachable graph module, which generates a database that consists of reachable states, transitions, and other information useful for analysis, and 3. the analysis module, which allows a user to query the database interactively and evaluate the behavior of the protocol. The selection/resolution model is discussed, and several examples are given. Then, a detailed description of the syntax and semantics of the SPANNER specification language is given. The reachability algorithm and the analysis module are discussed, and it is shown how SPANNER may be used …",51
A class of randomized strategies for low-cost comparison of file copies,"Daniel Barbara, Richard J Lipton",1991/4/1,Journal IEEE Transactions on Parallel & Distributed Systems,"A class of algorithms that use randomized signatures to compare remotely located filecopies is presented. A simple technique that sends on the order of 4/sup f/log (n) bits, where f is the number of differing pages that are to be diagnosed and n is the number ofpages in the file, is described. A method to improve the bound in the number of bits sent, making them grow with f as flog (f) and with n as log (n) log (log (n)), and a class ofalgorithms in which the number of signatures grows with f as fr/sup f/, where r can bemade to approach 1, are also presented. A comparison of these techniques is discussed.",46
Active authentication of users,"Angelos Stavrou, Rahul Murmuria, Ryan Johnson, Daniel Barbara",2019/5/14,Patent office US,"Embodiments herein disclose a method and system for actively authenticating users of an electronic device in a continuous manner using a plurality of factors comprising of biometric modalities, power consumption, application usage, user interactions, user movement, and user location/travel.",45
Testing e-commerce site scalability with tpc-w,"Ronald C Dodge, Daniel A Menascé, Daniel Barbará",2001/12,Journal Proc. of 2001 Computer Measurement Group Conference,"Being able to assess the scalability of Web and e-commerce sites is a challenge. The Transaction Processing Council (TPC) recently released a benchmark for e-commerce sites. This benchmark, called TPC-W, measures a system under test using Web Interactions per Second (WIPS) as its primary metric. This paper describes the benchmark's main features, the authors’ experience in building a TPC-W compliant ecommerce site and a workload generator for TPC-W. It also presents performance metrics and an analysis of self-similarity obtained with the TPC-W site.",45
Sleepers and workaholics: Caching in mobile distributed environments,"Daniel Barbara, Tomasz Imielinski",1994/6,Journal Proc. of ACM SIGMOD Int. Conf. on Management of Data,,45
Using loglinear models to compress datacubes,"Daniel Barbara, Xintao Wu",2000,"Conference Web-Age Information Management: First International Conference, WAIM 2000 Shanghai, China, June 21–23, 2000 Proceedings 1","A data cube is a popular organization for summary data. A cube is simply a multidimensional structure that contains in each cell an aggregate value, ie, the result of applying an aggregate function to an underlying relation. In practical situations, cubes can require a large amount of storage, so, compressing them is of practical importance. In this paper, we propose an approximation technique that reduces the storage cost of the cube at the price of getting approximate answers for the queries posed against the cube. The idea is to characterize regions of the cube by using statistical models whose description take less space than the data itself. Then, the model parameters can be used to estimate the cube cells with a certain level of accuracy. To increase the accuracy, and to guarantee the level of error in the query answers, some of the “outliers”(ie, cells that incur in the largest errors when estimated), are retained. The …",44
Exploiting symmetries for low-cost comparison of file copies,"Daniel Barbara, Hector Garcia-Molina",1988/6/13,Conference [1988] Proceedings. The 8th International Conference on Distributed,"A novel technique for comparison of remotely located file copies is examined. With this technique up to two differing pages can be located, and any other number of multiple differing pages can be detected. It uses a communication overhead of O(log/sup 2/(N)), where N is the number of pages in the file. It is based on a set of symmetries of a hypercube with dimension log(N).< >",44
Optimizing the Reliability Provided by Voting Mechanisms.,"Hector Garcia-Molina, Daniel Barbara",1984/5,Conference ICDCS,"In a faulty distributed system, voting is commonly used to achieve mutual exclusion among groups of nodes. Each node is assigned a number of votes, and any group with a major-ity of votes can perform the critical operations. In this paper we show that the choice of vote distribution can have as ignificant impact on the reliability of the system. We study the selection of the best vote assignment for a given system. that there is at most one coordinator)",44
Mining Cinematic Knowledge Work in Progress,"Duminda Wijesekera, Daniel Barbará",2000/8/20,Conference MDM/KDD,"¢¤£¦¥ § ©©© § !"" $# § %#£¦'&¦() 0©¥ 1"" $# 3 2546 5"" 7 25"" 9 852@¥"" 08A BC2!#) 0"" D E! FG H# P IQ 25 8@ S RT 5 § ! 25"" V UQ"" 0¥ WX Y § !¥#HQ# 2G a# 6¤ bc2 Wd¥ e bc¥"" 0¥"" 08 § fH § f# bg#£ h#¤)¦ § ! § ¤(EHi p¥ 1 § f#¥""¦ 8'a25"" $#"" $# E# a#¥ 2@"" c# aq£ 0""¦ 2@(rD 2585H $ st¢¤£ 0 A bc© 0£ 0 5 § !¥ § u 254%#£ 0¥ § v© 2 wx a# c¥ § '# 27 p¦ bc¥ 1""¦ c#£ 0 y § !) 0¥ r#! D &0¥(¥ r# xH 2 4Q p¥ § f#¥"" 087 a25"" 0a©# § v¥"" E h# q 7 bc¥""¦¥ 1""¦ 8T# 27 bv) 0 (r#¥ bc E¥ d F£¦ S#£¦ S § ! by"" d#¥ a6 a2@"" $#"" $#¥ § #¥ bc § !"" 0 § !¥ r#¥ WX G"" Ea2@""¦ § f#!) 0a# E & $ Hc 4) 0 § !¥"" 08E# qu 2@ &# q 5¥"" 0 E4 25b a2@ bc© 25"" 0"" $#¤ § f#! 5bc § s6 R#£¦ 2E § )¦ § ! E4 25 u#£ 0¥ § © 0)© 2@ § ! i£ 0 WX c""¦ 2@"" t 2T©¦ 25& &0¥(¥#H9 254G &¥""¦ 8¥""¦ a25! aY# se E¥ 1 § ! a) 0 § ! § ! E#£ 0¤¥ § ! § !) 0 § 6¥"" dWX2@(WX E¥"" v bc¥""¦¥ 1""¦ 8Q d"" 02 F (rD E8@ 4 2@ b 25 3 & 2@)¦#% bc2hWd¥ § 5"" E©¦ 25© 2@ § ! § ! 25bc § ! 2@()¦#¥ 2@""¦ § s",43
Learning missing values from summary constraints,"Xintao Wu, Daniel Barbará",2002/6/1,Journal ACM SIGKDD Explorations Newsletter,"Real-world data sets often contain errors and inconsistency. Even though this is a very important problem it has received relatively little attention in the research community. In this paper we examine the problem of learning missing values when some summary information is available. We use linear algebra and constraint programming techniques to learn the missing values using apriori-known summary information and that derived from the raw data. We reconstruct the missing values by different methods in three scenarios: ideal-constrained, under-constrained, and over-constrained. Furthermore, for a range query involving missing values, we also give the lower bound and upper bound for the values using constraint programming techniques. We believe that theory of linear algebra and constraint programming constitutes a sound basis for learning missing values when summary information is available.",42
The characterization of continuous queries,Daniel Barbará,1999/12,Journal International Journal of Cooperative Information Systems,"In a world where the amount of electronic information available is constantly growing, techniques to select and filter information efficiently become increasingly important. Continuous queries are a tool that allows users to monitor one or more information sources, by giving the impression that the queries are being run continually over them. In this paper, we formalize the notion of continuous queries for a wide spectrum of environments. We consider both append-only data sources and systems that allow more general data manipulation. We examine the case where the database management software may be modified as well as where we must treat it as a black box. We study the classes of queries that can be supported in each case and present efficient implementation techniques for them.",42
Method and apparatus for indexing a plurality of handwritten objects,"Daniel Barbara, Walid Aref, Ibrahim Kamel, Padmavathi Vallabhaneni",1997/7/15,Patent office US,"A method for indexing a plurality of handwritten objects is provided. A B-tree data structure of order m is generated, where m is an integer. The B-tree has a plurality of nodes divided into a plurality of levels ordinally numbered 0 th through n th. Each node in the 0 th level is a leaf. Each node in the 1 th level has at least m/2 leaves as children. Each one of the handwritten objects is assigned to a respective leaf. A respectively different hidden Markov model (HMM) is associated with each respective child of each of the nodes in the 1 th to n th levels. Each one of the nodes in the 1 th to n th levels contains the respective HMM associated with the child of the one node. Each HMM in each one of the nodes in the 1 th level is trained to accept the handwritten object of the respective leaf that is a child of the one node. Each HMM associated with any of the nodes in the 2 th through n th levels is trained to accept all of the …",42
The handwritten trie: Indexing electronic ink,"Walid Aref, Daniel Barbará, Padmavathi Vallabhaneni",1995/5/22,Journal ACM SIGMOD Record,"The emergence of the pen as the main interface device for personal digital assistants and pen-computers has made handwritten text, and more generally ink, a first-class object. As for any other type of data, the need of retrieval is a prevailing one. Retrieval of handwritten text is more difficult than that of conventional data since it is necessary to identify a handwritten word given slightly different variations in its shape. The current way of addressing this is by using handwriting recognition, which is prone to errors and limits the expressiveness of ink. Alternatively, one can retrieve from the database handwritten words that are similar to a query handwritten word using techniques borrowed from pattern and speech recognition. In particular, Hidden Markov Models (HMM) can be used as representatives of the handwritten words in the database. However, using HMM techniques to match the input against every item in the …",40
Screening and interpreting multi-item associations based on log-linear modeling,"Xintao Wu, Daniel Barbara, Yong Ye",2003/8/24,Book Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining,"Association rules have received a lot of attention in the data mining community since their introduction. The classical approach to find rules whose items enjoy high support (appear in a lot of the transactions in the data set) is, however, filled with shortcomings. It has been shown that support can be misleading as an indicator of how interesting the rule is. Alternative measures, such as lift, have been proposed. More recently, a paper by DuMouchel et al. proposed the use of all-two-factor loglinear models to discover sets of items that cannot be explained by pairwise associations between the items involved. This approach, however, has its limitations, since it stops short of considering higher order interactions (other than pairwise) among the items. In this paper, we propose a method that examines the parameters of the fitted loglinear models to find all the significant association patterns among the items. Since fitting …",39
Using stashing to increase node autonomy in distributed file systems,"Rafael Alonso, Daniel Barbará, Luis L Cova",1990/10/9,Conference Proceedings Ninth Symposium on Reliable Distributed Systems,"The authors present an enhancement to distributed file systems that allows the users of the system to keep local copies of important files, decreasing the dependency over file servers. Using the notions of stashing and quasi-copies, the system allows users to tune up the quality of the service they want to receive when the file server is not reachable. One of the key points of this work is the focus on the tradeoff between availability and degradation of service. The other main contribution is the design of a distributed file system which is ideally suited to very large distributed systems, in that it provides users with greater tolerance of network partitions and server failures. It is emphasized that the use of stashing does not preclude the use of other performance-enhancing or fault-tolerant techniques. The file system architecture has been implemented and FACE, a prototype of a file system service based on Sun's NFS, is …",39
Loglinear-based quasi cubes,"Daniel Barbara, Xintao Wu",2001/8,Journal Journal of Intelligent Information Systems,"A data cube is a popular organization for summary data. A cube is simply a multidimensional structure that contains in each cell an aggregate value, i.e., the result of applying an aggregate function to an underlying relation. In practical situations, cubes can require a large amount of storage, so, compressing them is of practical importance. In this paper, we propose an approximation technique that reduces the storage cost of the cube at the price of getting approximate answers for the queries posed against the cube. The idea is to characterize regions of the cube by using statistical models whose description take less space than the data itself. Then, the model parameters can be used to estimate the cube cells with a certain level of accuracy. To increase the accuracy, and to guarantee the level of error in the query answers, some of the “outliers” (i.e., cells that incur in the largest errors when estimated), are …",36
Apparatus and method for certifying the delivery of information,"Daniel Barbara, Calton Pu",1995/12/12,Patent office US,"A method and apparatus by which the recipient of several pieces of newly released information can automatically verify its accurate delivery is disclosed. The first step in the method is to generate a certificate, for example, a checksum, for each of the pieces of information. The certificates are combined, for example, using an exclusive OR function to form elements of a release vector such that each certificate is used to generate multiple ones of the release vector elements. The release vector and a program are then delivered to the recipient by one medium while the pieces of information are delivered by another medium. The program is used at the recipient's location to generate a current vector using the same methods that were used to generate the release vector. Next, the current vector is compared to the release vector and the result is used to identify missing or corrupted pieces of the delivered information.",35
Efficient processing of proximity queries for large databases,"Walid G Aref, Daniel Barbara, Stephen Johnson, Sharad Mehrotra",1995/3/6,Conference Proceedings of the Eleventh International Conference on Data Engineering,"Emerging multimedia applications require database systems to provide support for new types of objects and to process queries that may have no parallel in traditional database applications. One such important class of queries are the proximity queries that aims to retrieve objects in the database that are related by a distance metric in a way that is specified by the query. The importance of proximity queries has earlier been realized in developing constructs for visual languages. In this paper, we present algorithms for answering a class of proximity queries-fixed-radius nearest-neighbor queries over point object. Processing proximity queries using existing query processing techniques results in high CPU and I/O costs. We develop new algorithms to answer proximity queries over objects that lie in the one-dimensional space (e.g., words in a document). The algorithms exploit query semantics to reduce the CPU and I …",32
Tracking Clusters in Evolving Data Sets.,"Daniel Barbara, Ping Chen",2001/5/21,Conference FLAIRS Conference,"As organizations accumulate data over time, the problem of tracking how patterns evolve becomes important. In this paper, we present an algorithm to track the evolution of cluster models in a stream of data. Our algorithm is based on the application of bounds derived using Chernoff’s inequality and makes use of a clustering algorithm that was previously developed by us, namely Practal Clustering, which uses self-similarity as the property to group points together. Experiments show that our tracking algorithm is efficient and effective in finding changes on the patterns.",31
Information brokers: Sharing knowledge in a heterogeneous distributed system,"Daniel Barbara, Chris Clifton",2005/5/27,"Book Database and Expert Systems Applications: 4th International Conference, DEXA'93 Prague, Czech Republic, September 6–8, 1993 Proceedings","A large percentage of valuable electronic information is not stored in conventional database systems. Very often, applications have to deal with heterogeneous services such as electronic libraries, airline reservation systems or weather information services. Many times, finding these services and information can be an overwhelming task. In this paper, we describe a tool to facilitate the finding of such information. The cornerstone of the service is the idea of a broker. A broker indexes services and objects by their describing properties. A query to a broker returns enough information to contact the service and get the object or information needed. The type and amount of information indexed by the broker depends on the information that is known and available about the service or object. We present a simple but powerful design for the broker that is flexible enough to accommodate a wide variety of information …",30
Embedding semantics in LDA topic models,"Loulwah Alsumait, Pu Wang, Carlotta Domeniconi, Daniel Barbará",2010/3/26,Journal Text mining: applications and theory,"This chapter investigates the role of semantic embedding in two main directions. The first is to embed semantics from an external prior‐knowledge source to enhance the generative process of the model parameters. The second direction which suits the online knowledge discovery problem is to embed data‐driven semantics. The idea is to construct the current latent Dirichlet alglocation (LDA) model based on information propagated from topic models that were learned from previously seen documents of the domain. The chapter focuses on three major advancements to solve the problem such as vector space modeling, latent semantic analysis and probabilistic latent semantic analysis. It introduces the LDA topic model with a brief description of its graphical model and generative process and the posterior inference. The chapter investigates the role of embedding semantics from a source by enhancing the …",29
Random subspace ensembles for clustering categorical data,"Muna Al-Razgan, Carlotta Domeniconi, Daniel Barbará",2008,Journal Supervised and unsupervised ensemble methods and their applications,"Cluster ensembles provide a solution to challenges inherent to clustering arising from its ill-posed nature. In fact, cluster ensembles can find robust and stable solutions by leveraging the consensus across multiple clustering results, while averaging out spurious structures that arise due to the various biases to which each participating algorithm is tuned. In this chapter we focus on the design of ensembles for categorical data. Our techniques build upon diverse input clusterings discovered in random subspaces, and reduce the problem of defining a consensus function to a graph partitioning problem. We experimentally demonstrate the efficacy of our approach in combination with the categorical clustering algorithm COOLCAT.",29
A software environment for the specification and analysis of problems of coordination and concurrency,"Sudhir Aggarwal, Daniel Barbara, Kalman Z.  Meth",1988/3,Journal IEEE Transactions on Software Engineering,"The SPANNER software environment for the specification and analysis of concurrent process coordination and resource sharing coordination is described. In the SPANNER environment, one can formally produce a specification of a distributed computing problem, and then verify its validity through reachability analysis and simulation. SPANNER is based on a finite-state machine model called the selection/resolution model. The capabilities of SPANNER are illustrated by the analysis of two classical coordination problems: (1) the dining philosophers; and (2) Dijkstra's concurrent programming problem. In addition, some of the more recently implemented capabilities of the SPANNER system are discussed, such as process types and cluster variables.< >",29
16S rRNA metagenome clustering and diversity estimation using locality sensitive hashing,"Zeehasham Rasheed, Huzefa Rangwala, Daniel Barbará",2013/10,Journal BMC systems biology,"Advances in biotechnology have changed the manner of characterizing large populations of microbial communities that are ubiquitous across several environments.""Metagenome"" sequencing involves decoding the DNA of organisms co-existing within ecosystems ranging from ocean, soil and human body. Several researchers are interested in metagenomics because it provides an insight into the complex biodiversity across several environments. Clinicians are using metagenomics to determine the role played by collection of microbial organisms within human body with respect to human health wellness and disease.",28
Fractal characterization of web workloads,"Daniel Menascé, Bruno Abrahao, Daniel Barbará, Virgílio Almeida, Flávia Ribeiro",2002/5,"Journal Eleventh International World Wide Web Conference, Honolulu, HI","Understanding the workload of Web and e-commerce sites is a fundamental step in sizing the IT infrastructure that supports these sites and in planning for their evolution so that Quality of Service (QoS) goals are met within cost constraints. This paper discusses the use of fractal-based methods to simplify and characterize Web and e-commerce workloads. Fractal clustering is quite appropriate to find sets of points that are somehow “similar” with respect to a fractal dimension. This implies that clusters do not have to be shaped as hyperspheres, as is the case with traditional clustering techniques. We apply the fractal techniques to an actual e-commerce workload and use the results to understand what customers do, what navigational patterns they follow, and to identify groups of users that have similar behavior. A comparison with results obtained with k-means analysis is also discussed. The main contributions of this work are techniques that improve the process of workload characterization.",28
Modeling and imputation of large incomplete multidimensional datasets,"Xintao Wu, Daniel Barbará",2002,"Conference Data Warehousing and Knowledge Discovery: 4th International Conference, DaWaK 2002 Aix-en-Provence, France, September 4–6, 2002 Proceedings 4","The presence of missing or incomplete data is a commonplace in large real-word databases. In this paper, we study the problem of missing values which occur at the measure dimension of data cube. We propose a two-part mixture model, which combines the logistic model and loglinear model together, to predict and impute the missing values. The logistic model here is applied to predict missing positions while the loglinear model is applied to compute the estimation. Experimental results on real datasets and synthetic datasets are presented.",28
Chaotic Mining: Knowledge Discovery Using the Fractal Dimension.,Daniel Barbará,1999,Conference 1999 ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery,"Nature is lled with examples of phenomena that exhibit seemingly chaotic behavior, such as air turbulence, forest res and the like. However, under this behavior it is almost always possible to nd self-similarity, ie an invariance with respect to the scale used. The structures that appear as a consequence of self-similarity are known as fractals 12].",27
Quasi-cubes: A space-efficient way to support approximate multidimensional databases,"Daniel Barbará, Mark Sullivan",1998/10,"Journal Technical report, ISSE George Mason University","A data cube is a popular organization forsummary data. A cube is simply a multidimensional structure that contains at each point an aggregate value, ie, the result of applying an aggregate function to an underlying relation. In practical situations, cubes can require a large amount of storage. The typical approach to reducing storage cost is to materialize parts of the cube on demand. Unfortunately, this lazy evaluation can be a time-consuming operation. In this paper, we propose an approximation technique that reduces the storage cost of the cube without incurring the run time cost of lazy evaluation. The idea is to provide an incomplete description of the cube and a method of estimating the missing entries with a certain level of accuracy. The description, of course, should take a fraction of the space of the full cube and the estimation procedure should be faster than computing the data from the underlying relations …",27
The Gold text indexing engine,"Daniel Barbará, Sharad Mehrotra, Padmavathi Vallabhaneni",1996/2/26,Conference Proceedings of the Twelfth International Conference on Data Engineering,"The proliferation of electronic communication including computer mail, faxes, voice mail, and net news has led to a variety of disjoint applications and usage paradigms that forces users to deal with multiple different user interfaces and access related information arriving over the different communication media separately. To enable users to cope with the overload of information arriving over heterogeneous communication media, we have developed the Gold document handling system that allows users to access all of these forms of communication at once, or to intermix them. The Gold system provides users with an integrated way to send and recieve messages using different media, efficiently store the messages, retrieve the messages based on their contents, and to access a variety of other sources of useful information. At the center of the Gold document handling system is the Gold Text Indexing Engine (GTIE …",27
Ink as a first-class datatype in multimedia databases,"Walid G Aref, Daniel Barbará, Daniel Lopresti",1996,Journal Multimedia Database Systems: Issues and Research Directions,"In this chapter, we turn out attention to databases that contain ink. The methods and techniques covered in this chapter can be used to deal effectively with the NOTES database of the Medical Scenario described in the Introduction of the book. With these techniques, doctors would be able to retrieve the handwritten notes about their patients, by using the pen as an input device for their queries.",27
Categorization and keyword identification of unlabeled documents,"Ning Kang, Carlotta Domeniconi, Daniel Barbará",2005/11/27,Conference Fifth IEEE International Conference on Data Mining (ICDM'05),"In this paper, we first propose a global unsupervised feature selection approach for text, based on frequent itemset mining. As a result, each document is represented as a set of words that co-occur frequently in the given corpus of documents. We then introduce a locally adaptive clustering algorithm, designed to estimate (local) word relevance and, simultaneously, to group the documents. We present experimental results to demonstrate the feasibility of our approach. Furthermore, the analysis of the weights credited to terms provides evidence that the identified keywords can guide the process of label assignment to clusters. We take into consideration both spam email filtering and general classification datasets. Our analysis of the distribution of weights in the two cases provides insights on how the spam problem distinguishes from the general classification case.",25
An architecture for anomaly detection,"Daniel Barbara, Julia Couto, Sushil Jajodia, Ningning Wu",2002,Journal Applications of Data Mining in Computer Security,"Anomaly detection systems have become popular over the years. Their basic principle is the comparison of the incoming traffic with a previously-built profile that contains a representation of the “normal” or expected traffic. The system flags anything that exceeds the normal activity (usually by means of thresholds) as an attack. Unfortunately, not everything that surpasses the expected activity is indeed an attack. Thus, anomaly detection systems have the proclivity of generating lots of false alarms. In this chapter we present an efficient architecture that can effectively be used to design anomaly detection systems and keep false alarms at a manageable level. We also present an implementation of this architecture that we have realized and experimented with.",24
Detecting ROP with statistical learning of program characteristics,"Mohamed Elsabagh, Daniel Barbara, Dan Fleck, Angelos Stavrou",2017/3/22,Book Proceedings of the Seventh ACM on Conference on Data and Application Security and Privacy,"Return-Oriented Programming (ROP) has emerged as one of the most widely used techniques to exploit software vulnerabilities. Unfortunately, existing ROP protections suffer from a number of shortcomings: they require access to source code and compiler support, focus on specific types of gadgets, depend on accurate disassembly and construction of Control Flow Graphs, or use hardware-dependent (microarchitectural) characteristics. In this paper, we propose EigenROP, a novel system to detect ROP payloads based on unsupervised statistical learning of program characteristics. We study, for the first time, the feasibility and effectiveness of using microarchitecture-independent program characteristics -- namely, memory locality, register traffic, and memory reuse distance -- for detecting ROP. We propose a novel directional statistics based algorithm to identify deviations from the expected program characteristics …",23
Method for indexing and searching handwritten documents in a database,"Daniel Barbara, Walid Aref",1996/9/3,Patent office US,"A method for indexing electronic handwritten documents is provided. Each document includes a plurality of output symbols in an output sequence, and is modeled by a respective Hidden Markov Model (HMM). The HMMs share a common alphabet and a common sequence length. A tree is established, having linked nodes stored in a memory. Each node has n pointers, each identifying a different node in the next level of the tree. Each path from the root to a different one of the leaf nodes defines a respective sequence of pointers. An indexing procedure is performed, for each of a subset of the nodes in one of the levels of the tree. The procedure includes:(1) determining the probability that a subset of one of the sequences of pointers leading from the root to that node represents a subset of the output symbols in one of the documents;(2) invoking the procedure for the next level, if the determined probability exceeds …",23
The gold mailer,"Daniel Barbará, Chris Clifton, Fred Douglis, Hector Garcia-Molina, Stephen Johnson, Ben Kao, Sharad Mehrotra, Jens Tellefsen, Rosemary Walsh",1993/4/19,Conference Proceedings of IEEE 9th International Conference on Data Engineering,"The Gold Mailer, a system that provides users with an integrated way to send and receive messages using different media, efficiently store and retrieve these messages, and access a variety of sources of other useful information, is described. The mailer solves the problems of information overload, organization of messages and multiple interfaces. By providing good storage and retrieval facilities, it can be used as a powerful information processing engine covering a range of useful office information. The Gold Mailer's query language, indexing engine, file organization, data structures, and support of mail message data and multimedia documents are discussed.< >",23
Aggressive transmissions over redundant paths,"Hector Garcia-Molina, Ben Kao, Daniel Barbara",1991/1/1,Conference Proceedings 11th International Conference on Distributed Computing Systems,"Fault-tolerant computer systems have redundant paths connecting their components. Given these paths, it is possible to use aggressive techniques to reduce the average value and variability of the response time for critical messages. One technique is to send a copy of a packet over an alternate path before it is known if the first copy failed or was delayed. A second technique is to split a single stream of packets over multiple paths. The authors analyze both approaches and show that these techniques can provide significant improvements over conventional, conservative mechanisms.<>",22
LSH-Div: Species diversity estimation using locality sensitive hashing,"Zeehasham Rasheed, Huzefa Rangwala, Daniel Barbara",2012/10/4,Conference 2012 IEEE International Conference on Bioinformatics and Biomedicine,"Metagenome sequencing projects attempt to determine the collective DNA of organisms, co-existing as communities across different environments. Computational approaches analyze the large volumes of sequence data obtained from these ecological samples, to provide an understanding of the species diversity, content and abundance. In this work we present a scalable, species diversity estimation algorithm that achieves computational efficiency by use of a locality sensitive hashing algorithm (LSH). Using fixed-length, gapless subsequences, we improve the sensitivity of pairwise sequence comparisons. Using the LSH-based function, we first group similar sequences into bins commonly referred to as operational taxonomic units (OTUs) and then compute several species diversity/richness metrics. The performance of our algorithm is evaluated on synthetic data and eight targeted metagenome samples obtained …",20
Dtb project: A behavioral model for detecting insider threats,"Paulo CG Costa, Kathryn B Laskey, Ghazi AlGhamdi, Daniel Barbara, Thomas Shackelford, Sepideh Mirza, Mehul Revankar",2005,Publisher MITRE Corporation,"This paper describes the Detection of Threat Behavior (DTB) project, a joint effort being conducted by George Mason University (GMU) and Information Extraction and Transport, Inc. (IET). DTB uses novel approaches for detecting insiders in tightly controlled computing environments. Innovations include a distributed system of dynamically generated document-centric intelligent agents for document control, object oriented hybrid logic-based and probabilistic modeling to characterize and detect illicit insider behaviors, and automated data collection and data mining of the operational environment to continually learn and update the underlying statistical and probabilistic nature of characteristic behaviors. To evaluate the DTB concept, we are conducting a human subjects experiment, which we will also include in our discussion.",20
Using approximations to scale exploratory data analysis in datacubes,"Daniel Barbara, Xintao Wu",1999/8/1,Book Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining,"Exploratory Data Analysis is a widely used technique to determine which factors have the most influence on data values in a multi-way table, or which cells in the table can be considered anomalous with respect to the other cells. In particular, median polish is a simple, yet robust method to perform Exploratory Data Analysis. Median polish is resistant to holes in the table (cells that have no values), but it may require a lot of iterations through the data. This factor makes it difficult to apply median polish to large multidimensional tables, since the I/O requirements may be prohibitive. This paper describes a technique that uses median polish over an approximation of a datacube, easing the burden of I/O. The results obtained are tested for quality, using a variety of measures. The technique scales to large datacubes and proves to give a good approximation of the results that would have been obtained by median polish in …",18
Data sharing in a large heterogeneous environment,"Rafael Alonso, Daniel Barbara, Steve Cohn",1991/4/8,Conference [1991] Proceedings. Seventh International Conference on Data Engineering,"The issues involved in sharing information among a large collection of independent databases is explored. Some of the distinguishing features that characterize such large-scale environments (such as size, autonomy, and heterogeneity) are discussed. A multistep information sharing process for those systems is outlined and an architecture supporting that exchange is presented. A detailed description of a working prototype based on this architecture and some measurements of its performance are provided.< >",18
Efficient clustering of metagenomic sequences using locality sensitive hashing,"Zeehasham Rasheed, Huzefa Rangwala, Daniel Barbara",2012/4/26,Book Proceedings of the 2012 SIAM International Conference on Data Mining,"The new generation of genomic technologies have allowed researchers to determine the collective DNA of organisms (e.g., microbes) co-existing as communities across the ecosystem (e.g., within the human host). There is a need for the computational approaches to analyze and annotate the large volumes of available sequence data from such microbial communities (metagenomes).",17
Mining relevant text from unlabelled documents,"Daniel Barbará, Carlotta Domeniconi, Ning Kang",2003/11/22,Conference Third IEEE International Conference on Data Mining,"Automatic classification of documents is an important area of research with many applications in the fields of document searching, forensics and others. Methods to perform classification of text rely on the existence of a sample of documents whose class labels are known. However, in many situations, obtaining this sample may not be an easy (or even possible) task. We focus on the classification of unlabelled documents into two classes: relevant and irrelevant, given a topic of interest. By dividing the set of documents into buckets (for instance, answers returned by different search engines), and using association rule mining to find common sets of words among the buckets, we can efficiently obtain a sample of documents that has a large percentage of relevant ones. This sample can be used to train models to classify the entire set of documents. We prove, via experimentation, that our method is capable of filtering …",17
How Expensive is Data Replication? An Example.,"Daniel Barbara, Hector Garcia-Molina",1982/2,Conference ICDCS,"In this paper, we present a case study which illus-trates the cost of replicating data in a distributed computing system. We study the average response time of transactions and hardware costs under three configurations: one processor, one database copy; one processor, two database copies; and two processors, two database copies. The performance results are obtained using detailed simulations which take into account factors such as the computing, input-output and transmis. sion times involved in processing transactions; the queueing delays; the conflicts among transactions; the concurrency control mechanism (with deadlock avoidance); and the two phase commit protocol and writ-ing of logs.",17
Fractal mining-self similarity-based clustering and its applications,"Daniel Barbara, Ping Chen",2010,Journal Data Mining and Knowledge Discovery Handbook,"Self-similarity is the property of being invariant with respect to the scale used to look at the data set. Self-similarity can be measured using the fractal dimension. Fractal dimension is an important charactaristics for many complex systems and can serve as a powerful representation technique. In this chapter, we present a new clustering algorithm, based on self-similarity properties of the data sets, and also its applications to other fields in Data Mining, such as projected clustering and trend analysis. Clustering is a widely used knowledge discovery technique. The new algorithm which we call Fractal Clustering (FC) places points incrementally in the cluster for which the change in the fractal dimension after adding the point is the least. This is a very natural way of clustering points, since points in the same clusterhave a great degree of self-similarity among them (and much less self-similarity with respect to points …",16
Modeling insider behavior using multi-entity Bayesian networks,"Ghazi AlGhamdi, Kathryn B Laskey, Edward J Wright, Daniel Barbará, KC Chang",2006/3/6,"Description This paper tackles a key aspect of the information security problem: modeling the behavior of insider threats. The specific problem addressed by this paper is the identification of malicious insider behavior in trusted computing environments. Although most security techniques in intrusion detection systems (IDS’s) focus on protecting the system boundaries from outside attacks, defending against an insider who attempts to misuse privileges is an equally significant problem for network security. It is usually assumed that users who are given access to network resources can be trusted. However, the eighth annual CSI/FBI 2003 report found that insider abuse of network access was the most cited form of attack or abuse. 80% of respondents were concerned about insider abuse, although 92% of the responding organizations employed some form of access control mechanism [7]. Therefore, though insider users are legally granted access to network resources, it is essential to protect against misuse by insiders. This paper presents a scalable model to represent insider behavior. We provide simulation experiments to demonstrate the ability of the model to detect threat behavior. Information security objectives can be accomplished through a layered approach that represents several lines of defense. This approach constitutes one of these lines of defense.","This paper tackles a key aspect of the information security problem: modeling the behavior of insider threats. The specific problem addressed by this paper is the identification of malicious insider behavior in trusted computing environments. Although most security techniques in intrusion detection systems (IDS’s) focus on protecting the system boundaries from outside attacks, defending against an insider who attempts to misuse privileges is an equally significant problem for network security. It is usually assumed that users who are given access to network resources can be trusted. However, the eighth annual CSI/FBI 2003 report found that insider abuse of network access was the most cited form of attack or abuse. 80% of respondents were concerned about insider abuse, although 92% of the responding organizations employed some form of access control mechanism [7]. Therefore, though insider users are legally granted access to network resources, it is essential to protect against misuse by insiders. This paper presents a scalable model to represent insider behavior. We provide simulation experiments to demonstrate the ability of the model to detect threat behavior. Information security objectives can be accomplished through a layered approach that represents several lines of defense. This approach constitutes one of these lines of defense.",15
Supporting electronic ink databases,"Walid Aref, Daniel Barbara",1999/6/1,Journal Information Systems,"The emergence of the pen as the main interface device for personal digital assistants and pen-computers has made handwritten text, and more generally ink, a first-class object. As for any other type of data, the need of retrieval is a prevailing one. Retrieval of handwritten text is more difficult than that of conventional data since it is necessary to identify a handwritten word given slightly different variations in its shape. The current way of addressing this is by using handwriting recognition, which is prone to errors and limits the expressiveness of ink. Alternatively, one can retrieve from the database handwritten words that are similar to a query handwritten word using techniques borrowed from pattern and speech recognition. In this paper, an indexing technique based on Hidden Markov Models is proposed. Its implementation and its performance is reported in this paper.",15
Contrast-set mining of aircraft accidents and incidents,"Zohreh Nazeri, Daniel Barbara, Kenneth De Jong, George Donohue, Lance Sherry",2008,"Conference Advances in Data Mining. Medical Applications, E-Commerce, Marketing, and Theoretical Aspects: 8th Industrial Conference, ICDM 2008 Leipzig, Germany, July 16-18, 2008 Proceedings 8","Identifying patterns of factors associated with aircraft accidents is of high interest to the aviation safety community. However, accident data is not large enough to allow a significant discovery of repeating patterns of the factors. We applied the STUCCO algorithm to analyze aircraft accident data in contrast to the aircraft incident data in major aviation safety databases and identified factors that are significantly associated with the accidents. The data pertains to accidents and incidents involving commercial flights within the United States. The NTSB accident database was analyzed against four incident databases and the results were compared. We ranked the findings by the Factor Support Ratio, a measure introduced in this work.",14
Retrieving electronic ink by content,"Ibrahim Kamel, Daniel Barbara",1996/8/14,Conference Proceedings of International Workshop on Multimedia Database Management Systems,"This paper deals with a new emerging multimedia data, namely, electronic ink. As pen-based computers and personal digital assistants (PDAs) become more popular, searching electronic ink becomes an important issue. We treat the ink object as a one dimensional image which is described by a set of features. This is different from the traditional methods that use handwritten recognition techniques to convert it into ASCII. The search retrieves a set of ink objects that most resembles the query object. We describe a multi-stages filter for searching large repository of electronic ink. The first stage is an R-tree based index used to prune the search space. The output of the first stage is a set of words that have some common features with the query. A sequential search algorithm is then used to extract the most similar word to the query string. Our schema is 12 time faster than the sequential and improves the retrieval rate …",14
Radmin: early detection of application-level resource exhaustion and starvation attacks,"Mohamed Elsabagh, Daniel Barbará, Dan Fleck, Angelos Stavrou",2015,"Conference Research in Attacks, Intrusions, and Defenses: 18th International Symposium, RAID 2015, Kyoto, Japan, November 2-4, 2015. Proceedings 18","Software systems are often engineered and tested for functionality under normal rather than worst-case conditions. This makes the systems vulnerable to denial of service attacks, where attackers engineer conditions that result in overconsumption of resources or starvation and stalling of execution. While the security community is well familiar with volumetric resource exhaustion attacks at the network and transport layers, application-specific attacks pose a challenging threat. In this paper, we present Radmin, a novel system for early detection of application-level resource exhaustion and starvation attacks. Radmin works directly on compiled binaries. It learns and executes multiple probabilistic finite automata from benign runs of target programs. Radmin confines the resource usage of target programs to the learned automata, and detects resource usage anomalies at their early stages. We demonstrate the …",13
The cost of data replication,"Hector Garcia-Holina, Daniel Barbara",1981/10/1,Journal ACM SIGCOMM Computer Communication Review,"With the advent of data communication networks, researchers have been looking at the possibility of placing copies of a database at two or more nodes of a network. Such data replication is interesting because it makes the database accessible even when some of the nodes in the system fail. Furthermore, transactions which only read data may get faster access to the data when multiple copies exist.",13
Exploring representations of protein structure for automated remote homology detection and mapping of protein structure space,"Kevin Molloy, M Jennifer Van, Daniel Barbara, Amarda Shehu",2014/7,Journal BMC bioinformatics,"Due to rapid sequencing of genomes, there are now millions of deposited protein sequences with no known function. Fast sequence-based comparisons allow detecting close homologs for a protein of interest to transfer functional information from the homologs to the given protein. Sequence-based comparison cannot detect remote homologs, in which evolution has adjusted the sequence while largely preserving structure. Structure-based comparisons can detect remote homologs but most methods for doing so are too expensive to apply at a large scale over structural databases of proteins. Recently, fragment-based structural representations have been proposed that allow fast detection of remote homologs with reasonable accuracy. These representations have also been used to obtain linearly-reducible maps of protein structure space. It has been shown, as additionally supported from analysis in this paper that such maps preserve functional co-localization of the protein structure space. Inspired by a recent application of the Latent Dirichlet Allocation (LDA) model for conducting structural comparisons of proteins, we propose higher-order LDA-obtained topic-based representations of protein structures to provide an alternative route for remote homology detection and organization of the protein structure space in few dimensions. Various techniques based on natural language processing are proposed and employed to aid the analysis of topics in the protein structure domain. We show that a topic-based representation is just as effective as a fragment-based one at automated detection of remote homologs and organization of protein structure …",12
Detecting suspicious behavior in surveillance images,"Daniel Barbará, Carlotta Domeniconi, Zoran Duric, Maurizio Filippone, Richard Mansfield, Edgard Lawson",2008/12/15,Conference 2008 IEEE International Conference on Data Mining Workshops,"We introduce a novel technique to detect anomalies in images. The notion of normalcy is given by a baseline of images, under the assumption that the majority of such images is normal. The key of our approach is a featureless probabilistic representation of images, based on the length of the codeword necessary to represent each image. Such codeword's lengths are then used for anomaly detection based on statistical testing. Our techniques were tested on synthetic and real data sets. The results show that our approach can achieve high true positive and low false positive rates.",12
Classifying documents without labels,"Daniel Barbará, Carlotta Domeniconi, Ning Kang",2004/4/22,Book Proceedings of the 2004 SIAM International Conference on Data Mining,"Automatic classification of documents is an important area of research with many applications in the fields of document searching, forensics and others. Methods to perform classification of text rely on the existence of a sample of documents whose class labels are known. However, in many situations, obtaining this sample may not be an easy (or even possible) task. Consider for instance, a set of documents that is returned as a result of a query. If we want to separate the documents that are truly relevant to the query from those that are not, it is unlikely that we will have at hand labelled documents to train classification models to perform this task. In this paper we focus on the classification of an unlabelled set of documents into two classes: relevant and irrelevant, given a topic of interest. By dividing the set of documents into buckets (for instance, answers returned by different search engines), and using association …",12
Probabilistic diagnosis of hot spots,"Kenneth Salem, Daniel Barbara, Richard J Lipton",1992/1/1,Conference 1992 Eighth International Conference on Data Engineering,"The authors present several techniques to identify, or diagnose, hot spots in a database. All of them are probabilistic in the sense that they will classify the items as hot or cold and exhibit a non-zero probability of false diagnoses. Each technique is analysed to identify the tradeoffs of time and space involved in maintaining a low probability of false diagnosis. Each of the techniques is presented. The analyses of the techniques is considered to determine how likely they are to diagnose without error. The techniques are compared. A numerical comparison based on the analyses is included.<>",12
Detecting spatio-temporal outliers with kernels and statistical testing,"James P Rogers, Daniel Barbara, Carlotta Domeniconi",2009/8/12,Conference 2009 17th International Conference on Geoinformatics,"Outlier detection is the discovery of points that are exceptional when compared with a set of observations that are considered normal. Such points are important since they often lead to the discovery of exceptional events. In spatio-temporal data, observations are vectors of feature values, tagged with a geographical location and a timestamp. A spatio-temporal outlier is an observation whose attribute values are significantly different from those of other spatially and temporally referenced objects in a spatio-temporal neighborhood. It represents an object that is significantly different from its neighbors, even though it may not be significantly different from the entire population. The discovery of outliers in spatio-temporal data is then complicated by the fact that one needs to focus the search on appropriate spatio-temporal neighborhoods of points. The work in this paper leverages an algorithm, StrOUD (strangeness-based …",10
Self-similar mining of time association rules,"Daniel Barbará, Ping Chen, Zohreh Nazeri",2004,"Conference Advances in Knowledge Discovery and Data Mining: 8th Pacific-Asia Conference, PAKDD 2004, Sydney, Australia, May 26-28, 2004. Proceedings 8","Although the task of mining association rules has received considerable attention in the literature, algorithms to find time association rules are often inadequate, by either missing rules when the time interval is arbitrarily partitioned in equal intervals or by clustering the data before the search for high-support itemsets is undertaken. We present an e.cient solution to this problem that uses the fractal dimension as an indicator of when the interval needs to be partitioned. The partitions are done with respect to every itemset in consideration, and therefore the algorithm is in a better position to find frequent itemsets that would have been missed otherwise. We present experimental evidence of the e.ciency of our algorithm both in terms of rules that would have been missed by other techniques and also in terms of its scalability with respect to the number of transactions and the number of items in the data set.",10
FACE: Enhancing Distributed File Systems for Autonomous Computing Environments,"Rafael Alonso, Daniel Barbará, Luis L Cova",1989,"Publisher Princeton University, Department of Computer Science",,10
The Vulnerability of Voting Mechanisms.,"Daniel Barbará, Hector Garcia-Molina",1984/10,Conference Symposium on Reliability in Distributed Software and Database Systems,,10
Special issue on data mining for intrusion detection and threat analysis,Daniel Barbara,2001/12/1,Journal ACM SIGMOD Record,"As our dependency on hlformation systems grows, the threat of having those disrupted by cyber attacks becomes a very pressing reality. We have witnesses nmltiple occurrences of attacks in the recent past that have seriously disrupted businesses and organizations. And, unfortunately, this trend is only increasing. For some time now, some research groups have been doing research oil data mining techniques that can potentially help in meeting the challenges posed by the attacks. This special issue is an attempt to bring some of these people together and disseminate some of the results among the SIGMOD audience, and perhaps spark the interest of the community for this emerging field.",9
Augmenting Availability in Distributed File Systems,"Rafael Alonso, Daniel Barbara, Luis L Cova",1989,"Publisher Princeton University, Department of Computer Science",,9
Maintaining availability of replicated data in a dynamic failure environment,Boris Kogan,1986/12/8,Description An approach is presented for maintaining high availability in a replicated database system with a failure prone communications network. The status of the network is assumed to change dynamically making the detection of partitions infeasible. The approach is based on restricting the data items transactions can access and on special requirements placed on update propagation.,An approach is presented for maintaining high availability in a replicated database system with a failure prone communications network. The status of the network is assumed to change dynamically making the detection of partitions infeasible. The approach is based on restricting the data items transactions can access and on special requirements placed on update propagation.,9
A checksum-based corruption detection technique,"Daniel Barbará, Rajni Goel, Sushil Jajodia",2003/1/1,Journal Journal of Computer Security,"We consider the problem of malicious attacks that lead to corruption of files in a file system. A typical method to detect such corruption is to compute signatures of all the files and store these signatures in a secure place. A malicious modification of a file can be detected by verifying the signature. This method, however, leaves the system vulnerable to an attacker who has access to some of the files and the signatures (but not the signing transformation) and who replaces some of the files by their old versions and the corresponding signatures by the signatures of the old versions.",8
Extending the scope of database services,Daniel Barbará,1993/3/1,Journal ACM SIGMOD Record,"A wide variety of important data remains outside of the scope of database management systems. In recent years researchers have been making efforts in two directions: first, developing database management systems that can support non-traditional data, and secondly, offering database services for data that remains under control of autonomous (not necessarily database) systems. The purpose of this paper is to provide a brief review of these efforts.",8
Evaluating vote assignments with A probabilistic metric,"Daniel Barbara, Hector Garcia-Molina",1985/6,Journal to appear Proceedings FTCS,"In a faulty distributed system, voting is commonly used to achieve mutual exclusion among groups of isolated nodes. Each node is assigned a number of votes, and any group with a majority of votes can perform the critical operations. Vote assignments can have a significant impact on system reliability. In this paper we address the problem of selecting vote assignments in order to maximize the probability that the critical operations can be performed at a given time by some group of nodes. We suggest simple heuristics to assign votes, and show that they give good results in most cases. We also study three particular homogeneous topologies (fully connected, ethernet, and ring networks), and derive analytical expressions for system reliability. These expressions provide useful insights into the reliability provided by voting mechanisms.",8
Your data in your hands: Privacy-preserving user behavior models for context computation,"Rahul Murmuria, Angelos Stavrou, Daniel Barbara, Vincent Sritapan",2017/3/13,Conference 2017 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops),"Modern smartphone applications rely on contextual information while providing the users with relevant and timely content and services. One way of generating such contextual information is by employing learning systems to model user behavior. Motion-based sensors, such as the accelerometer or gyroscope, have been previously employed for recognizing predefined high-level physical activities such as climbing stairs, jogging, or driving. In practice, human activities are highly diverse and unsupervised methods must be used to expose complex behavioral characteristics that are user-centric. This paper proposes a novel machine learning model for user authentication and trust that is continuously assessing the user activities in an effort to expose deviations from known training data. The goal is to export this trust score as a contextual input to mobile apps for detection of unauthorized access, fraudulent …",7
The role of semantic history on online generative topic modeling,"Loulwah AlSumait, Daniel Barbará, Carlotta Domeniconi",2009,"Journal Proceedings of the Workshop on Text Mining, held in conjunction with the SIAM International Conference on Data Mining","Online processing of text streams is an essential task of many genuine applications. The objective is to identify the underlying structure of evolving themes in the incoming streams online at the time of their arrival. As many topics tend to reappear consistently in text streams, incorporating semantics that were discovered in previous streams would eventually enhance the identification and description of topics in the future. Latent Dirichlet Allocation (LDA) topic model is a probabilistic technique that has been successfully used to automatically extract the topical or semantic content of documents. In this paper, we investigate the role of past semantics in estimating future topics under the framework of LDA topic modeling, based on the online version implemented in [1]. The idea is to construct the current model based on information propagated from topic models that fall within a “sliding history window”. Then, this model is incrementally updated according to the information inferred from the new stream of data with no need to access previous data. Since the proposed approach is totally unsupervised and data-driven, we analyze the effect of different factors that are involved in this model, including the window size, history weight, and equal/decaying history contribution. The proposed approach is evaluated using benchmark datasets. Our experiments show that the embedded semantics from the past improved the quality of the document modeling. We also found that the role of history varies according to the domain and nature of text data.",7
Malware detection in critical infrastructures using the electromagnetic emissions of plcs,"Constantinos Kolias, R Borrelli, Daniel Barbara, Angelos Stavrou",2019/11,Journal Transactions,,6
On early detection of application-level resource exhaustion and starvation,"Mohamed Elsabagh, Daniel Barbará, Dan Fleck, Angelos Stavrou",2018/3/1,Journal Journal of Systems and Software,"Software systems are often engineered and tested for functionality under normal rather than worst-case conditions. This makes the systems vulnerable to denial-of-service attacks, where attackers engineer conditions that result in overconsumption of resources or starvation and stalling of execution. While the security community is well familiar with volumetric resource exhaustion attacks at the network and transport layers, application-specific attacks pose a challenging threat. In this paper, we present Radmin, a novel system for early detection of application-level resource exhaustion and starvation attacks. Radmin works directly on compiled binaries. It learns and executes multiple probabilistic finite automata from benign runs of target programs. Radmin confines the resource usage of target programs to the learned automata and detects resource usage anomalies at their early stages. We demonstrate the …",6
Metagenome sequence clustering with hash-based canopies,"Mohammad Arifur Rahman, Nathan LaPierre, Huzefa Rangwala, Daniel Barbara",2017/12/8,Journal Journal of bioinformatics and computational biology,"Metagenomics is the collective sequencing of co-existing microbial communities which are ubiquitous across various clinical and ecological environments. Due to the large volume and random short sequences (reads) obtained from community sequences, analysis of diversity, abundance and functions of different organisms within these communities are challenging tasks. We present a fast and scalable clustering algorithm for analyzing large-scale metagenome sequence data. Our approach achieves efficiency by partitioning the large number of sequence reads into groups (called canopies) using hashing. These canopies are then refined by using state-of-the-art sequence clustering algorithms. This canopy-clustering (CC) algorithm can be used as a pre-processing phase for computationally expensive clustering algorithms. We use and compare three hashing schemes for canopy construction with five popular …",6
Improving the recognition of grips and movements of the hand using myoelectric signals,"Gene Shuman, Zoran Durić, Daniel Barbará, Jessica Lin, Lynn H Gerber",2016/7,Journal BMC Medical Informatics and Decision Making,"People want to live independently, but too often disabilities or advanced age robs them of the ability to do the necessary activities of daily living (ADLs). Finding relationships between electromyograms measured in the arm and movements of the hand and wrist needed to perform ADLs can help address performance deficits and be exploited in designing myoelectrical control systems for prosthetics and computer interfaces.",6
Detecting Threatening Behavior Using Bayesian Networks,"Ghazi AlGhamdi, Kathryn B Laskey, Xun Wang, Daniel Barbará, Thomas Shackelford, Edward J Wright, Julie Fitzgerald",2006/3/6,"Description This paper presents an innovative use of human behavior models for detecting insider threats to information systems. While most work in information security concerns detecting and responding to intruders, violations of system security policy by authorized computer users present a major threat to information security. A promising approach to detection and response is to model behavior of normal users and threats, and apply sophisticated inference methods to detect patterns of behavior that deviate from normal behavior in ways suggesting a possible security threat. This paper presents an approach, based on multi-entity Bayesian networks, to modeling user queries and detecting situations in which users in sensitive positions may be accessing documents outside their assigned areas of responsibility. Such unusual access patterns might be characteristic of users attempting illegal activities such as disclosure of classified information. We present a scalable proof of concept behavior model, provide an experimental demonstration of its ability to detect unusual access patterns in simulated situations, and describe future plans to increase the realism and fidelity of the model.","This paper presents an innovative use of human behavior models for detecting insider threats to information systems. While most work in information security concerns detecting and responding to intruders, violations of system security policy by authorized computer users present a major threat to information security. A promising approach to detection and response is to model behavior of normal users and threats, and apply sophisticated inference methods to detect patterns of behavior that deviate from normal behavior in ways suggesting a possible security threat. This paper presents an approach, based on multi-entity Bayesian networks, to modeling user queries and detecting situations in which users in sensitive positions may be accessing documents outside their assigned areas of responsibility. Such unusual access patterns might be characteristic of users attempting illegal activities such as disclosure of classified information. We present a scalable proof of concept behavior model, provide an experimental demonstration of its ability to detect unusual access patterns in simulated situations, and describe future plans to increase the realism and fidelity of the model.",6
An approximate median polish algorithm for large multidimensional data sets,"Daniel Barbará, Xintao Wu",2003/11,Journal Knowledge and information systems,"Exploratory data analysis is a widely used technique to determine which factors have the most influence on data values in a multi-way table, or which cells in the table can be considered anomalous with respect to the other cells. In particular, median polish is a simple yet robust method to perform exploratory data analysis. Median polish is resistant to holes in the table (cells that have no values), but it may require many iterations through the data. This factor makes it difficult to apply median polish to large multidimensional tables, since the I/O requirements may be prohibitive. This paper describes a technique that uses median polish over an approximation of a datacube, easing the burden of I/O. The cube approximation is achieved by fitting log-linear models to the data. The results obtained are tested for quality, using a variety of measures. The technique scales to large datacubes and proves to give a good …",6
Gene interaction analysis using k-way interaction loglinear model: a case study on yeast data,"Xintao Wu, Daniel Barbará, Liying Zhang, Yong Ye",2003/8,Journal ICML03 Workshop on Machine Learning in Bioinformatics,"Microarray data provides a powerful basis for analysis of gene expression. Data mining methods such as clustering have been widely applied to microarray data to link genes that show similar expression patterns. However, this approach usually fails to unveil multiple interactions by the same gene. Association rule mining has been used for this purpose, but the inherent limitations of association rules limit the applicability of the results. In this paper we use a combination of association rule mining and loglinear modeling to discover k-gene interactions. Using this technique we can discover interactions among k-genes that cannot be explained by the combined effects of any of the subsets of those genes. We test our technique experimentally, using yeast microarray data. Our results reveal some previously unknown associations that have solid biological explanations.",6
Using fractals to compress real data sets: Is it feasible,"Xintao Wu, Daniel Barbara",2003,Journal Proc. of SIGKDD,"Fractal techniques based on iterated function systems have been successfully applied to the compression of low-dimensional data (eg, one-dimensional signals, two-dimensional images, and three-dimensional volume). Fractal compression partitions the original data set into range chunks which are replaced in the output data set by transformations that map large portions of the data set into blocks that resemble the original range partitions. This paper is an extension of applying fractal compression technique to real data sets. As the additional high dimensions increase the already high time complexity of the fractal technique, approximate search methods are investigated in the paper. Experiments over both real data sets and synthetic data sets show that fractal compression method performs competitively against other data reduction methods such as log-linear models.",6
Finding dense clusters in hyperspace: an approach based on row shuffling,"Daniel Barbará, Xintao Wu",2001/6/28,"Book Advances in Web-Age Information Management: Second International Conference, WAIM 2001 Xi’an, China, July 9–11, 2001 Proceedings","High dimensional data sets generally exhibit low density, since the number of possible cells exceeds the actual number of cells in the set. This characteristic has prompted researchers to automate the search for subspaces where the density is higher. In this paper we present an algorithm that takes advantage of categorical, unordered dimensions to increase the density of subspaces in the data set. It does this by shuffling rows in those dimensions, so the final ordering results in increased density of regions in hyperspace. We argue for the usage of this shuffling technique as a preprocessing step for other techniques that compress the hyperspace by means of statistical models, since denser regions usually result in better-fitting models. The experimental results support this argument. We also show how to integrate this algorithm with two grid clustering procedures in order to find these dense regions. The …",6
Supporting online queries in rolap,"Daniel Barbará, Xintao Wu",2000,"Conference Data Warehousing and Knowledge Discovery: Second International Conference, DaWaK 2000 London, UK, September 4–6, 2000 Proceedings 2","Data warehouses are becoming a powerful tool to analyze enterprise data. A critical demand imposed by the users of data warehouses is that the time to get an answer (latency) after posing a query is to be as short as possible. It is arguable that a quick, albeit approximate, answer that can be refined over time is much better than a perfect answer for which a user has to wait a long time. In this paper we addressed the issue of online support for data warehouse queries, meaning the ability to reduce the latency of the answer at the expense of having an approximate answer that can be refined as the user is looking at it. Previous work has address the online support by using sampling techniques. We argue that a better way is to preclassify the cells of the data cube into error bins and bring the target data for a query in “waves,” i.e., by fetching the data in those bins one after the other. The cells are classified into …",6
The Role of approximations in maintaining and using aggregate views,"Daniel Barbara, Xintao Wu",1999/12,Journal IEEE Data Eng. Bull.,,6
The AudioWeb,Daniel Barbara,1997/1/1,Book Proceedings of the sixth international conference on Information and knowledge management,"This paper describes the idea of a wide area information system based entirely on audio information (Audioweb). We address two issues. First, we address the issue of adding hyperaudio links to audio documents non-intrusively (Le., without the need to modify the audio track). By doing so, audio documents can be linked together to form the AudioWeb. Secondly, we show how, based on the audio format discussed previously, a series of interfaces (browsers), that enable the user to navigate a web of audio documents, can be implemented.",6
A file storage implementation for very large distributed systems,"Rafael Alonso, Daniel Barbara, Luis L Cova",1989/9/27,Conference Proceedings of the Second Workshop on Workstation Operating Systems,"The issues that must be considered in structuring file storage for very large distributed systems are discussed. The authors describe the distributed file system they are developing, which is called FACE (file system for ACE). The first prototype of FACE consists of a series of enhancements to Sun's network file system (NFS) in order to add a stashing capability. User processes interact with the system call interface to perform file and stashing operations. These operations may be invoked directly by user processes or by the FACE user-level routines. The FACE user-level routines implement diverse facilities to allow users to select the files that will be stashed (or dropped from the stash). The first FACE prototype is being implemented on a Sun 3/50 computer running Suri's Unix 4.2 release 3.3.< >",6
Real-time coordination of concurrent activities,"Sudhir Aggarwal, Daniel Barbara, Costas Courcoubetis",1987,"Journal Protocol Specification, Testing, and Verification, VI. North Holland, Amsterdam","In this paper we propose a model called Coordinated Concurrent Activities (CCA) for the real-time coordination of concurrent activities in distributed systems. We focus on three important aspects of the CCA model. The first aspect is the formal specification features that the model provides. The second aspect is the capability of analyzing the behavior of the system from its formal specification. The third aspect is the implementation of such a formally specified system. The implementation takes into account issues such as communication delays between machines, timing based on local clocks, and physical constraints on the speed that activities can be switched.",6
Specifying and Analyzing Protocols with SPANNER.,"Sudhir Aggarwal, Daniel Barbará, Kalman Z Meth",1986/6/22,Conference ICC,,6
Characterizing e-Business workloads using fractal methods,"D Menasc, Bruno Abrahão, D Barbar, Virgílio Almeida, Flávia Ribeiro",2002/7/31,Journal Journal of Web Engineering,Understanding the workload of Web and e-business sites is a fundamental step in sizing the IT infrastructure that supports these sites and in planning for their evolution so the Quality of Service (QoS) goals are met within cost constraints.,5
Adam: Detecting intrusions by data mining,"Daniel Barbará Julia Couto Sushil Jajodia, Leonard Popyack Ningning Wu",2001,Journal Workshop on Information Assurance and Security,"Intrusion detection systems have traditionally been based on the characterization of an attack and the tracking of the activity on the system to see if it matches that characterization. Recently, new intrusion detection systems based on data mining are making their appearance in the field. This paper describes the design and experiences with the ADAM (Audit Data Analysis and Mining) system, which we use as a testbed to study how useful data mining techniques can be in intrusion detection.",5
A randomized technique for remote file comparison,"Daniel Barbara, Richard J Lipton",1989/1/1,Conference Proceedings. The 9th International Conference on Distributed Computing Systems,"A technique for file comparison is presented that is based in a set of signatures that are selected by a randomized algorithm. The sites performing the comparison agree on this randomized set of signatures before any comparison takes place. This technique proves to be very competitive with previously published algorithms. It has an advantage over previous techniques in that one can set up the algorithm to diagnose up to a given number of different pages. This is done by changing the total number of bits sent to guarantee that the expected number of falsely diagnosed pages remains under a given level. A metric for comparing the complexity of file comparison techniques is introduced, based on the number of bits that the algorithm needs to send in order to diagnose a given number of differing pages while keeping the probability of false diagnosis under a certain level of confidence.<>",5
Em fingerprints: Towards identifying unauthorized hardware substitutions in the supply chain jungle,"Constantinos Kolias, Daniel Barbará, Craig Rieger, Jacob Ulrich",2020/5/21,Conference 2020 IEEE Security and Privacy Workshops (SPW),"This paper proposes a system capable of branding digital device components based on the EM signals typically emitted during their normal operational cycles. Such signals contain digital artifacts that are unique, which may act as an identifier of a particular device component e.g., its CPU, or the entire device if one chooses to take into account a combination of multiple such components. In real-life scenarios, this “bio-metrical” fingerprinting of hardware has to be conducted only once, possibly as part of an initial device configuration process with minimum additional maintenance time and cost, by the network administrators. At a subsequent stage, devices can get “authenticated” by comparing their newly emitted signals against the preexisting database during routine checks. The experimental results attest that the proposed approach can effectively protect a network against unrecognized potentially rogue devices …",4
Learning organizations of protein energy landscapes: An application on decoy selection in template-free protein structure prediction,"Nasrin Akhter, Liban Hassan, Zahra Rajabi, Daniel Barbará, Amarda Shehu",2019,Journal Protein Supersecondary Structures: Methods and Protocols,"The protein energy landscape, which lifts the protein structure space by associating energies with structures, has been useful in improving our understanding of the relationship between structure, dynamics, and function. Currently, however, it is challenging to automatically extract and utilize the underlying organization of an energy landscape to the link structural states it houses to biological activity. In this chapter, we first report on two computational approaches that extract such an organization, one that ignores energies and operates directly in the structure space and another that operates on the energy landscape associated with the structure space. We then describe two complementary approaches, one based on unsupervised learning and another based on supervised learning. Both approaches utilize the extracted organization to address the problem of decoy selection in template-free protein structure …",4
Fractal mining of association rules over interval data,"D Barbara, Z Nazeri",2000,"Publisher Technical Report, George Mason University, 2000, 9",,4
On the limits of em based detection of control logic injection attacks in noisy environments,"Kurt Vedros, Georgios Michail Makrakis, Constantinos Kolias, Min Xian, Daniel Barbara, Craig Rieger",2021/10/18,Conference 2021 Resilience Week (RWS),"The difficulty in applying traditional security mechanisms in Industrial Control System (ICS) environments makes a large portion of these mission-critical assets vulnerable to cyber attacks. Therefore, there is a dire need for the development of novel security mechanisms specifically designed to protect such critical systems. Recently a lot of attention has been given to mechanisms that exploit the EM emanations of devices for defense purposes. Such practices may lead to the development of robust external and non-intrusive anomaly detection systems. Nevertheless, the majority of current work in the area neglects to consider the implications of real-life environments, particularly environmental noise. In this work, we explore the limits of EM-based anomaly detection towards identifying injection attacks in control logic software in noisy environments. Our study conducted upon both synthetically generated and real …",3
Automated storytelling evaluation and story chain generation,"JT Rigsby, Daniel Barbará",2017/11/18,Conference 2017 IEEE International Conference on Data Mining Workshops (ICDMW),"Given a beginning and ending document, automated storytelling attempts to fill in intermediary documents to form a coherent story. This is a common problem for analysts; they often have two snippets of information and want to find the other pieces that relate them. Evaluation of the quality of the created stories is difficult and has routinely involved human judgment. This work extends the state of the art by providing quantitative methods of story quality evaluation which are shown to have good agreement with human judgment. Two methods of automated storytelling evaluation, dispersion and coherence are developed. Dispersion, a measure of story flow, ascertains how well the generated story flows away from the beginning document and towards the ending document. Coherence measures how well the articles in the middle of the story provide information about the relationship of the beginning and ending …",3
Using myoelectric signals to recognize grips and movements of the hand,"Gene Shuman, Zoran Durić, Daniel Barbara, Jessica Lin, Lynn H Gerber",2015/11/9,Conference 2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),"People want to live independently, but too often disabilities or advanced age robs them of the ability to do the necessary activities of daily living (ADLs). Finding relationships between electromyograms measured in the arm and movements of the hand and wrist needed to perform ADLs can help address performance deficits and be exploited in designing myoelectrical control systems for prosthetics and computer interfaces. This paper reports on several machine learning techniques employed to discover the electromyogram patterns present when using the hand to perform 14 typical fine motor functional activities used to accomplish ADLs. Classification and clustering techniques are employed. Improvements to accuracies are introduced, including the use of exponential smoothing and using a symbolic representation to approximate signal streams. Results show the patterns can be learned to an accuracy of …",3
transAD: An Anomaly Detection Network Intrusion Sensor for the Web,"Sharath Hiremagalore, Daniel Barbará, Dan Fleck, Walter Powell, Angelos Stavrou",2014,"Conference Information Security: 17th International Conference, ISC 2014, Hong Kong, China, October 12-14, 2014. Proceedings 17","Content-based Anomaly Detection (AD) techniques are regarded as a promising mechanism to detect ‘zero-day’ attacks. AD sensors have also been shown to perform better than signature-based systems in detecting polymorphic attacks. However, the False Positive Rates (FPRs) produced by current AD sensors have been a cause of concern. In this paper, we introduce and evaluate transAD, a system of network traffic inspection AD sensors that are based on Transductive Confidence Machines (TCM). Existing TCM-based implementations have very high FPRs when used as NIDS.",3
NSF workshop on industrial/academic cooperation in database systems,"Mike Carey, Len Seligman",1999/3/1,Journal ACM SIGMOD Record,"Many academic researchers in computer science want their research to be of relevance to industry. They would like to work on topics that enhance products and dab-intensive applications. However, often they are unable to discover which topics fall in that category. In addition, academics have incentives to write papers which will be easy to get accepted for publication in good journals and conferences. This normally requires algorithmic and/or mathematical content. The problem is to find projects which yield publishable papers yet are of interest to industry. One solution is for academics to listen to indus t (ial researchers describe projects and problems with significant intellectual, possibly mathematical or scientific, content. But researchers in industry have little incentive to give such talks. They must produce products and patents, not papers. In an effort to bridge this gap, the National Science Foundation sponsored …",3
The Case for Controlled Inconsistency in Replicated Data,"Hector Garcia-Molina, D Barbará",1990/11,Journal Proceedings of the IEEE Workshop on Replicated Data,"Although replication it is widely accepted as a good technique for increasing reliability and availability of data, it is also known as an expensive proposition, especially when the number of replicas increases. Protocols that keep the copies consistent, such as two-phase commit, require one or more rounds of mes-sages and have a high overhead in the overall performance. We claim that there are some applications that could run perfectly using copies that may not be consistent, as long as the application knows how much the copy can differ from the most recent version of the data.",3
Exploring deep neural network architectures: A case study on improving antimicrobial peptide recognition,"Manpriya Dua, Daniel Barbará, Amarda Shehu",2020/3/11,Journal Proceedings of the 12th international conference,"With antibiotic resistance on the rise, health organizations are urging for the design of new drug templates. Naturally-occurring antimicrobial peptides (AMPs) promise to serve as such templates, as they show lower likelihood for bacteria to form resistance. This has motivated wet and dry laboratories to seek novel AMPs. The sequence diversity of these peptides, however, renders systematic wet-lab screening studies either infeasible or too narrow in scope. Dry laboratories have focused instead on machine learning approaches. In this paper, we explore various deep neural network architectures aimed at improving antimicrobial peptide recognition. Our enquiry results in several architectures with comparable or better performance than existing, state-of-the-art discriminative models.",2
Detecting threatening behavior using Bayesian networks,"A Ghazi, K Laskey, X Wang, D Barbará, T Shackelford, E Wright",2006,Journal C4I papers,,2
Data-Mining Techniques for Microarray data analysis,"Carlotta Domeniconi, Daniel Barbará, Harsh Chaudhary, Ali Al-Timimi, Curtis Jamison",2005/3/8,Journal Next Generation of Data-Mining Applications,"Gene expression profiling studies via DNA microarrays offer unprecedented opportunities for advancing fundamental biological research and clinical practice (Schena et al., 1995; Debouck and Goodfellow, 1999; Aitman, 2001). Microarray technology allows researchers to simultaneously measure the expression level of tens of thousands of genes, creating a comprehensive overview of exactly what genes are being expressed in a specific tissue under various conditions. However, these studies produce a massive amount of data which need to be treated using informatics and algorithms that are sensitive to the biological context to produce meaningful results.",2
Proceedings of the 2003 SIAM International Conference on Data Mining,"Daniel Barbara, Chandrika Kamath",2003/5/1,Publisher Society for Industrial and Applied Mathematics,"The Third SIAM International Conference on Data Mining continues the tradition of providing an open forum for the presentation, discussion, and development of innovative algorithms, software, and theories for data mining applications and data intensive computation. This year's invited speakers will highlight new trends in algorithm development, discuss new trends and challenges for data mining from an industrial perspective, reveal important issues in both the monitoring and mining of network data streams, and expose important mathematical and computational problems that arise in protecting privacy during transactional database mining and analysis.",2
Agressive transmissions over redundant paths for time critical messages,"Hector Garcia-Molina, Ben Kao, Daniel Barbará",1992,"Publisher Tech. Rep. STAN-CS-92-1431, Stanford University","Fault-tolerant computer systems have redundant paths connecting their components. Given these paths, it is possible to use aggressive techniques to reduce the average value and variability of the response time for critical messages. One technique is to send a copy of a packet over an alternate path before it is known if the first copy failed or was delayed. A second technique is to split a single stream of packets over multiple paths. We analyze both approaches and show that they can provide significant improvements over conventional, conservative mechanisms.",2
The complexity of collapsing reachability graphs,"Sudhir Aggarwal, Daniel Barbara, Walter Cunto, Michael R Garey",1990,"Conference Automatic Verification Methods for Finite State Systems: International Workshop, Grenoble, France June 12–14, 1989 Proceedings 1","There is an increasing proliferation of communication protocols, ranging from low level physical layer to the application layers. Consequently, more and more tools are being developed for specification and validation of protocols. Many of these tools are based on describing the protocols as a set finite state machines ([BM80],[RW83],[ABM88],[HK89].) Validation of such protocols is generally based on the following approach. The global states of the protocol reachable from an initial state are determined using the descriptions of the component machines that make up the protocol and the rules for their composition. The result of this procedure defines a graph, commonly referred to as the reachabUity graph. This directed graph has vertices that correspond to global states of the protocol, and edges that represent possible state transitions. Thus, paths in the directed graph describe possible state trajectories and can be …",2
"Mutual exclusion in distributed systems (databases, voting, partitions)",Daniel Barbara,1985,Institution Princeton University,"This thesis studies the use of voting mechanisms as a tool to achieve mutual exclusion in Distributed Systems. As an example, consider a system that manages replicated data. In the event of a network partition, the system is divided into isolated groups of nodes. If we do not want these copies to diverge, we should prevent more than one group from performing updates. The decision as to which group can update must be reached without communication among the groups.",2
Anomaly Detection-Based Recognition of Near-Native Protein Structures,"Sivani Tadepalli, Nasrin Akhter, Daniel Barbará, Amarda Shehu",2020/4/27,Journal IEEE Transactions on NanoBioscience,"The three-dimensional structures populated by a protein molecule determine to a great extent its biological activities. The rich information encoded by protein structure on protein function continues to motivate the development of computational approaches for determining functionally-relevant structures. The majority of structures generated in silico are not relevant. Discriminating relevant/native protein structures from non-native ones is an outstanding challenge in computational structural biology. Inherently, this is a recognition problem that can be addressed under the umbrella of machine learning. In this paper, based on the premise that near-native structures are effectively anomalies, we build on the concept of anomaly detection in machine learning. We propose methods that automatically select relevant subsets, as well as methods that select a single structure to offer as prediction. Evaluations are carried out on …",1
Identifying near-native protein structures via anomaly detection,"Sivani Tadepalli, Nasrin Akhter, Daniel Barbará, Amarda Shehu",2019/11/18,Conference 2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),"Discriminating biologically-active/native tertiary protein structures from non-native ones is an outstanding challenge in computational structural biology. Computationally, the task involves teasing out near-native structures out of several thousands generated in silico. In this paper we build on the concept of anomaly detection in machine learning and propose several methods for discriminating near-native structures. Evaluations on benchmark datasets demonstrate that the proposed methods advance the state of the art and warrant further research on adapting concepts and techniques from machine learning to improve recognition of near-native structures in template-free protein structure prediction.",1
Storytelling with Signal Injection: Focusing Stories with Domain Knowledge,"JT Rigsby, Daniel Barbará",2018,"Conference Machine Learning and Data Mining in Pattern Recognition: 14th International Conference, MLDM 2018, New York, NY, USA, July 15-19, 2018, Proceedings, Part II 14","Given a beginning and ending document, automated storytelling attempts to fill in intermediary documents to form a coherent story. This is a common problem for analysts; they often have two snippets of information and want to find the other pieces that relate them. The goal of storytelling is to help the analysts limit the number of documents that must be sifted through and show connections between events, people, organizations, and places. But existing algorithms fail to allow for the insertion of analyst knowledge into the story generation process. Often times, analysts have an understanding of the situation or prior knowledge that could be used to focus the story in a better way. A storytelling algorithm is proposed as a multi-criteria optimization problem that allows for signal injection by the analyst while maintaining good story flow and content.",1
Clustering Metagenome Sequences Using Canopies,"Mohammad Arifur Rahman, Nathan LaPierre, Huzefa Rangwala, Daniel Barbara",2017,Journal Proc. 9th Int. Conf. Bioinf. Comput. Biol.,"Advances in biotechnologies has allowed for the collective sequencing of co-existing microbial communities (Metagenomics). These microbial communities are ubiquitous across various clinical and ecological environments. Metagenomics has spurred the development of several bioinformatics approaches for analyzing the diversity, abundance and functions of different organisms within these communities.",1
Higher-order representations for automated organization of protein structure space,"Kevin Molloy, JM Van, Daniel Barbará, Amarda Shehu",2013/6,"Journal IEEE International Conference on Computational Advances in Bio and Medical Sciences (ICCABS), New Orleans, LA","Due to rapid sequencing of genomes, there are millions of deposited protein sequences with no known function. Fast sequence-based comparisons allow detecting close homologs for a protein of interest to transfer functional information from the homologs to the given protein. Sequence-based comparison cannot detect remote homologs, in which evolution has adjusted the sequence while preserving structure. Structure-based comparisons can detect remote homologs but are too expensive to apply at a large scale over structural databases of proteins. Fragment-based structural representations allow fast detection of remote homologs with reasonable accuracy and can also be used to obtain linearly-reducable maps of protein structure space.",1
Categorization of Unlabeled Documents driven by Word Weighting,"Ning Kang, Carlotta Domeniconi, Daniel Barbará",2006,"Description In text mining we often have to handle large document collections. The labeling of such large corpuses of documents is too expensive and impractical. Thus, there is a need to develop (unsupervised) clustering techniques for text data, where the distributions of words can vary significantly from one category to another.The vector space model of documents easily leads to a 30000 or more dimensions. In such high dimensionality, the effectiveness of any distance function that equally uses all input features is severely compromised. Furthermore, it is expected that different words may have different degrees of relevance for a given category of documents, and a single word may have a different importance across different categories.","In text mining we often have to handle large document collections. The labeling of such large corpuses of documents is too expensive and impractical. Thus, there is a need to develop (unsupervised) clustering techniques for text data, where the distributions of words can vary significantly from one category to another.",1
Compressing high dimensional datasets by fractals,"Xintao Wu, Daniel Barbará",2003/1/1,Conference Data Compression Conference,"Summary form only given. Fractal technique extensions to general datasets were proposed. The high-dimensional dataset can be viewed as a collection of cells that represent some measure on an integer nD grid. The measure over different scales along the dimension's hierarchies may exhibit self-similarities. A two-phase searching strategy was applied to overcome the increased searching time caused by additional dimensions. The search scheme checks a small number of spatially close local domain chunks. The data structure used is defined by 2/sup n/-tree which is a natural extension of quadtree (for image) and cotree (for volume). Each node, corresponding to a range chunk or a domain chunk, contains the summary information used for local matching. The experimental results have shown that the performance of fractal compression is comparable with rivals such as nonlinear model. The experiments over …",1
Data Mining Tutorial,Daniel Barbará,2000/6,Journal George Mason Universisty,,1
LAN Broadcast Protocols for Implementing the CCA Model,"Sudhir Aggarwal, Daniel Barbará, Costas Courcoubetis",1987/5/5,"Book Proceedings of the IFIP WG6. 1 Seventh International Conference on Protocol Specification, Testing and Verification VII",,1
Multiple Instance Learning for Detecting Anomalies over Sequential Real-World Datasets,"Parastoo Kamranfar, David Lattanzi, Amarda Shehu, Daniel Barbará",2022/10/4,Journal arXiv preprint arXiv:2210.01707,"Detecting anomalies over real-world datasets remains a challenging task. Data annotation is an intensive human labor problem, particularly in sequential datasets, where the start and end time of anomalies are not known. As a result, data collected from sequential real-world processes can be largely unlabeled or contain inaccurate labels. These characteristics challenge the application of anomaly detection techniques based on supervised learning. In contrast, Multiple Instance Learning (MIL) has been shown effective on problems with incomplete knowledge of labels in the training dataset, mainly due to the notion of bags. While largely under-leveraged for anomaly detection, MIL provides an appealing formulation for anomaly detection over real-world datasets, and it is the primary contribution of this paper. In this paper, we propose an MIL-based formulation and various algorithmic instantiations of this framework based on different design decisions for key components of the framework. We evaluate the resulting algorithms over four datasets that capture different physical processes along different modalities. The experimental evaluation draws out several observations. The MIL-based formulation performs no worse than single instance learning on easy to moderate datasets and outperforms single-instance learning on more challenging datasets. Altogether, the results show that the framework generalizes well over diverse datasets resulting from different real-world application domains.",
Active authentication of users,"Angelos Stavrou, Rahul Murmuria, Ryan Johnson, Daniel Barbara",2019/5/14,Patent office US,"Embodiments herein disclose a method and system for actively authenticating users of an electronic device in a continuous manner using a plurality of factors comprising of biometric modalities, power consumption, application usage, user interactions, user movement, and user location/travel.",45
Higher-order representations of protein structure space,"Kevin Molloy, M Jennifer Van, Daniel Barbara, Amarda Shehu",2013/6/12,Conference 2013 IEEE 3rd International Conference on Computational Advances in Bio and medical Sciences (ICCABS),"Fragment-based representations of protein structure have recently been proposed to identify remote homologs with reasonable accuracy. The representations have also been shown through PCA to elucidate low-dimensional maps of protein structure space. In this work we conduct further analysis of these representations, showing that the low-dimensional maps preserve functional co-localization. Moreover, we employ Latent Dirichlet Allocation to investigate a new, topic-based representation. We show through various techniques adapted from text mining that the topics have unique signatures over structural classes and allow a complementary yet informative organization of protein structure space.",
2005 KAIS Reviewers,Springer London Ltd,2005/11,Journal Knowledge and Information Systems,"Knowledge and Information Systems wishes to acknowledge and thank the individuals listed below, who have provided their time and valuable experience to review manuscripts during the past year. It is only through the dedicated efforts of these individuals and those on the Editorial Board listed on the inner front cover, who have also provided valuable input and support, that the quality of publication in the Journal can be maintained.",
"Workshop on Link Analysis, Counterterrorism and Security","Sutton Place Hotel, David Skillicorn, Kathleen Carley, Bülent Yener, Rensselaer Ankur Teredesai, RIT Edna Reid, Bill Pottenger, Lehigh Scott Knight, Bernardo Huberman, Susan Gauch, Christos Faloutsos, CMU Li-Chiou Chen, Malú Castellanos, Murray Browne, Steve Borgatti, Michael W Berry, Daniel Barbará",2005/4/23,"Description The Enron email corpus is appealing to researchers because it is a) a large scale email collection from b) a real organization c) over a period of 3.5 years. For research related to Social Networks, Organizational Theory, and Organizational Behavior this dataset is of particular interest and potential value because it enables","The Enron email corpus is appealing to researchers because it is a) a large scale email collection from b) a real organization c) over a period of 3.5 years. For research related to Social Networks, Organizational Theory, and Organizational Behavior this dataset is of particular interest and potential value because it enables",
Fractal Mining,"Daniel Barbara, Ping Chen",2005,Journal Data Mining and Knowledge Discovery Handbook,"Self-similarity is the property of being invariant with respect to the scale used to look at the data set. Self-similarity can be measured using the fractal dimension. Fractal dimension is an important charactaristics for many complex systems and can serve as a powerful representation technique. In this chapter, we present a new clustering algorithm, based on self-similarity properties of the data sets, and also its applications to other fields in Data Mining, such as projected clustering and trend analysis. Clustering is a widely used knowledge discovery technique. The new algorithm which we call Fractal Clustering (FC) places points incrementally in the cluster for which the change in the fractal dimension after adding the point is the least. This is a very natural way of clustering points, since points in the same clusterhave a great degree of self-similarity among them (and much less self-similarity with respect to points …",
Multimedia applications,"Duminda Wijesekera, Daniel Barbará",2002/1/1,Book Handbook of data mining and knowledge discovery,"As multimedia proliferate throughout the computing domain, ever more documents are being made using semantically rich audiovisual media. Consequently, mining knowledge hidden in multimedia documents is a complex task that involves fusing data from many media and depends upon basic capabilities of identifying basic features in audio and video streams. Existing work in this area mines for cinematic structures, interesting audiovisual sequences and spatiotemporal rules, and medical imaging.",
Session details: Special section on data mining for intrusion detection and threat analysis,Daniel Barbará,2001/12/1,Journal ACM SIGMOD Record,,
Protecting File Systems Against Corruption Using Checksums,"Daniel Barbará, Rajni Goel, Sushil Jajodia",2001,Journal Data and Application Security: Developments and Directions,"We consider the problem of malicious attacks that lead to corruption of files in a file system. A typical method to detect such corruption is to compute signatures of all the files and store these signatures in a secure place. A malicious modification of a file can be detected by verifying the signature. This method, however, has the weakness that it cannot detect an attacker who has access to some of the files and the signatures (but not the signing transformation) and who replaces some of the files by their old versions and the corresponding signatures by the signatures of the old versions.",
TOPICS OF INTEREST,"Elisa Bertino, Daniel Barbara, Ami Motro, Stefano Ceri, Christian S Jensen",1998/2/23,"Description Authors are also required to send an abstract of the paper by e-mail to the above address by May 26, 1997. The message should be in ASCII format and contain the title of the paper, authors’ names, the abstract, the name of one or two areas most relevant to the paper and whether the paper is submitted to the Industrial program","Authors are also required to send an abstract of the paper by e-mail to the above address by May 26, 1997. The message should be in ASCII format and contain the title of the paper, authors’ names, the abstract, the name of one or two areas most relevant to the paper and whether the paper is submitted to the Industrial program",
Information systems research at George Mason University,"Sushil Jajodia, Daniel Barbara, Alex Brodsky, Larry Kerschberg, Ami Motro, Edgar Sibley, X Sean Wang",1997/12/1,Journal ACM SIGMOD Record,"George Mason University began as an independent state university in 1972. Its development has been marked by rapid growth and innovative planning, resulting in an enrollment of more than 24,000 students in 1997. It is located in Fairfax, Virginia—about fifteen miles southwest of Washington, DC—near many governmental agencies and industrial firms specializing in information-intensive products and services.",
Databases and mobile computing,"Daniel Barbara, Ravi Jain, Narayanan Krishnakumar",1996/7/31,Volume 3,"Database and Mobile Computing brings together in one place important contributions and up-to-date research results in this important area. Databases and Mobile Computing serves as an excellent reference, providing insight into some of the most important research issues in the field.",
Special issue on databases and mobile computing-Guest Editors' introduction,"D Barbara, R Jain, N Krishnakumar",1996/7/1,Source DISTRIBUTED AND PARALLEL DATABASES,,
Electronic Catalogs-Panel,"Arthur M Keller, Don Brown, Anna-Lena Neches, Sherif Danish, Daniel Barbará",1996/2/26,Book Proceedings of the Twelfth International Conference on Data Engineering,,
The Impact of Database Research on Industrial Products,"D Barbara, J Blakeley, D Fishman, D Lomet",1994,Journal INTERNATIONAL CONFERENCE ON DATA ENGINEERING,,
Panel: the impact of database research on industrial products,"Jose Blakeley, David Fishman, David Lomet, C Mohan, Michael Stonebraker, Daniel Barbara",1994,"Journal PROC INT CONF DATA ENG, IEEE, LOS ALAMITOS, CA,(USA), 1994, 168",This panel will discuss the effect that database research carried out in academia and industry has had in products released by database companies over the years. The panelists will present cases taken from their own experience in developing products and will offer guidelines for judging the relevance of research in the area.,
The Impact of Database Research on Industrial Products (Panel Summary).,"Daniel Barbará, Jose A.  Blakeley, Daniel H.  Fishman, David B.  Lomet, Michael Stonebraker",1994,Journal SIGMOD Record,"Call for Nominations-2016 SIGMOD Systems Award The SIGMOD Systems Award is awarded to an individual or set of individuals to recognize the development of a piece of software that made a significant technical contribution to the database management field and which was made available for others to use. The nomination deadline is April 1, 2016.",
Interoperability with unstructured data and services,"Daniel Barbara, Yuri Breitbart, Hector Garcia-Molina, Henry F Korth, Sharad Mehrotra",1993/4/19,Conference Proceedings RIDE-IMS93: Third International Workshop on Research Issues in Data Engineering: Interoperability in Multidatabase Systems,"A large percentage of valuable information is not stored in database management systems. Therefore, many applications must deal only only with heterogeneous structured data, but with a wide variety of unstructured and semi-structured data such as electronic mail, documents, files and spreadsheets. In addition, these applications must deal with heterogeneous services such as an electronic library or an airline reservation service. While it is, of course, important to study interoperability among heterogeneous conventional database systems, it is also very important to study interoperation in this broader domain, where application programs must interact with a wide variety of services and must handle many types of structures, unstructured, and semi-structured data.< >",
Sharing Knowledge in a Heterogeneous Distributed System,"Daniel Barbarát, Chris Clifton",1993,Journal Database and Expert Systems Applications,"A large percentage of valuable electronic information is not stored in conventional database systems. Very often, applications have to deal with heterogeneous services such as electronic libraries, airline reservation systems or weather information services. Many times, finding these services and information can be an overwhelming task. In this paper, we describe a tool to facilitate the finding of such information. The cornerstone of the service is the idea of a broker. A broker indexes services and objects by their describing properties. A query to a broker returns enough information to contact the service and get the object or information needed. The type and amount of information indexed by the broker depends on the information that is known and available about the service or object. We present a simple but powerful design for the broker that is flexible enough to accommodate a wide variety of information providers. We also present a complete architecture for our distributed information system.",
Aggressive Transmissions Over Redundant Paths for Time Critical Messages,"Ben Kao, Hector Garcia-Molina, Daniel Barbara",1992,"Description Fault-tolerant computer systems have redundant paths connecting their components. Given these paths, it is possible to use aggressive techniques to reduce the average value and variability of the response time for critical messages. One technique is to send a copy of a packet over an alternative path before it is known if the first copy failed or was delayed. A second technique is to split a single stream of packets over multiple paths. We analyze both approaches and show that they can provide significant improvements over conventional, conservative mechanisms. (NTIS)","Fault-tolerant computer systems have redundant paths connecting their components. Given these paths, it is possible to use aggressive techniques to reduce the average value and variability of the response time for critical messages. One technique is to send a copy of a packet over an alternative path before it is known if the first copy failed or was delayed. A second technique is to split a single stream of packets over multiple paths. We analyze both approaches and show that they can provide significant improvements over conventional, conservative mechanisms. (NTIS)",
Polynets: providing reliable communications for distributed systems,"Daniel Barbará, Hector Garcia-Molina",1990/9/3,Book Proceedings of the 4th workshop on ACM SIGOPS European workshop,"In spite of advances in fault tolerant computing, computer systems do fail or become unavailable more often than one would like. Pan of the reason is that modem computer systems are complex and contain many interconnected processors and components. Even if the individual processors are reliable, they can interact in ways that can bring down an entire system.",
Stashing as a fault-tolerant mechanism for distributed systems,"Luis L Cova, Rafael Alonso, Daniel Barbará",1990/9/3,Book Proceedings of the 4th workshop on ACM SIGOPS European workshop,"At the third ACM SIGOPS European Workshop the term stashing was introduced to define the idea of keeping local copies of key information to be used when a communi: cation failure occurred between servers and clients machines [Birrel188]. In that same workshop, we presented our views on autonomy in Very Large Distributed Systems (VLDS)[Alonso88]. Our ideas paralleled those proposed under the name of stashing, so we decided to also adopt the term. Since that workshop, we have been exploring how to implement a stashing facility in a distributed file system. We have identified the main design issues involved in providing this service and we have built a prototype to measure the overhead of the stashing service when instrumented within a Sun's Network File System implementation [Alonso90a].",
Random Walk Techniques for Protocol Validation,"Daniel Barbara, José L Palacios",1989,"Publisher Princeton University, Department of Computer Science",,
ses in PROLOG'Software Pract. & Exper. Vol 18 No 3 March 1988 pp,"S Aggarwal, D Barbara, K Meth, J Bigelow",1988/5,Journal Software (IEEE),'The future of Unix in the CASE renaissance'Software (IEEE) Vol 5 No 2 (March 1988) pp 18-22 This paper asserts that the CASE renaissance will link the commercial and scientific computing communities and that a standard version of Unix will provide the bridge.,
Session 2B Systems Diagnosis II Chairperson: M. Dal Cin,"D Barbara, H Garcia-Molina, CL Yang, GM Masson",1985,"Journal Digest of Papers: FTCS 15, the Fifteenth Annual International Symposium on Fault-Tolerant Computing, June 19-21, 1985, Horace H. Rackham Building, The University of Michigan, Ann Arbor, Michigan, USA",,
"George Mason University Fairfax, VA 22030 dbarbara@ gmu. edu 2 University of Houston-Downtown","Daniel Barbara, Ping Chen",Data Mining and Knowledge Discovery Handbook,Pages 573,"Self-similarity is the property of being invariant with respect to the scale used to look at the data set. Self-similarity can be measured using the fractal dimension. Fractal dimension is an important charactaristics for many complex systems and can serve as a powerful representation technique. In this chapter, we present a new clustering algorithm, based on self-similarity properties of the data sets, and also its applications to other fields in Data Mining, such as projected clustering and trend analysis. Clustering is a widely used knowledge discovery technique. The new algorithm which we call Fractal Clustering (FC) places points incrementally in the cluster for which the change in the fractal dimension after adding the point is the least. This is a very natural way of clustering points, since points in the same clusterhave a great degree of self-similarity among them (and much less self-similarity with respect to points in other clusters). FC requires one scan of the data, is suspendable at will, providing the best answer possible at that point, and is incremental. We show via experiments that FC effectively deals with large data sets, high-dimensionality and noise and is capable of recognizing clusters of arbitrary shape.",
Jaydeep Bhat 1850 Mahua Bhattacharya 2438 Jinbo Bi 330 Jiang Bian 1544 Xiaofei Bian 1492,"Xiangyun Bai, Abdullah Baihan, Tanvi Banerjee, Daniel Barbara, Megan Barefoot, Dhundy Bastola, Kristin P Bennett","Author Index Toggle navigation IEEE Computer Society Digital Library Jobs Tech News Resource 
Center Press Room Advertising About Us IEEE IEEE Computer Society IEEE Computer Society 
Digital Library My Subscriptions Magazines Journals Conference Proceedings Institutional 
Subscriptions IEEE IEEE Computer Society More Jobs Tech News Resource Center Press Room 
Advertising About Us Cart All Advanced Search Conference Cover Image Download 1.Home 
2.Proceedings 3.bibm 2019 Author Index 2019, pp. 1-32, DOI Bookmark: 
10.1109/BIBM47256.2019.8983208 Keywords Authors Author Index Keith Aaronson 995 Rashmie 
Abeysinghe 1948 Theresa Abiodun 1465,2421 Daniel Abrams 569 Subrata Acharya 2628,2655 
Torin Adamson 2041 Donald Adjeroh 279,1100,2029 Justin Ady 2393 Fatemeh Afghah 
2350 Giuseppe Agapito 2232,2239,2244 Sahil Aggarwal 2569 Ankur Agrawal 792 Shobhit …","Scholar articles Jaydeep Bhat 1850 Mahua Bhattacharya 2438 Jinbo Bi 330 Jiang Bian 1544 Xiaofei Bian 1492X Bai, A Baihan, T Banerjee, D Barbara, M Barefoot…All 2 versions ",,
Programme Committee Members,"S Abiteboul, D Agrawal, A Albano, PMG Apers, T Atwood, S Baker, D Barbara, J Blakeley, JB Bocca UK, R Brachman, M Casanova, S Ceri, S Chakravarthy, CC Chang, G Copeland, P Dadam, U Dayal, SM Deen UK, R Demolombe, A Deshpande, KR Dittrich, M Duzi, M Freeston, G Gardarin, H Garcia-Molina, N Gehani, A Gray IJK, J Gray, PMD Gray UK, E Hanson, R Hull, T Haerder, T Imielinski, Y Ioannidis, S Jajodia, P Kanellakis, M Kitsuregawa, P Larson, C Leung, W Litwin, D Lomet, P Lockemann, II Lu, R Lu, A Mendelzon, M Missikoff, E Moss, EJ Neuhold, S Nishio, S Osborn, T Ozsu, J Richardson, R Van de Riet, R Sacks-Davis, B Salzberg, II Samet, S Salza, W Samson UK, HJ Schek, A Silberschatz, W Staniszkis, P Stocker UK, M Stonebraker, YC Tay, B Wah, KY Whang, C Yu, L Zhou","Programme Committee Members Page 1 Programme Committee Members S. Abiteboul (France) 
D. Agrawal (USA) A. Albano (Italy) PMG Apers (The Netherlands) T. Atwood (USA) S. Baker 
(Ireland) D. Barbara (USA) J. Blakeley (USA) JB Bocca (UK) R. Brachman (USA) M. Casanova 
(Brazil) S. Ceri (Italy) S. Chakravarthy (USA) CC Chang (Taiwan) G. Copeland (USA) P. 
Dadam (Germany) U. Dayal (USA) SM Deen (UK) R. Demolombe (France) A. Deshpande 
(India) KR Dittrich (Switzerland) M. Duzi (Czechoslova.kia) M. Freeston (Germany) G. Gardarin 
(France) H. Garcia-Molina. (USA) N. Gehani (USA) A. Gray (IJK) J. Gray (USA) PMDGray 
(UK) E. Hanson (USA) R. Hull (USA) T. Haerder (Germany) T. Imielinski (USA) Y. Ioannidis 
(USA) S. Jajodia (USA) P. Kanellakis (USA) M. Kitsuregawa (Ja.pan) R. Lanzelot te (Brazil) 
P. Larson (Canada) C. Leung (Singapore) W. Litwin (France) D. Lomet (USA) P. Lockemann (…","Scholar articles Programme Committee MembersS Abiteboul, D Agrawal, A Albano, PMG Apers…All 4 versions ",,
Detecting outliers using transduction and statistical significance testing,"Daniel Barbará, Carlotta Domeniconi, James P Rogers, James P Rogers II","Finding points that are outliers with respect to a set of other points is an important task in data mining. Outlier detection can uncover important anomalies in fields like intrusion detection and fraud analysis. In data streaming, the presence of a large number of outliers indicates that the underlying process that is generating the data is undergoing significant changes and the models that attempt to characterize it need to be updated. Although there has been a significant amount of work in outlier detection, most of the algorithms in the literature resort to a particular definition of what an outlier is (eg, density-based), and use thresholds to detect them. In this paper we present a novel technique to detect outliers that does not impose any particular definition for them. The test we propose aims to diagnose whether a given point is an outlier with respect to an existing clustering model (ie, a set of points partitioned in groups). However, the test can also be successfully utilize to recognize outliers when the clustering information is not available. This test is based on Transductive Confidence Machines, which have been previously proposed as a mechanism to provide individual confidence measures on classification decisions. The test uses hypothesis testing to prove or disprove whether a point is fit to be in each of the clusters of the model. We demonstrate, experimentally, that the test is highly robust, and produces very few misdiagnosed points, even when no clustering information is available. We also show that the test can be succesfully applied to identify outliers present inside a data set for which no other information is available, thereby provinding the user …","Scholar articles Detecting outliers using transduction and statistical significance testingD Barbará, C Domeniconi, JP Rogers, JP Rogers IIRelated articles ","Finding points that are outliers with respect to a set of other points is an important task in data mining. Outlier detection can uncover important anomalies in fields like intrusion detection and fraud analysis. In data streaming, the presence of a large number of outliers indicates that the underlying process that is generating the data is undergoing significant changes and the models that attempt to characterize it need to be updated. Although there has been a significant amount of work in outlier detection, most of the algorithms in the literature resort to a particular definition of what an outlier is (eg, density-based), and use thresholds to detect them. In this paper we present a novel technique to detect outliers that does not impose any particular definition for them. The test we propose aims to diagnose whether a given point is an outlier with respect to an existing clustering model (ie, a set of points partitioned in groups). However, the test can also be successfully utilize to recognize outliers when the clustering information is not available. This test is based on Transductive Confidence Machines, which have been previously proposed as a mechanism to provide individual confidence measures on classification decisions. The test uses hypothesis testing to prove or disprove whether a point is fit to be in each of the clusters of the model. We demonstrate, experimentally, that the test is highly robust, and produces very few misdiagnosed points, even when no clustering information is available. We also show that the test can be succesfully applied to identify outliers present inside a data set for which no other information is available, thereby provinding the user …",
Notice and Invitation,"Ghadi Salem, Monson Hayes, Daniel Barbara, Jana Kosecka, Andrzej Manitius","Action analysis for mice has garnered wide attention in biomedical research. Mice are the most common mammalian animal model used in research laboratories. In recent years, researchers and laboratory support companies have recognized the utility of automated profiling of laboratory mouse activity and behavior in the home-cage. Video-based systems have emerged as a viable solution for non-invasive mouse monitoring. Animal facilities hold large numbers of mice housed inhome-cages' densely stored within ventilated racks. Automated analysis of mice activity in their home-cages can provide a new set of sensitive measures for detecting abnormalities and time-resolved deviation from baseline behavior. Large scale monitoring in animal facilities requires minimal footprint hardware that integrates seamlessly with the ventilated racks. Compactness of hardware imposes use of fisheye lenses positioned in close …","Scholar articles Notice and InvitationG Salem, M Hayes, D Barbara, J Kosecka, A Manitius","Action analysis for mice has garnered wide attention in biomedical research. Mice are the most common mammalian animal model used in research laboratories. In recent years, researchers and laboratory support companies have recognized the utility of automated profiling of laboratory mouse activity and behavior in the home-cage. Video-based systems have emerged as a viable solution for non-invasive mouse monitoring. Animal facilities hold large numbers of mice housed inhome-cages' densely stored within ventilated racks. Automated analysis of mice activity in their home-cages can provide a new set of sensitive measures for detecting abnormalities and time-resolved deviation from baseline behavior. Large scale monitoring in animal facilities requires minimal footprint hardware that integrates seamlessly with the ventilated racks. Compactness of hardware imposes use of fisheye lenses positioned in close …",
"Premkumar Devanbu, Michael Gertz, Charles Martel",,,,,
Theekshana Abayawickrama Emna Ben Abdallah 281 Vida Abedi 680,"Purang Abo1maesumi, Don Adjeroh, Tazin Afrin, Komal Agarwal, Kareem S Aggour, Ankur Agrawal, Tatsuya Akutsu, Abdulaziz Alamri, Reda Alhajj, Hesham Ali, Hayda Almeida, AI-Milaji Zahraa, Srinivas Aluru, Nancy Amato, Nawanol Ampompunt, AN Jing, Yuan An, Sandra Andorf, Sameer Antani, Maciej Antczak, Shinya Ariyasu, Jose A Arjona-Medina, Ahmet Ay, Ali Azari, Tian Bai, Akshay Balasubramanya, Yvan Bamps, Jasjit Banwait, Daniel Barbara, Josep Bassaganya-Riera680, Richard Beal, Tanja Bekhuis, Monika Belickova",Presents an index of the authors whose articles are published in the conference proceedings record.,"Scholar articles Theekshana Abayawickrama Emna Ben Abdallah 281 Vida Abedi 680P Abo1maesumi, D Adjeroh, T Afrin, K Agarwal…",Presents an index of the authors whose articles are published in the conference proceedings record.,
AU THOR IN DEX,"H Abe, C Aggarwal, I Ahmad, Aijun An, W Al-Khatib, KC Almeroth, L Alvisi, MH Ammar, An Aijun, YA Aslandogan, DP Ballou, D Barbara, FB Bastani, Beng Chin Ooi, PB Berra, E Bertino, B Bhargava, DL Bitzer, T Bozkaya, V Brusoni, N Cercone, C Chan, YI Chang, Chang Chia-Hui, WB ChangLiaw, Chang-Tien Lu, S Christodoulakis, P Ciancarini, A Colorni, L Console, M Dahlin, P Dasgupta, YF Day, DHC Du, MH Dunham, Du Zhang, A Fetterer, P Frasconi, L Fu, Fu Yongjian, A Ghafoor, J Ghosh, M Gori, A Grama, S Greco, SJ Green, H Gregersen, A Gupta, Han Jiawei, Han Jiawen, CC Hayes, Ho Lee Jang, Hong Tzung-Pei, Hsieh Jenwei","This index covers all technical items-papers, correspondence, reviews, etc.-that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the co-authors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under the primary entry in the Author Index.","Scholar articles AU THOR IN DEXH Abe, C Aggarwal, I Ahmad, A An, W Al-Khatib…All 4 versions ","This index covers all technical items-papers, correspondence, reviews, etc.-that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the co-authors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under the primary entry in the Author Index.",
IEEE SOFTWARE 1993 REFEREES,"Timothy С Abel, Dharma Agrawal, Yoshihiro Alriyama, Yahya Al-Salqan, Wayne P Men, Tom A Almy, Angel Alvarez, Gail A Alverson, Allen L Ambler, Paul E Ammann, Timodiy A Andrews, Stephen Andrlole, Mikio Aoyama, Keijiro Araki, Guillermo F Arango, Takashi Arano, James D Arthur, Yeshayahu Artsy, David Athersych, Kenn Atkinson, Brent J Auernheimer, Motoei Azuma, Paul Bailes, Venu P Banda, Allan P Bangs, Arvind K Bansal, Mehmet В Baray, Daniel Barbara, Naser Barghouti, Jack Barnard, Victor Basili, Remi Bastide, Peter C Bates, Bob Beck, Gerald M Berns, Ted Biggerstaff, Bob Binder, Matt Bishop, Mark R Blackburn, Michael Blaha, Patrick O Bobbie, Barry Boehm, Terry В Bollinger, Ronald Borgstahl, Pradip Bose, Terry Bossomaier, Adrian Bowles, John W Brackett, Sarah Brocklehurst, Graham R Brookes, David В Brown, Frank M Brown, Alan Brown, William L Bryan","1120 Science and Engineering Offices М/С 154 Page 1 lo become a referee, send a letter of 
interest staling your quoliffcations to Carl Chang University of Iflinœs 1120 Science and 
Engineering Offices М/С 154 PO Box 4348 Chicago, IL 60680 CSnet: c.chancj@uicbert.eecs.uic.edu 
IEEE SOFTWARE 1993 REFEREES Abel, Timothy С, Акт Adrion, W. Richards, University 
ofMassachusetts utAmherst Agrawal, Dharma, North Carolina State University Alriyama, 
Yoshihiro, IBM Japan Al-Salqan, Yahya, University of ¡Minois at Chicago Men, Wayne P., 
Microelectronics & Computer Almy, Tom A., Tektronix Alvarez, Angel, Ciudad Universitaria 
Alverson, Gail A, Tera Computer Ambler, Allen L., University of Kansas Ammann, Paul E., 
George Mason University Andrews, Timodiy A, Ontologie Andrlole, Stephen, Drexel University 
Aoyama, Mikio, Fujitsu Araki, Keijiro, Advanced Institute of Sdente and Technology Arango, …","Scholar articles IEEE SOFTWARE 1993 REFEREESTС Abel, D Agrawal, Y Alriyama, Y Al-Salqan, WP Men…All 3 versions ",,
"Elizabeth. Burnside 539, Greg. Butler 503, Gustavo. Caetano-Anolles 593, Hong. Cai 77","Bingjing Cai, Genevera Allen, Laurent Alquier, Mohammed Alshalalfa, Li An, Yuan An, Daniel Arend, Cecilia Arighi, Budak Arpinar, Fayez Aziz, Francisco Azuaje, Yu Bai, Fedor Bakalov, Nikolay Balov, Lauren Bange, Daniel Barbara, Abhirami Baskaran, Josep Bassaganya-Riera, Yuanzhe Bei, Alfredo Benso, Stefano Beretta, Pratibha Bhaskaran, Sandip Bhaumik, Sanjukta Bhowmick, Jinbo Bi, Xia Bi, Hongjin Bian, David Birnbach, Adrian Di Bisceglie, Keith Bisset, Timothy Block, Paola Bonizzoni, Claus Braun, Michael Brennan, Anca Bucur, Alex Bui, Dongfeng Cai, Vince Calhoun, Jamie Cannone, Yang Cao, Hongbao Cao, Stefano Di Carlo, Ben Carterette, Fabio Cerqueira, Philemon Chan, Shuyi Chen, Yu-Heng Chen, Jinbo Chen, Hung-I Harry Chen, Bolin Chen, Ruobing Chen, Yidong Chen, Brian Chen, Tzu-Yi Chen, Ming-Syan Chen, Ye Chen, Chun-Pei Cheng, Donavan T Cheng, Tak Chien Chiam, Wai-Ki Ching, Hamidreza Chitsaz, Young-Rae Cho, Jaehoon Choi, Anastasia Christianson, Eric Y Chuang, Joseph Ciervo, James Cleveland, Christian Colmsee",Presents an index of the authors whose articles are published in the conference proceedings record.,"Scholar articles Elizabeth. Burnside 539, Greg. Butler 503, Gustavo. Caetano-Anolles 593, Hong. Cai 77B Cai, G Allen, L Alquier, M Alshalalfa, L An, Y An…",Presents an index of the authors whose articles are published in the conference proceedings record.,
Tracking the Lyapunov Exponent in data streams,"Raphael Ladysz, Daniel Barbará","Temporal data mining: algorithms, theory and applications (TDM 2005)",Pages 53,"1 Even though many physical phenomena exhibit non-linear behavior, time series data mining techniques have largely concentrated in analyzing linear processes. In this paper we address the issue of measuring and tracking chaotic behavior in a data stream. Chaotic behavior can be measured through the Lyapunov Exponent, which loosely speaking, measures the rate of deviation between two neighbors in the series as time evolves. While algorithms to measure the Lyapunov Exponent exist in the literature, no technique has previously developed to track it as data points arrive continuously to a sensor. We present in this paper a technique that can effectively manage to track the exponent by taking advantage of the computations done previously to receiving a new batch of points. Measuring chaotic behavior has proven important in discovering changes in a system: for instance, it has been successfully utilized to predict the onset of epileptic attacks in patients. We demonstrate, through experimentation, that our technique is robust with respect to a large range of choices for the parameters used, while being able to quickly track drastic changes of chaotic behavior (from linear to non-linear phenomena and viceversa). We show results of applying our algorithm to a series of real data sets in a variety of applications such as£ nancial, environmental, and medical.",
Program Committee Vice Chairs,"Daniel Barbara, Tamraparni Dasu, Inderjit Dhillon, Venkatesh Ganti, Bart Goethals, Dimitrios Gunopulos, Hillol Kargupta, George Karypis, S Muthu Muthukrishnan, Dino Pedreschi, Jian Pei, Sunita Sarawagi, Arno Siebes, Jeffrey Xu Yu, Dimitris Achlioptas, Gediminas Adomavicius, Gagan Agarwal, Charu Aggarwal, Eugene Agichtein, Hiroki Arimura, Arindam Banerjee, Francesco Bonchi, Jean-Francois Boulicaut, Paul Bradley, Erick Cantu-Paz, Philip Chan, Kevin Chang, Sanjay Chawla, Hsinchun Chen, Ming-Syan Chen, David Wai-lok Cheung, Chris Clifton, Frans Coenen, Diane Cook, Rob Cooley, Graham Cormode, Honghua Dai, Gautam Das, Chris Ding, Alin Dobra, Carlotta Domeniconi","Program Committee Page 1 xxi Program Committee Program Committee Vice Chairs 
Daniel Barbara, George Mason University, USA Tamraparni Dasu, AT&T Research Labs, 
USA Inderjit Dhillon, University of Texas at Austin, USA Venkatesh Ganti, Microsoft 
Research, USA Bart Goethals, University of Antwerp, Belgium Dimitrios Gunopulos, 
University of California, Riverside, USA Hillol Kargupta, University of Maryland, Baltimore 
County & Agnik, LLC, USA George Karypis, University of Minnesota, USA S. Muthu 
Muthukrishnan, Rutgers University, USA Dino Pedreschi, Univ. of Pisa, Italy Jian Pei, State 
University of New York at Buffalo, USA Sunita Sarawagi, Indian Institute of Technology, 
Bombay, India Arno Siebes, Utrecht University, Netherlands Jeffrey Xu Yu, Chinese 
University of Hong Kong, PR China Program Committee Members Dimitris Achlioptas, 
Microsoft Research, USA Gediminas Adomavicius, University …","Scholar articles Program Committee Vice ChairsD Barbara, T Dasu, I Dhillon, V Ganti, B Goethals…All 2 versions ",,
Clustering Ensembles for Categorical Data,"Muna Al-Razgan, Carlotta Domeniconi, Daniel Barbará",Cluster ensembles offer a solution to challenges inherent to clustering arising from its ill-posed nature. In this paper we focus on the design of ensembles for categorical data. Our approach leverages diverse input clusterings discovered in random subspaces. We experimentally demostrate the efficacy of our technique in combination with the categorical clustering algorithm COOLCAT.,"Scholar articles Clustering Ensembles for Categorical DataM Al-Razgan, C Domeniconi, D BarbaráRelated articles All 6 versions ",Cluster ensembles offer a solution to challenges inherent to clustering arising from its ill-posed nature. In this paper we focus on the design of ensembles for categorical data. Our approach leverages diverse input clusterings discovered in random subspaces. We experimentally demostrate the efficacy of our technique in combination with the categorical clustering algorithm COOLCAT.,
TITLE FRACTAL MINING,"Daniel Barbara, Ping Chen","Self-similarity is the property of being invariant with respect to the scale used to look at the data set. While fractals are self-similar at every scale used to look at them, many data sets exhibit self-similarity over a range of scales. Self-similarity can be measured using the fractal dimension. Fractal dimension is an important charactaristics for many complex systems and can serve as a powerful representation technique. In this chapter, we present a new clustering algorithm, based on self-similarity properties of the data sets, and also its applications to other fields in data mining, such as projected clustering and trend analysis. Clustering is a widely used knowledge discovery technique. It helps uncovering structures in data that were not previously known. The clustering of large data sets has received a lot of attention in recent years, however, clustering is a still a challenging task since many published algorithms fail to do well in scaling with the size of the data set and the number of dimensions that describe the points, or in finding arbitrary shapes of clusters, or dealing effectively with the presence of noise. The new algorithm which we call Fractal Clustering (FC) places points incrementally in the cluster for which the change in the fractal dimension after adding the point is the least. This is a very natural way of clustering points, since points in the same clusterhave a great degree of self-similarity among them (and much less selfsimilarity with respect to points in other clusters). FC requires one scan of the data, is suspendable at will, providing the best answer possible at that point, and is incremental. We show via experiments that FC effectively deals with …","Scholar articles TITLE FRACTAL MININGD Barbara, P ChenRelated articles All 3 versions ","Self-similarity is the property of being invariant with respect to the scale used to look at the data set. While fractals are self-similar at every scale used to look at them, many data sets exhibit self-similarity over a range of scales. Self-similarity can be measured using the fractal dimension. Fractal dimension is an important charactaristics for many complex systems and can serve as a powerful representation technique. In this chapter, we present a new clustering algorithm, based on self-similarity properties of the data sets, and also its applications to other fields in data mining, such as projected clustering and trend analysis. Clustering is a widely used knowledge discovery technique. It helps uncovering structures in data that were not previously known. The clustering of large data sets has received a lot of attention in recent years, however, clustering is a still a challenging task since many published algorithms fail to do well in scaling with the size of the data set and the number of dimensions that describe the points, or in finding arbitrary shapes of clusters, or dealing effectively with the presence of noise. The new algorithm which we call Fractal Clustering (FC) places points incrementally in the cluster for which the change in the fractal dimension after adding the point is the least. This is a very natural way of clustering points, since points in the same clusterhave a great degree of self-similarity among them (and much less selfsimilarity with respect to points in other clusters). FC requires one scan of the data, is suspendable at will, providing the best answer possible at that point, and is incremental. We show via experiments that FC effectively deals with …",
Mining Conditions in Rapid Intensifications of Tropical Cyclones---A successful example of scientific data mining---,"Jiang Tang, Ruixin Yang, Daniel Barbara, Menas Kafatos","Rapid intensification (RI) of tropical cyclones (TC) is a major error source in TC intensity forecasting. Unexpectedly strong storms can cause substantial damages and losses. In order to improve RI probability estimation, the association rule is used in this study in order to mine candidate sets of factors which have strong interactions with rapidly intensifying TCs. Our mining results identified a reduced predictor set with fewer factors identified in previous studies but improved RI probabilities. This is a real, successful example of scientific data mining.","Scholar articles Mining Conditions in Rapid Intensifications of Tropical Cyclones---A successful example of scientific data mining---J Tang, R Yang, D Barbara, M KafatosRelated articles All 6 versions ","Rapid intensification (RI) of tropical cyclones (TC) is a major error source in TC intensity forecasting. Unexpectedly strong storms can cause substantial damages and losses. In order to improve RI probability estimation, the association rule is used in this study in order to mine candidate sets of factors which have strong interactions with rapidly intensifying TCs. Our mining results identified a reduced predictor set with fewer factors identified in previous studies but improved RI probabilities. This is a real, successful example of scientific data mining.",
1991 are listed below. Some of these reports are available for anonymous ftp or can be purchased from the Department. Details are given at the end of this report. TR-001-85 …,"Daniel Barbara, Frank Pittelli, Hector Garcia-Molina","Daniel D. Sleator, Robert E. Tarjan, and William P. Thurston In this note we summarize our recent results on rotation distance, a distance measure on binary trees with computer science applications. Our main result is that the maximum rotation distance between any two n-node binary trees is at most 2n 06 for n 11, and this bound is tight for in nitely many n.(10 pages, July 1985)TR-004-85 A Locally Adaptive Data Compression Scheme Jon Louis Bentley, Daniel E. Sleator, Robert E. Tarjan, and Victor K. Wei We describe a data compression scheme that exploits locality of reference, such as occurs when words are used frequently over short intervals and then fall into long periods of disuse. The scheme is based on a simple heuristic for self-organizing sequential search and on variable-length encodings of intergers. We prove that it never performs much worse than Hu man coding and can perform substantially better; experiments on real les show that its performance is usually quite close to that of Hu man coding. Our scheme has many implementation advantages; it is simple, allows fast encoding and decoding, and requires only one pass over the data to be compressed (static Hu man coding takes two passes).(30 pages, July 1985)","Scholar articles 1991 are listed below. Some of these reports are available for anonymous ftp or can be purchased from the Department. Details are given at the end of this report. TR-001-85 Mutual Exclusion in Partitioned Distributed SystemsD Barbara, F Pittelli, H Garcia-MolinaAll 6 versions ","Daniel D. Sleator, Robert E. Tarjan, and William P. Thurston In this note we summarize our recent results on rotation distance, a distance measure on binary trees with computer science applications. Our main result is that the maximum rotation distance between any two n-node binary trees is at most 2n 06 for n 11, and this bound is tight for in nitely many n.(10 pages, July 1985)",
