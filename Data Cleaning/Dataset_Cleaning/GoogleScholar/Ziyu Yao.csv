titles,authors,date,source,descriptions,citations
Unifiedskg: Unifying and multi-tasking structured knowledge grounding with text-to-text language models,"Tianbao Xie, Chen Henry Wu, Peng Shi, Ruiqi Zhong, Torsten Scholak, Michihiro Yasunaga, Chien-Sheng Wu, Ming Zhong, Pengcheng Yin, Sida I Wang, Victor Zhong, Bailin Wang, Chengzu Li, Connor Boyle, Ansong Ni, Ziyu Yao, Dragomir Radev, Caiming Xiong, Lingpeng Kong, Rui Zhang, Noah A Smith, Luke Zettlemoyer, Tao Yu",2022/1/16,Journal arXiv preprint arXiv:2201.05966,"Structured knowledge grounding (SKG) leverages structured knowledge to complete user requests, such as semantic parsing over databases and question answering over knowledge bases. Since the inputs and outputs of SKG tasks are heterogeneous, they have been studied separately by different communities, which limits systematic and compatible research on SKG. In this paper, we overcome this limitation by proposing the SKG framework, which unifies 21 SKG tasks into a text-to-text format, aiming to promote systematic SKG research, instead of being exclusive to a single task, domain, or dataset. We use UnifiedSKG to benchmark T5 with different sizes and show that T5, with simple modifications when necessary, achieves state-of-the-art performance on almost all of the 21 tasks. We further demonstrate that multi-task prefix-tuning improves the performance on most tasks, largely improving the overall performance. UnifiedSKG also facilitates the investigation of zero-shot and few-shot learning, and we show that T0, GPT-3, and Codex struggle in zero-shot and few-shot learning for SKG. We also use UnifiedSKG to conduct a series of controlled experiments on structured knowledge encoding variants across SKG tasks. UnifiedSKG is easily extensible to more tasks, and it is open-sourced at https://github.com/hkunlp/unifiedskg Latest collections at https://unifiedskg.com.",81
CoaCor: Code Annotation for Code Retrieval with Reinforcement Learning,"Ziyu Yao, Jayavardhan Reddy Peddamail, Huan Sun",2019,Conference The Web Conference 2019,"To accelerate software development, much research has been performed to help people understand and reuse the huge amount of available code resources. Two important tasks have been widely studied: code retrieval, which aims to retrieve code snippets relevant to a given natural language query from a code base, and code annotation, where the goal is to annotate a code snippet with a natural language description. Despite their advancement in recent years, the two tasks are mostly explored separately. In this work, we investigate a novel perspective of Code annotation for Code retrieval (hence called “CoaCor”), where a code annotation model is trained to generate a natural language annotation that can represent the semantic meaning of a given code snippet and can be leveraged by a code retrieval model to better distinguish relevant code snippets from others. To this end, we propose an effective …",81
Staqc: A systematically mined question-code dataset from stack overflow,"Ziyu Yao, Daniel S Weld, Wei-Peng Chen, Huan Sun",2018/4/10,Book Proceedings of the 2018 World Wide Web Conference,"Stack Overflow (SO) has been a great source of natural language questions and their code solutions (i.e., question-code pairs), which are critical for many tasks including code retrieval and annotation. In most existing research, question-code pairs were collected heuristically and tend to have low quality. In this paper, we investigate a new problem of systematically mining question-code pairs from Stack Overflow (in contrast to heuristically collecting them). It is formulated as predicting whether or not a code snippet is a standalone solution to a question. We propose a novel Bi-View Hierarchical Neural Network which can capture both the programming content and the textual context of a code snippet (i.e., two views) to make a prediction. On two manually annotated datasets in Python and SQL domain, our framework substantially outperforms heuristic methods with at least 15% higher F1 and accuracy. Furthermore …",70
Model-based interactive semantic parsing: A unified formulation and a text-to-SQL case study,"Ziyu Yao, Yu Su, Huan Sun, Wen-tau Yih",2019/10,Journal 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP'19),"As a pr o misi ng para di gm, i nter active se ma ntic p arsi ng has showntoim pr o ve b ot h se ma ntic parsi ng acc urac yand user con fi de nce int he res ults. I nt his pa per, we pr op ose a ne w, u ni fie d f or m ulati on of t he i nteracti ve se ma ntic parsi ng pr o ble m, w here t he g oal is to desi gnamo delb ase di ntelli ge nt a ge nt. T he a ge nt mai ntai ns its own state as t he c urre nt pre dicte d se ma ntic parse, deci des w het her andw here hu ma ni nterve nti on is nee de d, and ge nerates a clari ficati on q uesti onin nat ural la ng ua ge. A ke y part of t he a ge nt is aw orl dmo del: it ta kes a perce pt (eit her ani nitial q uesti on or su bse q ue nt fee d bac k fr omt he user) and tra nsiti o ns toa ne w state. We t he n pr op ose a si m ple yet re mar ka bl y effecti ve i nsta ntiati on of o ur fra me w or k, de mo nstrate dontwo te xt-t o-SQL datasets (Wi ki SQL and S pi der) wit h differe nt state-of-t he-art base se ma ntic parsers. C om pare dtoane xisti ngi nteracti ve se ma ntic parsi ngap pr oac ht hat treats t he base parser as a blac kbox, o ur ap pr oac h s olicits less user fee d bac kb ut yiel ds hi g her ru n-ti me acc urac y. 1",53
Reinforced dynamic reasoning for conversational question generation,"Boyuan Pan, Hao Li, Ziyu Yao, Deng Cai, Huan Sun",2019/7/29,Journal arXiv preprint arXiv:1907.12667,"This paper investigates a new task named Conversational Question Generation (CQG) which is to generate a question based on a passage and a conversation history (i.e., previous turns of question-answer pairs). CQG is a crucial task for developing intelligent agents that can drive question-answering style conversations or test user understanding of a given passage. Towards that end, we propose a new approach named Reinforced Dynamic Reasoning (ReDR) network, which is based on the general encoder-decoder framework but incorporates a reasoning procedure in a dynamic manner to better understand what has been asked and what to ask next about the passage. To encourage producing meaningful questions, we leverage a popular question answering (QA) model to provide feedback and fine-tune the question generator using a reinforcement learning mechanism. Empirical results on the recently released CoQA dataset demonstrate the effectiveness of our method in comparison with various baselines and model variants. Moreover, to show the applicability of our method, we also apply it to create multi-turn question-answering conversations for passages in SQuAD.",41
Interactive Semantic Parsing for If-Then Recipes via Hierarchical Reinforcement Learning,"Ziyu Yao, Xiujun Li, Jianfeng Gao, Brian Sadler, Huan Sun",2018/8/21,Conference arxiv,"Given a text description, most existing semantic parsers synthesize a program in one shot. However, it is quite challenging to produce a correct program solely based on the description, which in reality is often ambiguous or incomplete. In this paper, we investigate interactive semantic parsing, where the agent can ask the user clarification questions to resolve ambiguities via a multi-turn dialogue, on an important type of programs called “If-Then recipes.” We develop a hierarchical reinforcement learning (HRL) based agent that significantly improves the parsing performance with minimal questions to the user. Results under both simulation and human evaluation show that our agent substantially outperforms non-interactive semantic parsers and rule-based agents. 1",28
Semi-supervised multinomial naive bayes for text classification by leveraging word-level statistical constraint,"Li Zhao, Minlie Huang, Ziyu Yao, Rongwei Su, Yingying Jiang, Xiaoyan Zhu",2016/3/5,Journal Proceedings of the AAAI Conference on Artificial Intelligence,"Multinomial Naive Bayes with Expectation Maximization (MNB-EM) is a standard semi-supervised learning method to augment Multinomial Naive Bayes (MNB) for text classification. Despite its success, MNB-EM is not stable, and may succeed or fail to improve MNB. We believe that this is because MNB-EM lacks the ability to preserve the class distribution on words. In this paper, we propose a novel method to augment MNB-EM by leveraging the word-level statistical constraint to preserve the class distribution on words. The word-level statistical constraints are further converted to constraints on document posteriors generated by MNB-EM. Experiments demonstrate that our method can consistently improve MNB-EM, and outperforms state-of-art baselines remarkably.",25
Learning structural edits via incremental tree transformations,"Ziyu Yao, Frank F Xu, Pengcheng Yin, Huan Sun, Graham Neubig",2021/1/28,Journal arXiv preprint arXiv:2101.12087,"While most neural generative models generate outputs in a single pass, the human creative process is usually one of iterative building and refinement. Recent work has proposed models of editing processes, but these mostly focus on editing sequential data and/or only model a single editing pass. In this paper, we present a generic model for incremental editing of structured data (i.e., ""structural edits""). Particularly, we focus on tree-structured data, taking abstract syntax trees of computer programs as our canonical example. Our editor learns to iteratively generate tree edits (e.g., deleting or adding a subtree) and applies them to the partially edited data, thereby the entire editing process can be formulated as consecutive, incremental tree transformations. To show the unique benefits of modeling tree edits directly, we further propose a novel edit encoder for learning to represent edits, as well as an imitation learning method that allows the editor to be more robust. We evaluate our proposed editor on two source code edit datasets, where results show that, with the proposed edit encoder, our editor significantly improves accuracy over previous approaches that generate the edited program directly in one pass. Finally, we demonstrate that training our editor to imitate experts and correct its mistakes dynamically can further improve its performance.",19
An imitation game for learning semantic parsers from user interaction,"Ziyu Yao, Yiqi Tang, Wen-tau Yih, Huan Sun, Yu Su",2020/5/2,Journal arXiv preprint arXiv:2005.00689,"Despite the widely successful applications, bootstrapping and fine-tuning semantic parsers are still a tedious process with challenges such as costly data annotation and privacy risks. In this paper, we suggest an alternative, human-in-the-loop methodology for learning semantic parsers directly from users. A semantic parser should be introspective of its uncertainties and prompt for user demonstration when uncertain. In doing so it also gets to imitate the user behavior and continue improving itself autonomously with the hope that eventually it may become as good as the user in interpreting their questions. To combat the sparsity of demonstration, we propose a novel annotation-efficient imitation learning algorithm, which iteratively collects new datasets by mixing demonstrated states and confident predictions and re-trains the semantic parser in a Dataset Aggregation fashion (Ross et al., 2011). We provide a theoretical analysis of its cost bound and also empirically demonstrate its promising performance on the text-to-SQL problem. Code will be available at https://github.com/sunlab-osu/MISP.",18
Cliniqg4qa: Generating diverse questions for domain adaptation of clinical question answering,"Xiang Yue, Xinliang Frederick Zhang, Ziyu Yao, Simon Lin, Huan Sun",2021/12/9,Conference 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),"Clinical question answering (QA) aims to automatically answer questions from medical professionals based on clinical texts. Studies show that neural QA models trained on one corpus may not generalize well to new clinical texts from a different institute or a different patient group, where largescale QA pairs are not readily available for model retraining. To address this challenge, we propose a simple yet effective framework, CliniQG4QA, which leverages question generation (QG) to synthesize QA pairs on new clinical contexts and boosts QA models without requiring manual annotations. In order to generate diverse types of questions that are essential for training QA models, we further introduce a seq2seq-based question phrase prediction (QPP) module that can be used together with most existing QG models to diversify the generation. Our comprehensive experiment results show that the QA corpus generated by …",16
Synthetic question value estimation for domain adaptation of question answering,"Xiang Yue, Ziyu Yao, Huan Sun",2022/3/16,Journal arXiv preprint arXiv:2203.08926,"Synthesizing QA pairs with a question generator (QG) on the target domain has become a popular approach for domain adaptation of question answering (QA) models. Since synthetic questions are often noisy in practice, existing work adapts scores from a pretrained QA (or QG) model as criteria to select high-quality questions. However, these scores do not directly serve the ultimate goal of improving QA performance on the target domain. In this paper, we introduce a novel idea of training a question value estimator (QVE) that directly estimates the usefulness of synthetic questions for improving the target-domain QA performance. By conducting comprehensive experiments, we show that the synthetic questions selected by QVE can help achieve better target-domain QA performance, in comparison with existing techniques. We additionally show that by using such questions and only around 15% of the human annotations on the target domain, we can achieve comparable performance to the fully-supervised baselines.",5
A comprehensive study of staqc for deep code summarization,"Jayavardhan Peddamail, Ziyu Yao, Zhen Wang, Huan Sun",2018/8,"Journal Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Lond, UK","Learning the mapping between natural language (NL) and programming language, such as retrieving or generating code snippets based on NL queries and annotating code snippets using NL, has been explored by lots of research works [2, 19, 21]. At the core of these works are machine learning and deep learning models, which usually demand for large datasets of< NL, code> pairs for training. This paper describes an experimental study of StaQC [50], a large-scale and high-quality dataset of< NL, code> pairs in Python and SQL domain, systematically mined from the Stack Overflow forum (SO). We compare StaQC with two other popular datasets mined from SO on the code summarization task, showing that StaQC helps achieve substantially better results, improving the current state-of-the-art model by an order of 8%∼ 9% in BLEU metric.",3
A paradigm shift from “human writing” to “machine generation” in personality test development: An application of state-of-the-art natural language processing,"Philseok Lee, Shea Fyffe, Mina Son, Zihao Jia, Ziyu Yao",2023/2,Source Journal of Business and Psychology,"Natural language processing (NLP) techniques have become increasingly popular in areas of psychological assessment. Recently, researchers have sought to use NLP techniques for automatic item generation (AIG) in the personality domain. Nevertheless, NLP-based approaches to personality AIG are new and many questions are still unanswered. Our research builds upon previous illustrations of AIG in personality in several ways. First, we applied a prompt-based generative pre-trained transformer 3 (GPT-3) to generate personality items. This approach provides several practical advantages for researchers and practitioners compared to previous AIG approaches. Second, we thoroughly compared various psychometric properties between machine- and human-authored personality items. Lastly, we examined the measurement invariance of machine-authored personality items between gender groups to ensure …",1
Explaining Large Language Model-Based Neural Semantic Parsers (Student Abstract),"Daking Rai, Yilun Zhou, Bailin Wang, Ziyu Yao",2023/1/25,Journal arXiv preprint arXiv:2301.13820,"While large language models (LLMs) have demonstrated strong capability in structured prediction tasks such as semantic parsing, few amounts of research have explored the underlying mechanisms of their success. Our work studies different methods for explaining an LLM-based semantic parser and qualitatively discusses the explained model behaviors, hoping to inspire future research toward better understanding them.",
Proceedings of the Workshop on Structured and Unstructured Knowledge Integration (SUKI),"Wenhu Chen, Xinyun Chen, Zhiyu Chen, Ziyu Yao, Michihiro Yasunaga, Tao Yu, Rui Zhang",2022/7,Conference Proceedings of the Workshop on Structured and Unstructured Knowledge Integration (SUKI),,
Proceedings of the 1st Workshop on Natural Language Processing for Programming (NLP4Prog 2021),"Royi Lachmy, Ziyu Yao, Greg Durrett, Milos Gligoric, Junyi Jessy Li, Ray Mooney, Graham Neubig, Yu Su, Huan Sun, Reut Tsarfaty",2021/8,Conference Proceedings of the 1st Workshop on Natural Language Processing for Programming (NLP4Prog 2021),"The proliferation of programming-related platforms such as GitHub and Stack Overflow has led to large amounts of rich, open-source data consisting of programs associated with natural language, such as natural language questions and answers with code snippets, open-source repositories with natural language comments, and communications between software developers. At the same time, deep learning based techniques have shown promising performance for modeling both natural language and computer programs. Driven by these revolutions on data and models, recent years have witnessed a major resurgence of using NLP techniques to assist programming (NLP4Prog).",
"On Advancing Natural Language Interfaces: Data Collection, Model Development, and User Interaction",Ziyu Yao,2021,Institution The Ohio State University,"Natural language provides a universal and efficient way for humans to express their intent and perceive the world. This inspires a surge of natural language interface (NLI) systems, which enable humans to acquire knowledge and solve problems using solely natural language. These include question answering systems such as the early BASEBALL system and IBM Watson, as well as virtual assistants such as Amazon Alexa, Apple Siri, Google Home, and Microsoft Cortana.",
IEC: Towards Interest-Eliciting Neural Conversational Agents,"Ziyu Yao, Yizhe Zhang, Xiujun Li, Jianfeng Gao, Michel Galley, Chris Brockett, Huan Sun, Bill Dolan",2019,"Description Conversational agents need sufficient social skills to establish long-term connections with human users. Identifying users’ interests without explicitly asking about them, such as in salesperson-customer conversations, is among the most important social skills. In this paper we formulate the problem as an Interest-Eliciting Conversation (IEC) task, where a conversational agent must elicit users’ interests and shift to topics that can effectively drive the conversation forward. We present a first-of-its-kind research testbed with a neural user simulator and a set of competitive baseline agents. Some of these agents are equipped with a neural decision module to intelligently elicit users’ interests so as to sustainably anticipate and respond to their needs. We empirically demonstrate the effectiveness of the IEC agents and lay the foundation for the development of future conversational agents that are more user-engaging.","Conversational agents need sufficient social skills to establish long-term connections with human users. Identifying users’ interests without explicitly asking about them, such as in salesperson-customer conversations, is among the most important social skills. In this paper we formulate the problem as an Interest-Eliciting Conversation (IEC) task, where a conversational agent must elicit users’ interests and shift to topics that can effectively drive the conversation forward. We present a first-of-its-kind research testbed with a neural user simulator and a set of competitive baseline agents. Some of these agents are equipped with a neural decision module to intelligently elicit users’ interests so as to sustainably anticipate and respond to their needs. We empirically demonstrate the effectiveness of the IEC agents and lay the foundation for the development of future conversational agents that are more user-engaging.",
Code Editing from Few Exemplars by Adaptive Multi-Extent Composition,"Peizhao Li, Xuchao Zhang, Ziyu Yao, Wei Cheng, Haifeng Chen, Hongfu Liu",Deep Learning for Code Workshop,"Description This paper considers the computer source code editing with a few exemplars. The editing exemplar, containing the original and modified support code snippets, showcases a certain editorial pattern, and code editing adapts the common pattern derived from a few support exemplars to a query code snippet. In this work, we propose a compositional deep learning approach to solve this code editing problem automatically. Our learning approach combines edit representations extracted from support exemplars and compositionally generalizes them to the query code snippet editing via multi-extent similarities ensemble. Specifically, we parse the support and query code snippets using language-specific grammar into abstract syntax trees. We apply the similarities measurement in multiple extents from individual nodes to collective tree representations for query and support sample matching, and ensemble the matching results through a similarity-ranking error estimator. We evaluate the proposed method on C\# and Python datasets, and show up to 8.6\% accuracy improvements compared to non-composition baselines.","This paper considers the computer source code editing with a few exemplars. The editing exemplar, containing the original and modified support code snippets, showcases a certain editorial pattern, and code editing adapts the common pattern derived from a few support exemplars to a query code snippet. In this work, we propose a compositional deep learning approach to solve this code editing problem automatically. Our learning approach combines edit representations extracted from support exemplars and compositionally generalizes them to the query code snippet editing via multi-extent similarities ensemble. Specifically, we parse the support and query code snippets using language-specific grammar into abstract syntax trees. We apply the similarities measurement in multiple extents from individual nodes to collective tree representations for query and support sample matching, and ensemble the matching results through a similarity-ranking error estimator. We evaluate the proposed method on C\# and Python datasets, and show up to 8.6\% accuracy improvements compared to non-composition baselines.",
