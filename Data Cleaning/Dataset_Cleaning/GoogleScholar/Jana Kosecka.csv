titles,authors,date,source,descriptions,citations
An invitation to 3-d vision: from images to geometric models,"Yi Ma, Stefano Soatto, Jana Košecká, Shankar Sastry",2004/11,Volume 26,"This book is intended to give students at the advanced undergraduate or introduc tory graduate level, and researchers in computer vision, robotics and computer graphics, a self-contained introduction to the geometry of three-dimensional (3-D) vision. This is the study of the reconstruction of 3-D models of objects from a collection of 2-D images. An essential prerequisite for this book is a course in linear algebra at the advanced undergraduate level. Background knowledge in rigid-body motion, estimation and optimization will certainly improve the reader's appreciation of the material but is not critical since the first few chapters and the appendices provide a review and summary of basic notions and results on these topics. Our motivation Research monographs and books on geometric approaches to computer vision have been published recently in two batches: The first was in the mid 1990s with books on the …",2616
3d bounding box estimation using deep learning and geometry,"Arsalan Mousavian, Dragomir Anguelov, John Flynn, Jana Kosecka",2017,Conference Proceedings of the IEEE conference on Computer Vision and Pattern Recognition,"We present a method for 3D object detection and pose estimation from a single image. In contrast to current techniques that only regress the 3D orientation of an object, our method first regresses relatively stable 3D object properties using a deep convolutional neural network and then combines these estimates with geometric constraints provided by a 2D object bounding box to produce a complete 3D bounding box. The first network output estimates the 3D object orientation using a novel hybrid discrete-continuous loss, which significantly outperforms the L2 loss. The second output regresses the 3D object dimensions, which have relatively little variance compared to alternatives and can often be predicted for many object types. These estimates, combined with the geometric constraints on translation imposed by the 2D bounding box, enable us to recover a stable and accurate 3D object pose. We evaluate our method on the challenging KITTI object detection benchmark [??] both on the official metric of 3D orientation estimation and also on the accuracy of the obtained 3D bounding boxes. Although conceptually simple, our method outperforms more complex and computationally expensive approaches that leverage semantic segmentation, instance level segmentation and flat ground priors [??] and sub-category detection [??][??]. Our discrete-continuous loss also produces state of the art results for 3D viewpoint estimation on the Pascal 3D+ dataset [??].",915
Image based localization in urban environments,"Wei Zhang, Jana Kosecka",2006/6/14,"Conference Third international symposium on 3D data processing, visualization, and transmission (3DPVT'06)","In this paper we present a prototype system for image based localization in urban environments. Given a database of views of city street scenes tagged by GPS locations, the system computes the GPS location of a novel query view. We first use a wide-baseline matching technique based on SIFT features to select the closest views in the database. Often due to a large change of viewpoint and presence of repetitive structures, a large percentage of matches (> 50%) are not correct correspondences. The subsequent motion estimation between the query view and the reference view, is then handled by a novel and efficient robust estimation technique capable of dealing with large percentage of outliers. This stage is also accompanied by a model selection step among the fundamental matrix and the homography. Once the motion between the closest reference views is estimated, the location of the query view is then …",483
On evaluation of embodied navigation agents,"Peter Anderson, Angel Chang, Devendra Singh Chaplot, Alexey Dosovitskiy, Saurabh Gupta, Vladlen Koltun, Jana Kosecka, Jitendra Malik, Roozbeh Mottaghi, Manolis Savva, Amir R Zamir",2018/7/18,Journal arXiv preprint arXiv:1807.06757,"Skillful mobile operation in three-dimensional environments is a primary topic of study in Artificial Intelligence. The past two years have seen a surge of creative work on navigation. This creative output has produced a plethora of sometimes incompatible task definitions and evaluation protocols. To coordinate ongoing and future research in this area, we have convened a working group to study empirical methodology in navigation research. The present document summarizes the consensus recommendations of this working group. We discuss different problem statements and the role of generalization, present evaluation measures, and provide standard scenarios that can be used for benchmarking.",465
Video compass,"Jana Košecká, Wei Zhang",2002,"Conference Computer Vision—ECCV 2002: 7th European Conference on Computer Vision Copenhagen, Denmark, May 28–31, 2002 Proceedings, Part IV 7","In this paper we describe a flexible approach for determining the relative orientation of the camera with respect to the scene. The main premise of the approach is the fact that in man-made environments, the majority of lines is aligned with the principal orthogonal directions of the world coordinate frame. We exploit this observation towards efficient detection and estimation of vanishing points, which provide strong constraints on camera parameters and relative orientation of the camera with respect to the scene.",457
Vision guided navigation for a nonholonomic mobile robot,"Yi Ma, Jana Kosecka, S Shankar Sastry",1999/6,Journal IEEE Transactions on robotics and automation,"Theoretical and analytical aspects of the visual servoing problem have not received much attention. Furthermore, the problem of estimation from the vision measurements has been considered separately from the design of the control strategies. Instead of addressing the pose estimation and control problems separately, we attempt to characterize the types of control tasks which can be achieved using only quantities directly measurable in the image, bypassing the pose estimation phase. We consider the task of navigation for a nonholonomic ground mobile base tracking an arbitrarily shaped continuous ground curve. This tracking problem is formulated as one of controlling the shape of the curve in the image plane. We study the controllability of the system characterizing the dynamics of the image curve, and show that the shape of the image curve is controllable only up to its ""linear"" curvature parameters. We …",316
A comparative study of vision-based lateral control strategies for autonomous highway driving,"Camillo J Taylor, Jana Košecká, Robert Blasi, Jitendra Malik",1999/5,Journal The International Journal of Robotics Research,"With the increasing speeds of modern microprocessors, it has become ever more common                 for computer-vision algorithms to find application in real-time control tasks. In                 this paper, we present an analysis of the problem of steering an autonomous vehicle                 along a highway based on the images obtained from a CCD camera mounted in the                 vehicle. We explore the effects of changing various important system parameters like                 the vehicle velocity, the look-ahead range of the vision sensor, and the processing                 delay associated with the perception and control systems.",232
Piecewise planar city 3D modeling from street view panoramic sequences,"Branislav Micusik, Jana Kosecka",2009/6/20,Conference 2009 IEEE Conference on Computer Vision and Pattern Recognition,"City environments often lack textured areas, contain repetitive structures, strong lighting changes and therefore are very difficult for standard 3D modeling pipelines. We present a novel unified framework for creating 3D city models which overcomes these difficulties by exploiting image segmentation cues as well as presence of dominant scene orientations and piecewise planar structures. Given panoramic street view sequences, we first demonstrate how to robustly estimate camera poses without a need for bundle adjustment and propose a multi-view stereo method which operates directly on panoramas, while enforcing the piecewise planarity constraints in the sweeping stage. At last, we propose a new depth fusion method which exploits the constraints of urban environments and combines advantages of volumetric and viewpoint based fusion methods. Our technique avoids expensive voxelization of space …",204
Synthesizing training data for object detection in indoor scenes,"Georgios Georgakis, Arsalan Mousavian, Alexander C Berg, Jana Kosecka",2017/2/25,Journal arXiv preprint arXiv:1702.07836,"Detection of objects in cluttered indoor environments is one of the key enabling functionalities for service robots. The best performing object detection approaches in computer vision exploit deep Convolutional Neural Networks (CNN) to simultaneously detect and categorize the objects of interest in cluttered scenes. Training of such models typically requires large amounts of annotated training data which is time consuming and costly to obtain. In this work we explore the ability of using synthetically generated composite images for training state-of-the-art object detectors, especially for object instance detection. We superimpose 2D images of textured object models into images of real environments at variety of locations and scales. Our experiments evaluate different superimposition strategies ranging from purely image-based blending all the way to depth and semantics informed positioning of the object models into real scenes. We demonstrate the effectiveness of these object detector training strategies on two publicly available datasets, the GMU-Kitchens and the Washington RGB-D Scenes v2. As one observation, augmenting some hand-labeled training data with synthetic examples carefully composed onto scenes yields object detectors with comparable performance to using much more hand-labeled data. Broadly, this work charts new opportunities for training detectors for new objects by exploiting existing object model repositories in either a purely automatic fashion or with only a very small number of human-annotated examples.",199
Multi-view image and tof sensor fusion for dense 3d reconstruction,"Young Min Kim, Christian Theobalt, James Diebel, Jana Kosecka, Branislav Miscusik, Sebastian Thrun",2009/9/27,"Conference 2009 IEEE 12th international conference on computer vision workshops, ICCV workshops","Multi-view stereo methods frequently fail to properly reconstruct 3D scene geometry if visible texture is sparse or the scene exhibits difficult self-occlusions. Time-of-Flight (ToF) depth sensors can provide 3D information regardless of texture but with only limited resolution and accuracy. To find an optimal reconstruction, we propose an integrated multi-view sensor fusion approach that combines information from multiple color cameras and multiple ToF depth sensors. First, multi-view ToF sensor measurements are combined to obtain a coarse but complete model. Then, the initial model is refined by means of a probabilistic multi-view fusion framework, optimizing over an energy function that aggregates ToF depth sensor information with multi-view stereo and silhouette constraints. We obtain high quality dense and detailed 3D models of scenes challenging for stereo alone, while simultaneously reducing complex …",192
Optimization criteria and geometric algorithms for motion and structure estimation,"Yi Ma, Jana Košecká, Shankar Sastry",2001/9,Journal International Journal of Computer Vision,"Prevailing efforts to study the standard formulation of motion and structure recovery have recently been focused on issues of sensitivity and robustness of existing techniques. While many cogent observations have been made and verified experimentally, many statements do not hold in general settings and make a comparison of existing techniques difficult. With an ultimate goal of clarifying these issues, we study the main aspects of motion and structure recovery: the choice of objective function, optimization techniques and sensitivity and robustness issues in the presence of noise.",179
Generation of conflict resolution manoeuvres for air traffic management,"Jana Kosecka, Claire Tomlin, George Pappas, Shankar Sastry",1997/9/11,Conference Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS'97,"We explore the use of distributed online motion planning algorithms for multiple mobile agents, in air traffic management systems (ATMS). The work is motivated by current trends in ATMS to move towards decentralized air traffic management, in which the aircraft operate in ""free flight"" mode instead of following prespecified ""sky freeways"". Conflict resolution strategies are an integral part of the free flight setting. The purpose of this paper is to obtain a set of manoeuvres to cover all possible conflict scenarios involving multiple agents. A distributed motion planning algorithm based on potential and vortex fields is used. While the algorithm is not always guaranteed to generate flyable trajectories, the obtained trajectories can serve as qualitative prototypes for coordination manoeuvres between multiple aircraft. The actual manoeuvres are generated by approximating these prototypes with trajectories made zip of straight …",168
A dataset for developing and benchmarking active vision,"Phil Ammirato, Patrick Poirson, Eunbyung Park, Jana Košecká, Alexander C Berg",2017/5/29,Conference 2017 IEEE International Conference on Robotics and Automation (ICRA),"We present a new public dataset with a focus on simulating robotic vision tasks in everyday indoor environments using real imagery. The dataset includes 20,000+ RGB-D images and 50,000+ 2D bounding boxes of object instances densely captured in 9 unique scenes. We train a fast object category detector for instance detection on our data. Using the dataset we show that, although increasingly accurate and fast, the state of the art for object detection is still severely impacted by object scale, occlusion, and viewing direction all of which matter for robotics applications. We next validate the dataset for simulating active vision, and use the dataset to develop and evaluate a deep-network-based system for next best move prediction for object classification using reinforcement learning. Our dataset is available for download at cs.unc.edu/~ammirato/active_vision_dataset_website/.",163
Vision based topological Markov localization,"Jana Kosecká, Fayin Li",2004/4/26,"Conference IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA'04. 2004","In this paper we study the problem of acquiring a topological model of indoors environment by means of visual sensing and subsequent localization given the model. The resulting model consists of a set of locations and neighborhood relationships between them. Each location in the model is represented by a collection of representative views and their associated descriptors selected from a temporally sub-sampled video stream captured by a mobile robot during exploration. We compare the recognition performance using global image histograms as well as local scale-invariant features as image descriptors, demonstrate their strengths and weaknesses and show how to model the spatial relationships between individual locations by a Hidden Markov Model. The quality of the acquired model is tested in the localization stage by means of location recognition: given a new view or a sequence of views, the most likely …",163
Visual representations for semantic target driven navigation,"Arsalan Mousavian, Alexander Toshev, Marek Fišer, Jana Košecká, Ayzaan Wahid, James Davidson",2019/5/20,Conference 2019 International Conference on Robotics and Automation (ICRA),"What is a good visual representation for navigation? We study this question in the context of semantic visual navigation, which is the problem of a robot finding its way through a previously unseen environment to a target object, e.g. go to the refrigerator. Instead of acquiring a metric semantic map of an environment and using planning for navigation, our approach learns navigation policies on top of representations that capture spatial layout and semantic contextual cues. We propose to use semantic segmentation and detection masks as observations obtained by state-of-the-art computer vision algorithms and use a deep network to learn the navigation policy. The availability of equitable representations in simulated environments enables joint training using real and simulated data and alleviates the need for domain adaptation or domain randomization commonly used to tackle the sim-to-real transfer of the learned …",161
"Extraction, matching, and pose recovery based on dominant rectangular structures","Jana Košecká, Wei Zhang",2005/12/1,Journal Computer Vision and Image Understanding,"Man-made environments possess many regularities which can be efficiently exploited for image-based rendering as well as robotic navigation and localization tasks. In this paper, we present an approach for automatic extraction of dominant rectangular structures from a single view and show how they facilitate the recovery of camera pose, planar structure, and matching across widely separated views. In the presented approach, the rectangular hypothesis formation is based on a higher-level information encoded by the presence of orthogonal vanishing directions, the dominant rectangular structures can be detected and matched despite the presence of multiple repetitive structures often encountered in a variety of buildings. Different stages of the approach are demonstrated on various examples of images of indoor and outdoor structured environments.",159
Qualitative image based localization in indoors environments,"Jana Kosecka, Liang Zhou, Philip Barber, Zoran Duric",2003/6/18,"Conference 2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings.","Man made indoor environments possess regularities, which can be efficiently exploited in automated model acquisition by means of visual sensing. In this context we propose an approach for inferring a topological model of an environment from images or the video stream captured by a mobile robot during exploration. The proposed model consists of a set of locations and neighborhood relationships between them. Initially each location in the model is represented by a collection of similar, temporally adjacent views, with the similarity defined according to a simple appearance based distance measure. The sparser representation is obtained in a subsequent learning stage by means of learning vector quantization (LVQ). The quality of the model is tested in the context of qualitative localization scheme by means of location recognition: given a new view, the most likely location where that view came from is determined.",149
Discrete event systems for autonomous mobile agents,"Jana Košecká, Ruzena Bajcsy",1994/4/1,Journal Robotics and Autonomous Systems,"Discrete Event Systems (DES) are a special type of dynamic system. The ‘state’ of these systems changes at discrete instants in time and the term ‘event’ represents the occurrence of discontinuous change (at possibly unknown intervals). Different Discrete Event Systems models are currently used for specification, verification, synthesis as well as for analysis and evaluation of different qualitative and quantitative properties of existing physical systems. The focus of this paper is the presentation of the automata and formal language model for DES introduced by Ramadge and Wonham and its application to the domain of mobile manipulator/observer agents. We demonstrate the feasibility of the DES framework for modeling, analysis and synthesis of some visually guided behaviors of agents engaged in navigational tasks and address synchronization issues between different components of the system. The use of DES …",149
Fast single shot detection and pose estimation,"Patrick Poirson, Phil Ammirato, Cheng-Yang Fu, Wei Liu, Jana Kosecka, Alexander C Berg",2016/10/25,Conference 2016 Fourth International Conference on 3D Vision (3DV),"For applications in navigation and robotics, estimating the 3D pose of objects is as important as detection. Many approaches to pose estimation rely on detecting or tracking parts or keypoints [11, 21]. In this paper we build on a recent state-of-the-art convolutional network for sliding-window detection [10] to provide detection and rough pose estimation in a single shot, without intermediate stages of detecting parts or initial bounding boxes. While not the first system to treat pose estimation as a categorization problem, this is the first attempt to combine detection and pose estimation at the same level using a deep learning approach. The key to the architecture is a deep convolutional network where scores for the presence of an object category, the offset for its location, and the approximate pose are all estimated on a regular grid of locations in the image. The resulting system is as accurate as recent work on pose …",138
Joint semantic segmentation and depth estimation with deep convolutional networks,"Arsalan Mousavian, Hamed Pirsiavash, Jana Košecká",2016/10/25,Conference 2016 Fourth International Conference on 3D Vision (3DV),"Multi-scale deep CNNs have been used successfully for problems mapping each pixel to a label, such as depth estimation and semantic segmentation. It has also been shown that such architectures are reusable and can be used for multiple tasks. These networks are typically trained independently for each task by varying the output layer(s) and training objective. In this work we present a new model for simultaneous depth estimation and semantic segmentation from a single RGB image. Our approach demonstrates the feasibility of training parts of the model for each task and then fine tuning the full, combined model on both tasks simultaneously using a single loss function. Furthermore we couple the deep CNN with fully connected CRF, which captures the contextual relationships and interactions between the semantic and depth cues improving the accuracy of the final results. The proposed model is trained and …",137
Global localization and relative positioning based on scale-invariant keypoints,"Jana Košecká, Fayin Li, Xialong Yang",2005/7/31,Journal Robotics and Autonomous Systems,"The localization capability of a mobile robot is central to basic navigation and map building tasks. We describe a probabilistic environment model which facilitates global localization scheme by means of location recognition. In the exploration stage the environment is partitioned into locations, each characterized by a set of scale-invariant keypoints. The descriptors associated with these keypoints can be robustly matched despite changes in contrast, scale and viewpoint. We demonstrate the efficacy of these features for location recognition, where given a new view the most likely location from which this view came from is determined. The misclassifications due to dynamic changes in the environment or inherent appearance ambiguities are overcome by exploiting location neighborhood relationships captured by a Hidden Markov Model. We report the recognition performance of this approach in an indoor …",135
Multi-view superpixel stereo in urban environments,"Branislav Micusik, Jana Kosecka",2010/8/1,Journal International journal of computer vision,"Urban environments possess many regularities which can be efficiently exploited for 3D dense reconstruction from multiple widely separated views. We present an approach utilizing properties of piecewise planarity and restricted number of plane orientations to suppress reconstruction and matching ambiguities causing failures of standard dense stereo methods. We formulate the problem of the 3D reconstruction in MRF framework built on an image pre-segmented into superpixels. Using this representation, we propose novel photometric and superpixel boundary consistency terms explicitly derived from superpixels and show that they overcome many difficulties of standard pixelbased formulations and handle favorably problematic scenarios containing many repetitive structures and no or low textured regions. We demonstrate our approach on several wide-baseline scenes demonstrating superior performance …",129
Localization in urban environments using a panoramic gist descriptor,"Ana C Murillo, Gautam Singh, Jana Kosecka, José Jesús Guerrero",2012/11/16,Journal IEEE Transactions on Robotics,"Vision-based topological localization and mapping for autonomous robotic systems have received increased research interest in recent years. The need to map larger environments requires models at different levels of abstraction and additional abilities to deal with large amounts of data efficiently. Most successful approaches for appearance-based localization and mapping with large datasets typically represent locations using local image features. We study the feasibility of performing these tasks in urban environments using global descriptors instead and taking advantage of the increasingly common panoramic datasets. This paper describes how to represent a panorama using the global gist descriptor, while maintaining desirable invariance properties for location recognition and loop detection. We propose different gist similarity measures and algorithms for appearance-based localization and an online loop …",123
Real-time classification of hand motions using ultrasound imaging of forearm muscles,"Nima Akhlaghi, Clayton A Baker, Mohamed Lahlou, Hozaifah Zafar, Karthik G Murthy, Huzefa S Rangwala, Jana Kosecka, Wilsaan M Joiner, Joseph J Pancrazio, Siddhartha Sikdar",2015/11/5,Journal IEEE Transactions on Biomedical Engineering,"Surface electromyography (sEMG) has been the predominant method for sensing electrical activity for a number of applications involving muscle-computer interfaces, including myoelectric control of prostheses and rehabilitation robots. Ultrasound imaging for sensing mechanical deformation of functional muscle compartments can overcome several limitations of sEMG, including the inability to differentiate between deep contiguous muscle compartments, low signal-to-noise ratio, and lack of a robust graded signal. The objective of this study was to evaluate the feasibility of real-time graded control using a computationally efficient method to differentiate between complex hand motions based on ultrasound imaging of forearm muscles. Dynamic ultrasound images of the forearm muscles were obtained from six able-bodied volunteers and analyzed to map muscle activity based on the deformation of the contracting …",117
Properties of different selection signature statistics and a new strategy for combining them,"Y Ma, X Ding, Saber Qanbari, Steffen Weigend, Q Zhang, Henner Simianer",2015/11,Journal Heredity,"Identifying signatures of recent or ongoing selection is of high relevance in livestock population genomics. From a statistical perspective, determining a proper testing procedure and combining various test statistics is challenging. On the basis of extensive simulations in this study, we discuss the statistical properties of eight different established selection signature statistics. In the considered scenario, we show that a reasonable power to detect selection signatures is achieved with high marker density (> 1 SNP/kb) as obtained from sequencing, while rather small sample sizes (~ 15 diploid individuals) appear to be sufficient. Most selection signature statistics such as composite likelihood ratio and cross population extended haplotype homozogysity have the highest power when fixation of the selected allele is reached, while integrated haplotype score has the highest power when selection is ongoing. We suggest a …",115
Nonparametric scene parsing with adaptive feature relevance and semantic context,"Gautam Singh, Jana Kosecka",2013,Conference Proceedings of the IEEE conference on computer vision and pattern recognition,"This paper presents a nonparametric approach to semantic parsing using small patches and simple gradient, color and location features. We learn the relevance of individual feature channels at test time using a locally adaptive distance metric. To further improve the accuracy of the nonparametric approach, we examine the importance of the retrieval set used to compute the nearest neighbours using a novel semantic descriptor to retrieve better candidates. The approach is validated by experiments on several datasets used for semantic parsing demonstrating the superiority of the method compared to the state of art approaches.",113
Cooperative material handling by human and robotic agents: Module development and system synthesis,"Julie A Adams, Ruzena Bajcsy, Jana Kosecka, Vijay Kumar, Robert Mandelbaum, Max Mintz, R Paul, Curtis Wang, Yoshio Yamamoto, Xiaoping Yun",1995/8/5,Source Proceedings 1995 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human Robot Interaction and Cooperative Robots,"Presents a collaborative effort to design and implement a cooperative material handling system by a small team of human and robotic agents in an unstructured indoor environment. The authors' approach makes fundamental use of the human agents' expertise for aspects of task planning, task monitoring, and error recovery. The authors' system is neither fully autonomous nor fully teleoperated. It is designed to make effective use of the human's abilities within the present state of the art of autonomous systems. The authors' robotic agents refer to systems which are each equipped with at least one sensing modality and which possess some capability for self-orientation and/or mobility. The authors' robotic agents are not required to be homogeneous with respect to either capabilities or function. The authors' research stresses both paradigms and testbed experimentation. Theory issues include the requisite coordination …",112
Visual door detection integrating appearance and shape cues,"Ana Cris Murillo, Jana Košecká, José Jesús Guerrero, Carlos Sagüés",2008/6/30,Journal Robotics and Autonomous Systems,"An important component of human–robot interaction is the capability to associate semantic concepts with encountered locations and objects. This functionality is essential for visually guided navigation as well as location and object recognition. In this paper we focus on the problem of door detection using visual information only. Doors are frequently encountered in structured man-made environments and function as transitions between different places. We adopt a probabilistic approach for door detection, by defining the likelihood of various features for generated door hypotheses. Differing from previous approaches, the proposed model captures both the shape and appearance of the door. This is learned from a few training examples, exploiting additional assumptions about the structure of indoor environments. After the learning stage, we describe a hypothesis generation process and several approaches to …",110
Vision-based lateral control of vehicles,"J Kosecka, R Blasi, CJ Taylor, Jitendra Malik",1997/11/12,Conference Proceedings of Conference on Intelligent Transportation Systems,"We describe the problem of automated steering using computer vision, focusing the analysis and design on appropriate lateral controllers. We investigate various static feedback strategies where the measurements obtained from vision, namely offset from the center line at some lookahead distance and the angle between the road tangent and the orientation of the vehicle at some lookahead distance, are directly used for control. Within this setting we explore the role of lookahead, its relation to the vision processing delay, the longitudinal velocity and road geometry. Results from ongoing experiments with our autonomous vehicle system are presented along with simulation results.",108
Linear differential algorithm for motion recovery: A geometric approach,"Yi Ma, Jana Košecká, Shankar Sastry",2000/1,Journal International Journal of Computer Vision,"The aim of this paper is to explore a linear geometric algorithm for recovering the three dimensional motion of a moving camera from image velocities. Generic similarities and differences between the discrete approach and the differential approach are clearly revealed through a parallel development of an analogous motion estimation theory previously explored in Vieville, T. and Faugeras, O.D. 1995. In Proceedings of Fifth International Conference on Computer Vision, pp. 750–756; Zhuang, X. and Haralick, R.M. 1984. In Proceedings of the First International Conference on Artificial Intelligence Applications, pp. 366–375. We present a precise characterization of the space of differential essential matrices, which gives rise to a novel eigenvalue-decomposition-based 3D velocity estimation algorithm from the optical flow measurements. This algorithm gives a unique solution to the motion estimation problem …",107
Nonparametric estimation of multiple structures with outliers,"Wei Zhang, Jana Kǒsecká",2007,"Conference Dynamical Vision: ICCV 2005 and ECCV 2006 Workshops, WDV 2005 and WDV 2006, Beijing, China, October 21, 2005, Graz, Austria, May 13, 2006. Revised Papers","Common problem encountered in the analysis of dynamic scene is the problem of simultaneous estimation of the number of models and their parameters. This problem becomes difficult as the measurement noise in the data increases and the data are further corrupted by outliers. This is especially the case in a variety of motion estimation problems, where the displacement between the views is large and the process of establishing correspondences is difficult. In this paper we propose a novel nonparametric sampling based method for estimating the number of models and their parameters. The main novelty of the proposed method lies in the analysis of the distribution of residuals of individual data points with respect to the set of hypotheses, generated by a RANSAC-like sampling process. We will show that the modes of the residual distributions directly reveal the presence of multiple models and facilitate …",106
Probabilistic location recognition using reduced feature set,"Fayin Li, Jana Kosecka",2006/5/15,"Conference Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006.","The localization capability is central to basic navigation tasks and motivates development of various visual navigation systems. In this paper we describe a two stage approach for localization in indoor environments. In the first stage, the environment is partitioned into several locations, each characterized by a set of scale-invariant keypoints and their associated descriptors. In the second stage the keypoints of the query view are integrated probabilistically yielding an estimate of most likely location. The novelty of our approach is in the selection of discriminative features, best suited for characterizing individual locations. We demonstrate that high location recognition rate is maintained with only 10% of the originally detected features, yielding a substantial speedup in recognition and capability of handling larger environments. The ambiguities due to the self-similarity and dynamic changes in the environment are …",106
Localization based on building recognition,"Wei Zhang, Jana Kosecka",2005/9/21,Conference 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)-Workshops,"Navigational capabilities of people in urban areas are to a large extent determined by their knowledge of current location. In addition to location information available by means of global positioning sensors, images can provide additional and often complementary information about relative position and/or viewpoint of the person with respect to some known landmarks. In order to enable such functionality, landmarks (e.g. buildings) have to be reliably and efficiently recognized. In this paper we describe a hierarchical approach for recognition of buildings. At the first stage, we use a novel and efficient representation named localized color histograms. This representation enables efficient retrieval of a small number of candidate matches from the database. At the second stage, the recognition is refined by matching descriptors associated with local image regions. Once the correct building is identified, the relative pose …",100
Semantic segmentation of street scenes by superpixel co-occurrence and 3d geometry,"Branislav Mičušĺík, Jana Košecká",2009/9/27,"Conference 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops","We present a novel approach for image semantic segmentation of street scenes into coherent regions, while simultaneously categorizing each region as one of the predefined categories representing commonly encountered object and background classes. We formulate the segmentation on small blob-based superpixels and exploit a visual vocabulary tree as an intermediate image representation. The main novelty of this generative approach is the introduction of an explicit model of spatial co-occurrence of visual words associated with super-pixels and utilization of appearance, geometry and contextual cues in a probabilistic framework. We demonstrate how individual cues contribute towards global segmentation accuracy and how their combination yields superior performance to the best known method on the challenging benchmark dataset which exhibits diversity of street scenes with varying viewpoints, large …",99
Detection and matching of rectilinear structures,"Branislav Micusik, Horst Wildenauer, Jana Kosecka",2008/6/23,Conference 2008 IEEE Conference on Computer Vision and Pattern Recognition,"Indoor and outdoor urban environments posses many regularities which can be efficiently exploited and used for general image parsing tasks. We present a novel approach for detecting rectilinear structures and demonstrate their use for wide baseline stereo matching, planar 3D reconstruction, and computation of geometric context. Assuming a presence of dominant orthogonal vanishing directions, we proceed by formulating the detection of the rectilinear structures as a labeling problem on detected line segments. The line segment labels, respecting the proposed grammar rules, are established as the MAP assignment of the corresponding MRF. The proposed framework allows to detect both full as well as partial rectangles, rectangle-in-rectangle structures, and rectangles sharing edges. The use of detected rectangles is demonstrated in the context of difficult wide baseline matching tasks in the presence of …",97
Experiments in place recognition using gist panoramas,"Ana C Murillo, Jana Kosecka",2009/9/27,"Conference 2009 IEEE 12Th international conference on computer vision workshops, ICCV workshops","In this paper we investigate large scale view based localization in urban areas using panoramic images. The presented approach utilizes global gist descriptor computed for portions of panoramic images and a simple similarity measure between two panoramas, which is robust to changes in vehicle orientation, while traversing the same areas in different directions. The global gist feature has been demonstrated previously to be a very effective conventional image descriptor, capturing the basic structure of different types of scenes in a very compact way. We present an extensive experimental validation of our panoramic gist approach on a large scale Street View data set of panoramic images for place recognition or topological localization.",96
A comparative study of vision-based lateral control strategies for autonomous highway driving,"Camillo J Taylor, Jana Košecká, Robert Blasi, Jitendra Malik",1999/5,Journal The International Journal of Robotics Research,"With the increasing speeds of modern microprocessors, it has become ever more common                 for computer-vision algorithms to find application in real-time control tasks. In                 this paper, we present an analysis of the problem of steering an autonomous vehicle                 along a highway based on the images obtained from a CCD camera mounted in the                 vehicle. We explore the effects of changing various important system parameters like                 the vehicle velocity, the look-ahead range of the vision sensor, and the processing                 delay associated with the perception and control systems.",232
Hierarchical building recognition,"Wei Zhang, Jana Košecká",2007/5/1,Journal Image and vision Computing,"In urban areas, buildings are often used as landmarks for localization. Reliable and efficient recognition of buildings is crucial for enabling this functionality. Motivated by the applications which would enhance visual localization and navigation capabilities, we propose in this paper a hierarchical approach for building recognition. In the first recognition stage the model views are indexed by localized color histograms computed from dominant orientation structures in the image. This novel representation enables quick retrieval of a small number of candidate buildings from the database. In the second stage the recognition results are refined by matching previously proposed SIFT descriptors associated with local image regions. For this stage, we propose a method for selecting discriminative SIFT features and a simple probabilistic model for integration of the evidence from individual matches based on the match quality …",94
Landmark-based pedestrian navigation with enhanced spatial reasoning,"Harlan Hile, Radek Grzeszczuk, Alan Liu, Ramakrishna Vedantham, Jana Košecka, Gaetano Borriello",2009,"Conference Pervasive Computing: 7th International Conference, Pervasive 2009, Nara, Japan, May 11-14, 2009. Proceedings 7","Computer vision techniques can enhance landmark-based navigation by better utilizing online photo collections. We use spatial reasoning to compute camera poses, which are then registered to the world using GPS information extracted from the image tags. Computed camera pose is used to augment the images with navigational arrows that fit the environment. We develop a system to use high-level reasoning to influence the selection of landmarks along a navigation path, and lower-level reasoning to select appropriate images of those landmarks. We also utilize an image matching pipeline based on robust local descriptors to give users of the system the ability to capture an image and receive navigational instructions overlaid on their current context. These enhancements to our previous navigation system produce a more natural navigation plan and more understandable images in a fully automatic way.",89
Visual loop closing using gist descriptors in manhattan world,"Gautam Singh, Jana Kosecka",2010/10,Journal ICRA omnidirectional vision workshop,"We present an approach for detecting loop closures in a large sequence of omni-directional images of urban environments. In particular we investigate the efficacy of global gist descriptors computed for 360o cylindrical panoramas and compare it with the baseline vocabulary tree approach. In the context of loop closure detection, we describe a novel matching strategy for panoramic views, exploiting the fact that the vehicle travels in urban environments where heading of the vehicle at previously visited locations and loop closure points are related by multiple of 90o degrees. The performance of the presented approach is promising despite the simplicity of the descriptor.",87
Multiview rgb-d dataset for object instance detection,"Georgios Georgakis, Md Alimoor Reza, Arsalan Mousavian, Phi-Hung Le, Jana Košecká",2016/10/25,Conference 2016 Fourth International Conference on 3D Vision (3DV),"This paper presents a new multi-view RGB-D dataset of nine kitchen scenes, each containing several objects in realistic cluttered environments including a subset of objects from the BigBird dataset. The viewpoints of the scenes are densely sampled and objects in the scenes are annotated with bounding boxes and in the 3D point cloud. Also, an approach for detection and recognition is presented, which is comprised of two parts: (i) a new multi-view 3D proposal generation method and (ii) the development of several recognition baselines using AlexNet to score our proposals, which is trained either on crops of the dataset or on synthetically composited training images. Finally, we compare the performance of the object proposals and a detection baseline to the Washington RGB-D Scenes (WRGB-D) dataset and demonstrate that our Kitchen scenes dataset is more challenging for object detection and recognition …",80
Generalized ransac framework for relaxed correspondence problems,"Wei Zhang, Jana Kosecka",2006/6/14,"Conference Third International Symposium on 3D Data Processing, Visualization, and Transmission (3DPVT'06)","Finding correspondences between two (widely) separated views is essential for several computer vision tasks, such as structure and motion estimation and object recognition. In the wide-baseline matching using scale and/or affine invariant features the search for correspondences typically proceeds in two stages. In the first stage a putative set of correspondences is obtained based on distances between feature descriptors. In the second stage the matches are refined by imposing global geometric constraints by means of robust estimation of the epipolar geometry and the incorrect matches are rejected as outliers. For a feature in one view, usually only one ""best"" feature (the nearest neighbor) in the other view is chosen as corresponding feature, despite the fact that several match candidates exist. In this paper, we will consider multiple candidate matches for each feature, and integrate this choice with the robust …",71
Efficient computation of vanishing points,"J Kogecka, Wei Zhang",2002/5/11,Conference Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No. 02CH37292),"Man-made environments possess a lot of regularities which simplify otherwise difficult pose estimation and visual reconstruction tasks. The constraints arising front parallel and orthogonal lines and planes can be efficiently exploited at various stages of vision processing pipeline. In this paper we propose an approach for estimation of vanishing points by exploiting the constraints of structured man-made environments, where the majority of lines is aligned with the principal orthogonal directions of the world coordinate frame. We combine efficient image processing techniques used in the line detection and initialization stage with simultaneous grouping and estimation of vanishing directions using expectation maximization (EM) algorithm. Since we assume an uncalibrated camera the estimated vanishing points can be used towards partial camera calibration and estimation of the relative orientation of the camera with …",65
Euclidean reconstruction and reprojection up to subgroups,"Yi Ma, Stefano Soatto, Jana Košecká, Shankar Sastry",2000/7,Journal International Journal of Computer Vision,"The necessary and sufficient conditions for being able to estimate scene structure, motion and camera calibration from a sequence of images are very rarely satisfied in practice. What exactly can be estimated in sequences of practical importance, when such conditions are not satisfied? In this paper we give a complete answer to this question. For every camera motion that fails to meet the conditions, we give explicit formulas for the ambiguities in the reconstructed scene, motion and calibration. Such a characterization is crucial both for designing robust estimation algorithms (that do not try to recover parameters that cannot be recovered), and for generating novel views of the scene by controlling the vantage point. To this end, we characterize explicitly all the vantage points that give rise to a valid Euclidean reprojection regardless of the ambiguity in the reconstruction. We also characterize vantage points …",64
Hierarchical kinematic human mesh recovery,"Georgios Georgakis, Ren Li, Srikrishna Karanam, Terrence Chen, Jana Košecká, Ziyan Wu",2020,"Conference Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XVII 16","We consider the problem of estimating a parametric model of 3D human mesh from a single image. While there has been substantial recent progress in this area with direct regression of model parameters, these methods only implicitly exploit the human body kinematic structure, leading to sub-optimal use of the model prior. In this work, we address this gap by proposing a new technique for regression of human parametric model that is explicitly informed by the known hierarchical structure, including joint interdependencies of the model. This results in a strong prior-informed design of the regressor architecture and an associated hierarchical optimization that is flexible to be used in conjunction with the current standard frameworks for 3D human mesh recovery. We demonstrate these aspects by means of extensive experiments on standard benchmark datasets, showing how our proposed new design …",60
End-to-end learning of keypoint detector and descriptor for pose invariant 3D matching,"Georgios Georgakis, Srikrishna Karanam, Ziyan Wu, Jan Ernst, Jana Košecká",2018,Conference Proceedings of the IEEE conference on computer vision and pattern recognition,"Finding correspondences between images or 3D scans is at the heart of many computer vision and image retrieval applications and is often enabled by matching local keypoint descriptors. Various learning approaches have been applied in the past to different stages of the matching pipeline, considering detection, description, or metric learning objectives. These objectives were typically addressed separately and most previous work has focused on image data. This paper proposes an end-to-end learning framework for keypoint detection and its representation (descriptor) for 3D depth maps or 3D scans, where the two can be jointly optimized towards task-specific objectives without a need for separate annotations. We employ a Siamese architecture augmented by a sampling layer and a novel score loss function which in turn affects the selection of region proposals. The positive and negative examples are obtained automatically by sampling corresponding region proposals based on their consistency with known 3D pose labels. Matching experiments with depth data on multiple benchmark datasets demonstrate the efficacy of the proposed approach, showing significant improvements over state-of-the-art methods.",60
Experiments in behavior composition,"Jana Košecká, Henrik I Christensen, Ruzena Bajcsy",1997/3/1,Journal Robotics and Autonomous systems,"Widespread use of mobile robots can only be achieved when framworks that enable specification, design and implementation of systems are available. These frameworks must provide a level of abstraction that enables use of the same methods for different tasks/missions to facilitate fast prototyping and design at low cost. In this paper a Task Description Language (TDL) for task specification is outlined. The tasks are specified as network of processes. The processes are described in terms of finite state machines (FSMs) and their composition is achieved via a set of composition operators, common to many process algebra models. From the obtained description of the task a Discrete Event Systems supervisory controller can be synthesized. To demonstrate that such an approach is suitable basis for description of robot tasks a set of experiments with two different platforms situated in two different laboratories is …",58
Semantic segmentation with heterogeneous sensor coverages,"Cesar Cadena, Jana Košecká",2014/5/31,Conference 2014 IEEE International Conference on Robotics and Automation (ICRA),"We propose a new approach to semantic parsing, which can seamlessly integrate evidence from multiple sensors with overlapping but possibly different fields of view (FOV), account for missing data and predict semantic labels over the spatial union of sensors coverages. The existing approaches typically carry out semantic segmentation using only one modality, incorrectly interpolate measurements of other modalities or at best assign semantic labels only to the spatial intersection of coverages of different sensors. In this work we remedy these problems by proposing an effective and efficient strategy for inducing the graph structure of Conditional Random Field used for inference and a novel method for computing the sensor domain dependent potentials. We focus on RGB cameras and 3D data from lasers or depth sensors. The proposed approach achieves superior performance, compared to state of the art and …",56
Rank conditions on the multiple-view matrix,"Yi Ma, Kun Huang, René Vidal, Jana Košecká, Shankar Sastry",2004/9,Journal International Journal of Computer Vision,"Geometric relationships governing multiple images of points and lines and associated algorithms have been studied to a large extent separately in multiple-view geometry. The previous studies led to a characterization based on multilinear constraints, which have been extensively used for structure and motion recovery, feature matching and image transfer. In this paper we present a universal rank condition on the so-called multiple-view matrix M for arbitrarily combined point and line features across multiple views. The condition gives rise to a complete set of constraints among multiple images. All previously known multilinear constraints become simple instantiations of the new condition. In particular, the relationship between bilinear, trilinear and quadrilinear constraints can be clearly revealed from this new approach. The theory enables us to carry out global geometric analysis for multiple images, as well …",55
Semantically guided location recognition for outdoors scenes,"Arsalan Mousavian, Jana Košecká, Jyh-Ming Lien",2015/5/26,Conference 2015 IEEE international conference on robotics and automation (ICRA),"The problem of image based localization has a long history both in robotics and computer vision and shares many similarities with image based retrieval problem. Existing techniques use either local features or (semi)-global image signatures in the context of topological mapping or loop closure detection. Difficulties of the location recognition problem are often affected by large appearance and viewpoint variation between the query view and reference dataset and presence of non-discriminative features due to vegetation, sky and road. In this work we show that semantic segmentation labeling of man-made structures can inform the traditional bag-of-visual words models to obtain proper feature weighting and improve the overall location recognition accuracy. We also demonstrate additional capability of identifying individual buildings and estimating their extent in images, providing the essential building block for …",50
Semantic parsing for priming object detection in indoors RGB-D scenes,"César Cadena, Jana Košecka",2015/4,Journal The International Journal of Robotics Research,"The semantic mapping of the environment requires simultaneous segmentation and categorization of the acquired stream of sensory information. The existing methods typically consider the semantic mapping as the final goal and differ in the number and types of considered semantic categories. We envision semantic understanding of the environment as an on-going process and seek representations which can be refined and adapted depending on the task and robot’s interaction with the environment. In this work we propose a novel and efficient method for semantic parsing, which can be adapted to the task at hand and enables localization of objects of interest in indoor environments. For basic mobility tasks we demonstrate how to obtain initial semantic segmentation of the scene into ground, structure, furniture and props categories which constitute the first level of hierarchy. Then, we propose a simple and …",48
Deep convolutional features for image based retrieval and scene categorization,"Arsalan Mousavian, Jana Kosecka",2015/9/20,Journal arXiv preprint arXiv:1509.06033,"Several recent approaches showed how the representations learned by Convolutional Neural Networks can be repurposed for novel tasks. Most commonly it has been shown that the activation features of the last fully connected layers (fc7 or fc6) of the network, followed by a linear classifier outperform the state-of-the-art on several recognition challenge datasets. Instead of recognition, this paper focuses on the image retrieval problem and proposes a examines alternative pooling strategies derived for CNN features. The presented scheme uses the features maps from an earlier layer 5 of the CNN architecture, which has been shown to preserve coarse spatial information and is semantically meaningful. We examine several pooling strategies and demonstrate superior performance on the image retrieval task (INRIA Holidays) at the fraction of the computational cost, while using a relatively small memory requirements. In addition to retrieval, we see similar efficiency gains on the SUN397 scene categorization dataset, demonstrating wide applicability of this simple strategy. We also introduce and evaluate a novel GeoPlaces5K dataset from different geographical locations in the world for image retrieval that stresses more dramatic changes in appearance and viewpoint.",44
Detecting changes in images of street scenes,Jana Košecka,2013,"Conference Computer Vision–ACCV 2012: 11th Asian Conference on Computer Vision, Daejeon, Korea, November 5-9, 2012, Revised Selected Papers, Part IV 11","In this paper we propose an novel algorithm for detecting changes in street scenes when the vehicle revisits sections of the street at different times. The proposed algorithm detects structural geometric changes, changes due to dynamically moving objects and as well as changes in the street appearance (e.g. posters put up) between two traversal times. We exploit geometric, appearance and semantic information to determine which areas have changed and formulate the problem as an optimal image labeling problem in the Markov Random Field framework. The approach is evaluated on street sequences from 3 different locations which were visited multiple times by the vehicle. The proposed method is applicable to monitoring and updating models and images of urban environments.",43
Advanced air traffic automation: A case study in distributed decentralized control,"Claire J Tomlin, George J Pappas, Jana Košecká, John Lygeros, Shankar S Sastry",1998,Conference Control Problems in Robotics and Automation,"In this survey chapter, we present some of the issues in designing algorithms for the control of distributed, multi-agent systems. The control of such systems is becoming an increasing issue in many areas owing to technological advances which make it possible to take “legacy” systems to new levels of functioning and efficiency. Of specific interest to us in this chapter is advanced air traffic management (ATM) to increase the efficiency and safety of air travel while accommodating the growing demand for air traffic. ATM systems will replace the completely centralized, ground-based air traffic control procedures. Within ATM, the concept of free flight allows each aircraft to plan four dimensional trajectories in real time, thus replacing the rigid and inefficient discrete airspace structure. These changes are feasible due to technological innovations such as advanced flight management systems with GPS. In this chapter …",42
Discrete event modeling of visually guided behaviors,"Jana Košecka, Henrik I Christensen, Ruzena Bajcsy",1995/3,Journal International Journal of Computer Vision,"When visual behaviors are combined to provide a specific functionality needed for a task, the combination is often based on heuristic rules. In this article we show that by adopting the Discrete-Event Systems (DES) formalism for describing the interaction between visual behaviors it is possible to provide systems that have well-defined properties in terms of observability and controllability. The method is in particular suited for describing the coupling between action and perception. An introduction to the use of DES is provided and it is demonstrated how DES are used for modeling behaviors and controlling a mobile robot equipped with a binocular camera head and some additional sensors.",41
An invitation to 3-D vision: from images to geometric models,"Stefano Soatto, Jana Kosecká, S Shankar Sastry, Yi Ma",2004,Publisher Springer,,39
Visually guided navigation,Jana Košecká,1997/7/1,Journal Robotics and Autonomous Systems,"Rich sensory information, robust control strategies and proper representation of the environment are crucial for successful navigation of the mobile robot. We propose a model of the environment which is suitable for global navigation using visual sensing. At the lowest level of interaction of the robot with the environment we employ visual servoing techniques which facilitate robust local navigation by means of relative positioning. Further we demonstrate how to use these local control strategies in a global setting. The environment is represented in terms of place graph, where the nodes correspond to places and arcs have associated servoing strategies for moving from one place to another. The global navigation is expressed as a sequence of relative positioning tasks obtainable from the search of a place graph. The proposed model facilitates generation of motion plans which can be executed in a robust manner …",38
Motion recovery from image sequences: Discrete viewpoint vs. differential viewpoint,"Yi Ma, Jana Košecká, Shankar Sastry",1998,"Conference Computer Vision—ECCV’98: 5th European Conference on Computer Vision Freiburg, Germany, June 2–6, 1998 Proceedings, Volume II 5",The aim of this paper is to explore intrinsic geometric methods of recovering the three dimensional motion of a moving camera from a sequence of images. Generic similarities between the discrete approach and the differential approach are revealed through a parallel development of their analogous motion estimation theories.,37
Dense piecewise planar RGB-D SLAM for indoor environments,"Phi-Hung Le, Jana Košecka",2017/9/24,Conference 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),"The paper exploits weak Manhattan constraints to parse the structure of indoor environments from RGB-D video sequences in an online setting. We extend the previous approach for single view parsing of indoor scenes to video sequences and formulate the problem of recovering the floor plan of the environment as an optimal labeling problem solved using dynamic programming. The temporal continuity is enforced in a recursive setting, where labeling from previous frames is used as a prior term in the objective function. In addition to recovery of piecewise planar weak Manhattan structure of the extended environment, the orthogonality constraints are also exploited by visual odometry and pose graph optimization. This yields reliable estimates in the presence of large motions and absence of distinctive features to track. We evaluate our method on several challenging indoors sequences demonstrating accurate …",36
Kruppa equation revisited: Its renormalization and degeneracy,"Yi Ma, René Vidal, Jana Kosecka, Shankar Sastry",2000/4,Conference ECCV (2),"In this paper, we study general questions about the solvability of the Kruppa equations and show that, in several special cases, the Kruppa equations can be renormalized and become linear. In particular, for cases when the camera motion is such that its rotation axis is parallel or perpendicular to translation, we can obtain linear algorithms for self-calibration. A further study of these cases not only reveals generic difficulties with degeneracy in conventional self-calibration methods based on the nonlinear Kruppa equations, but also clarifies some incomplete discussion in the literature about the solutions of the Kruppa equations. We demonstrate that Kruppa equations do not provide sufficient constraints on camera calibration and give a complete account of exactly what is missing in Kruppa equations. In particular, a clear relationship between the Kruppa equations and chirality is revealed. The results then resolve the discrepancy between the Kruppa equations and the necessary and sufficient condition for a unique calibration. Simulation results are presented for evaluation of the sensitivity and robustness of the proposed linear algorithms.",36
"A framework for modeling and verifying visually guided agents: Design, analysis and experiments",Jana Kosecka,1996,Institution University of Pennsylvania,The successful functioning of robotic agents in a dynamically changing environment requires rich sensory input and advanced sensory-motor control. The robotic agents are typically equipped with multiple sensors and multiple actuators. The interactions between agents and the environment can be characterized by both discrete and continuous models. The accomplishment of various tasks is mediated by complex coordination and interaction between individual sensing and control strategies. It is crucial for the reliable and predictable operation of robotic systems that the design be within a structured methodology which supports analysis and modularity.,35
Application of discrete events systems for modeling and controlling robotic agents,"Jana Kosecka, Luca Bogoni",1994/5/8,Conference Proceedings of the 1994 IEEE International Conference on Robotics and Automation,"In this paper we present a framework for modeling behaviors and tasks for heterogeneous robotic agents. For this purpose we have adopted a formalism from the discrete events systems (DES) theory. We distinguish two kinds of scenarios. In the first one, reactive behaviors of mobile agents directly connect observations with actions. The overall objective is to achieve controllability of the system which is composed from modular components operating in parallel. In the second one, observations are implicitly connected with actions and the objective is to design an observer for manipulatory tasks which would guarantee the task's observability. The use of the DES formalism allows one to describe complex interactions between different components in a systematic fashion and guarantee some control-theoretic properties. We demonstrate our approach by presenting examples of navigation, obstacle avoidance, piercing …",33
Gist vocabularies in omnidirectional images for appearance based mapping and localization,"AC Murillo, P Campos, J Kosecka, J Guerrero",2010/6,"Journal 10th OMNIVIS, held with Robotics: Science and Systems (RSS)","Appearance based topological localization and mapping is a subject of great interest for autonomous robotics systems. The need for mapping larger environments and describing them at different levels of abstraction requires alternatives to purely metric representations of the environment and additional ability to deal with large amounts of data efficiently. The key component of image based localization is the search for the closest view in the image database representing the environment. In this work we study the efficiency and potential of global gist descriptor [1] adapted to catadioptric systems and present a new hierarchical approach for topological mapping and localization. Our method relies on the omni-gist descriptor and integrates local feature matching to refine the candidates at places where loop-closure detection can occur. Three different omnidirectional image datasets from real scenarios are used to demonstrate the performance of this method, providing comparable results for appearance based localization than previous approaches based on local features. The storage and computation efficiency of global descriptors notably improves the efficiency of the system.",32
Adaptive rgb-d localization,"Michael Paton, Jana Kosecka",2012/5/28,Conference 2012 Ninth Conference on Computer and Robot Vision,"The advent of RGB-D cameras which provide synchronized range and video data creates new opportunities for exploiting both sensing modalities for various robotic applications. This paper exploits the strengths of vision and range measurements and develops a novel robust algorithm for localization using RGB-D cameras. We show how correspondences established by matching visual SIFT features can effectively initialize the generalized ICP algorithm as well as demonstrate situations where such initialization is not viable. We propose an adaptive architecture which computes the pose estimate from the most reliable measurements in a given environment and present thorough evaluation of the resulting algorithm against a dataset of RGB-D benchmarks, demonstrating superior or comparable performance in the absence of the global optimization stage. Lastly we demonstrate the proposed algorithm on a …",31
Acquiring semantics induced topology in urban environments,"Gautam Singh, Jana Košecká",2012/5/14,Conference 2012 IEEE International Conference on Robotics and Automation,"Methods for acquisition and maintenance of an environment model are central to a broad class of mobility and navigation problems. Towards this end, various metric, topological or hybrid models have been proposed. Due to recent advances in sensing and recognition, acquisition of semantic models of the environments have gained increased interest in the community. In this work, we will demonstrate a capability of using weak semantic models of the environment to induce different topological models, capturing the spatial semantics of the environment at different levels. In the first stage of the model acquisition, we propose to compute semantic layout of the street scenes imagery by recognizing and segmenting buildings, roads, sky, cars and trees. Given such semantic layout, we propose an informative feature characterizing the layout and train a classifier to recognize street intersections in challenging urban inner …",31
Creating compact architectural models by geo-registering image collections,"Radek Grzeszczuk, Jana Košecka, Ramakrishna Vedantham, Harlan Hile",2009/9/27,"Conference 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops","We present a method for automatically constructing compact, photo-realistic architectural 3D models. This method uses simple 3D building outlines obtained from existing GIS databases to bootstrap reconstruction and works with both structured and unstructured image datasets. We propose an optimal view-selection algorithm for selecting a small set of views for texture mapping that best describe the structure, while minimizing warping and stitching artifacts, and producing a consistent visual representation. The proposed method is fully automatic and can process large structured datasets in close to real-time, making it suitable for large scale urban modeling and 3D map construction.",30
Global localization and relative pose estimation based on scale-invariant features,"Jana Kosecka, Xiaolong Yang",2004/8/26,"Conference Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.","The capability of maintaining the pose of the mobile robot is central for basic navigation and map building tasks. In This work we describe a vision-based hybrid localization scheme based on scale-invariant keypoints. In the first stage the topological localization is accomplished by matching the keypoints detected in the current view with the database of model views. Once the best match has been found, the relative pose between the model view and the current image is recovered. We demonstrate the efficiency of the location recognition approach and present a closed form solution to the relative pose recovery for the case of planar motion and unknown focal length of the camera. The approach is demonstrated on several examples of indoor environments.",30
Representation of a three-dimensional moving scene,"Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry, Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry",2004,Journal An invitation to 3-d vision: from images to geometric models,"The study of the geometric relationship between a three-dimensional (3-D) scene and its two-dimensional (2-D) images taken from a moving camera is at heart the interplay between two fundamental sets of transformations: Euclidean motion, also called rigid-body motion,which models how the camera moves, and perspective projection,which describes the image formation process. Long before these two transformations were brought together in computer vision, their theory had been developed independently. The study of the principles of motion of a material body has a long history belonging to the foundations of mechanics. For our purpose, more recent noteworthy insights to the understanding of the motion of rigid objects came from Chasles and Poinsot in the early 1800s. Their findings led to the current treatment of this subject, which has since been widely adopted.",28
2 1/2 D conflict resolution maneuvers for ATMS,"Jana Kosecka, Claire Tomlin, George Pappas, Shankar Sastry",1998/12/18,Conference Proceedings of the 37th IEEE Conference on Decision and Control (Cat. No. 98CH36171),"This work is motivated by the current trend in the aviation community to move towards decentralized air traffic management systems (ATMS), in which the aircraft operate in ""free flight"" mode instead of following prespecified ""freeways in the sky"". Automatic conflict resolution strategies are an integral part of the free flight setting. Given the nature of the problem, the limited sensing capabilities, and the complex aircraft dynamics and constraints, it is very hard to solve the conflict resolution problem in its full generality. Indeed, the appropriate solution should be safe (collisions never occur), live (destinations are always reached), and flyable (dynamic constraints on accelerations and velocities are satisfied). This paper explores the use of distributed motion planning for multiple aircraft using vector field techniques. The coordination between aircraft is achieved using a series of horizontal and vertical planar avoidance …",28
Location recognition and global localization based on scale invariand keypoints,"Jana Košecká, Xiaolong Yang",2004/5,"Journal Proc. Workshop on Statistical Learning in Computer Vision, ECCV","The localization capability of a mobile robot is central to basic navigation and map building tasks. We describe a probabilistic environment model which facilitates global localization scheme by means of location recognition. In the exploration stage the environment is partitioned into several locations, each characterized by a set of scale-invariant keypoints. The descriptors associated with these keypoints can be robustly matched despite the changes in contrast, scale and affine distortions. We demonstrate the efficacy of these features for location recognition, where given a new view the most likely location from which this view came is determined. The misclassifications due to dynamic changes in the environment or inherent location appearance ambiguities are overcome by exploiting the location neighborhood relationships captured by a Hidden Markov Model. We report the recognition performance of this approach in an indoor environment consisting of eighteen locations and discuss the suitability of this approach for a more general class of recognition problems.",27
Estimating planar surface orientation using bispectral analysis,"Hany Farid, Jana Kosecka",2007/7/16,Journal IEEE Transactions on image processing,"In this correspondence, we propose a direct method for estimating the orientation of a plane from a single view under perspective projection. Assuming that the underlying planar texture has random phase, we show that the nonlinearities introduced by perspective projection lead to higher order correlations in the frequency domain. We also empirically show that these correlations are proportional to the orientation of the plane. Minimization of these correlations, using tools from polyspectral analysis, yields the orientation of the plane. We show the efficacy of this technique on synthetic and natural images.",25
"J. KOˇSECK A, S. SASTRY,“An invitation to 3-D vision”","Y Ma, S Soatto",2004,Publisher Springer,,25
Visual navigation for mobile devices,"Harlan Hile, Alan Liu, Gaetano Borriello, Radek Grzeszczuk, Ramakrishna Vedantham, Jana Kosecka",2010/4/1,Journal IEEE MultiMedia,This article presents the integration of an improved camera pose recovery method into a landmark-based visual navigation system for mobile devices.,24
Optimal motion from image sequences: A riemannian viewpoint,"Yi Ma, Jana Košecká, Sosale Shankara Sastry",1998/6/22,"Publisher Electronics Research Laboratory, College of Engineering, University of California","Motion recovery from image correspondences is typically a problem of optimizing an objective function associated with the epipolar (or Longuet-Higgins) constraint. This objective function is dened on the so called essential manifold, which has a nice intrinsic Riemannian structure. Based on existing optimization techniques on Riemannian manifolds, in particular on Stiefel or Grassmann manifolds, we propose a Riemannian Newton algorithm to solve the motion recovery problem, making use of the natural geometric structure of the essential manifold. The same ideas also apply to conjugate gradient algorithms. The proposed geometric algorithms have quadratic rates of convergence.",24
Cooperation of visually guided behaviors,"Jana Kosecka, Ruzena Bajcsy",1993/5/11,Conference 1993 (4th) International Conference on Computer Vision,"The authors present modeling, analysis, and synthesis of visual behaviors of agents engaged in navigational tasks. They consider situations in which two agents can navigate independently or in cooperation. For the purpose of modeling the behaviors, a formalism is adopted from the discrete events systems (DES) theory that is suitable for investigating control-theoretic issues of a system. The focus is on the identification of elementary behaviors and their composition, leading to more complex behaviors. Two kinds of elementary behaviors are identified: one where observations are directly connected with actions, and one where observations and actions are either received or transmitted. The use of the DES formalism allows synthesis of complex behaviors in a systematic fashion and guarantees their controllability.< >",23
Sign language recognition analysis using multimodal data,"Al Amin Hosain, Panneer Selvam Santhalingam, Parth Pathak, Jana Kosecka, Huzefa Rangwala",2019/9/24,Journal arXiv preprint arXiv:1909.11232,"Voice-controlled personal and home assistants (such as the Amazon Echo and Apple Siri) are becoming increasingly popular for a variety of applications. However, the benefits of these technologies are not readily accessible to Deaf or Hard-ofHearing (DHH) users. The objective of this study is to develop and evaluate a sign recognition system using multiple modalities that can be used by DHH signers to interact with voice-controlled devices. With the advancement of depth sensors, skeletal data is used for applications like video analysis and activity recognition. Despite having similarity with the well-studied human activity recognition, the use of 3D skeleton data in sign language recognition is rare. This is because unlike activity recognition, sign language is mostly dependent on hand shape pattern. In this work, we investigate the feasibility of using skeletal and RGB video data for sign language recognition using a combination of different deep learning architectures. We validate our results on a large-scale American Sign Language (ASL) dataset of 12 users and 13107 samples across 51 signs. It is named as GMUASL51. We collected the dataset over 6 months and it will be publicly released in the hope of spurring further machine learning research towards providing improved accessibility for digital assistants.",22
Hand pose guided 3d pooling for word-level sign language recognition,"Al Amin Hosain, Panneer Selvam Santhalingam, Parth Pathak, Huzefa Rangwala, Jana Kosecka",2021,Conference Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision,"Gestures in American Sign Language (ASL) are characterized by fast, highly articulate motion of upper body, including arm movements with complex hand shapes and facial expressions. In this work, we propose a new method for word-level sign recognition from American Sign Language (ASL) using video. Our method uses both motion and hand shape cues while being robust to variations of execution. We exploit the knowledge of the body pose, estimated from an off-the-shelf pose estimator. Using the pose as a guide, we pool spatio-temporal feature maps from different layers of a 3D convolutional neural network. We train separate classifiers using pose guided pooled features from different resolutions and fuse their prediction scores during test time. This leads to a significant improvement in performance on the WLASL benchmark dataset [25]. The proposed approach achieves 10%, 12%, 9: 5% and 6: 5% performance gain on WLASL100, WLASL300, WLASL1000, WLASL2000 subsets respectively. To demonstrate the robustness of the pose guided pooling and proposed fusion mechanism, we also evaluate our method by fine tuning the model on another dataset. This yields 10% performance improvement for the proposed method using only 0: 4% training data during fine tuning stage.",21
"Real-time, ultrasound-based control of a virtual hand by a trans-radial amputee","Clayton A Baker, Nima Akhlaghi, Huzefa Rangwala, Jana Kosecka, Siddhartha Sikdar",2016/8/16,Conference 2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),"Advancements in multiarticulate upper-limb prosthetics have outpaced the development of intuitive, non-invasive control mechanisms for implementing them. Surface electromyography is currently the most popular non-invasive control method, but presents a number of drawbacks including poor deep-muscle specificity. Previous research established the viability of ultrasound imaging as an alternative means of decoding movement intent, and demonstrated the ability to distinguish between complex grasps in able-bodied subjects via imaging of the anterior forearm musculature. In order to translate this work to clinical viability, able-bodied testing is insufficient. Amputation-induced changes in muscular geometry, dynamics, and imaging characteristics are all likely to influence the effectiveness of our existing techniques. In this work, we conducted preliminary trials with a transradial amputee participant to assess these …",21
Semantically guided geo-location and modeling in urban environments,"Gautam Singh, Jana Košecká",2016,Journal Large-Scale Visual Geo-Localization,"The problem of localization and geo-location estimation of an image has a long-standing history both in robotics and computer vision. With the advent of availability of large amounts of geo-referenced image data, several image retrievalImage retrieval approaches have been deployed to tackle this problem. In this work, we will show how the capability of semantic labelingSemantic labeling of both query views and the reference dataset by means of semantic segmentationSemantic segmentation can aid (1) the problem of retrieval of views similar and possibly overlapping with the query and (2) guide the recognition and discovery of commonly occurring scene layouts in the reference dataset. We will demonstrate the effectiveness of these semantic representations on examples of localization, semantic conceptSemantic concept discovery, and intersection recognition in the images of urban scenes.",20
Target driven instance detection,"Phil Ammirato, Cheng-Yang Fu, Mykhailo Shvets, Jana Kosecka, Alexander C Berg",2018/3/13,Journal arXiv preprint arXiv:1803.04610,"While state-of-the-art general object detectors are getting better and better, there are not many systems specifically designed to take advantage of the instance detection problem. For many applications, such as household robotics, a system may need to recognize a few very specific instances at a time. Speed can be critical in these applications, as can the need to recognize previously unseen instances. We introduce a Target Driven Instance Detector(TDID), which modifies existing general object detectors for the instance recognition setting. TDID not only improves performance on instances seen during training, with a fast runtime, but is also able to generalize to detect novel instances.",19
Strangeness based feature selection for part based recognition,"Fayin Li, Jana Kosecka, Harry Wechsler",2006/6/17,Conference 2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06),"Motivated by recent approaches to object recognition, where objects are represented in terms of parts, we propose a new algorithm for selecting discriminative features based on strangeness measure. We will show that k-nearest neighbour strangeness can be used to measure the uncertainty of individual features with respect to the class labels and forms piecewise constant decision boundary. We study its properties and generalization capability by comparing it with optimal decision boundary and boundary obtained by k-nearest-neighbor methods. The proposed feature selection algorithm is tested both in simulation and real experiments, demonstrating that meaningful discriminative local features are selected despite the presence of large numbers of distractors. In the second stage we demonstrate how to integrate the local evidence provided by the selected features in the boosting framework in order to obtain …",19
Learning local rgb-to-cad correspondences for object pose estimation,"Georgios Georgakis, Srikrishna Karanam, Ziyan Wu, Jana Kosecka",2019,Conference Proceedings of the IEEE/CVF International Conference on Computer Vision,"We consider the problem of 3D object pose estimation. While much recent work has focused on the RGB domain, the reliance on accurately annotated images limits generalizability and scalability. On the other hand, the easily available object CAD models are rich sources of data, providing a large number of synthetically rendered images. In this paper, we solve this key problem of existing methods requiring expensive 3D pose annotations by proposing a new method that matches RGB images to CAD models for object pose estimation. Our key innovations compared to existing work include removing the need for either real-world textures for CAD models or explicit 3D pose annotations for RGB images. We achieve this through a series of objectives that learn how to select keypoints and enforce viewpoint and modality invariance across RGB images and CAD model renderings. Our experiments demonstrate that the proposed method can reliably estimate object pose in RGB images and generalize to object instances not seen during training.",18
Semantic image based geolocation given a map,"Arsalan Mousavian, Jana Kosecka",2016/9/1,Journal arXiv preprint arXiv:1609.00278,"The problem visual place recognition is commonly used strategy for localization. Most successful appearance based methods typically rely on a large database of views endowed with local or global image descriptors and strive to retrieve the views of the same location. The quality of the results is often affected by the density of the reference views and the robustness of the image representation with respect to viewpoint variations, clutter and seasonal changes. In this work we present an approach for geo-locating a novel view and determining camera location and orientation using a map and a sparse set of geo-tagged reference views. We propose a novel technique for detection and identification of building facades from geo-tagged reference view using the map and geometry of the building facades. We compute the likelihood of camera location and orientation of the query images using the detected landmark (building) identities from reference views, 2D map of the environment, and geometry of building facades. We evaluate our approach for building identification and geo-localization on a new challenging outdoors urban dataset exhibiting large variations in appearance and viewpoint.",18
Semantic parsing of street scenes from video,"Branislav Micusik, Jana Košecká, Gautam Singh",2012/4,Journal The International Journal of Robotics Research,"Semantic models of the environment can significantly improve navigation and decision making capabilities of autonomous robots or enhance level of human and robot interaction. We present a novel approach for semantic segmentation of street scene images into coherent regions, while simultaneously categorizing each region as one of the predefined categories representing commonly encountered object and background classes. We formulate the segmentation on small blob-based superpixels and exploit a visual vocabulary tree as an intermediate image representation. The main novelty of our approach is the introduction of an explicit model of spatial co-occurrence of visual words associated with superpixels and utilization of appearance, geometry and contextual cues in a probabilistic framework. We demonstrate how individual cues contribute towards global segmentation accuracy and how their combination …",18
A New Inlier Identification Scheme for Robust Estimation Problems.,"Wei Zhang, Jana Kosecka",2006/8,Conference Robotics: Science and Systems,"Common goal of many computer vision and robotics algorithms is to extract geometric information from the sensory data. Due to noisy measurements and errors in matching or segmentation, the available data are often corrupted with outliers. In such instances robust estimation methods are employed for the problem of parametric model estimation. In the presence of a large fraction of outliers sampling based methods are often the preferred choice. Traditionally used RANSAC algorithm however requires a large number of samples, prior knowledge of the outlier ratio and an additional, difficult to obtain, inlier threshold for hypothesis evaluation.",18
"Optimization criteria, sensitivity and robustness of motion and structure estimation","Jana Košecká, Yi Ma, Shankar Sastry",2000,"Conference Vision Algorithms: Theory and Practice: International Workshop on Vision Algorithms Corfu, Greece, September 21–22, 1999 Proceedings","The prevailing efforts to study the standard formulation of motion and structure recovery have been recently focused on issues of sensitivity and robustness of existing techniques. While many cogent observations have been made and verified experimentally, many statements do not hold in general settings and make a comparison of existing techniques difficult. With an ultimate goal of clarifying these issues we study the main aspects of the problem: the choice of objective functions, optimization techniques and the sensitivity and robustness issues in the presence of noise.",18
Rank Deficiency Condition o the Multiple View Matrix or Mixed Point and Line Features,"Yi Ma, Jana Kośseckéa, Kun Huang",2002/1,"Description Geometric relationships governing multiple images of points and lines and associated algorithms have been studied to a large extent separately in multiple view geometry. In this paper we present a universal rank condition on the so-called multiple view matrix Å comprised of arbitrarily combined point and line features across multiple views. The proposed formulation is shown to be equivalent (but superior) to the multilinear (or multifocal) constraints based approach. For the first time, it allows us to carry out global geometric analysis for multiple images, as well as systematically characterize all degenerate configurations, without breaking image sequence into pairwise or triple-wise sets of views. The additional advantage behind this formulation is that it allows to utilize all incidence conditions that govern all features in all images simultaneously for a consistent recovery of motion and structure from multiple views. Simulation results are presented to validate the multiple view matrix based approach.","Geometric relationships governing multiple images of points and lines and associated algorithms have been studied to a large extent separately in multiple view geometry. In this paper we present a universal rank condition on the so-called multiple view matrix Å comprised of arbitrarily combined point and line features across multiple views. The proposed formulation is shown to be equivalent (but superior) to the multilinear (or multifocal) constraints based approach. For the first time, it allows us to carry out global geometric analysis for multiple images, as well as systematically characterize all degenerate configurations, without breaking image sequence into pairwise or triple-wise sets of views. The additional advantage behind this formulation is that it allows to utilize all incidence conditions that govern all features in all images simultaneously for a consistent recovery of motion and structure from multiple views. Simulation results are presented to validate the multiple view matrix based approach.",17
Control of visually guided behaviors,"Jana Košecká, Ruzena Bajcsy, Max L Mintz",1993/1/1,Journal Technical Reports (CIS),"We propose an approach for modeling visually guided behaviors of agents which explore and navigate in unknown and partially known environments. Behaviors are modeled as finite state machines (FSM), where the states of the model correspond to particular continuous control strategies and the transitions between them are caused by events representing qualitative or asynchronous changes in the behavior evolution. In order to prevent conflicts in parallel execution of multiple behaviors we adopt the supervisory control theory of discrete Event System (DES). Modeling the participating processes using the DES framework allows us to capture often complex interactions between components of the system and synthesize the resulting supervisor, guaranteeing the overall controllability of the system at the discrete event level. In the real world agents have multiple options/paths for carrying out their task. Hence there …",17
Label propagation in videos indoors with an incremental non-parametric model update,"J Rituerto, AC Murillo, J Košecka",2011/9/25,Conference 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems,"Semantic interpretation of the environment can significantly improve the capabilities of our autonomous robots. This work is focused on automatic semantic label propagation in video of indoor environments acquired by a mobile robot. Using a small number of training examples, we propose a new approach to recognize and label dominant background regions of interest, such as floor, wall and doors, and separate them from the remaining of foreground/object image categories. Our approach performs the labeling at the level of image superpixels. A simple non-parametric model is initialized from a few hand labeled examples in the first frame, and then it is propagated and updated along the sequence. We demonstrate the promising results obtained with our proposal in five different indoor sequences from different environments. The obtained semantic labeling can be used both for autonomous navigation and to …",16
Learning view and target invariant visual servoing for navigation,"Yimeng Li, Jana Košecka",2020/5/31,Conference 2020 IEEE International Conference on Robotics and Automation (ICRA),"The advances in deep reinforcement learning recently revived interest in data-driven learning based approaches to navigation. In this paper we propose to learn viewpoint invariant and target invariant visual servoing for local mobile robot navigation; given an initial view and the goal view or an image of a target, we train deep convolutional network controller to reach the desired goal. We present a new architecture for this task which rests on the ability of establishing correspondences between the initial and goal view and novel reward structure motivated by the traditional feedback control error. The advantage of the proposed model is that it does not require calibration and depth information and achieves robust visual servoing in a variety of environments and targets without any parameter fine tuning. We present comprehensive evaluation of the approach and comparison with other deep learning architectures as …",15
Matching rgb images to cad models for object pose estimation,"Georgios Georgakis, Srikrishna Karanam, Ziyan Wu, Jana Kosecka",2018,Journal arXiv preprint arXiv:1811.07249,"We propose a novel method for 3D object pose estimation in RGB images, which does not require pose annotations of objects in images in the training stage. We tackle the pose estimation problem by learning how to establish correspondences between RGB images and rendered depth images of CAD models. During training, our approach only requires textureless CAD models and aligned RGB-D frames of a subset of object instances, without explicitly requiring pose annotations for the RGB images. We employ a deep quadruplet convolutional neural network for joint learning of suitable keypoints and their associated descriptors in pairs of rendered depth images which can be matched across modalities with aligned RGB-D views. During testing, keypoints are extracted from a query RGB image and matched to keypoints extracted from rendered depth images, followed by establishing 2D-3D correspondences. The object’s pose is then estimated using the RANSAC and PnP algorithms. We conduct experiments on the recently introduced Pix3D [33] dataset and demonstrate the efficacy of our proposed approach in object pose estimation as well as generalization to object instances not seen during training.",15
Euclidean structure and motion from image sequences,"Yi Ma, Jana Košecká, Sosale Shankara Sastry",1998,"Publisher Electronics Research Laboratory, College of Engineering, University of California",,15
The problem of signal and symbol integration: a study of cooperative mobile autonomous agent behaviors,"Ruzena Bajcsy, Jana Košecká",1995,Conference Mustererkennung 1995: Verstehen akustischer und visueller Informationen,"This paper explores and reasons about the interplay between symbolic and continuous representations. We first provide some historical perspective on the signal and symbol integration as viewed by the Artificial Intelligence (AI), Robotics and Computer Vision communities. The domain of autonomous robotic agents residing in the dynamically changing environments anchors well different aspects of this integration and allows us to look at the problem in its entirety. Models of reasoning, sensing and control actions of such agents determine three different dimensions for discretization of the agent-world behavioral state space. The design and modeling of robotic agents, where these three aspects have to be closely tied together, provide a good experimental platform for addressing the signal-to-symbol-to-signal transformation problem. We present some experimental results from the domain of cooperating …",15
Simultaneous mapping and target driven navigation,"Georgios Georgakis, Yimeng Li, Jana Kosecka",2019/11/18,Journal arXiv preprint arXiv:1911.07980,"This work presents a modular architecture for simultaneous mapping and target driven navigation in indoors environments. The semantic and appearance stored in 2.5D map is distilled from RGB images, semantic segmentation and outputs of object detectors by convolutional neural networks. Given this representation, the mapping module learns to localize the agent and register consecutive observations in the map. The navigation task is then formulated as a problem of learning a policy for reaching semantic targets using current observations and the up-to-date map. We demonstrate that the use of semantic information improves localization accuracy and the ability of storing spatial semantic map aids the target driven navigation policy. The two modules are evaluated separately and jointly on Active Vision Dataset and Matterport3D environments, demonstrating improved performance on both localization and navigation tasks.",13
A mathematical theory of camera self-calibration,"Yi Ma, Jana Košecká, Sosale Shankara Sastry",1998/10,"Publisher Electronics Research Laboratory, College of Engineering, University of California","In this paper, a mathematical theory of camera self-calibration is developed from a differential geometry viewpoint and no projective geometry is assumed. The problem of camera self-calibration is shown to be equivalent to the problem of recovering an unknown (Riemannian) metric of an appropriate space. An intrinsic geometric interpretation is thus revealed for camera\intrinsic"" parameters: the intrinsic parameter space can be characterized as the quotient space SL (3)= SO (3). Complete lists of geometric invariants associated to an uncalibrated camera are given. The (dual) absolute conic is shown to be a special (co) invariant generated by the lists. The self-calibration problem is then studied in both discrete and dierential settings. In the discrete case, the Kruppa equation is derived from a projective geometry free approach. In the dierential case, it is shown that the intrinsic parameter space is reduced to the …",13
Finehand: Learning hand shapes for american sign language recognition,"Panneer Selvam Santhalingam, Parth Pathak, Huzefa Rangwala, Jana Košecká",2020/11/16,Conference 2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020),"American Sign Language recognition is a difficult gesture recognition problem, characterized by fast, highly articulate gestures. These are comprised of arm movements with different hand shapes, facial expression and head movements. Among these components, hand shape is the vital, often the most discriminative part of a gesture. In this work, we present an approach for effective learning of hand shape embeddings, which are discriminative for ASL gestures. For hand shape recognition our method uses a mix of manually labelled hand shapes and high confidence predictions to train deep convolutional neural network (CNN). The sequential gesture component is captured by recursive neural network (RNN) trained on the embeddings learned in the first stage. We will demonstrate that higher quality hand shape models can significantly improve the accuracy of final video gesture classification in challenging …",12
Experiments in building recognition,"Wei Zhang, Jana Kosecka",2004,Journal Technical report CMU-CS-TR-2004,"In this report we study the problem of building recognition. Given a database of building images, we are interested in classifying a novel view of a building by finding the closest match from the database. We examine the efficacy of local scale-invariant features and their associated descriptors as representations of building appearance and use a simple voting scheme in the recognition phase.",12
Efficient computation of vanishing points,"J Kogecka, Wei Zhang",2002/5/11,Conference Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No. 02CH37292),"Man-made environments possess a lot of regularities which simplify otherwise difficult pose estimation and visual reconstruction tasks. The constraints arising front parallel and orthogonal lines and planes can be efficiently exploited at various stages of vision processing pipeline. In this paper we propose an approach for estimation of vanishing points by exploiting the constraints of structured man-made environments, where the majority of lines is aligned with the principal orthogonal directions of the world coordinate frame. We combine efficient image processing techniques used in the line detection and initialization stage with simultaneous grouping and estimation of vanishing directions using expectation maximization (EM) algorithm. Since we assume an uncalibrated camera the estimated vanishing points can be used towards partial camera calibration and estimation of the relative orientation of the camera with …",65
Motion bias and structure distortion induced by calibration errors.,"Marco Zucchelli, Jana Kosecka",2001/9,Conference BMVC,"This article provides an account of sensitivity and robustness of structure and motion recovery with respect to the errors in intrinsic parameters of the camera. We demonstrate both analytically and in simulation, the interplay between measurement and calibration errors and their effect on motion and structure estimates. In particular we show that the calibration errors introduce an additional bias towards the optical axis, which has opposite sign to the bias typically observed by egomotion algorithms. The overall bias causes a distortion of the resulting 3D structure, which we express in a parametric form. The analysis and experiments are carried out in the differential setting for motion and structure estimation from image velocities. While the analytical explanations are derived in the context of linear techniques for motion estimation, we verify our observations experimentally on a variety of optimal and suboptimal motion and structure estimation algorithms. The obtained results illuminate and explain the performance and sensitivity of the differential structure and motion recovery techniques in the presence of calibration errors.",12
Self-supervisory signals for object discovery and detection,"Etienne Pot, Alexander Toshev, Jana Kosecka",2018/6/8,Journal arXiv preprint arXiv:1806.03370,"In robotic applications, we often face the challenge of discovering new objects while having very little or no labelled training data. In this paper we explore the use of self-supervision provided by a robot traversing an environment to learn representations of encountered objects. Knowledge of ego-motion and depth perception enables the agent to effectively associate multiple object proposals, which serve as training data for learning object representations from unlabelled images. We demonstrate the utility of this representation in two ways. First, we can automatically discover objects by performing clustering in the learned embedding space. Each resulting cluster contains examples of one instance seen from various viewpoints and scales. Second, given a small number of labeled images, we can efficiently learn detectors for these labels. In the few-shot regime, these detectors have a substantially higher mAP of 0.22 compared to 0.12 of off-the-shelf standard detectors trained on this limited data. Thus, the proposed self-supervision results in effective environment specific object discovery and detection at no or very small human labeling cost.",10
Active vision dataset benchmark,"Phil Ammirato, Alexander C Berg, Jana Kosecka",2018,Conference Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops,"Several recent efforts in computer vision indicate a trend toward studying and understanding problems in larger scale environments, beyond single images, and focus on connections to tasks in navigation, mobile manipulation, and visual question answering. A common goal of these tasks is the capability of moving in the environment, acquiring novel views during perception and while performing a task. This capability comes easily in synthetic environments, however achieving the same effect with real images is much more laborious. We propose using the existing Active Vision Dataset to form a benchmark for such problems in a real-world settings with real images. The dataset is well suited for evaluating tasks of multiview active recognition, target driven navigation, and target search, and also can be effective for studying the transfer of strategies learned in simulation to real settings.",10
Reinforcement learning for semantic segmentation in indoor scenes,"Md Reza, Jana Kosecka",2016/6/3,Journal arXiv preprint arXiv:1606.01178,"Future advancements in robot autonomy and sophistication of robotics tasks rest on robust, efficient, and task-dependent semantic understanding of the environment. Semantic segmentation is the problem of simultaneous segmentation and categorization of a partition of sensory data. The majority of current approaches tackle this using multi-class segmentation and labeling in a Conditional Random Field (CRF) framework or by generating multiple object hypotheses and combining them sequentially. In practical settings, the subset of semantic labels that are needed depend on the task and particular scene and labelling every single pixel is not always necessary. We pursue these observations in developing a more modular and flexible approach to multi-class parsing of RGBD data based on learning strategies for combining independent binary object-vs-background segmentations in place of the usual monolithic multi-label CRF approach. Parameters for the independent binary segmentation models can be learned very efficiently, and the combination strategy---learned using reinforcement learning---can be set independently and can vary over different tasks and environments. Accuracy is comparable to state-of-art methods on a subset of the NYU-V2 dataset of indoor scenes, while providing additional flexibility and modularity.",10
Object recognition and segmentation in indoor scenes from RGB-D images,"Md Alimoor Reza, Jana Kosecka",2014/7,Journal Robotics Science and Systems (RSS) conference-5th workshop on RGB-D: Advanced Reasoning with Depth Cameras,"We study the problem of automatic recognition and segmentation of objects in indoor RGB-D scenes. We propose to formulate the object recognition and segmentation in RGBD data as a binary object-background segmentation, using an informative set of features and grouping cues for small regular superpixels. The main novelty of the proposed approach is the exploitation of the informative depth channel features which indicate presence of depth boundaries, the use of efficient supervised object specific binary segmentation and effective hard negative mining exploiting the object co-occurrence statistics. The binary segmentation is meaningful in the context of robotics applications, where often only an object of interest needs to be sought. This yields an efficient and flexible method, which can be easily extended to additional object categories. We report the performance of the approach on NYU-V2 indoor dataset and demonstrate improvement in the global and average accuracy compared to the state of the art methods.",10
Vision based lateral control of vehicles: look-ahead and delay issues,Jana Kosecka,1997,"Journal Internal Memo, Department of EECS, University of California Berkeley",,10
Object pose estimation using mid-level visual representations,"Negar Nejatishahidin, Pooya Fayyazsanavi, Jana Košecka",2022/10/23,Conference 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),"This work proposes a novel pose estimation model for object categories that can be effectively transferred to pre-viously unseen environments. The deep convolutional network models (CNN) for pose estimation are typically trained and evaluated on datasets specifically curated for object detection, pose estimation, or 3D reconstruction, which requires large amounts of training data. In this work, we propose a model for pose estimation that can be trained with small amount of data and is built on the top of generic mid-level represen-tations [33] (e.g. surface normal estimation and re-shading). These representations are trained on a large dataset without requiring pose and object annotations. Later on, the predictions are refined with a small CNN neural network that exploits object masks and silhouette retrieval. The presented approach achieves superior performance on the Pix3D dataset [26] and shows nearly 35 …",9
Communication enhanced navigation strategies for teams of mobile agents,"Justin Hayes, Martha McJunkin, Jana Kosecka",2003/10/27,Conference Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003)(Cat. No. 03CH37453),"In multi-agent systems engaged in cooperative activities there is an apparent trade-off between the complexity of the individual agents, their sensing capabilities and communication required for accomplishment of particular tasks. One of the main computationally intensive components which affects the complexity of the overall system is the acquisition and maintenance of the environment model where the agents reside. In this paper, in the context of foraging and coordinated traversal task, we will examine control strategies that in the absence of the global model of the environment can substantially improve the performance of the team using additional sensing and communication capabilities. In one case the coordinated strategy is motivated by an ant trail following behavior while in another case the line of sight information is used to constrain the movement of individual agents guaranteeing shorter total traversal …",9
Label propagation in RGB-D video,"Md Alimoor Reza, Hui Zheng, Georgios Georgakis, Jana Košecká",2017/9/24,Conference 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),"We propose a new method for the propagation of semantic labels in RGB-D video of indoor scenes given a set of ground truth keyframes. Manual labeling of all pixels in every frame of a video sequence is labor intensive and costly, yet required for training and testing of semantic segmentation methods. The availability of video enables propagation of labels between the frames for obtaining a large amounts of annotated pixels. While previous methods commonly used optical flow motion cues for label propagation, we present a novel approach using the camera poses and 3D point clouds for propagating the labels in superpixels computed on the unannotated frames of the sequence. The propagation task is formulated as an energy minimization problem in a Conditional Random Field (CRF). We performed experiments on 8 video sequences from SUN3D dataset [1] and showed superior performance to an optical …",8
Ensemble method for robust motion estimation,"Wei Zhang, Jana Kosecka",2006/6/17,Conference 2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06),"The core of the traditional RANSAC algorithm and its more recent efficient counterparts is the hypothesis evaluation stage, with the focus on finding the best, outlier free hypothesis. Motivated by a non-parametric ensemble techniques, we demonstrate that it proves advantageous to use the entire set of hypotheses generated in the sampling stage. We show that by studying the residual distribution of each data point with respect to the entire set of hypotheses, the problem of inlier/ outlier identification can be formulated as a classification problem. We present extensive simulations of the approach, which in the presence of a large percentage (> 50%) of outliers, provides a repeatable and, an order of magnitude more efficient method compared to the currently existing techniques. Results on widebaseline matching and fundamental matrix estimation are presented.",8
Discrete event modeling of navigation and gaze control,"R Bajscy, J Kosecka, H Christiansen",1995,"Journal International Journal of Computer Vision, Special Issue on Qualitative Vision",,8
Farsight: Long-range depth estimation from outdoor images,"Md Alimoor Reza, Jana Kosecka, Philip David",2018/10/1,Conference 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),"This paper introduces the problem of long-range monocular depth estimation for outdoor urban environments. Range sensors and traditional depth estimation algorithms (both stereo and single view) predict depth for distances of less than 100 meters in outdoor settings and 10 meters in indoor settings. The shortcomings of outdoor single view methods that use learning approaches are, to some extent, due to the lack of long-range ground truth training data, which in turn is due to limitations of range sensors. To circumvent this, we first propose a novel strategy for generating synthetic long-range ground truth depth data. We utilize Google Earth images to reconstruct large-scale 3D models of different cities with proper scale. The acquired repository of 3D models and associated RGB views along with their long-range depth renderings are used as training data for depth prediction. We then train two deep neural …",7
Mosaic construction from a sparse set of views,"Wei Zhang, Jana Kosecka, Fayin Li",2002/6/19,Conference Proceedings. First International Symposium on 3D Data Processing Visualization and Transmission,"This paper describes a flexible approach for mosaic construction from a sparse set of uncalibrated views. The observation, that in architectural environments the majority of lines is aligned with the principal orthogonal directions of the world coordinate frame, is exploited in different stages of the mosaic construction pipeline. In the first stage the vanishing points are automatically detected and used for partial calibration of the camera and estimation of camera's relative orientation with respect to the scene. This single view analysis enables efficient feature matching and alignment of multiple views. In the final mosaic construction stage the internal camera parameters are refined simultaneously using all available views. We point out some practical issues related to the conditioning of this self-calibration technique. While the approach described here can be presented in the context of rotational mosaics, the alignment …",7
Introduction to Multiview Rank Conditions and their Applications: A Review.,"Jana Košecká, Yi Ma",2002,"Source Proceedings of the Tyrrhenian International Workshop on Digital Communications (IWDC 2002), Advanced Methods for Multimedia Signal Processing","Understanding the representations of 3D scenes as encoded in multiple views taken by a camera from different vantage points is central to many tasks in image and video analysis. These tasks range from recovering the camera motion, 3D structure of the scene and detection and characterization of multiple motions in video. We will demonstrate that the natural representations of a 3D scene in 2D images is in terms of the incidence relations among different geometric primitives, which can be concisely characterized by rank conditions of multiview matrices. The proposed rank conditions capture all existing independent multilinear constraints and enable truly global geometric analysis of the multiple views comprised of different geometric features. In addition to the analysis, we present natural factorization based linear algorithms for structure and motion recovery, image transfer and matching across multiple views applicable in both calibrated and uncalibrated setting. We will demonstrate the approach experimentally on a problem of multiframe structure and motion recovery using point and line features and their incidence relations.",7
"Development of binocular stereopsis for vehicle lateral control, longitudinal control and obstacle detection","Jitendra Malik, Jana Kosecka, Camillo J Taylor, Philip McLauchlan",1999/11/1,"Description This nal report describes the application of computer vision techniques to the lateral and longitudinal control of an autonomous highway vehicle. In the part of the project we focused on an analysis of the vehicle's lateral dynamics and the design of an appropriate controller for lateral control and investigated various static feedback strategies where the measurements obtained from vision, namely o set from the centerline and angle between the road tangent and the orientation of the vehicle at some look-ahead distance, are directly used for control. The role of the look-ahead, its relation to the vision processing delay, longitudinal velocity and road geometry was crucial on the design of the control and their experimental evaluation. We carried out a thorough analysis of the e ects of changing various important system parameters like the vehicle velocity, thelookahead range of the vision sensor and the processing delay associated with the perception and control systems. We also present the results of a series of experiments that were designed to provide a systematic comparison of a number of control strategies. The control strategies that were explored include a lead-lag control law, a full- state linear controller and input-output linearizing control law. Each of these control strategies was implemented and tested at highway speeds on our experimental vehicle platform, a Honda Accord LX sedan. For the longitudinal control problem, we investigated the possibility of using stereo vision to provide the range information, in conjunction with a scanning laser radar sensor. The vision based tracking system utilizes a layered architecture wherein the bottom …","This nal report describes the application of computer vision techniques to the lateral and longitudinal control of an autonomous highway vehicle. In the part of the project we focused on an analysis of the vehicle's lateral dynamics and the design of an appropriate controller for lateral control and investigated various static feedback strategies where the measurements obtained from vision, namely o set from the centerline and angle between the road tangent and the orientation of the vehicle at some look-ahead distance, are directly used for control. The role of the look-ahead, its relation to the vision processing delay, longitudinal velocity and road geometry was crucial on the design of the control and their experimental evaluation. We carried out a thorough analysis of the e ects of changing various important system parameters like the vehicle velocity, thelookahead range of the vision sensor and the processing delay associated with the perception and control systems. We also present the results of a series of experiments that were designed to provide a systematic comparison of a number of control strategies. The control strategies that were explored include a lead-lag control law, a full- state linear controller and input-output linearizing control law. Each of these control strategies was implemented and tested at highway speeds on our experimental vehicle platform, a Honda Accord LX sedan. For the longitudinal control problem, we investigated the possibility of using stereo vision to provide the range information, in conjunction with a scanning laser radar sensor. The vision based tracking system utilizes a layered architecture wherein the bottom …",7
Motion estimation in computer vision: optimization on Stiefel manifolds,"Yi Ma, Jana Kosecka, Shankar Sastry",1998/12/18,Conference Proceedings of the 37th IEEE Conference on Decision and Control (Cat. No. 98CH36171),"Motion recovery from image correspondences is typically a problem of optimizing an objective function associated with the epipolar (or Longuet-Higgins) constraint. This objective function is defined on the so called essential manifold. In the paper, the intrinsic Riemannian structure of the essential manifold is thoroughly studied. Based on existing optimization techniques on Riemannian manifolds, in particular on Stiefel manifolds, we propose a Riemannian Newton algorithm to solve the motion recovery problem, making use of the natural geometric structure of the essential manifold. Although only the Newton algorithm is studied in detail, the same ideas also apply to other typical conjugate gradient algorithms. It is shown that the proposed nonlinear algorithms converge very rapidly (with quadratic rate of convergence) as long as the conventional SVD based eight-point linear algorithm has a unique solution. Such …",7
Supervisory control theory for autonomous mobile agents,J Kosecká,1996,"Institution PhD thesis, University of Pennsylvania, GRASP Laboratory",,7
Uncertainty aware proposal segmentation for unknown object detection,"Yimeng Li, Jana Košecká",2022,Conference Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision,"Recent efforts in deploying Deep Neural Networks for object detection in real world applications, such as autonomous driving, assume that all relevant object classes have been observed during training. Quantifying the performance of these models in settings when the test data is not represented in the training set has mostly focused on pixel-level uncertainty estimation techniques of models trained for semantic segmentation. This paper proposes to exploit additional predictions of semantic segmentation models and quantifying its confidences, followed by classification of object hypotheses as known vs. unknown, out of distribution objects. We use object proposals generated by Region Proposal Network (RPN) and adapt distance aware uncertainty estimation of semantic segmentation using Radial Basis Functions Networks (RBFN) for class agnostic object mask prediction. The augmented object proposals are then used to train a classifier for known vs. unknown objects categories. Experimental results demonstrate that the proposed method achieves parallel performance to state of the art methods for unknown object detection and can also be used effectively for reducing object detectors' false positive rate. Our method is well suited for applications where prediction of non-object background categories obtained by semantic segmentation is reliable.",6
Recursive inference for prediction of objects in urban environments,"Cesar Cadena, Jana Košecká",2016,Journal Robotics Research: The 16th International Symposium ISRR,"Future advancements in robotic navigation and mapping rest to a large extent on robust, efficient and more advanced semantic understanding of the surrounding environment. The existing semantic mapping approaches typically consider small number of semantic categories, require complex inference or large number of training examples to achieve desirable performance. In the proposed work we present an efficient approach for predicting locations of generic objects in urban environments by means of semantic segmentation of a video into object and non-object categories. We exploit widely available exemplars of non-object categories (such as road, buildings, vegetation) and use geometric cues which are indicative of the presence of object boundaries to gather the evidence about objects regardless of their category. We formulate the object/non-object semantic segmentation problem in the …",6
Special issue on robot vision,"Jana Košecká, Eric Marchand, Peter Corke",2015/4,Source The International Journal of Robotics Research,"The International Journal of Robotics Research (IJRR) has a long history of publishing the state-of-the-art in the field of robotic vision. This is the fourth special issue devoted to the topic. Previous special issues were published in 2012 (Volume 31, No. 4), 2010 (Volume 29, Nos 2–3) and 2007 (Volume 26, No. 7, jointly with the International Journal of Computer Vision). In a closely related field was the special issue on Visual Servoing published in IJRR, 2003 (Volume 22, Nos 10–11). These issues nicely summarize the highlights and progress of the past 12 years of research devoted to the use of visual perception for robotics. Looking back across these issues we see perennial topics such as calibration; feature detection, description and matching; multi-view geometry; and filtering and prediction. Of course for robotic vision we have also seen many papers with a strong control focus and also a focus on high-speed …",6
Introspective semantic segmentation,"Gautam Singh, Jana Košecká",2014/3/24,Conference IEEE Winter Conference on Applications of Computer Vision,"Traditional approaches for semantic segmentation work in a supervised setting assuming a fixed number of semantic categories and require sufficiently large training sets. The performance of various approaches is often reported in terms of average per pixel class accuracy and global accuracy of the final labeling. When applying the learned models in the practical settings on large amounts of unlabeled data, possibly containing previously unseen categories, it is important to properly quantify their performance by measuring a classifier's introspective capability. We quantify the confidence of the region classifiers in the context of a non-parametric k-nearest neighbor (k-NN) framework for semantic segmentation by using the so called strangeness measure. The proposed measure is evaluated by introducing confidence based image ranking and showing its feasibility on a dataset containing a large number of …",6
Motion bias and structure distortion induced by intrinsic calibration errors,"Marco Zucchelli, Jana Košecká",2008/5/1,Journal Image and Vision Computing,"This article provides an account of sensitivity and robustness of structure and motion recovery with respect to the errors in intrinsic parameters of the camera. We demonstrate both analytically and in simulation, the interplay between measurement and calibration errors and their effect on motion and structure estimates. In particular we show that the calibration errors introduce an additional bias towards the optical axis, which has opposite sign to the bias typically observed by egomotion algorithms. The overall bias causes a distortion of the resulting 3D structure, which we express in a parametric form. The analysis and experiments are carried out in the differential setting for motion and structure estimation from image velocities. While the analytical explanations are derived in the context of linear techniques for motion estimation, we verify our observations experimentally on a variety of optimal and suboptimal motion …",6
Diverse knowledge distillation (dkd): A solution for improving the robustness of ensemble models against adversarial attacks,"Ali Mirzaeian, Jana Kosecka, Houman Homayoun, Tinoosh Mohsenin, Avesta Sasan",2021/4/7,Conference 2021 22nd International Symposium on Quality Electronic Design (ISQED),"This paper proposes an ensemble learning model that is resistant to adversarial attacks. To build resilience, we introduced a training process where each member learns a radically distinct latent space. Member models are added one at a time to the ensemble. Simultaneously, the loss function is regulated by a reverse knowledge distillation, forcing the new member to learn different features and map to a latent space safely distanced from those of existing members. We assessed the security and performance of the proposed solution on image classification tasks using CIFAR10 and MNIST datasets and showed security and performance improvement compared to the state of the art defense methods.",5
An intuitive muscle-computer interface using ultrasound sensing and Markovian state transitions,"Ananya S Dhawan, Jana Košecká, Huzefa Rangwala, Siddhartha Sikdar",2018/4/4,Conference 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018),"In recent work regarding gesture recognition and muscle computer interfaces, ultrasound-based sensing strategies have been demonstrated as a viable alternative to the pervasive surface electromyography (sEMG) modality. However, in order to facilitate switching between available gestures, both sEMG and ultrasound-based strategies have traditionally relied on unintuitive control mechanisms. The most common among these are: requiring the users to return to rest as an intermediary state between motions; mode switching through co-contraction or other ad-hoc user input; and switching based on muscle activations that are functionally unrelated to the desired motion. The unintuitive nature of such control has historically led to increased user frustration, and is often cited a major reason for device abandonment in the prosthetic control setting. In this work, we propose using an approach inspired by Hidden Markov …",5
Semantically aware bag-of-words for localization,"Arsalan Mousavian, Jana Košecka",2015,Journal CVPR Workshops,"The problem of image based localization has a long history both in robotics and computer vision and shares many similarities with image based retrieval problem. Existing techniques use either local features or (semi)-global image signatures in the context of topological mapping or loop closure detection. Difficulties of the location recognition problem are often affected by large appearance and viewpoint variation between the query view and reference dataset and presence of non-discriminative features due to vegetation, sky and road. We demonstrate that the availability of semantic information about the presence of manmade landmark structures such as buildings, can enhance the traditional BoW local features methods. Focusing the matching on man-made structures, helps to discard irrelevant features from the scene that often act as confusers in various voting strategies (eg trees, vegetation and road features are often not discriminative of location).",5
Semantic context for nonparametric scene parsing and scene classification,"Gautam Singh, Jana Košecká",2013,"Journal Scene Understanding Workshop, CVPR",,5
Door detection in images integrating appearance and shape cues,"AC Murillo, J Košecká, JJ Guerrero, C Sagüés",2007,"Journal 2nd From Sensors to Human Spatial Concepts, held together with IROS","Important component of human-robot interaction is the capability to associate semantic concepts to encountered locations and objects. This functionality is essential for visually guided navigation as well as place and object recognition. In this paper we focus on the problem of door detection using visual information only. Doors are frequently encountered in structured man-made environments and function as transitions between different places. We adopt a probabilistic approach to the problem using a model based Bayes inference to detect the door. Different from previous approaches the proposed model captures both the shape and appearance of the door. This is learned from a few training examples, exploiting additional assumptions about structure of indoors environments. After the learning stage, we describe a hypothesis generation process and several approaches to evaluate the probability of each generated hypothesis. The new proposal is tested on numerous examples of indoor environments, showing a good performance as long as enough features are encountered.",5
Reconstruction from two calibrated views,"Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry, Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry",2004,Journal An Invitation to 3-D Vision: From Images to Geometric Models,"In this chapter we begin unveiling the basic geometry that relates images of points to their 3-D position. We start with the simplest case of two calibrated cameras, and describe an algorithm, first proposed by the British psychologist H.C. Longuet-Higgins in 1981, to reconstruct the relative pose (i.e. position and orientation) of the cameras as well as the locations of the points in space from their projection onto the two images.",5
Camera self-calibration: Geometry and Algorithms,"Yi Ma, René Vidal, J Košecká, Shankar Sastry",1999/6/6,Journal Submitted to IEEE transactions on PAMI and also see UC Berkeley Technical Report,"In this paper, a geometric theory of camera self-calibration is developed. The problem of camera self-calibration is shown to be equivalent to the problem of recovering an unknown (Riemannian) metric of an appropriate space. This observation leads to a new account of the necessary and sucient condition for a unique calibration. Based on this understanding, we obtain a new and complete critical motion analysis without introducing a projective space. A complete list of geometric invariants associated to an uncalibrated camera is given. Due to a new characterization of fundamental matrices, the Kruppa equations are re-derived and directly associated to the basic (co) invariants of the uncalibrated camera. We study general questions about the solvability of the Kruppa equations and show that, in some special cases, the Kruppa equations can be renormalized so as to allow for linear self-calibration algorithms. A …",5
Learning diverse latent representations for improving the resilience to adversarial attacks,"Ali Mirzaeian, Mohammad Sabokrou, Mohammad Khalooei, Jana Kosecka, Houman Homayoun, Tinoosh Mohsening, Avesta Sasan",2020,Journal arXiv preprint arXiv:2006.15127,"This paper proposes an ensemble learning model that is resistant to adversarial learning attacks. To build resilience, we proposed a training process where each member learns a radically different latent space. Member models are added one at a time to the ensemble. Each model is trained on data set to improve accuracy, while the loss function is regulated by a reverse knowledge distillation, forcing the new member to learn new features and map to a latent space safely distanced from those of existing members. We have evaluated the reliability and performance of the proposed solution on image classification tasks using CIFAR10 and MNIST datasets and show improved performance compared to the state of the art defense methods",4
RGB-D multi-view object detection with object proposals and shape context,"Georgios Georgakis, Md Alimoor Reza, Jana Košecka",2016/10/9,Conference 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),"We propose a novel approach for multi-view object detection in 3D scenes reconstructed from RGB-D sensor. We utilize shape based representation using local shape context descriptors along with the voting strategy which is supported by unsupervised object proposals generated from 3D point cloud data. Our algorithm starts with a single-view object detection where object proposals generated in 3D space are combined with object specific hypotheses generated by the voting strategy. To tackle the multi-view setting, the data association between multiple views enabled view registration and 3D object proposals. The evidence from multiple views is combined in simple bayesian setting. The approach is evaluated on the Washington RGB-D scenes datasets [1], [2] containing several classes of objects in a table top setting. We evaluated our approach against the other state-of-the-art methods and demonstrated …",4
Recognizing manipulation actions in arts and crafts shows using domain-specific visual and textual cues,"Benjamin Sapp, Rizwan Chaudhry, Xiaodong Yu, Gautam Singh, Ian Perera, Francis Ferraro, Evelyne Tzoukermann, Jana Kosecka, Jan Neumann",2011/11/6,Conference 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops),"We present an approach for automatic annotation of commercial videos from an arts-and-crafts domain with the aid of textual descriptions. The main focus is on recognizing both manipulation actions (e.g. cut, draw, glue) and the tools that are used to perform these actions (e.g. markers, brushes, glue bottle). We demonstrate how multiple visual cues such as motion descriptors, object presence, and hand poses can be combined with the help of contextual priors that are automatically extracted from associated transcripts or online instructions. Using these diverse features and linguistic information we propose several increasingly complex computational models for recognizing elementary manipulation actions and composite activities, as well as their temporal order. The approach is evaluated on a novel dataset of comprised of 27 episodes of PBS Sprout TV, each containing on average 8 manipulation actions.",4
Language models for semantic extraction and filtering in video action recognition,"Evelyne Tzoukermann, Jan Neumann, Jana Kosecka, Cornelia Fermuller, Ian Perera, Frank Ferraro, Ben Sapp, Rizwan Chaudhry, Gautam Singh",2011/8/24,Conference Workshops at the Twenty-Fifth AAAI Conference on Artificial Intelligence,"The paper addresses the following issues:(a) how to represent semantic information from natural language so that a vision model can utilize it?(b) how to extract the salient textual information relevant to vision? For a given domain, we present a new model of semantic extraction that takes into account word relatedness as well as word disambiguation in order to apply to a vision model. We automatically process the text transcripts and perform syntactic analysis to extract dependency relations. We then perform semantic extraction on the output to filter semantic entities related to actions. The resulting data are used to populate a matrix of co-occurrences utilized by the vision processing modules. Results show that explicitly modeling the co-occurrence of actions and tools significantly improved performance.",4
Weakly supervised labeling of dominant image regions in indoor sequences,"AC Murillo, Jana Kosecka, Branislav Micusik, Carlos Sagüés, JJ Guerrero",2008/10,Conference Workshop on Vision in Action: Efficient strategies for cognitive agents in complex environments,"The capability of associating semantic concepts with available sensory data is an important component of environment understanding. In this work we describe an approach for annotation of dominant image regions of uniform appearance, which are typically encountered indoors, such as doors, walls and floors. One of the main challenges behind correct classification of these regions requires handling large changes in the appearance as a function of lighting conditions. Instead of using large amount of training data taken under different illumination conditions, we propose an online updating of the model learned from a small number of training examples in the initial frame. We follow a two stage classification strategy: first we estimate the probabilities of individual regions belonging to each class based on appearance only; in the second stage we use Markov Random Fields (MRF) to exploit spatial layout of the scene and improve classification results. The appearance model learned in the first frame is updated in subsequent frames using the confidences obtained by the two stage classification strategy. We demonstrate our approach on two sequences of indoor environments.",4
An automaton based algebra for specifying robotic agents,"Jana Košecká, Hanêne Ben-Abdallah",2007,"Book Real-Time Systems: Modeling, Design, and Applications",The following sections are included:  Introduction   Related Work   Example   Our Framework  Elementary Processes Composition Operators     Synthesis Example   Conclusion  ,4
Multiple-view geometry for image-based modeling,"Jana Košecká, Yi Ma, Stefano Soatto, René Vidal",2004/8/8,Book ACM SIGGRAPH 2004 Course Notes,"This course presents the state of the art in multiple-view geometry, including methods and algorithms for reconstructing 3-D geometric models of scenes from video or photographs. This course is based on a novel approach to multiple-view geometry that only requires linear algebra, as opposed to more involved projective and algebraic geometry that most current methods employ. This new approach aims to make image-based modeling techniques accessible to a larger audience compared to existing ones. The presentations will be based on a recent Springer-Verlag textbook on 3D vision (coauthored by the course organizers). Matlab code for the algorithms will be made available at the book website.",4
Step-by-step building of a 3-D model from images,"Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry, Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry",2004,Journal An Invitation to 3-D Vision: From Images to Geometric Models,"This chapter serves a dual purpose. For those who have been following the book up to this point, it provides hands-on experience by guiding them through the application of various algorithms on concrete examples.",4
Cooperative Behaviors-Discrete Event Systems based approach.,"Jana Košecká, Ruzena Bajcsy",1993/7/14,"Description In this paper we present modeling, analysis and synthesis of visual behaviors of agents engaged in navigational tasks. We consider situations in which two agents can navigate independently or in cooperation. For the purpose of modeling the behaviors we have adopted a formalism from the Discrete Events Systems (DES) theory, suitable for investigating controltheoretic issues of a system. Our contribution is in: the development of the visual process that enables visual navigation and obstacle avoidance, and the identification of some elementary behaviors needed for navigation and communication and their composition leading to more complex behaviors. We distinguish two kinds of elementary behaviors, one where observations are directly connected with physical actions, and another where observations and actions are either received or transmitted. The use of the DES formalism allows us to synthesize complex behaviors in a systematic fashion and guarantee their controllability.","In this paper we present modeling, analysis and synthesis of visual behaviors of agents engaged in navigational tasks. We consider situations in which two agents can navigate independently or in cooperation. For the purpose of modeling the behaviors we have adopted a formalism from the Discrete Events Systems (DES) theory, suitable for investigating controltheoretic issues of a system. Our contribution is in: the development of the visual process that enables visual navigation and obstacle avoidance, and the identification of some elementary behaviors needed for navigation and communication and their composition leading to more complex behaviors. We distinguish two kinds of elementary behaviors, one where observations are directly connected with physical actions, and another where observations and actions are either received or transmitted. The use of the DES formalism allows us to synthesize complex behaviors in a systematic fashion and guarantee their controllability.",4
Classification of motor intent in transradial amputees using sonomyography and spatio-temporal image analysis,"Harishwaran Hariharan, Nima Aklaghi, Clayton A Baker, Huzefa Rangwala, Jana Kosecka, Siddhartha Sikdar",2016/4/1,Conference Medical imaging 2016: Ultrasonic imaging and tomography,"In spite of major advances in biomechanical design of upper extremity prosthetics, these devices continue to lack intuitive control. Conventional myoelectric control strategies typically utilize electromyography (EMG) signal amplitude sensed from forearm muscles. EMG has limited specificity in resolving deep muscle activity and poor signal-to-noise ratio. We have been investigating alternative control strategies that rely on real-time ultrasound imaging that can overcome many of the limitations of EMG. In this work, we present an ultrasound image sequence classification method that utilizes spatiotemporal features to describe muscle activity and classify motor intent. Ultrasound images of the forearm muscles were obtained from able-bodied subjects and a trans-radial amputee while they attempted different hand movements. A grid-based approach is used to test the feasibility of using spatio-temporal features by …",3
"THE INSTITUTE OF ELECTRICAL AND ELECTRONICS ENGINEERS, INC.","PAOLO DARIO, AYDAN ERKMEN, BRUNO SICILIANO, DAVID E ORIN, RICHARD D VOLZ, PETER B LUH, RICHARD A VOLZ, RUSSELL H TAYLOR, GEORGE A BEKEY, ALESSANDRO DE LUCA, SETH A HUTCHINSON, IAND WALKER, N VISWANADHAM, NANCY M AMATO, JORGE ANGELES, HIROHIKO ARAI, FRANCOIS CHAUMETTE, FAN-TIEN CHENG, STEFANO CHIAVERINI, CHENGBIN CHU, PIERRE E DUPONT, MUDER JENG, JANA KOSEKA, DAVID J KRIEGMAN, YASUO KUNIYOSHI, JOHN LEONARD, ZEXIANG LI, YUNHUI LIU, KEVIN LYNCH, ANTHONY A MACIEJEWSKI, MAJA J MATARIC, CLAUDIO MELCHIORRI, JEAN-PIERRE MERLET, GIUSEPPE ORIOLO, JAMES P OSTROWSKI, LYNNE PARKER, SPYROS A REVELIOTIS, NILANJAN SARKAR",2004,"Description IEEE TRANSACTIONS ON ROBOTICS AND AUTOMATION (ISSN 1042–296X) is published bimonthly by The Institute of Electrical and Electronics Engineers, Inc. Responsibility for the contents rests upon the authors and not upon the IEEE, the Society/Council, or its members. IEEE Corporate Office: 3 Park Avenue, 17th Floor, New York, NY 10016-5997. IEEE Operations Center: 445 Hoes Lane, PO Box 1331, Piscataway, NJ 08855-1331. NJ Telephone:+ 1 732 981 0060. Price/Publication Information: Individual copies: IEEE Members $10.00 (first copy only), nonmembers $20.00 per copy.(Note: Add $4.00 postage and handling charge to any order from $1.00 to $50.00, including prepaid orders.) Member and nonmember subscription prices available upon request. Available in microfiche and microfilm. Copyright and Reprint Permissions: Abstracting is permitted with credit to the source. Libraries are permitted to …","IEEE TRANSACTIONS ON ROBOTICS AND AUTOMATION (ISSN 1042–296X) is published bimonthly by The Institute of Electrical and Electronics Engineers, Inc. Responsibility for the contents rests upon the authors and not upon the IEEE, the Society/Council, or its members. IEEE Corporate Office: 3 Park Avenue, 17th Floor, New York, NY 10016-5997. IEEE Operations Center: 445 Hoes Lane, PO Box 1331, Piscataway, NJ 08855-1331. NJ Telephone:+ 1 732 981 0060. Price/Publication Information: Individual copies: IEEE Members $10.00 (first copy only), nonmembers $20.00 per copy.(Note: Add $4.00 postage and handling charge to any order from $1.00 to $50.00, including prepaid orders.) Member and nonmember subscription prices available upon request. Available in microfiche and microfilm. Copyright and Reprint Permissions: Abstracting is permitted with credit to the source. Libraries are permitted to …",3
Image formation,"Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry, Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry",2004,Journal An Invitation to 3-D Vision: From Images to Geometric Models,"This chapter introduces simple mathematical models of the image formation process. In a broad figurative sense, vision is the inverse problem of image formation: the latter studies how objects give rise to images, while the former attempts to use images to recover a description of objects in space. Therefore, designing vision algorithms requires first developing a suitable model of image formation. Suitable, in this context, does not necessarily mean physically accurate: the level of abstraction and complexity in modeling image formation must trade off physical constraints and mathematical simplicity in order to result in a manageable model (i.e. one that can be inverted with reasonable effort). Physical models of image formation easily exceed the level of complexity necessary and appropriate for this book, and determining the right model for the problem at hand is a form of engineering art.",3
A Lie theoretic approach to structure and motion in computer vision,"Yi Ma, Omid Shakernia, Jana Košecká, Shankar Sastry",1999/7/1,Journal IFAC Proceedings Volumes,"There has been an increasing interest in applying computer vision in robot control such as vision guided navigation, manipulation, and object recognition. A combination of a robot's rigid body motion and a camera's perspective projection has brought us a new geometric subject to study, the so called multiview geometry in computer vision literature. In this paper, we propose a new approach to this subject based on mathematical tools commonly used in robotics such as linear algebra, differential geometry and Lie group theory. Based on the geometric model of a vision system, main results of multiview geometry are outlined, including reconstruction theory of camera motion, scene structure and camera self-calibration. Potential applications of multiview geometry in robot control are also presented.",3
A differential geometric approach to camera self-calibration,"Y Ma, J Kosecka, S Sastry",1999,Journal International Conference on Computer Vision.(ICCV),,3
Control of discrete event systems,Jana Košecká,1992,"Description Discrete Event Systems (DES) are a special type of dynamic systems. The"" state"" of these systems changes only at discrete instants of time and the term"" event"" is used to represent the occurrence of discontinuous changes (at possibly unknown intervals). Different Discrete Event Systems models are currently used for specification, verification, synthesis as well as for analysis and evaluation of different qualitative and quantitative properties of existing physical systems.","Discrete Event Systems (DES) are a special type of dynamic systems. The"" state"" of these systems changes only at discrete instants of time and the term"" event"" is used to represent the occurrence of discontinuous changes (at possibly unknown intervals). Different Discrete Event Systems models are currently used for specification, verification, synthesis as well as for analysis and evaluation of different qualitative and quantitative properties of existing physical systems.",3
Slaw: Scaled loss approximate weighting for efficient multi-task learning,"Michael Crawshaw, Jana Košecká",2021/9/16,Journal arXiv preprint arXiv:2109.08218,"Multi-task learning (MTL) is a subfield of machine learning with important applications, but the multi-objective nature of optimization in MTL leads to difficulties in balancing training between tasks. The best MTL optimization methods require individually computing the gradient of each task's loss function, which impedes scalability to a large number of tasks. In this paper, we propose Scaled Loss Approximate Weighting (SLAW), a method for multi-task optimization that matches the performance of the best existing methods while being much more efficient. SLAW balances learning between tasks by estimating the magnitudes of each task's gradient without performing any extra backward passes. We provide theoretical and empirical justification for SLAW's estimation of gradient magnitudes. Experimental results on non-linear regression, multi-task computer vision, and virtual screening for drug discovery demonstrate that SLAW is significantly more efficient than strong baselines without sacrificing performance and applicable to a diverse range of domains.",2
Generative multi-stream architecture for american sign language recognition,"Dom Huh, Sai Gurrapu, Yuanqi Du, Jay Deorukhkar, Frederick Olson, Huzefa Rangwala, Parth Pathak, Jana Kosecka",2019/10/11,Conference 2019 IEEE MIT Undergraduate Research Technology Conference (URTC),"With advancements in deep model architectures, tasks in computer vision can reach optimal convergence provided proper data preprocessing and model parameter initialization. However, training on datasets with low feature-richness for complex applications limit and detriment optimal convergence below human performance. In past works, researchers have provided external sources of complementary data at the cost of supplementary hardware, which are fed in streams to counteract this limitation and boost performance. We propose a generative multi-stream architecture, eliminating the need for additional hardware with the intent to improve feature richness without risking impracticability. We also introduce the compact spatiotemporal residual block to the standard 3-dimensional convolutional model, C3D. Our rC3D model performs comparatively to the top C3D residual variant architecture, the pseudo-3D …",2
Visual representations for semantic target driven navigation,"Arsalan Mousavian, Alexander Toshev, Marek Fišer, Jana Košecká, Ayzaan Wahid, James Davidson",2019/5/20,Conference 2019 International Conference on Robotics and Automation (ICRA),"What is a good visual representation for navigation? We study this question in the context of semantic visual navigation, which is the problem of a robot finding its way through a previously unseen environment to a target object, e.g. go to the refrigerator. Instead of acquiring a metric semantic map of an environment and using planning for navigation, our approach learns navigation policies on top of representations that capture spatial layout and semantic contextual cues. We propose to use semantic segmentation and detection masks as observations obtained by state-of-the-art computer vision algorithms and use a deep network to learn the navigation policy. The availability of equitable representations in simulated environments enables joint training using real and simulated data and alleviates the need for domain adaptation or domain randomization commonly used to tackle the sim-to-real transfer of the learned …",161
Reconstruction from Two Uncalibrated Views,"Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry, Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry",2004,Journal An Invitation to 3-D Vision: From Images to Geometric Models,"In Chapter 3 we have seen that the projection of a point in space with coordinates X onto the image plane has (homogeneous) coordinates x´ that satisfy the equation (3.19)  where Π0 = [I, 0] ∈ ℝ3x4, and g ∈ SE(3) is the pose of the camera in the (chosen) world reference frame.",2
Rank Conditions of the Multiple View Matrix in Multiple View Geometry,"Yi Ma, Kun Huang, René Vidal, Jana Košecká, Shankar Sastry",2001,"Source Coordinated Science Laboratory Report no. UILU-ENG-01-2215, DC-202","This technical report is a comprehensive collection of four self-contained technical papers which I have jointly written with my PhD student Kun Huang (UIUC ECE), PhD student Rene Vidal (UCB EECS), professor Jana Košecká (GMU CS) and professor Shankar Sastry (UCB EECS). It consists of a coherent treatment of multiple view geometry from a linear algebraic viewpoint. In particular, a newly introduced concept of multiple view matrix and its associated rank deficiency condition have been extensively studied for the  purpose of 2-D to 3-D reconstruction. The proposed framework provides a brand new approach to multiple view geometry, which is independent of previous approaches based on projective geometry, tensor analysis or algebraic geometry, and which has, nonetheless, demonstrated significant theoretical and algorithmic advantages.  The technical report adopts a homogeneous terminology - which makes it slightly different from each original paper. Each chapter corresponds to an original paper and it is still kept rather self-contained in this report. Although we are still in the process of grasping the full implication of the developed theory and algorithms and carrying out more experiments on real images, the report is contrived for the purpose of communicating among researchers who share the same interest in multiple view geometry and would like to try to extend the theory and apply to other applications.",2
New rank deficiency condition for multiple view geometry of line features,"Yi Ma, Kun Huang, Jana Košecká",2001,"Journal Coordinated Science Laboratory Report no. UILU-ENG-01-2209, DC-201","In this paper, a new rank deficiency condition for multiple images of a line is presented.  It is shown that a set of m image lines correspond to a unique 3-D line if and only if an associated (m-1 x 4 matrix Hl is of maximum rank 1.  This condition is shown to be equivalent to all multilinear constraints among image lines, but it tremendously simplifies previously known derivations. Since rank deficiency is a purely linear algebraic condition, it gives rise to a set of natural linear algorithms for line matching, line transfer to a new view and motion estimation from images of multiple lines. These linear algorithms use all available data simultaneously without specifying a particular choice of image triplets.  Hence apart from the initialization, the algorithms allow us to bypass trifocal tensors used for similar purposes.  The theory and algorithms for the line case are developed in exact parallel to that for the point case.  Geometric interpretation of the Hl matrix and the duality between point and line are also clearly revealed through this approach.",2
Cooperative material handling by human and robotic agents: Task description and experiments,"J Adams, R Bajcsy, J Kosecka, V Kumar, R Mandelbaum, M Mintz, R Paul, C Wang, Y Yamamoto, X Yun",1995/8,"Journal Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, Pittsburgh, PA",,2
Control of Discrete Event Systems,Jana Kos̆ecká,1992,"Publisher University of Pennsylvania, School of Engineering and Applied Science, Department of Computer and Information Science",,2
Learning-augmented model-based planning for visual exploration,"Yimeng Li, Arnab Debnath, Gregory Stein, Jana Kosecka",2022/11/15,Journal arXiv preprint arXiv:2211.07898,"We consider the problem of time-limited robotic exploration in previously unseen environments where exploration is limited by a predefined amount of time. We propose a novel exploration approach using learning-augmented model-based planning. We generate a set of subgoals associated with frontiers on the current map and derive a Bellman Equation for exploration with these subgoals. Visual sensing and advances in semantic mapping of indoor scenes are exploited for training a deep convolutional neural network to estimate properties associated with each frontier: the expected unobserved area beyond the frontier and the expected timesteps (discretized actions) required to explore it. The proposed model-based planner is guaranteed to explore the whole scene if time permits. We thoroughly evaluate our approach on a large-scale pseudo-realistic indoor dataset (Matterport3D) with the Habitat simulator. We compare our approach with classical and more recent RL-based exploration methods, demonstrating its clear advantages in several settings.",1
Confidence Estimation in Stem Cell Classification,"Zahra Rajabi, Jana Kosecka, Peter Bajcsy",2015,Journal BioImage Informatics Conference,"We study the problem of supervised classification of stem cell colonies and confidence estimation of the attained classification labels. The problem is investigated in the application context of heterogeneity labels of stem cell colonies observed by using fluorescent microscopy imaging. Given the features of colonies using numerous image statistics, we report the classification results using adaptive k-Nearest Neighbor (NN) algorithm. This algorithm minimizes typical k-NN classification bias by giving more weight to more informative features in predicting class posterior probabilities. We then estimate the confidence of each prediction for unlabeled data using transductive p-value and strangeness metrics. We show that such an introspection can gradually increase the accuracy of learned model, quantify false positives, and guide the resource-limited manual colony annotation process to provide training labels for the less confident unlabeled samples.",1
Semantic Segmentation in Indoor Scenes from Supervised Object-Background Hypotheses,"Md Alimoor Reza, Jana Kosecka",2015,Journal In workshop of Scene Understanding Workshop (SUN) in conjunction with (CVPR),"We present a novel framework for semantic segmentation of RGB-D data by effectively combining multiple binary object-background segmentations. The object-background segmentations are learned in a supervised setting, by training binary Conditional Random Field (CRF) models formulated on an image regions of planar and non-planar surfaces. The object hypotheses are combined in a prioritized manner utilizing shape, confidence cues, and object-scene context. The object-scene co-occurrence statistics are exploited both for hard-negative mining for training the data term in the CRF model as well as evaluation methodology.",1
Semantic segmentation of urban environments into object and background categories,"Cesar C Lerma, Jana Kosecka",2013/1/1,Publisher GEORGE MASON UNIV FAIRFAX VA,"Advancements in robotic navigation, object search and exploration rest to a large extent on robust, efficient and more advanced semantic understanding of the surrounding environment. Since the choice of most relevant semantic information depends on the task, it is desirable to develop approaches which can be adopted for different tasks at hand and which separate the aspects related to surroundings from object entities. In the proposed work we present an efficient approach for detecting generic objects in urban environments from videos acquired by a moving vehicle by means of semantic segmentation. Compared to traditional approaches for semantic labeling, we strive to detect variety of objects, while avoiding the need for large amounts of training data required for recognizing individual object categories and visual variability within and across the categories. In the proposed approach we exploit the features providing evidence about widely available non-object categories such as sky, road, buildings and use informative features which are indicative of the presence of object boundaries to gather the evidence about objects. We formulate the objectnon-object semantic segmentation problem in the Conditional Random Field Framework, where the structure of the graph is induced by the minimum spanning tree computed over 3D reconstruction, yielding an efficient algorithm for an exact inference. We carry out extensive experiments on videos of urban environments acquired by a moving vehicle and compare our approach to existing alternatives.",1
Semantic Segmentation of Urban Environments into Object and Background Categories,"Cesar Cadena, Jana Kosecka",2013/1,"Journal George Mason University, Department of Computer Science, Technical Report GMU-CS-TR-2013-6","Advancements in robotic navigation, object search and exploration rest to a large extent on robust, efficient and more advanced semantic understanding of the surrounding environment. Since the choice of most relevant semantic information depends on the task, it is desirable to develop approaches which can be adopted for different tasks at hand and which separate the aspects related to surroundings from object entities. In the proposed work we present an efficient approach for detecting generic objects in urban environments from videos acquired by a moving vehicle by means of semantic segmentation. Compared to traditional approaches for semantic labeling, we strive to detect variety of objects, while avoiding the need for large amounts of training data required for recognizing individual object categories and visual variability within and across the categories. In the proposed approach we exploit the features providing evidence about widely available non-object categories (such as sky, road, buildings) and use informative features which are indicative of the presence of object boundaries to gather the evidence about objects. We formulate the object/non-object semantic segmentation problem in the Conditional Random Field Framework, where the structure of the graph is induced by the minimum spanning tree computed over 3D reconstruction, yielding an efficient algorithm for an exact inference. We carry out extensive experiments on videos of urban environments acquired by a moving vehicle and compare our approach to existing alternatives.",1
Image based localization,"Jana Kosecka, Wei Zhang",2007,Journal IEEE Trans Rob,"In this paper we present an approach for image based localization in urban environments. Given a database of views of city street views tagged by GPS locations, the system computes the GPS location of a novel query view. We first use a wide-baseline matching technique based on SIFT features to select the closest views in the database. Often due to a large change of viewpoint and presence of repetitive structures, a large percentage of matches (> 50%) are not correct correspondences. The subsequent motion estimation between the query view and the reference view, is then handled by a novel and efficient robust estimation technique capable of dealing with large percentage of outliers. We will discuss in detail sensitivity and robustness of the proposed robust estimation method. The motion estimation stage is also accompanied by a model selection step among the fundamental matrix and the homography …",1
Estimation of Multiple Motions from Two Views,"Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry, Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry",2004,Journal An Invitation to 3-D Vision: From Images to Geometric Models,"So far we have been concerned with single rigid-body motions. Consequently, the algorithms described can be applied to a camera moving within a static scene, or to a single rigid object moving relative to a camera. In practice, this assumption is rather restrictive: interaction with real-world scenes requires negotiating physical space with multiple objects. In this chapter we consider the case of scenes populated with multiple rigid objects moving independently.",1
Camera Self-Calibration: Renormalization and Degeneracy Re× olution for Kruppa'× Equation,"Yi Ma, R Vidal, J Kosecka, S Sastry",2001/4/11,"Description In this paper, we study general questions about the solvability of the Kruppa's equations and show that, in several special cases, the Kruppa's equations can be renormalized and become linear. In particular, for cases when the camera motion is such that its rotation axis is parallel or perpendicular to translation, we can obtain linear algorithms for self-calibration. A further study of these cases not only reveals generic difficulties with degeneracy in conventional self-calibration methods based on the nonlinear Kruppa's equations, but also clarifies some incomplete discussion in the literature about the solutions of the Kruppa's equations. We demonstrate that Kruppa's equations do not provide sufficient constraints on camera calibration and give a complete account of exactly what is missing in Kruppa's equations. In particular, a clear relationship between the Kruppa's equations and chirality is revealed. The results then resolve the discrepancy between the Kruppa's equations and the necessary and sufficient condition for a unique calibration. Simulation results are presented demonstrating the sensitivity and robustness of the proposed linear algorithms.","In this paper, we study general questions about the solvability of the Kruppa's equations and show that, in several special cases, the Kruppa's equations can be renormalized and become linear. In particular, for cases when the camera motion is such that its rotation axis is parallel or perpendicular to translation, we can obtain linear algorithms for self-calibration. A further study of these cases not only reveals generic difficulties with degeneracy in conventional self-calibration methods based on the nonlinear Kruppa's equations, but also clarifies some incomplete discussion in the literature about the solutions of the Kruppa's equations. We demonstrate that Kruppa's equations do not provide sufficient constraints on camera calibration and give a complete account of exactly what is missing in Kruppa's equations. In particular, a clear relationship between the Kruppa's equations and chirality is revealed. The results then resolve the discrepancy between the Kruppa's equations and the necessary and sufficient condition for a unique calibration. Simulation results are presented demonstrating the sensitivity and robustness of the proposed linear algorithms.",1
Comparison of Model-Free and Model-Based Learning-Informed Planning for PointGoal Navigation,"Yimeng Li, Arnab Debnath, Gregory J Stein, Jana Kosecka",2022/12/17,Journal arXiv preprint arXiv:2212.08801,"In recent years several learning approaches to point goal navigation in previously unseen environments have been proposed. They vary in the representations of the environments, problem decomposition, and experimental evaluation. In this work, we compare the state-of-the-art Deep Reinforcement Learning based approaches with Partially Observable Markov Decision Process (POMDP) formulation of the point goal navigation problem. We adapt the (POMDP) sub-goal framework proposed by [1] and modify the component that estimates frontier properties by using partial semantic maps of indoor scenes built from images' semantic segmentation. In addition to the well-known completeness of the model-based approach, we demonstrate that it is robust and efficient in that it leverages informative, learned properties of the frontiers compared to an optimistic frontier-based planner. We also demonstrate its data efficiency compared to the end-to-end deep reinforcement learning approaches. We compare our results against an optimistic planner, ANS and DD-PPO on Matterport3D dataset using the Habitat Simulator. We show comparable, though slightly worse performance than the SOTA DD-PPO approach, yet with far fewer data.",
Self-supervised Pre-training for Semantic Segmentation in an Indoor Scene,"Sulabh Shrestha, Yimeng Li, Jana Kosecka",2022/10/4,Journal arXiv preprint arXiv:2210.01884,"The ability to endow maps of indoor scenes with semantic information is an integral part of robotic agents which perform different tasks such as target driven navigation, object search or object rearrangement. The state-of-the-art methods use Deep Convolutional Neural Networks (DCNNs) for predicting semantic segmentation of an image as useful representation for these tasks. The accuracy of semantic segmentation depends on the availability and the amount of labeled data from the target environment or the ability to bridge the domain gap between test and training environment. We propose RegConsist, a method for self-supervised pre-training of a semantic segmentation model, exploiting the ability of the agent to move and register multiple views in the novel environment. Given the spatial and temporal consistency cues used for pixel level data association, we use a variant of contrastive learning to train a DCNN model for predicting semantic segmentation from RGB views in the target environment. The proposed method outperforms models pre-trained on ImageNet and achieves competitive performance when using models that are trained for exactly the same task but on a different dataset. We also perform various ablation studies to analyze and demonstrate the efficacy of our proposed method.",
Using Unmanned Aerial Systems (UAS) for Assessing and Monitoring Fall Hazard Prevention Systems in High-rise Building Projects,"Yimeng Li, Behzad Esmaeili, Masoud Gheisari, Jana Kosecka, Abbas Rashidi",2022/9/27,Journal arXiv preprint arXiv:2209.13137,"This study develops a framework for unmanned aerial systems (UASs) to monitor fall hazard prevention systems near unprotected edges and openings in high-rise building projects. A three-step machine-learning-based framework was developed and tested to detect guardrail posts from the images captured by UAS. First, a guardrail detector was trained to localize the candidate locations of posts supporting the guardrail. Since images were used in this process collected from an actual job site, several false detections were identified. Therefore, additional constraints were introduced in the following steps to filter out false detections. Second, the research team applied a horizontal line detector to the image to properly detect floors and remove the detections that were not close to the floors. Finally, since the guardrail posts are installed with approximately normal distribution between each post, the space between them was estimated and used to find the most likely distance between the two posts. The research team used various combinations of the developed approaches to monitor guardrail systems in the captured images from a high-rise building project. Comparing the precision and recall metrics indicated that the cascade classifier achieves better performance with floor detection and guardrail spacing estimation. The research outcomes illustrate that the proposed guardrail recognition system can improve the assessment of guardrails and facilitate the safety engineer's task of identifying fall hazards in high-rise building projects.",
Message from the Program Chairs: 3DV 2022,"Angela Dai, Jana Kosecka, Gin Hee Lee, Konrad Schindler",2022/9/12,Conference 2022 International Conference on 3D Vision (3DV),"We welcome you to the 2022 edition of the International Conference on 3D Vision (3DV 2022). The conference took place in hybrid format: after the hiatus due to the global pandemic, we are happy to be able to host an in-person meeting in Prague, Czech Republic, while attendees who could not travel to Prague still also had the possibility to participate virtually.",
Improving Sign Video Modeling Using Graph Neural Network,"Huzefa Rangwala, Jana Košecká",2021/12/15,Conference 2021 IEEE International Conference on Big Data (Big Data),"In this work, we present an ensemble based sign video recognition method. Our proposed method uses different input representations – such as RGB video and body key-points or pose data – to model sign videos in a multi-modal manner. We represent an input sign video in two ways: the dense frame and the sparse frame inputs. The dense input uses 3D Convolutional Neural Network (CNN) on a 64 frame input window and Long Short Term Memory (LSTM) Network on 32 frame pose input. The sparse input picks 5 representative frames from a sign video, and utilizes CNN and Graph Convolutional Network (GCN) based modeling. These representative frames for a video are selected using pose confidences that are obtained from an off-the-shelf pose estimation model. Our experimental results show that, while the dense 3D CNN model achieves best performance as a single classifier, the GCN based sparse …",
American Sign Language Recognition Using an FMCW Wireless Sensor (Student Abstract),"Yuanqi Du, Nguyen Dang, Riley Wilkerson, Parth Pathak, Huzefa Rangwala, Jana Kosecka",2020/4/3,Journal Proceedings of the AAAI Conference on Artificial Intelligence,"In today's digital world, rapid technological advancements continue to lessen the burden of tasks for individuals. Among these tasks is communication across perceived language barriers. Indeed, increased attention has been drawn to American Sign Language (ASL) recognition in recent years. Camera-based and motion detection-based methods have been researched extensively; however, there remains a divide in communication between ASL users and non-users. Therefore, this research team proposes the use of a novel wireless sensor (Frequency-Modulated Continuous-Wave Radar) to help bridge the gap in communication. In short, this device sends out signals that detect the user's body positioning in space. These signals then reflect off the body and back to the sensor, developing thousands of cloud points per second, indicating where the body is positioned in space. These cloud points can then be examined for movement over multiple consecutive time frames using a cell division algorithm, ultimately showing how the body moves through space as it completes a single gesture or sentence. At the end of the project, 95% accuracy was achieved in one-object prediction as well as 80% accuracy on cross-object prediction with 30% other objects' data introduced on 19 commonly used gestures. There are 30 samples for each gesture per person from three persons.",
IEEE Robotics and Automation Society Congratulates Recently Elevated Senior Members,"Taif Al Obaidi, Mohammad Al-Shabi, Sven Behnke, Saroj Biswas, Aymeric Bonnaud, Mike Borowczak, Pinar Boyraz, Adrijan Bozinovski, Ramachandra Budihal, Sindhu Preetham Burugupally, Daniel Casner, Wenceslao Cebuhar, Fernando De la Rosa, Christian Debrunner, Kristen Dorsey, Gyorgy Eigner, Fausto Ferreira, Gabriele Ferri, Daniele Fontanelli, Matthew Garratt, Selvakumar Gopalasamy, Jonathan Hurst, Loay Ismail, Endra Joelianto, Aaron Johnson, Michael Kaess, Sungchul Kang, Jana Kosecka, Swagat Kumar, Rafiq Lakhani, Xuguang Lan, Dimitri Lefebvre, Chaomin Luo, Samer Mohammed, Meeko Mitsuko Oishi",2019/12,Journal IEEE Robotics & Automation Magazine,,
Target Driven Instance Detection,"Jana Košecká, Alexander C Berg",2018/7/17,"Description While state-of-the-art general object detectors are getting better and better, there are not many systems specifically designed to take advantage of the instance detection problem. For many applications, such as household robotics, a system may need to recognize a few very specific instances at a time. Speed can be critical in these applications, as can the need to recognize previously unseen instances. We introduce a Target Driven Instance Detector (TDID), which modifies existing general object detectors for the instance recognition setting. TDID not only improves performance on instances seen during training, with a fast runtime, but is also able to generalize to detect novel instances.","While state-of-the-art general object detectors are getting better and better, there are not many systems specifically designed to take advantage of the instance detection problem. For many applications, such as household robotics, a system may need to recognize a few very specific instances at a time. Speed can be critical in these applications, as can the need to recognize previously unseen instances. We introduce a Target Driven Instance Detector (TDID), which modifies existing general object detectors for the instance recognition setting. TDID not only improves performance on instances seen during training, with a fast runtime, but is also able to generalize to detect novel instances.",
Self-supervisory Signals for Robotic Object Discovery and Detection,"Etienne Pot, Alexander Toshev, Jana Kosecka",2018,"Description In robotic application we often face the challenge of detecting instances of objects for which we have neither trained models or very little labeled data. In this paper we propose to use self-supervisory signals, generated without human supervision by a robot exploring an environment, to learn a representation of the novel object instances present in this environment. We demonstrate the utility of this representation in two ways. First, we can automatically discover objects by performing clustering in this space. Each resulting cluster contains examples of one instance seen from various viewpoints and scales. Second, if given a small number of labeled images, we can learn efficiently detectors for these labels. In the few-shot regime these detectors have a substantially higher mAP of XX compared to off-the-shelf standard detectors trained on this limited data. Thus, the self-supervision results in efficient and performant …","In robotic application we often face the challenge of detecting instances of objects for which we have neither trained models or very little labeled data. In this paper we propose to use self-supervisory signals, generated without human supervision by a robot exploring an environment, to learn a representation of the novel object instances present in this environment. We demonstrate the utility of this representation in two ways. First, we can automatically discover objects by performing clustering in this space. Each resulting cluster contains examples of one instance seen from various viewpoints and scales. Second, if given a small number of labeled images, we can learn efficiently detectors for these labels. In the few-shot regime these detectors have a substantially higher mAP of XX compared to off-the-shelf standard detectors trained on this limited data. Thus, the self-supervision results in efficient and performant …",
Message from the general and program chairs,"L Agapito, T Berg, J Kosecka, L Zelnik-Manor, T Tuytelaars, FF Li, R Bajcsy",2016,Journal Proceedings of the 29th IEEE conference on computer vision and pattern recognition-CVPR 2016,,
Confidence Estimation in Stem Cell Classification,"Zahra Rajabi, Jana Kosecka, Peter Bajcsy",2015,Journal BioImage Informatics Conference,"We study the problem of supervised classification of stem cell colonies and confidence estimation of the attained classification labels. The problem is investigated in the application context of heterogeneity labels of stem cell colonies observed by using fluorescent microscopy imaging. Given the features of colonies using numerous image statistics, we report the classification results using adaptive k-Nearest Neighbor (NN) algorithm. This algorithm minimizes typical k-NN classification bias by giving more weight to more informative features in predicting class posterior probabilities. We then estimate the confidence of each prediction for unlabeled data using transductive p-value and strangeness metrics. We show that such an introspection can gradually increase the accuracy of learned model, quantify false positives, and guide the resource-limited manual colony annotation process to provide training labels for the less confident unlabeled samples.",1
Evaluating the robustness of an ultrasound based sensing strategy for intuitive control of upper extremity prosthetics,"Nima Akhlaghi, Alex Baker, Huzefa J Rangwala, Jana Kosecka, Siddhartha Sikdar",2015/9,Journal The Journal of the Acoustical Society of America,"Current commercially available prostheses based on myoelectric control have limited functionality, leading to many amputees abandoning use. Myoelectric control using surface electrodes has a number of limitations and lacks specificity for deep muscles, presenting a continued need for more robust strategies. We propose a new strategy for sensing muscle activity based on real-time ultrasound imaging. Results from our previous work demonstrate that complex motions could be classified with 92% accuracy in real-time. However, arm and hand repositioning during natural movements tend to alter the geometry of forearm musculature, possibly affecting performance. In this study, we evaluated the robustness of the image-based control strategy in the presence of varied forearm positions on able-bodied subjects. Ultrasound images of the forearm muscles were collected during two different scenarios using a Sonix …",
Novel use of ultrasound imaging to decode activity of forearm muscles for upper extremity prosthetic control,"Nima Akhlaghi, Mohamed Lahlou, Brian J Monroe, Parag V Chitnis, Huzefa Rangwala, Jana Kosecka, Joseph J Pancrazio, Siddhartha Sikdar",2015/4,Journal The Journal of the Acoustical Society of America,"With the recent developments in the electro-mechanical design of upper extremity prosthetics, the need for more advanced control strategies for such prosthetics has increased. Current commercially available prostheses based on myoelectric control have limited functionality, which leads to many amputees abandoning use. Myoelectric control using surface electrodes has a number of limitations, such as low signal to noise ratio and lack of specificity for deep muscles. To address these limitations, and enable more intuitive dexterous control, we propose a new strategy for sensing muscle activity based on real-time ultrasound imaging. Ultrasound imaging of the forearm muscles was performed on six healthy volunteers and a transradial amputee using a Sonix RP system with a 5–14 MHz linear array transducer. Images were analyzed to map muscle activity based on the changes in the ultrasound echogenicity of the …",
"Acquiring Semantically Meaningful Models for Robotic Localization, Mapping and Target Recognition",Jana Kosecka,2014/12/21,Publisher GEORGE MASON UNIV FAIRFAX VA,"The goal of this proposal is to develop novel representations and techniques for localization, mapping and target recognition from videos of indoors and urban outdoors environments. The proposed techniques will facilitate enhanced navigation capabilities by means of visual sensing and enable scalable, long-term navigation and target detection in outdoors and indoors environments. The attained representations will also be applicable towards human-robot interaction, enhancement of human navigational and decision making capabilities and provide compact semantically meaningful summaries of the acquired sensory experience. The proposed representations will be governed by principles of compositionality, facilitate bottom-up learning, enable efficient inference and could be adapted to a task at hand. The main novelty of the approach will be the use both 3D and 2D geometric and photometric cues computed either from video sequence or from novel RBG-D cameras, which provide synchronized video and range data at frame rate. Video poses challenges related to more extreme variations in viewpoint and scale, dramatic changes in lighting and large amount of clutter and occlusions, but also enables computation of 3D structure and motion cues, which can aid segmentation and recognition of object and non-object categories. As a part of this proposal we have developed techniques for semantic labeling of outdoors and indoors environments using photometric and geometric cues from video. The proposed approach is informed by novel features and representations for learning models of objects and non-object categories from video …",
Semantic Context for Nonparametric Scene Parsing and Scene Classification (Author's Manuscript),"Gautam Singh, Jana Kosecka",2013/6/23,Publisher George Mason University Fairfax United States,"Our work focuses on different aspects of image representations as related to a variety of scene understanding tasks. We are interested in simple patch based representations as basic primitives and the role of semantic context as provided by different datasets. In our work, we have pursued a nonparametric approach for semantic parsing which uses small patches and simple gradient, color and location features. We demonstrate the value of relevance of different features channels by learning a locally adaptive distance metric and the effect of feedback in terms of semantic context, which greatly improves the performance, achieving state of the art results on different semantic parsing datasets. Here we report on an additional utility of the proposed representation for scene categorization on a subset of the scene attributes dataset introduced in.",
Detecting simple objects in RGB-D data,"Jana Kosecka, Xing Zhou",2013/1/1,Publisher GEORGE MASON UNIV FAIRFAX VA,"In this paper we present an approach for detection of simple objects in RGB-D data. Object detection in cluttered indoors environments is an important perceptual capability of robotic systems required for object search and pick and deliver tasks. For long term autonomy robots should learn how objects look like and where they appear in an weakly supervised manner. In this work we exploit the depth information to provide evidence about occlusion boundaries and scale of the objects. The depth discontinuities along with image contours computed in the vicinity of the detection window boundary form an em objectness measure, which is used to train an SVM classifier. In the testing stage we exploit the knowledge of the actual size of the object to propose the scale of the detection window significantly pruning the number window candidates to be evaluated. We evaluate our approach for detecting simple objects on NYU RGB-D dataset, illustrate the effectiveness of our approach as well as difficulties with the standard evaluation methodologies.",
Semantic parsing for priming object detection in RGB-D Scenes,"C Cadena Lerma, J Kosecka",2013,Publisher SPME,"The advancements in robot autonomy and capabilities for carrying out more complex tasks in unstructured indoors environments can be greatly enhanced by endowing existing environment models with semantic information. In this paper we describe an approach for semantic parsing of indoors environments into semantic categories of Ground, Structure, Furniture and Props. Instead of striving to categorize all object classes and instances encountered in the environment, this choice of semantic labels separates clearly objects and nonobject categories. We use RGB-D images of indoors environments and formulate the problem of semantic segmentation in the Conditional Random Fields Framework. The appearance and depth information enables us induce the graph structure of the random field, which can be effectively approximated by a tree, and to design robust geometric features, which are informative for separation and characterization of different categories. These two choices notably improve the efficiency and performance of the semantic parsing tasks. We carry out the experiments on a NYU V2 dataset and achieve superior or comparable performance and the fraction of computational cost.",
Segmentation of behavioral spaces for navigation,"Ruzena Bajcsy, Henrik I Christensen, Jana Košecká",2012/12/6,Journal Advances in Computer Vision,"From the very beginning, the forefathers of the Artificial Intelligence field (Mc-Carthy, Minsky, Newel and Simon) have emphasized the importance of the internal representation of an agent, whether artificial or biological. The issue that has been debated for the last 30 years is what the exact form of this representation is. In fact some philosophers, such as Dreyfus [5], even doubt whether this inter-nal representation can ever be formalized. In this paper we shall assume such a formalism exists and do our part to address the long-debated question of what it is or what it should be.",
Dynamic RGB-D Mapping,Michael Paton,2012/1/31,"Description Localization and mapping has been an area of great importance and interest to the robotics and computer vision community. Localization and mapping has traditionally been accomplished with range sensors such as lasers and sonars. Recent improvements in processing power coupled with advancements in image matching and motion estimation has allowed development of vision based localization techniques. Despite much progress, there are disadvantages to both range sensing and vision techniques making localization and mapping that is inexpensive and robust hard to attain. With the advent of RGB-D cameras which provide synchronized range and video data, localization and mapping is now able to exploit both range data as well as RGB features. This thesis exploits the strengths of vision and range sensing localization and mapping strategies and proposes novel algorithms using RGB-D cameras. We show how to combine existing strategies and present through evaluation of the resulting algorithms against a dataset of RGB-D benchmarks. Lastly we demonstrate the proposed algorithm on a challenging indoor dataset and demonstrate improvements where either pure range sensing or vision techniques perform poorly.","Localization and mapping has been an area of great importance and interest to the robotics and computer vision community. Localization and mapping has traditionally been accomplished with range sensors such as lasers and sonars. Recent improvements in processing power coupled with advancements in image matching and motion estimation has allowed development of vision based localization techniques. Despite much progress, there are disadvantages to both range sensing and vision techniques making localization and mapping that is inexpensive and robust hard to attain. With the advent of RGB-D cameras which provide synchronized range and video data, localization and mapping is now able to exploit both range data as well as RGB features. This thesis exploits the strengths of vision and range sensing localization and mapping strategies and proposes novel algorithms using RGB-D cameras. We show how to combine existing strategies and present through evaluation of the resulting algorithms against a dataset of RGB-D benchmarks. Lastly we demonstrate the proposed algorithm on a challenging indoor dataset and demonstrate improvements where either pure range sensing or vision techniques perform poorly.",
Special issue on Virtual Representations and Modeling of Large-scale environments (VRML),"Jan-Michael Frahm, Marc Pollefeys, Frank Dellaert, Jana Kosecka",2012/1/1,Journal Computer Vision and Image Understanding,,
Augmenting Images with Context on Mobile Devices,"Harlan Hile, Radek Grzeszczuk, Ramakrishna Vedantham, Jana Košecka, Alan Liu, Gaetano Borriello",2009,"Description Mobile phones are an attractive platform that include image capture, location sensing, increasing processing power, and network connectivity. This set of features is ideal for navigation and other location-based services. We present a system to provide additional contextual information to images displayed on these mobile devices. By utilizing reconstruction and alignment techniques, we can produce highly accurate georegistered camera poses for existing sets of images. This pose information can then be used to accurately render new details onto the images. In the area of navigation, we use this set of images to automatically generate landmark-based navigation instructions, providing additional context to the images in the form of directional arrows, surrounding map information, and building annotations. Our system also enables live registration of views acquired by a camera phone, allowing users to conceptually point at and click on a building in their environment through the window of their phone’s camera. We demonstrate a light-weight mobile client that can utilize a touch-based user interface for easy access to all of the functionality supported by our context-rich navigation system.This work makes the following contributions to the area of augmenting images with contextual information:• We present an approach to automatically compute camera poses from unstructured datasets and to correct poor GPS readings by leveraging on algorithms for robust image-based matching and 3D structure and motion computation. Our system automatically reconstructs camera pose by using the Photo Tourism system [2]. We extend this reconstruction by …","Mobile phones are an attractive platform that include image capture, location sensing, increasing processing power, and network connectivity. This set of features is ideal for navigation and other location-based services. We present a system to provide additional contextual information to images displayed on these mobile devices. By utilizing reconstruction and alignment techniques, we can produce highly accurate georegistered camera poses for existing sets of images. This pose information can then be used to accurately render new details onto the images. In the area of navigation, we use this set of images to automatically generate landmark-based navigation instructions, providing additional context to the images in the form of directional arrows, surrounding map information, and building annotations. Our system also enables live registration of views acquired by a camera phone, allowing users to conceptually point at and click on a building in their environment through the window of their phone’s camera. We demonstrate a light-weight mobile client that can utilize a touch-based user interface for easy access to all of the functionality supported by our context-rich navigation system.",
From sensors to human spatial concepts,"Zoran Zivkovic, Jana Kosecka",2008/6/1,Journal Robotics and Autonomous Systems,,
estimation problems,"Wei Zhang, Jana Košecká",2007,Journal Robotics: Science and Systems II,"Common goal of many computer vision and robotics only 50% of outliers. Although it is desirable to design estima-algorithms is to extract geometric information from the sensory tors with a solid theoretical footing and provable breakdown data. Due to noisy measurements and errors in matching or points, they often have a small bearing on practical problems, segmentation, the available data are often corrupted with outliers.",
Motion Segmentation and Estimation-Nonparametric Estimation of Multiple Structures with Outliers (WDV 2006),"Wei Zhang, Jana Kosecka",2007,Journal Lecture Notes in Computer Science,,
IEEE Executive Staff,"KAZUO TANIE, TJ TARN, ANTHONY A MACIEJEWSKI, SUKHAN LEE, MAKOTO KANEKO, ALESSANDRO DE LUCA, PETER B LUH, RICHARD A VOLZ, RUSSELL H TAYLOR, GEORGE A BEKEY, HIROHIKO ARAI, SETH A HUTCHINSON, FRANK C PARK, IAND WALKER, JORGE ANGELES, FRANCOIS CHAUMETTE, WAN KYUN CHUNG, PIERRE E DUPONT, DIETER FOX, QIANG HUANG, JANA KOSECKA, KEVIN LYNCH, SHUGEN MA, JEAN-PIERRE MERLET, BRADLEY J NELSON, GIUSEPPE ORIOLO, EVANGELOS PAPADOPOULOS, LYNNE PARKER, RAJNI PATEL, DOMENICO PRATTICHIZZO, RODNEY ROBERTS, PAOLO ROCCO, JOSEPH M SCHIMMELS, GAURAV SUKHATME, DONG SUN, JOCELYNE TROCCAZ",2005,"Description IEEE Transactions on Robotics publication information Page 1 IEEE TRANSACTIONS ON 
ROBOTICS IEEE TRANSACTIONS ON ROBOTICS is published by the IEEE Robotics and 
Automation Society. All members of the IEEE are eligible for membership in the Society and 
will receive this TRANSACTIONS upon payment of the annual Society membership fee of 
$25.00 plus an annual subscription fee of $19.00. For information on joining, write to the lEEE 
Service Center at the address below. Member copies of Transactions/Journals are for 
personal use only. IEEE ROBOTICS AND AUTOMATION SOCIETY URL: http://www.ncsu.edu/IEEE-RAS/ 
(Continued on inside back cover) President KAZUO TANIE Natl. Inst. Advanced Industrial Sci. 
and Technol. Ibaraki 305-8568, Japan tanie.k@aist.go.jp Vice President, Conference Activities 
TJ TARN Systems Sci. & Math. Dept. Washington Univ. St. Louis, MO 63130 USA tarn@…",,
Errata of An Invitation to 3-D Vision,"Yi Ma, Stefano Soatto, Jana Košecká, Shankar Sastry",2004/10/7,"Description Typos are listed below in the order in which they appear in the book. If you find additional typos in the book, please report to “yima@ uiuc. edu,” and your help will be greatly appreciated. We hope that these typos will be corrected in the paper edition.","Typos are listed below in the order in which they appear in the book. If you find additional typos in the book, please report to “yima@ uiuc. edu,” and your help will be greatly appreciated. We hope that these typos will be corrected in the paper edition.",
Image Primitives and Correspondence,"Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry, Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry",2004,Journal An Invitation to 3-D Vision: From Images to Geometric Models,"In previous chapters we have seen how geometric primitives, such as points and lines in space, can be transformed so that one can compute the coordinates of their “image,” i.e. their projection onto the image plane. In practice, however, images are arrays of positive numbers that measure the amount of light incident on a sensor at a particular location (see Sections 3.1 and 3.2, and Appendix 3.A). So, how do we reconcile a geometric image formation model (Section 3.3) with the fact that what we measure with a camera is not points and lines, but light intensity? In other words, how do we go from measurements of light (photometry) to geometry? This is the subject of this chapter: we will show how geometric primitives can be extracted from photometric measurements and matched across different views, so that the rest of the book can concentrate on geometry.",
Geometry and Reconstruction from Symmetry,"Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry, Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry",2004,Journal An Invitation to 3-D Vision: From Images to Geometric Models,"In Chapter 6 we have illustrated how prior assumptions on the scene can be exploited to simplify, or in some case enable, the reconstruction of camera pose and calibration. For instance, the presence of parallel lines and right angles in the scene allows one to upgrade the projective reconstruction to affine and even Euclidean. In this chapter, we generalize these concepts to the case where the scene contains objects that are symmetric. While we will make this notion precise shortly, the intuitive terms of “regular structures,” (deterministic) “patterns,” “tiles,” etc. can all be understood in terms of symmetries (Figure 10.1).",
Extension to General Incidence Relations,"Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry, Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry",2004,Journal An Invitation to 3-D Vision: From Images to Geometric Models,"This chapter1 extends development in the previous chapter to the study of all incidence relations among different geometric primitives in 3-D space and in multiple images (e.g., intersection and coplanarity). We will demonstrate how incidence relations among multiple points, lines, and planes in space can be encoded in multiple images through the same matrix rank conditions. Such a generalization reveals additional instances that give rise to some nontrivial constraints among features in multiple views. This revelation will in turn lead to a more general class of techniques for structure and motion recovery that can use a multitude of geometric features simultaneously and exploit arbitrary incidence relations among them.",
Multiple-View Geometry of Points and Lines,"Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry, Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry",2004,Journal An Invitation to 3-D Vision: From Images to Geometric Models,"In this chapter we study how the framework of epipolar geometry introduced in Part II generalizes to the case of multiple views. As we shall see, this entails studying constraints that corresponding points in different views must satisfy if they are the projection of the same point in space. Not only is this development crucial for understanding the geometry of multiple views but, as in the two-view case, these constraints may be used to derive algorithms for reconstructing camera configuration and, ultimately, the 3-D position of geometric primitives. The search for the m-view analogue of the epipolar constraint has been an active research area for almost two decades. It was realized early on in [Liu and Huang, 1986, Spetsakis and Aloimonos, 1987] that the relationship between three views of the same point or line can be characterized by the trilinear constraints. Consequently, the study of multiple-view geometry …",
Visual Feedback,"Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry, Yi Ma, Stefano Soatto, Jana Košecká, S Shankar Sastry",2004,Journal An Invitation to 3-D Vision: From Images to Geometric Models,"In the introduction to this book we have emphasized the role of vision as a sensor for machines to interact with complex, unknown, dynamic environments, and we have given examples of successful application of vision techniques to autonomous driving and helicopter landing. Interaction with a dynamically changing environment requires action based on the current assessment of the situation, as inferred from sensory data. For instance, driving a car on the freeway requires inferring the position of neighboring vehicles as well as the ego-motion within the lane in order to adjust the position of the steering wheel and act on the throttle or the breaks. In order to be able to implement such a “sensing and action loop,” sensory information must be processed causally and in real time. That is, the situation at time t has to be assessed based on images up to time t. If we were to follow the guidelines and the algorithms …",
EXPLOITING GEOMETRIC AND TOPOLOGIC CONSTRAINTS OF INDOORS ENVIRONMENTS FOR MODEL ACQUISITION,J Kosecka,2002,Journal PROCEEDINGS OF THE ANNUAL ALLERTON CONFERENCE ON COMMUNICATION CONTROL AND COMPUTING,,
Experiments in estimation of independent 3D motion using EM,Jana Kosecka,2001/10/10,Conference Proceedings 30th Applied Imagery Pattern Recognition Workshop (AIPR 2001). Analysis and Understanding of Time Varying Imagery,In this paper we address the problem of multiple 3D rigid body motion estimation from the optical flow. We use the differential epipolar constraint to measure the consistency of the local flow estimates with 3D rigid body motion and employ a probabilistic interpretation of the overall flowfield in terms of mixture models. The estimation of 3D motion parameters as well as the refinement of the initial motion segmentation is carried out using an Expectation-Maximization (EM) algorithm. The algorithm is guaranteed to improve the overall likelihood of the data. The proposed technique is a step towards estimation of 3D motion of independently moving objects in the presence of egomotion.,
Hierarchies of sensing and control in visually guided agents,Jana Košecká,2000,Source SOFSEM 2000: Theory and Practice of Informatics,"The capability of perceiving the environment is crucial for advancing the level of autonomy and sophistication of (semi) autonomous robotic systems and determines the complexity of the tasks robotics agents can achieve. This article reviews some techniques as well as challenges shared by many applications which use visual sensing to guide the action of the robotic agent and require coordination between multiple agents. In order to support hierarchical view of such systems sensing both in the context of low-level control as well as planning and coordination between multiple mobile agents will be considered. Several examples of the design and analysis of these hierarchical hybrid systems will be outlined in the context of Intelligent Highways, namely autonomous driving and coordination between multiple vehicles and mobile robot navigation in indoors man made environments.",
"Development Of Binocular Stereopsis For Vehicle Lateral Control, Longitudinal Control And","Jitendra Malik, Camillo J Taylor, Philip Mclauchlan, Jana Kosecka",1997/11,Journal laser,"This report describes progress in the application of computer vision techniques to the lateral and longitudinal control of an autonomous highway vehicle. A vehicle's lateral dynamics and the design of an appropriate controller for lateral control are investigated. Stereo vision, in conjunction with a scanning laser radar sensor, are studied for providing range information applicable to the longitudinal control problem. The results from the experimental demonstration of this system are reported as part of the National Automated Highway Systems Consortium (NAHSC) Demonstration that took place in San Diego in August 1997.",
Segmentation of behavioral spaces for navigation tasks,"Ruzena Bajcsy, Henrik I Christensen, Jana Košecká",1997,Conference Advances in Computer Vision,"From the very beginning, the forefathers of the Artificial Intelligence field (McCarthy, Minsky, Newel and Simon) have emphasized the importance of the internal representation of an agent, whether artificial or biological. The issue that has been debated for the last 30 years is what the exact form of this representation is. In fact some philosophers, such as Dreyfus [5], even doubt whether this internal representation can ever be formalized. In this paper we shall assume such a formalism exists and do our part to address the long-debated question of what it is or what it should be.",
Cooperative material handling by human and robotic agents: module development and system synthesis,J Kosecka,1995/8/5,Book Proceedings of the International Conference on Intelligent Robots and Systems-Volume 1-Volume 1,"Presents a collaborative effort to design and implement a cooperative material handling system by a small team of human and robotic agents in an unstructured indoor environment. The authors' approach makes fundamental use of the human agents' expertise for aspects of task planning, task monitoring, and error recovery. The authors' system is neither fully autonomous nor fully teleoperated. It is designed to make effective use of the human's abilities within the present state of the art of autonomous systems. The authors' robotic agents refer to systems which are each equipped with at least one sensing modality and which possess some capability for self-orientation and/or mobility. The authors' robotic agents are not required to be homogeneous with respect to either capabilities or function. The authors' research stresses both paradigms and testbed experimentation. Theory issues include the requisite coordination …",
ICRA 2022 Conference Editorial Board,"Marcia O'Malley, Henny Admoni, Kaspar Althoefer, Eduardo Bayro-Corrochano, Sven Behnke, Kostas Bekris, Wan Kyun Chung, Jorge Dias, Tomohiro Kawahara, Jana Kosecka, Cecilia Laschi, Dongjun Lee, Honghai Liu, Nina Mahmoudian, Hyungpil Moon, Taskin Padir, Lorenzo Sabattini, Jim Schmiedeler, Yu Sun, Lydia Tapia, Hesheng Wang","ICRA 2022 Conference Editorial Board Page 1 ICRA 2022 Conference Editorial Board 
Editor-In-Chief Marcia O'Malley Rice University, USA Editors Henny Admoni Carnegie 
Mellon University USA Kaspar Althoefer Queen Mary University of London UK Eduardo 
Bayro-Corrochano CINVESTAV, Campus Guadalajara Mexico Sven Behnke University of 
Bonn Germany Kostas Bekris Rutgers University USA Wan Kyun Chung Robotics 
Laboratory POSTECH Korea Jorge Dias University of Coimbra / Khalifa University Portugal / 
UAE Alexander Dietrich Institute for Robotics and Mechatronics Germany Antonio Franchi 
LAAS - CNRS France Tomohiro Kawahara Kyushu Institute of Technology, Frontier 
Research Academy for Young Researchers Japan Jana Kosecka George Mason University 
USA Cecilia Laschi National University of Singapore Singapore Dongjun Lee Seoul 
National University Korea Honghai Liu Shanghai …","Scholar articles ICRA 2022 Conference Editorial BoardM O'Malley, H Admoni, K Althoefer…",,
Advanced Features,Jana Kosecka,"Compute feature signature: Compute a"" gradient histogram"" of the local image region in a 4x4 pixel region. Do this for 4x4 regions of that size. Orient so that largest gradient points up (possibly multiple solutions). Result: feature vector with 128 values (15 fields, 8 gradients).",Scholar articles Advanced FeaturesJ KoseckaAll 3 versions ,"Compute feature signature: Compute a"" gradient histogram"" of the local image region in a 4x4 pixel region. Do this for 4x4 regions of that size. Orient so that largest gradient points up (possibly multiple solutions). Result: feature vector with 128 values (15 fields, 8 gradients).",
Supplemental Material: Hierarchical Kinematic Human Mesh Recovery,"Georgios Georgakis, Ren Li, Srikrishna Karanam, Terrence Chen, Jana Košecká, Ziyan Wu","–Chains Qc: Each Qc is implemented with a set of fully connected layers. The ψ embedding module Ec comprises two fully connected units (with ReLU activations and dropout in training) with 32-dimensional outputs each. The input dimensionality of Ec varies according to the chain. This is 2070 for the root chain, 2085 for the arm chains, 2082 for the leg chains, and 2076 for the head chain. Finally, each∆ θi is realized with one single fully connected layer with a 3-dimensional output.","Scholar articles Supplemental Material: Hierarchical Kinematic Human Mesh RecoveryG Georgakis, R Li, S Karanam, T Chen, J Košecká…Related articles All 2 versions ","–Chains Qc: Each Qc is implemented with a set of fully connected layers. The ψ embedding module Ec comprises two fully connected units (with ReLU activations and dropout in training) with 32-dimensional outputs each. The input dimensionality of Ec varies according to the chain. This is 2070 for the root chain, 2085 for the arm chains, 2082 for the leg chains, and 2076 for the head chain. Finally, each∆ θi is realized with one single fully connected layer with a 3-dimensional output.",
Personal Statement,Jana Košecká,"BackgroundI joined the faculty of the Computer Science Department in August 1999 as an assistant professor following 3 years as a postdoc at UC Berkeley in the EECS department. My PhD from the University of Pennsylvania in the Department of Computer and Information Science was completed in 1996 and focused on Computer Vision and Robotics. I received tenure and promotion to Associate Professor in 2005. I have taken a maternity leave, a year of sabbatical, and spent a year as a visiting professor at Stanford University and Google, returning in 2009 to George Mason University.",Scholar articles Personal StatementJ KošeckáRelated articles All 2 versions ,Background,
Notice and Invitation,"Ghadi Salem, Monson Hayes, Daniel Barbara, Jana Kosecka, Andrzej Manitius","Action analysis for mice has garnered wide attention in biomedical research. Mice are the most common mammalian animal model used in research laboratories. In recent years, researchers and laboratory support companies have recognized the utility of automated profiling of laboratory mouse activity and behavior in the home-cage. Video-based systems have emerged as a viable solution for non-invasive mouse monitoring. Animal facilities hold large numbers of mice housed inhome-cages' densely stored within ventilated racks. Automated analysis of mice activity in their home-cages can provide a new set of sensitive measures for detecting abnormalities and time-resolved deviation from baseline behavior. Large scale monitoring in animal facilities requires minimal footprint hardware that integrates seamlessly with the ventilated racks. Compactness of hardware imposes use of fisheye lenses positioned in close …","Scholar articles Notice and InvitationG Salem, M Hayes, D Barbara, J Kosecka, A Manitius","Action analysis for mice has garnered wide attention in biomedical research. Mice are the most common mammalian animal model used in research laboratories. In recent years, researchers and laboratory support companies have recognized the utility of automated profiling of laboratory mouse activity and behavior in the home-cage. Video-based systems have emerged as a viable solution for non-invasive mouse monitoring. Animal facilities hold large numbers of mice housed inhome-cages' densely stored within ventilated racks. Automated analysis of mice activity in their home-cages can provide a new set of sensitive measures for detecting abnormalities and time-resolved deviation from baseline behavior. Large scale monitoring in animal facilities requires minimal footprint hardware that integrates seamlessly with the ventilated racks. Compactness of hardware imposes use of fisheye lenses positioned in close …",
Modelling Man Made Environments: Geometric and Appearance Based Techniques,Jana Košecká,Man made indoors and outdoors environments posses a lot of regularities which can be efficiently exploited in a model acquisition by means of visual sensing. We are interested in these modelling issues in the context of navigation and exploration of mobile robots equipped with visual sensing and their interaction with humans. The presented techniques exploit the observations that in man made environments the majority of lines and planes is aligned with the principal directions of the world coordinate frame. This substantially simplifies all stages of the model acquisition pipeline. By combining the observations about environment’s geometry and topology we will demonstrate an interactive technique for acquisition of the metric model of the environment from a sparse set of views. Geometric Models. Recently developed insights into relationships and constraints between multiple views of different geometric features …,Scholar articles Modelling Man Made Environments: Geometric and Appearance Based TechniquesJ Košecká,Man made indoors and outdoors environments posses a lot of regularities which can be efficiently exploited in a model acquisition by means of visual sensing. We are interested in these modelling issues in the context of navigation and exploration of mobile robots equipped with visual sensing and their interaction with humans. The presented techniques exploit the observations that in man made environments the majority of lines and planes is aligned with the principal directions of the world coordinate frame. This substantially simplifies all stages of the model acquisition pipeline. By combining the observations about environment’s geometry and topology we will demonstrate an interactive technique for acquisition of the metric model of the environment from a sparse set of views. Geometric Models. Recently developed insights into relationships and constraints between multiple views of different geometric features …,
"19–22 October 2015 ENS, Lyon, France","Michael Brown, Jana Kosecka, Christian Theobalt","[Title page iii] | IEEE Conference Publication | IEEE Xplore Skip to Main Content [Title page 
iii] Abstract: Presents the title page of the proceedings record. Published in: 2015 
International Conference on 3D Vision Article #: Date of Conference: 19-22 October 2015 
Date Added to IEEE Xplore: 30 November 2015 ISBN Information: Electronic ISBN: 978-1-4673-8332-5 
USB ISBN: 978-1-4673-8331-8 INSPEC Accession Number: Persistent Link: https://xplorestaging.ieee.org/servlet/opac?punumber=7335442 
More » Publisher: IEEE IEEE Account Change Username/Password Update Address 
Purchase Details Payment Options Order History View Purchased Documents Profile 
Information Communications Preferences Profession and Education Technical Interests 
Need Help? US & Canada: +1 800 678 4333 Worldwide: +1 732 981 0060 Contact & 
Support About IEEE Xplore Contact Us Help Accessibility Terms of Use …","Scholar articles 19–22 October 2015 ENS, Lyon, FranceM Brown, J Kosecka, C Theobalt",,
3DV 2015 Foreword,"Jana Kosecka, Michael Brown, Christian Theobalt",Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.,"Scholar articles 3DV 2015 ForewordJ Kosecka, M Brown, C Theobalt",Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.,
IEEE Robotics and Automation Society,"ANTONIO BICCHI, ALLISON OKAMURA, NANCY AMATO, TAMIM ASFOUR, NAK YOUNG CHONG, WAN KYUN CHUNG, HAN DING, FRANCOIS CHAUMETTE, JANA KOSECKA, DONGHEUI LEE, JINGSHAN LI, KEVIN LYNCH, KEN MASAMUNE, JONATHAN ROBERTS, PAOLO ROCCO, CYRILL STACHNISS, YU SUN, NIKOS TSAGARAKIS, JOHN WEN, YOKOSHOJI YASUYOSHI","IEEE Robotics and Automation Letters publication information Page 1 IEEE ROBOTICS AND 
AUTOMATION SOCIETY IEEE ROBOTICS AND AUTOMATION LETTERS is published by the 
IEEE Robotics and Automation Society. All members of the IEEE are eligible for membership 
in the Society and will receive this LETTERS upon payment of the annual Society membership 
fee of $9.00. For information on joining, write to the IEEE Service Center at the address below. 
Member copies of Transactions/Journals are for personal use only. IEEE ROBOTICS AND 
AUTOMATION LETTERS URL: http://www.ieee-ras.org/publications/ra-l EDITORIAL BOARD 
Editor-in-Chief Deputy Editor-in-Chief ANTONIO BICCHI Univ. of Pisa, Pisa, Italy IIT - Istituto 
Italiano di Tecnologia, Genova, Italy antonio.bicchi@unipi.it ALLISON OKAMURA Stanford 
Univ. Stanford, CA, USA aokamura@stanford.edu Senior Editors NANCY AMATO Texas …","Scholar articles IEEE Robotics and Automation SocietyA BICCHI, A OKAMURA, N AMATO, T ASFOUR…All 2 versions ",,
Estimating Surface Orientation Using Bispectral Analysis,"Hany Farid, Jana Košecká","In this paper we propose a direct method for estimating the orientation of a plane from a single view under perspective projection. Assuming that the underlying planar texture has random phase, we show that the nonlinearities introduced by perspective projection lead to higher-order correlations in the frequency domain. We also show that these correlations are proportional to the orientation of the plane. Minimization of these correlations, using tools from polyspectral analysis, yields the orientation of the plane. We show the efficacy of this technique on synthetic and natural images.","Scholar articles Estimating Surface Orientation Using Bispectral AnalysisH Farid, J KošeckáRelated articles All 3 versions ","In this paper we propose a direct method for estimating the orientation of a plane from a single view under perspective projection. Assuming that the underlying planar texture has random phase, we show that the nonlinearities introduced by perspective projection lead to higher-order correlations in the frequency domain. We also show that these correlations are proportional to the orientation of the plane. Minimization of these correlations, using tools from polyspectral analysis, yields the orientation of the plane. We show the efficacy of this technique on synthetic and natural images.",
Geometric and Appearance Based Methods for Visual Model Acquisition and Localization,Jana Košecká,"Visual sensing is essential to robot’s interac-tion with its environment and can dramatically enhance its autonomy, navigation, manipulation and human interaction capabilities. In the context of these tasks, the crucial choice its the one of representation of the environment and objects, in order to enable robust relative positioning, localization and initialization of different visually guided tasks. In this paper I will overview a class of geometric techniques for acquisition of 3D models of objects from multiple views and simultaneous computation of camera/object motion. In the context localization task I will demonstrate that by endowing the geometric features with invariant appearance based signatures simplifies difficult matching stage and enables global localization and successful computation of the relative pose between the query view and the model database.",Scholar articles Geometric and Appearance Based Methods for Visual Model Acquisition and LocalizationJ KošeckáRelated articles All 3 versions ,"Visual sensing is essential to robot’s interac-tion with its environment and can dramatically enhance its autonomy, navigation, manipulation and human interaction capabilities. In the context of these tasks, the crucial choice its the one of representation of the environment and objects, in order to enable robust relative positioning, localization and initialization of different visually guided tasks. In this paper I will overview a class of geometric techniques for acquisition of 3D models of objects from multiple views and simultaneous computation of camera/object motion. In the context localization task I will demonstrate that by endowing the geometric features with invariant appearance based signatures simplifies difficult matching stage and enables global localization and successful computation of the relative pose between the query view and the model database.",
Invited Talk,Jana Kosecka,Provides an abstract for each of the invited presentations and a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.,Scholar articles Invited TalkJ KoseckaAll 2 versions ,Provides an abstract for each of the invited presentations and a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.,
A DISSERTATION PROPOSAL in,JANA KOSECKA,"This work is a presentation of Supervisory Control Theory of Discrete Event Systems for the design of complex robotic systems with multiple sensors and actuators. There has been a long tradition in the Articial Intelligence and Robotics community to incorporate behavior based components into the design of autonomous mobile agents. Even though it has been recognized that the idea of having multiple behaviors activated in parallel is feasible, the design and analysis issues of their interactions has not been well formulated. The choice of Supervisory Control Theory, which deals with the synthesis of reactive programs residing in a given environment, allows us to formulate in a clear and elegant way the basic concepts and models of our problem domain. In our work the elementary perceptual and motion strategies of autonomous mobile agents are modeled in a systematic fashion in terms of nite state machines. In …",Scholar articles A DISSERTATION PROPOSAL inJ KOSECKARelated articles ,"This work is a presentation of Supervisory Control Theory of Discrete Event Systems for the design of complex robotic systems with multiple sensors and actuators. There has been a long tradition in the Articial Intelligence and Robotics community to incorporate behavior based components into the design of autonomous mobile agents. Even though it has been recognized that the idea of having multiple behaviors activated in parallel is feasible, the design and analysis issues of their interactions has not been well formulated. The choice of Supervisory Control Theory, which deals with the synthesis of reactive programs residing in a given environment, allows us to formulate in a clear and elegant way the basic concepts and models of our problem domain. In our work the elementary perceptual and motion strategies of autonomous mobile agents are modeled in a systematic fashion in terms of nite state machines. In …",
Additional Reviewer,"Marc Alexa, Nina Amenta, Helder Araujo, Anup Basu, Peter Belhumeur, Alexander Belyaev, Fausto Bernardini, Jean-Daniel Boissonat, Vladimir Brajovic, Pere Brunet, Daniel Cohen-Or, David Cooper, Guido Cortelazzo, Daniel Cremers, Brian Curless, Kostas Daniilidis, Larry Davis, Leila De Floriani, Tamal Dey, Jan-Olof Eklundh, Davi Geiger, Craig Gotsman, Markus Gross, Concettina Guerra, Martial Hebert, David Jacobs, Avi Kak, Myung-Soo Kim, Leif Kobbelt, Jan Koenderink, Jana Kosecka, Kyros Kutulakos, Frederic Leymarie, Yi Ma, Nadia Magnenat-Thalmann, Roberto Manduchi, Dinesh Manocha, Ioana Martin, Ralph Martin, Takashi Matsuyama, Leonard McMillan, Dimitris Metaxas, Randal Nelson, Ko Nishino, Nikos Paragios, Valerio Pascucci, Yannis Pitas, Marc Pollefeys, Jean Ponce, Martin Rumpf, Holly Rushmeier, Szymon Rusinkiewicz, Dimitris Samaras, Francis Schmitt, Peter Schröder, Hans-Peter Seidel, Yoshihisa Shinagawa, Harry Shum, Claudio Silva, Stefano Soatto, Carlo Tomasi, Luc Van Gool, Luiz Velho, Naokazu Yokoya, Denis Zorin","Program Committee Page 1 xviii Program Committee Marc Alexa Nina Amenta Helder Araujo 
Anup Basu Peter Belhumeur Alexander Belyaev Fausto Bernardini Jean-Daniel Boissonat 
Vladimir Brajovic Pere Brunet Daniel Cohen-Or David Cooper Guido Cortelazzo Daniel 
Cremers Brian Curless Kostas Daniilidis Larry Davis Leila De Floriani Tamal Dey Jan-Olof 
Eklundh Davi Geiger Craig Gotsman Markus Gross Concettina Guerra Martial Hebert David 
Jacobs Avi Kak Myung-Soo Kim Leif Kobbelt Jan Koenderink Jana Kosecka Kyros Kutulakos 
Frederic Leymarie Yi Ma Nadia Magnenat-Thalmann Roberto Manduchi Dinesh Manocha 
Ioana Martin Ralph Martin Takashi Matsuyama Leonard McMillan Dimitris Metaxas Randal 
Nelson Ko Nishino Nikos Paragios Valerio Pascucci Yannis Pitas Marc Pollefeys Jean Ponce 
Martin Rumpf Holly Rushmeier Szymon Rusinkiewicz Dimitris Samaras Francis Schmitt Peter …","Scholar articles Additional ReviewerM Alexa, N Amenta, H Araujo, A Basu, P Belhumeur…",,
"Location Recognition, Global Localization and Relative Positioning Based on Scale-Invariant Keypoints","Jana Košecká, Xiaolong Yang","The localization capability of a mobile robot is central to basic navigation and map building tasks. We describe a probabilistic environment model which facilitates global localization scheme by means of location recognition. In the exploration stage the environment is partitioned into a class of locations, each characterized by a set of scale-invariant keypoints. The descriptors associated with these keypoints can be robustly matched despite changes in contrast, scale and viewpoint. We demonstrate the efficacy of these features for location recognition, where given a new view the most likely location from which this view came is determined. The misclassifications due to dynamic changes in the environment or inherent appearance ambiguities are overcome by exploiting neighborhood relationships captured by a Hidden Markov Model. We report the recognition performance of this approach on an indoor environment consisting of eighteen locations and discuss the suitability of this approach for a more general class of recognition problems. Once the most likely location has been determined we show how to compute the relative pose between the representative view and the current view.","Scholar articles Location Recognition, Global Localization and Relative Positioning Based on Scale-Invariant KeypointsJ Košecká, X YangRelated articles ","The localization capability of a mobile robot is central to basic navigation and map building tasks. We describe a probabilistic environment model which facilitates global localization scheme by means of location recognition. In the exploration stage the environment is partitioned into a class of locations, each characterized by a set of scale-invariant keypoints. The descriptors associated with these keypoints can be robustly matched despite changes in contrast, scale and viewpoint. We demonstrate the efficacy of these features for location recognition, where given a new view the most likely location from which this view came is determined. The misclassifications due to dynamic changes in the environment or inherent appearance ambiguities are overcome by exploiting neighborhood relationships captured by a Hidden Markov Model. We report the recognition performance of this approach on an indoor environment consisting of eighteen locations and discuss the suitability of this approach for a more general class of recognition problems. Once the most likely location has been determined we show how to compute the relative pose between the representative view and the current view.",
SESSION 1: Travel and Wayfinding Part I,"W Zhang, J Košecká, M Uddin, T Shioyama, J Sáez, F Escolano, A Peñalver","Learning in Computer Vision and Pattern Recognition LCVPR 2005 - Table of contents Toggle 
navigation IEEE Computer Society Digital Library Jobs Tech News Resource Center Press Room 
Browse By Date Advertising About Us IEEE IEEE Computer Society IEEE Computer Society Digital 
Library My Subscriptions Magazines Journals Conference Proceedings Institutional Subscriptions 
IEEE IEEE Computer Society More Jobs Tech News Resource Center Press Room Browse 
By Date Advertising About Us Cart All Advanced Search Conference Cover Image Download 
1.Home 2.Proceedings 3.cvprw 2005 Learning in Computer Vision and Pattern Recognition 
LCVPR 2005 - Table of contents 2005, pp. xxiii, DOI Bookmark: 10.1109/CVPR.2005.486 
Keywords Authors Abstract Presents the table of contents of the proceedings. Table 
of Contents ,Workshop on Computer Vision Applications for the Visually Impaired ,…","Scholar articles SESSION 1: Travel and Wayfinding Part IW Zhang, J Košecká, M Uddin, T Shioyama, J Sáez…All 3 versions ",,
Towards Integrated Representations of Objects and Environments,Jana Košecka,"Recent advances in Computer Vision, more specifically visual object recognition demonstrate the successful trend of the use of machine learning techniques for learning representations of objects and object categories and their classification. The main headway has been made with small amount of labelled or weakly labelled data or even completely unsupervised setting. Notable progress has been made in recognizing images in the presence of background clutter. These advances are mostly thanks to development on novel more robust low-level image representations, features and matching strategies and effective classification algorithms.The main focus of the research in robot perception has been in the past predominantly on metric environment representations and robot localization. The environment models were typically described in terms of simple geometric features, such as points, lines and planes. The above mentioned advances in low/mid level image representations developed in vision has been applied successfully in the context of localization and model building and semantic labeling of sensory data of indoors and outdoors environments [1, 2]. Algorithms proposed for detecting and recognizing common household objects are often tested on a small number of objects often in contrived environments. In addition to using solely visual data, strategies for integrating the laser range measurements have also proved invaluable.",Scholar articles Towards Integrated Representations of Objects and EnvironmentsJ KošeckaRelated articles ,"Recent advances in Computer Vision, more specifically visual object recognition demonstrate the successful trend of the use of machine learning techniques for learning representations of objects and object categories and their classification. The main headway has been made with small amount of labelled or weakly labelled data or even completely unsupervised setting. Notable progress has been made in recognizing images in the presence of background clutter. These advances are mostly thanks to development on novel more robust low-level image representations, features and matching strategies and effective classification algorithms.",
Mosaics Construction from a Sparse Set of Views,"J Košecká, W Zhang, F Li","In this paper we describe a flexible approach for constructing mosaics of architectural environments from a sparse set of uncalibrated views. The main contribution this paper is the use of environment constraints in order increase the efficiency and level of automation of the mosaic construction process. The observation that in architectural environments, the majority of lines is aligned with the principal orthogonal directions of the world coordinate frame, will be exploited in different stages of the mosaic construction pipeline. The automated detection of vanishing directions will enable us to partially calibrate the camera an estimate the relative orientation of the camera with respect to the scene from a single view. These initial estimates will facilitate efficient feature matching, computation of displacements between the views as well as alignment of multiple views.","Scholar articles Mosaics Construction from a Sparse Set of ViewsJ Košecká, W Zhang, F LiRelated articles All 6 versions ","In this paper we describe a flexible approach for constructing mosaics of architectural environments from a sparse set of uncalibrated views. The main contribution this paper is the use of environment constraints in order increase the efficiency and level of automation of the mosaic construction process. The observation that in architectural environments, the majority of lines is aligned with the principal orthogonal directions of the world coordinate frame, will be exploited in different stages of the mosaic construction pipeline. The automated detection of vanishing directions will enable us to partially calibrate the camera an estimate the relative orientation of the camera with respect to the scene from a single view. These initial estimates will facilitate efficient feature matching, computation of displacements between the views as well as alignment of multiple views.",
"9th IEEE workshop on omnidirectional vision, camera networks and non-classical cameras (OMNIVIS2009)","Nuno Gonçalves, Ana C Nogueira, A Salazar-Garibay, E Malis, David Dederscheck, Holger Friedrich, Christine Lenhart, Martin Zahn, Rudolf Mester, Michael Nischt, Rahul Swaminathan, Yuzuko Utsumi, Yosio Iwai, Hiroshi Ishiguro, Cyril Joly, Patrick Rives, Akihiko Torii, Michal Havlena, Tomáš Pajdla, AC Murillo, J Kosecka, Shinsaku Hiura, Ankit Mohan, Ramesh Raskar, Feng Yang, Luciano Sbaiz, Edoardo Charbon, Sabine Süsstrunk, Martin Vetterli, Huei-Yung Lin, Min-Liang Wang, Abd E Rahman Shabayek, David Fofi, Olivier Morel","9th IEEE workshop on omnidirectional vision, camera networks and non-classical cameras (OMNIVIS2009) 
Page 1 xxvi 9th IEEE Workshop on Omnidirectional Vision, Camera Networks and Non-classical 
Cameras (OMNIVIS2009) Organizers: Hajime Nagahara, Ryusuke Sagawa, Pascal Vasseur, 
Shree K. Nayar Date: Sunday, October 4, 2009, 9:30-18:00 S1: Omnidirectional Cameras: 
Applications Projection through Quadric Mirrors Made Faster Nuno Gonçalves, Ana C. 
Nogueira Direct Approach to the Self-calibration of Omnidirectional Cameras A. Salazar-Garibay, 
E. Malis Featuring' Optical Rails: View-based Robot Guidance Using Orientation Features 
on the Sphere David Dederscheck, Holger Friedrich, Christine Lenhart, Martin Zahn, Rudolf 
Mester S2: Camera Networks Self-calibration of Asynchronized Camera Networks Michael 
Nischt, Rahul Swaminathan Face Tracking by Using Omnidirectional Sensor …","Scholar articles 9th IEEE workshop on omnidirectional vision, camera networks and non-classical cameras (OMNIVIS2009)N Gonçalves, AC Nogueira, A Salazar-Garibay, E Malis…All 2 versions ",,
PATTERN ANALYSIS AND MACHINE INTELLIGENCE S,"JIRI MATAS, RAMIN ZABIH, ZOUBIN GHAHRAMANI, CHRIS BISHOP, ANDREW BLAKE, DAVID FLEET, ERIC GRIMSON, DAN HUTTENLOCHER, DAVID KRIEGMAN, GERARD MEDIONI, FRANCIS BACH, SERGE BELONGIE, HORST BISCHOF, LEON BOTTOU, OLIVIER CHAPELLE, DANIEL CREMERS, ANTONIO CRIMINISI, FRANK DELLAERT, PEDRO FELZENSZWALB, ANDREW WILLIAM FITZGIBBON, WOLFGANG FÖRSTNER, DAVID FORSYTH, ARTHUR GRETTON, GREGORY HAGER, DAVID HOGG, FREDRIK KAHL, SING BING KANG, JANA KOSECKA, NEIL LAWRENCE, DANIEL D LEE, STAN Z LI, MICHAEL LINDENBAUM, JIE LUO, YI MA, PETROS MARAGOS, MARINA MEILA, KEVIN MURPHY, LAWRENCE O'GORMAN, NIKOS PARAGIOS, VLADIMIR PAVLOVIC, MARCELLO PELILLO, PATRICK PEREZ, SALIL PRABHAKAR, AN RAJAGOPALAN, RAVI RAMAMOORTHI, NALINI RATHA, YOICHI SATO, ERIC SAUND, BERNT SCHIELE, DALE SCHUURMANS, STAN SCLAROFF, KALEEM SIDDIQI, CHARLES V STEWART, CK TANG, ANTONIO TORRALBA, DAPHNA WEINSHALL, JOHN WINN, MING-HSUAN YANG","[Inside front cover] Page 1 The IEEE Computer Society is an association of people with 
professional interest in the field of computers. All members of the IEEE are eligible for 
membership in the Computer Society, as are members of certain professional societies and other 
computer professionals. Computer Society members will receive this Transactions in print and 
online upon payment of the annual Society membership fee ($50 for IEEE members, $99 for all 
others) plus an annual subscription fee of $57. For additional membership and subscription 
information, visit our Web site at http://computer.org/subscribe, send email to help@computer.org, 
or write to IEEE Computer Society, 10662 Los Vaqueros Circle, PO Box 3014, Los Alamitos, 
CA 90720-1314 USA. Individual subscription copies of Transactions are for personal use 
only. IEEE TRANSACTIONS ON PATTERN ANALySIS & MAChINE INTELLIgENCE is …","Scholar articles PATTERN ANALYSIS AND MACHINE INTELLIGENCE SJ MATAS, R ZABIH, Z GHAHRAMANI, C BISHOP…",,
"Euclidean Structure and Motion Recovery: Multi-Frame Constraints, Invariants and Algorithms",Yi Ma Jana Kosecka Shankar Sastry,"In this paper we study the problem of Euclidean structure and motion recoveryfrom m-framesin the case of calibrated cameras. We formulate the problem in the\joint image space"" and rst review the existing multi-linear constraints between m-images of n-points using exterior algebraic notation. It is well known that the projective constraints capture the information about the motion between individual frames and are used to recover it up to a scale. We show how the structural scale information which is lost during the projection process can be recovered using additional Euclidean constraints and propose a linear algorithm for obtaining compatible scales of the joint image matrix entries. The presented theory and algorithms are developed for both the discrete and dierential case. We outline how the approach can be extended for the hybrid case where for particular image locations both optical ow information and point …","Scholar articles Euclidean Structure and Motion Recovery: Multi-Frame Constraints, Invariants and AlgorithmsYMJKS SastryRelated articles ","In this paper we study the problem of Euclidean structure and motion recoveryfrom m-framesin the case of calibrated cameras. We formulate the problem in the\joint image space"" and rst review the existing multi-linear constraints between m-images of n-points using exterior algebraic notation. It is well known that the projective constraints capture the information about the motion between individual frames and are used to recover it up to a scale. We show how the structural scale information which is lost during the projection process can be recovered using additional Euclidean constraints and propose a linear algorithm for obtaining compatible scales of the joint image matrix entries. The presented theory and algorithms are developed for both the discrete and dierential case. We outline how the approach can be extended for the hybrid case where for particular image locations both optical ow information and point …",
A Next Generation Architecture for Air Trac Management?,"C Tomlin, G Pappas, J Kosecka, J Lygeros, S Sastry","In this survey paper, we present some of the issues in designing algorithms for the control of distributed, multi-agent systems. The control of such systems is becoming an increasing issue in many areas owing to technological advances which make it possible to take\legacy"" systems to new levels of functioning and eciency. Of specic interest to us in this paper is advanced air trac management (ATM) to increase the eciency and safety of air travel while accommodating the growing demand for air trac. ATM systems will replace the completely centralized, ground-based air trac control procedures. Within ATM, the concept of free ight allows each aircraft to plan four dimensional trajectories in real time, thus replacing the rigid and inecient discrete airspace structure. These changes are feasible due to technological innovations such as advanced ight management systems with GPS. In this paper, we propose a …","Scholar articles A Next Generation Architecture for Air Trac Management?C Tomlin, G Pappas, J Kosecka, J Lygeros, S SastryRelated articles ","In this survey paper, we present some of the issues in designing algorithms for the control of distributed, multi-agent systems. The control of such systems is becoming an increasing issue in many areas owing to technological advances which make it possible to take\legacy"" systems to new levels of functioning and eciency. Of specic interest to us in this paper is advanced air trac management (ATM) to increase the eciency and safety of air travel while accommodating the growing demand for air trac. ATM systems will replace the completely centralized, ground-based air trac control procedures. Within ATM, the concept of free ight allows each aircraft to plan four dimensional trajectories in real time, thus replacing the rigid and inecient discrete airspace structure. These changes are feasible due to technological innovations such as advanced ight management systems with GPS. In this paper, we propose a …",
Multiview Geometry Revisited: A Differential Geometric Approach,Jana Kosecka Yi Ma Shankar Sastry,"Multiview geometry has been traditionally developed in the framework of projective geometry, which is technically rather algebraic. In this paper, we show an alternative approach which uses notation and concepts from dierential geometry. We review all projective (multilinear) constraints and Euclidean invariants associated with the problem of structure and motion recovery from n views. As a consequence of the study of projective constraints we show geometric dependency of the trilinear and quadrilinear constraints on the bilinear ones and associated conditions on motions which guarantee the dependency. The study of Euclidean invariants leads us to a new derivation and interpretation of Kruppa's equations as a inner product coinvariant of Euclidean transformations in a space with unknown metric. The dierential geometric approach allows us to establish the results in an elegant and concise way and reveal …",Scholar articles Multiview Geometry Revisited: A Differential Geometric ApproachJKYMS SastryRelated articles ,"Multiview geometry has been traditionally developed in the framework of projective geometry, which is technically rather algebraic. In this paper, we show an alternative approach which uses notation and concepts from dierential geometry. We review all projective (multilinear) constraints and Euclidean invariants associated with the problem of structure and motion recovery from n views. As a consequence of the study of projective constraints we show geometric dependency of the trilinear and quadrilinear constraints on the bilinear ones and associated conditions on motions which guarantee the dependency. The study of Euclidean invariants leads us to a new derivation and interpretation of Kruppa's equations as a inner product coinvariant of Euclidean transformations in a space with unknown metric. The dierential geometric approach allows us to establish the results in an elegant and concise way and reveal …",
