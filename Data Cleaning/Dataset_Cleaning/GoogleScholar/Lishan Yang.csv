titles,authors,date,source,descriptions,citations
{G-NET}: Effective {GPU} Sharing in {NFV} Systems,"Kai Zhang, Bingsheng He, Jiayu Hu, Zeke Wang, Bei Hua, Jiayi Meng, Lishan Yang",2018,Conference 15th USENIX Symposium on Networked Systems Design and Implementation (NSDI 18),"Network Function Virtualization (NFV) virtualizes software network functions to offer flexibility in their design, management and deployment. Although GPUs have demonstrated their power in significantly accelerating network functions, they have not been effectively integrated into NFV systems for the following reasons. First, GPUs are severely underutilized in NFV systems with existing GPU virtualization approaches. Second, data isolation in the GPU memory is not guaranteed. Third, building an efficient network function on CPUGPU architectures demands huge development efforts.",60
Fault site pruning for practical reliability analysis of GPGPU applications,"Bin Nie, Lishan Yang, Adwait Jog, Evgenia Smirni",2018/10/20,Conference 2018 51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO),"Graphics Processing Units (GPUs) have rapidly evolved to enable energy-efficient data-parallel computing for a broad range of scientific areas. While GPUs achieve exascale performance at a stringent power budget, they are also susceptible to soft errors, often caused by high-energy particle strikes, that can significantly affect the application output quality. Understanding the resilience of general purpose GPU applications is the purpose of this study. To this end, it is imperative to explore the range of application output by injecting faults at all the potential fault sites. This problem is especially challenging because unlike CPU applications, which are mostly single-threaded, GPGPU applications can contain hundreds to thousands of threads, resulting in a tremendously large fault site space - in the order of billions even for some simple applications. In this paper, we present a systematic way to progressively prune the …",41
Practical resilience analysis of gpgpu applications in the presence of single-and multi-bit faults,"Lishan Yang, Bin Nie, Adwait Jog, Evgenia Smirni",2020/3/13,Journal IEEE Transactions on Computers,"Graphics Processing Units (GPUs) have rapidly evolved to enable energy-efficient data-parallel computing for a broad range of scientific areas. While GPUs achieve exascale performance at a stringent power budget, they are also susceptible to soft errors, often caused by high-energy particle strikes, that can significantly affect the application output quality. Understanding the resilience of general purpose GPU (GPGPU) applications is especially challenging because unlike CPU applications, which are mostly single-threaded, GPGPU applications can contain hundreds to thousands of threads, resulting in a tremendously large fault site space in the order of billions, even for some simple applications and even when considering the occurrence of just a single-bit fault. We present a systematic way to progressively prune the fault site space aiming to dramatically reduce the number of fault injections such that …",20
Enabling software resilience in gpgpu applications via partial thread protection,"Lishan Yang, Bin Nie, Adwait Jog, Evgenia Smirni",2021/5/22,Conference 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE),"Graphics Processing Units (GPUs) are widely used by various applications in a broad variety of fields to accelerate their computation but remain susceptible to transient hardware faults (soft errors) that can easily compromise application output. By taking advantage of a general purpose GPU application hierarchical organization in threads, warps, and cooperative thread arrays, we propose a methodology that identifies the resilience of threads and aims to map threads with the same resilience characteristics to the same warp. This allows to engage partial replication mechanisms for error detection/correction at the warp level. By exploring 12 benchmarks (17 kernels) from 4 benchmark suites, we illustrate that threads can be remapped into reliable or unreliable warps with only 1.63% introduced overhead (on average), and then enable selective protection via replication to those groups of threads that truly need it …",8
Sugar: Speeding up gpgpu application resilience estimation with input sizing,"Lishan Yang, Bin Nie, Adwait Jog, Evgenia Smirni",2021/2/22,Journal Proceedings of the ACM on Measurement and Analysis of Computing Systems,"As Graphics Processing Units (GPUs) are becoming a de facto solution for accelerating a wide range of applications, their reliable operation is becoming increasingly important. One of the major challenges in the domain of GPU reliability is to accurately measure GPGPU application error resilience. This challenge stems from the fact that a typical GPGPU application spawns a huge number of threads and then utilizes a large amount of potentially unreliable compute and memory resources available on the GPUs. As the number of possible fault locations can be in the billions, evaluating every fault and examining its effect on theapplication error resilience is impractical. Application resilience is evaluated via extensive fault injection campaigns based on sampling of an extensive fault site space. Typically, the larger the input of the GPGPU application, the longer the experimental campaign. In this work, we devise a …",8
"The life and death of SSDs and HDDs: Similarities, differences, and prediction models","Riccardo Pinciroli, Lishan Yang, Jacob Alter, Evgenia Smirni",2020/12/22,Journal arXiv preprint arXiv:2012.12373,"Data center downtime typically centers around IT equipment failure. Storage devices are the most frequently failing components in data centers. We present a comparative study of hard disk drives (HDDs) and solid state drives (SSDs) that constitute the typical storage in data centers. Using a six-year field data of 100,000 HDDs of different models from the same manufacturer from the BackBlaze dataset and a six-year field data of 30,000 SSDs of three models from a Google data center, we characterize the workload conditions that lead to failures and illustrate that their root causes differ from common expectation but remain difficult to discern. For the case of HDDs we observe that young and old drives do not present many differences in their failures. Instead, failures may be distinguished by discriminating drives based on the time spent for head positioning. For SSDs, we observe high levels of infant mortality and characterize the differences between infant and non-infant failures. We develop several machine learning failure prediction models that are shown to be surprisingly accurate, achieving high recall and low false positive rates. These models are used beyond simple prediction as they aid us to untangle the complex interaction of workload characteristics that lead to failures and identify failure root causes from monitored symptoms.",5
Strategic safety-critical attacks against an advanced driver assistance system,"Xugui Zhou, Anna Schmedding, Haotian Ren, Lishan Yang, Philip Schowitz, Evgenia Smirni, Homa Alemzadeh",2022/4/14,Journal arXiv preprint arXiv:2204.06768,"A growing number of vehicles are being transformed into semi-autonomous vehicles (Level 2 autonomy) by relying on advanced driver assistance systems (ADAS) to improve the driving experience. However, the increasing complexity and connectivity of ADAS expose the vehicles to safety-critical faults and attacks. This paper investigates the resilience of a widely-used ADAS against safety-critical attacks that target the control system at opportune times during different driving scenarios and cause accidents. Experimental results show that our proposed Context-Aware attacks can achieve an 83.4% success rate in causing hazards, 99.7% of which occur without any warnings. These results highlight the intolerance of ADAS to safety-critical attacks and the importance of timely interventions by human drivers or automated recovery mechanisms to prevent accidents.",4
"Lifespan and Failures of SSDs and HDDs: Similarities, Differences, and Prediction Models","Riccardo Pinciroli, Lishan Yang, Jacob Alter, Evgenia Smirni",2021/11/30,Journal IEEE Transactions on Dependable and Secure Computing,"Data center downtime typically centers around IT equipment failure. Storage devices are the most frequently failing components in data centers. We present a comparative study of hard disk drives (HDDs) and solid state drives (SSDs) that constitute the typical storage in data centers. Using six-year field data of 100,000 HDDs of different models from the same manufacturer from the Backblaze dataset and six-year field data of 30,000 SSDs of three models from a Google data center, we characterize the workload conditions that lead to failures. We illustrate that their root failure causes differ from common expectations and that they remain difficult to discern. For the case of HDDs we observe that young and old drives do not present many differences in their failures. Instead, failures may be distinguished by discriminating drives based on the time spent for head positioning. For SSDs, we observe high levels of infant …",2
GeoSpread: an Epidemic Spread Modeling Tool for COVID-19 Using Mobility Data,"Anna Schmedding, Lishan Yang, SMIRNI EVGENIA",2022/9/7,Book Proceedings of the 2022 ACM Conference on Information Technology for Social Good," We present an individual-centric agent-based model and a flexible tool, GeoSpread, for studying and predicting the spread of viruses and diseases in urban settings. Using COVID-19 data collected by the Korean Center for Disease Control & Prevention (KCDC), we analyze patient and route data of infected people from January 20, 2020, to May 31, 2020, and discover how infection clusters develop as a function of time. This analysis offers a statistical characterization of population mobility and is used to parameterize GeoSpread to capture the spread of the disease. We validate simulation predictions from GeoSpread with ground truth and we evaluate different what-if counter-measure scenarios to illustrate the usefulness and flexibility of the tool for epidemic modeling.",1
Characterizing the COVID-19 Transmission in South Korea Using the KCDC Patient Data,"Anna Schmedding, Lishan Yang, Riccardo Pinciroli, Evgenia Smirni",2020/12/24,Journal arXiv preprint arXiv:2012.13296,"As the COVID-19 outbreak evolves around the world, the World Health Organization (WHO) and its Member States have been heavily relying on staying at home and lock down measures to control the spread of the virus. In the last months, various signs showed that the COVID-19 curve was flattening, but even the partial lifting of some containment measures (e.g., school closures and telecommuting) appear to favor a second wave of the disease. The accurate evaluation of possible countermeasures and their well-timed revocation are therefore crucial to avoid future waves or reduce their duration. In this paper, we analyze patient and route data of infected patients from January 20, 2020, to May 31, 2020, collected by the Korean Center for Disease Control & Prevention (KCDC). This data analysis helps us to characterize patient mobility patterns and then use this characterization to parameterize simulations to evaluate different what-if scenarios. Although this is not a definitive model of how COVID-19 spreads in a population, its usefulness and flexibility are illustrated using real-world data for exploring virus spread under a variety of circumstances.",
Simulating COVID-19 containment measures using the South Korean patient data,"Lishan Yang, Anna Schmedding, Riccardo Pinciroli, Evgenia Smirni",2020/11/16,Book Proceedings of the 18th Conference on Embedded Networked Sensor Systems,"As the COVID-19 outbreak evolves around the world, the World Health Organization (WHO) and its Member States have been heavily relying on staying at home and lock down measures to control the spread of the virus. In last months, various signs showed that the COVID-19 curve was flattening, but the premature lifting of some containment measures (e.g., school closures and telecommuting) are favouring a second wave of the disease. The accurate evaluation of possible countermeasures and their well-timed revocation are therefore crucial to avoid future waves or reduce their duration. In this paper, we analyze patient and route data collected by the Korea Centers for Disease Control & Prevention (KCDC). We extract information from real-world data sets and use them to parameterize simulations and evaluate different what-if scenarios.",
Evaluating Scalability and Performance of a Security Management Solution in Large Virtualized Environments,"Lishan Yang, Ludmila Cherkasova, Rajeev Badgujar, Jack Blancaflor, Rahul Konde, Jason Mills, Evgenia Smirni",2018/3/30,Book Proceedings of the 2018 ACM/SPEC International Conference on Performance Engineering,"Virtualized infrastructure is a key capability of modern enterprise data centers and cloud computing, enabling a more agile and dynamic IT infrastructure with fast IT provisioning, simplified, automated management, and flexible resource allocation to handle a broad set of workloads. However, at the same time, virtualization introduces new challenges, since securing virtual servers is more difficult than physical machines. HyTrust Inc. has developed an innovative security solution, called HyTrust Cloud Control (HTCC), to mitigate risks associated with virtualization and cloud technologies. HTCC is a virtual appliance deployed as a transparent proxy in front of a VMware-based virtualized environment. Since HTCC serves as a gateway to a customer virtualized environment, it is important to carefully assess its performance and scalability as well as provide its accurate resource sizing. In this work, we introduce a novel …",
"Evaluating Scalability and Performance of a Security Management Solution in Large Virtualized Environments Lishan Yang, Ludmila Cherkasova 2, Rajeev Badgujar 2, Jack Blancaflor …",Lishan Yang,2018/2/12,"Description Virtualized infrastructure is a key capability of modern enterprise data centers and cloud computing, enabling a more agile and dynamic IT infrastructure with fast IT provisioning, simplified, automated management, and flexible resource allocation to handle a broad set of workloads. However, at the same time, virtualization introduces new challenges, since securing virtual servers is more difficult than physical machines. HyTrust Inc. has developed an innovative security solution, called HyTrust Cloud Control (HTCC), to mitigate risks associated with virtualization and cloud technologies. HTCC is a virtual appliance deployed as a transparent proxy in front of a VMware-based virtualized environment. In essence, any action issued by a privileged user (through any of VMware management tools) is proxied, evaluated, logged, and then forwarded to vCenter (if approved). Since HTCC serves as a gateway to a customer …","Virtualized infrastructure is a key capability of modern enterprise data centers and cloud computing, enabling a more agile and dynamic IT infrastructure with fast IT provisioning, simplified, automated management, and flexible resource allocation to handle a broad set of workloads. However, at the same time, virtualization introduces new challenges, since securing virtual servers is more difficult than physical machines. HyTrust Inc. has developed an innovative security solution, called HyTrust Cloud Control (HTCC), to mitigate risks associated with virtualization and cloud technologies. HTCC is a virtual appliance deployed as a transparent proxy in front of a VMware-based virtualized environment. In essence, any action issued by a privileged user (through any of VMware management tools) is proxied, evaluated, logged, and then forwarded to vCenter (if approved). Since HTCC serves as a gateway to a customer …",
Typhoon: Enabling GPGPU Application Resilience Estimation with Different Input Types,Lishan Yang,"Graphics Processing Units (GPUs) are embraced in various domains because of their massive parallelism to process large amounts of data. Reliability concerns are raised as critical applications such as self-driving cars are deployed on GPUs. While different techniques are proposed to measure the resilience of a GPGPU application on one input, the reliability assessment has to be repeated for every different input. In this paper, we propose a methodology, Typhoon, which uses the norm of the input matrix to project application resilience. We observe an approximately monotonic trend between resilience and the norm of the input matrix. By sampling several selected input, the trend is captured and used to estimate the resilience of any new input.",Scholar articles Typhoon: Enabling GPGPU Application Resilience Estimation with Different Input TypesL YangRelated articles ,"Graphics Processing Units (GPUs) are embraced in various domains because of their massive parallelism to process large amounts of data. Reliability concerns are raised as critical applications such as self-driving cars are deployed on GPUs. While different techniques are proposed to measure the resilience of a GPGPU application on one input, the reliability assessment has to be repeated for every different input. In this paper, we propose a methodology, Typhoon, which uses the norm of the input matrix to project application resilience. We observe an approximately monotonic trend between resilience and the norm of the input matrix. By sampling several selected input, the trend is captured and used to estimate the resilience of any new input.",
Epidemic Spread Modeling for COVID-19 Using Mobility Data,"Anna Schmedding, Lishan Yang, Riccardo Pinciroli, Evgenia Smirni","We present an individual-centric model for COVID-19 spread in an urban setting. We first analyze patient and route data of infected patients from January 20, 2020, to May 31, 2020, collected by the Korean Center for Disease Control & Prevention (KCDC) and discover how infection clusters develop as a function of time. This analysis offers a statistical characterization of mobility habits and patterns of individuals at the beginning of the pandemic. While the KCDC data offer a wealth of information, they are also by their nature limited. To compensate, we use detailed mobility data from Berlin, Germany after observing that mobility of individuals is surprisingly similar in Berlin and Seoul. Using information from the Berlin mobility data, we cross-fertilize the Seoul data set and use it to parameterize an agent-based simulation that models the spread of the disease in an urban environment. We then validate the simulation predictions with ground truth infection spread in Seoul.","Scholar articles Epidemic Spread Modeling for COVID-19 Using Mobility DataA Schmedding, L Yang, R Pinciroli, E SmirniRelated articles ","We present an individual-centric model for COVID-19 spread in an urban setting. We first analyze patient and route data of infected patients from January 20, 2020, to May 31, 2020, collected by the Korean Center for Disease Control & Prevention (KCDC) and discover how infection clusters develop as a function of time. This analysis offers a statistical characterization of mobility habits and patterns of individuals at the beginning of the pandemic. While the KCDC data offer a wealth of information, they are also by their nature limited. To compensate, we use detailed mobility data from Berlin, Germany after observing that mobility of individuals is surprisingly similar in Berlin and Seoul. Using information from the Berlin mobility data, we cross-fertilize the Seoul data set and use it to parameterize an agent-based simulation that models the spread of the disease in an urban environment. We then validate the simulation predictions with ground truth infection spread in Seoul.",
